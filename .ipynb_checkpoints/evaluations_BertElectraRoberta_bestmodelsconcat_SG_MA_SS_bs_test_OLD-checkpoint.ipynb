{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b0ad47d-aef9-4d79-ac41-de890e0748ea",
   "metadata": {
    "id": "6b0ad47d-aef9-4d79-ac41-de890e0748ea"
   },
   "source": [
    "### All code below uses concatenated sentence pairs in the Substitute Generation step in order to generate similar substitutes (as opposed to generation of fitting substitutes only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f41c8337-c877-47d0-9b9d-2464ac9f76a6",
   "metadata": {
    "executionInfo": {
     "elapsed": 13869,
     "status": "ok",
     "timestamp": 1684240528436,
     "user": {
      "displayName": "Irma Tigchelaar",
      "userId": "16898548430591872778"
     },
     "user_tz": -120
    },
    "id": "f41c8337-c877-47d0-9b9d-2464ac9f76a6"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# read the tsv file\n",
    "filename = './data/test/tsar2022_en_test_none_no_noise.tsv'\n",
    "data = pd.read_csv(filename, sep='\\t', header=None, names=[\"sentence\", \"complex_word\"])\n",
    "\n",
    "# create an empty dataframe to store the substitutes for evaluation\n",
    "substitutes_df = pd.DataFrame(columns=[\"sentence\", \"complex_word\"] + [f\"substitute_{i+1}\" for i in range(10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c064223-bfc9-45c8-be1c-39538ce0e3d3",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1684240528437,
     "user": {
      "displayName": "Irma Tigchelaar",
      "userId": "16898548430591872778"
     },
     "user_tz": -120
    },
    "id": "5c064223-bfc9-45c8-be1c-39538ce0e3d3"
   },
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "524d32ce-ce1a-40d4-b13c-3baf9eb22187",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2636,
     "status": "ok",
     "timestamp": 1684240531067,
     "user": {
      "displayName": "Irma Tigchelaar",
      "userId": "16898548430591872778"
     },
     "user_tz": -120
    },
    "id": "524d32ce-ce1a-40d4-b13c-3baf9eb22187",
    "outputId": "9eb3b48e-da7a-44e2-d874-bc315f6eb148"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\IrmaT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8274756c-ed82-4720-aeb3-f4e789451069",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1684240531068,
     "user": {
      "displayName": "Irma Tigchelaar",
      "userId": "16898548430591872778"
     },
     "user_tz": -120
    },
    "id": "8274756c-ed82-4720-aeb3-f4e789451069"
   },
   "outputs": [],
   "source": [
    "# the code below is used when Bertscore is used in step SS\n",
    "import bert_score\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb201754-5724-4594-bfaf-fe5b3194e5b5",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1684240531069,
     "user": {
      "displayName": "Irma Tigchelaar",
      "userId": "16898548430591872778"
     },
     "user_tz": -120
    },
    "id": "bb201754-5724-4594-bfaf-fe5b3194e5b5"
   },
   "outputs": [],
   "source": [
    "# set the display.max_rows option to None to display all rows instead of limiting it to 50\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be039c2-39b1-42e1-8d2f-09064de746fb",
   "metadata": {
    "id": "7be039c2-39b1-42e1-8d2f-09064de746fb"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd3f2cbf-e5d3-4f8d-96e0-6785e1e4f974",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252,
     "referenced_widgets": [
      "0850f9ebf8e5492cbf2634d79779256f",
      "8f8d0a42b30c4e1b95c84272f01e241b",
      "93f98b3afc034967a6ea6c16c4ad9cc2",
      "89024962b9d1424a89b3bc403fbb424a",
      "893e24b85ec64427b51d478770affbfc",
      "e1514f8bad0f4b089d539ddd21086a57",
      "291707134e3d4b9c8a3f752d200b07b3",
      "c2f9568a58a04b68b7991514e05acd20",
      "e720c30050874212844d8194b03ddc75",
      "3f2c3ebccd9f4df299cd6fdbba8bf3e0",
      "f21f7c3e125842e1a6a905a78b33ee08",
      "bbf92c4fada4456abe8e9563f25f731a",
      "a88f4a91fe4f40eeab94aadf4af6fb4c",
      "60be5e10f54d475fab0a2d156c498ea0",
      "b3ba6e349ecc4a10ab6c93117f445956",
      "f181616db242429795d21b51efc271b3",
      "8314f6c9a28949b1b8d2865ab442aa5d",
      "65bcb9e3844941d0bfe6393e55332576",
      "924cf2485a1b489fa7b2e6a556b33874",
      "e315d5141b104ee3a92c4757e142ae1e",
      "f743035e99b347e29f2c140c630c2ccc",
      "636dd18530fe4c6192b9e0872b73aa9a",
      "2bea8bd2dce64f50a287e2a7fae5e2ac",
      "a12efe760abe4863b6e54f2a060e73dc",
      "499ec307428b41a78d27f9adabdeb53d",
      "2585904371a048b3a105f951dd8f000f",
      "6d8eeb989bf142faae600ae4c808f626",
      "1df08871ac4145aba971e0d367a31249",
      "e751b622b2704ea68d9c7143eff50ce3",
      "949024d006e447ebbe5dcc259bc22e9e",
      "f78c3b4355de482b9210b5469eb6f3e6",
      "93e988fc761648398baa05b3f914c0c7",
      "ea791374e2374fc3a1cb6783d67e6b79",
      "2b2bfbc0adfa4420a26abb692a7d97f7",
      "acde8a206e4147da937e617ad3a9f44e",
      "de0b051d9c5341de96c55029732f00cd",
      "30e3b4f86172421d8d2b16e55ea1f52d",
      "0816ce05ee17480596ea1bc14cf18096",
      "902ccc54bf9b4ebb8d956efc0cd5f9c2",
      "e655a0302c2840ca9080b888e15882a3",
      "d4ba16dec4184db9a5a4a9ead24a3e6b",
      "f58d1cbfa5a7464c9c26d17642c2cc42",
      "809ca7e36997464e8d21264062243447",
      "486e869e704f4fef90a73b27cc497c0a",
      "bcd078cc7dcc4f579e5fddcad5fb16ed",
      "2e1394495d9341668c1bd6f7e7f82a61",
      "d1e2a90376e34c779472c529a15b6b15",
      "b715f972a1fa48708f79e956f1b33421",
      "7080cf2b27064cd1bea2b76b34c45394",
      "828a972e099c41e18ede59d36202084c",
      "41a0f67728d7405a8dd10be01260f6db",
      "d405e6b4bfdd4c3bbaba6ec2fea34408",
      "8e7abec6ac454ebd9b061b90a9ab0c98",
      "b01e1a59c1fe4b26893b532111cbe58a",
      "940d8402983f4ceeb2d3db16162f5677"
     ]
    },
    "executionInfo": {
     "elapsed": 4513,
     "status": "ok",
     "timestamp": 1684240565256,
     "user": {
      "displayName": "Irma Tigchelaar",
      "userId": "16898548430591872778"
     },
     "user_tz": -120
    },
    "id": "fd3f2cbf-e5d3-4f8d-96e0-6785e1e4f974",
    "outputId": "fa63beb7-1229-44ed-8d2a-4c76a64a3fae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the tokenizer and the model\n",
    "\n",
    "# for bert-base:\n",
    "lm_tokenizer_bertbase = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "lm_model_bertbase = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "# Instantiate the fill-mask pipeline with the model\n",
    "fill_mask_bertbase = pipeline(\"fill-mask\", lm_model_bertbase, tokenizer = lm_tokenizer_bertbase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6660f490-7b14-4693-bccd-f36dab3eb958",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213,
     "referenced_widgets": [
      "9394d24fc86d4af18c99eb7248b61c76",
      "92470004f26b4ffdb56226969f714d71",
      "4ea954c7b73145a2bc4abe31385ea8ae",
      "19420e1873db4e6a80baff6f72081ee5",
      "123e1d84f7f2493c93bc9458a74cc859",
      "1d2d40add1b243fe99a31d1fae53abe3",
      "e865691b14644d909285cbb1d8dcf496",
      "d930e25291e34f93a05fee9ac1f1b55a",
      "0ce23f4cbb784dd5b21cd3737ddc1f7f",
      "ab02e818a77c45f3838d42a96be08f3b",
      "97bc704e816549f599a24bb6058c7be7",
      "f2d29fa1d9ce428dbd478b03e15f0d2e",
      "49722bd776d04226b0fd5d19cab994ee",
      "35f85c211de84640b106f79a44e4ba13",
      "1346c8efc182433a8dc87dd981618edd",
      "6e7b3a1ba67541a0bb58800028abed5f",
      "f09b59a008b4454f9cd4a2d5311bff39",
      "50b131102b424f3fad401baeae34648a",
      "dcbf0abd2e024ff5acd054f2baa1dcb6",
      "4343a16ac7c340afa3367ed08e390e3f",
      "691f390e96e54f56b2902ef09e8eb78c",
      "a7b1d432aafe47ceb6d9bb3185642c62",
      "36fad96a013148c691f875e1e46c66e6",
      "8f5f7af0acb84bc9bde7a5518e714453",
      "1f1eda0d23b743f2b02b729a3a8c981b",
      "c342d762227344d6bfa3d711eb7b0508",
      "60beb88d09334d148adaca3fa2a37f3f",
      "69da3350d31040bab71fe71ff06c7f63",
      "01ab0bfa52bd40bda4af3169cd15545b",
      "c59414047aed4376af9ffc79759b9e32",
      "0ebd0abc03ca4749bd9166c5d2223580",
      "52ef4af975fc414bb152fd12a65ce1d1",
      "dcaa9ae3027347229b3f3258aad015d1",
      "cdbdeff2209c4b958315cf5d71315cb0",
      "f545cc1f9c8f4b02b883bc6f0f2491b8",
      "0e0e82acf52848f49aeb31f719ffd99b",
      "ebdcb74a6a5c48c6bcdc1c92a19c8994",
      "d1c3c9bd0f274a6f870af7c64e376c17",
      "ea7de39db7c246b5be587183f1463623",
      "617eb3551a1a4b1da486646d29c3a1d3",
      "5c897070773441a394b3fba2f93b24f5",
      "5d36fa8e7ce940738f165692a26931e0",
      "93e2f4de97ca4e06920a2d871aa49083",
      "9cb9851c654843a3b3f62c4d7692906f",
      "5a599bb760364152aebdd773c98b3d2e",
      "f93a1275f1ca4fb98df56c731f5582be",
      "31dfd1f132ee44c6bc9956aaa52236b9",
      "82e9a39bbb4b4a4684ffdd5f8a6a19d3",
      "84e5997c68be4238b02847eaddadea83",
      "72f3724479364b448a969d2c93388076",
      "8bb8420357f441ea95520f9d94ace1a2",
      "57f558e69b6a44e3ab7b49bbd1938f25",
      "d3fea5a42bc546378b89c451ec76e0a1",
      "2d79549080974206869c6230a6d47781",
      "0a0785c303fa40118a0c97ecb7734bb3"
     ]
    },
    "executionInfo": {
     "elapsed": 2572,
     "status": "ok",
     "timestamp": 1684240574595,
     "user": {
      "displayName": "Irma Tigchelaar",
      "userId": "16898548430591872778"
     },
     "user_tz": -120
    },
    "id": "6660f490-7b14-4693-bccd-f36dab3eb958",
    "outputId": "3713ada2-47b6-4aba-e254-e67a8476baaf"
   },
   "outputs": [],
   "source": [
    "# Instantiate the tokenizer and the model\n",
    "\n",
    "# for electra-base:\n",
    "lm_tokenizer_electrabase = AutoTokenizer.from_pretrained(\"google/electra-base-generator\")\n",
    "lm_model_electrabase = AutoModelForMaskedLM.from_pretrained(\"google/electra-base-generator\")\n",
    "\n",
    "\n",
    "# Instantiate the fill-mask pipeline with the model\n",
    "fill_mask_electrabase = pipeline(\"fill-mask\", lm_model_electrabase, tokenizer = lm_tokenizer_electrabase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0iZ7SBLUHa1b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "08ce1cdf1dad4dcd9f0f3b7a2ce50d65",
      "e43b65112a7c4c1fb9904ca5ac4f6734",
      "d763da1a2d214656ae8cd198cf606281",
      "6a27acb8a7b94efeb1bcf4ce2e476e82",
      "f4649f0058484ebe81d02fe44d99f1b8",
      "3bfee968b89c4580b57f66becd02ea71",
      "433c92c35a0b46a68e415e33a9f41f1a",
      "08c2983c2c3a4ac2bd879496c93ead15",
      "c09b7b01f93d471e9d80ecf9759b2a13",
      "a754cd1c79db4deabc642c752264db5c",
      "bfcb3f06384b469fa74c513e03f02c20",
      "2924c72cc2b04094942cf1f59560b7ee",
      "969de54dd25c4c3aa734aef2b8545e29",
      "0ce97a1f5fbd49d8a9efbb6d71d85fdb",
      "d16fe136c8da4ced914add81a51d6383",
      "49e23629175c449887d41d17e28445c5",
      "945c97bbec234e43b0c3630b6f01321a",
      "a95eb5420e68483a8c1016c722a5daad",
      "7a6c9d2551734fd793cd20c75ef0439a",
      "0806ae913ce6408ca816b6f08a024925",
      "5bbf19d1e6d142a5b78de83c90929c09",
      "f0ca52e1f04d44ac935a0da44580f9d1",
      "1c3e3b457a544715ae8f44285a2afbbc",
      "87a83c5842df496ca091b32d05bf517c",
      "c82ef727b14b4ee09fba8bbf950a8420",
      "4366eecfeb8945adb82670e785a7419a",
      "f3007c832f8f403ca83a59b3b03136e7",
      "007e6ba4510e4dde89f7325cb48fca5c",
      "272f204b67aa4e04864064b0853b1a36",
      "f6e45467a442439eb034c7326f08cf4e",
      "3676f73895064c30b2bf261c18cdf7d3",
      "359e0ddbd64c4849be635b9b0e7c6d7f",
      "c986609b554b4f4494b1b847f872d08d",
      "dadcaefa543b42d6b78d351f0388c072",
      "2bd6873d108e478cb9ef916a587408c8",
      "eed76499db3b4fa2aadf72cf165fe4c8",
      "90e2ae4c4f4d47eb826a34f567f6838f",
      "02ff42ab910c4145bd9510cc08f3b94f",
      "e55696bdbb5041979ddba03b2ebe9ddd",
      "c88e4918710141399ca6bf0da79711e9",
      "61705d7534234ef1b19daab67f44ca58",
      "6aa1b4caffa04e3bad3cf0fd336fb706",
      "4eba72a878014dacafefd044381ba0ec",
      "6f226b4607cf40ed849a1d7eff6ec9df",
      "cfdcc443a71749fdb21a22c918fbaf00",
      "cc9e4730cf954e00bff4ef0503758e07",
      "273ac09e03a44ee490fe4ba5b543f255",
      "9301272e564145839972eca8f77b70a4",
      "c45f7a5046ff4f15ad9e571c0571ed27",
      "ce39aca40ebd4a93a784cfa8938c1d03",
      "03bc194d73f4486d89a3767e8d14f34c",
      "4868510551cf413c916f4d9a04f30af4",
      "e87de82893af4558adec0d8b26bc6a1f",
      "45ff9d7363734a34bc412de20fd6eee5",
      "ffec2e6c5a234b00884a144bbf67e17f"
     ]
    },
    "executionInfo": {
     "elapsed": 4697,
     "status": "ok",
     "timestamp": 1684240583989,
     "user": {
      "displayName": "Irma Tigchelaar",
      "userId": "16898548430591872778"
     },
     "user_tz": -120
    },
    "id": "0iZ7SBLUHa1b",
    "outputId": "c7f2f450-4b4d-4751-85ad-4559c53d4444"
   },
   "outputs": [],
   "source": [
    "# Instantiate the tokenizer and the model\n",
    "\n",
    "# for roberta-base:\n",
    "lm_tokenizer_robertabase = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "lm_model_robertabase = AutoModelForMaskedLM.from_pretrained(\"roberta-base\")\n",
    "\n",
    "\n",
    "# Instantiate the fill-mask pipeline with the model\n",
    "fill_mask_robertabase = pipeline(\"fill-mask\", lm_model_robertabase, tokenizer = lm_tokenizer_robertabase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NgnjDVeqj0Ga",
   "metadata": {
    "id": "NgnjDVeqj0Ga"
   },
   "source": [
    "### Get top-x of 4 models (bert-base, for bertscore bert-base and bertscore electra-base; and electrabase, for bertscore bert-base and bertscore electrabase)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6580a0ae-d493-4da2-8541-47dbdbcafe30",
   "metadata": {
    "id": "6580a0ae-d493-4da2-8541-47dbdbcafe30"
   },
   "source": [
    "##### top-5 duplicates for all 4 models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9366200a-73be-4cae-b3d6-1bea2c3d7f8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 94302,
     "status": "ok",
     "timestamp": 1684241519933,
     "user": {
      "displayName": "Irma Tigchelaar",
      "userId": "16898548430591872778"
     },
     "user_tz": -120
    },
    "id": "9366200a-73be-4cae-b3d6-1bea2c3d7f8f",
    "outputId": "54bd8437-0342-487b-92fa-016ddea35ad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: top-5 substitutes based on bertscores with Bert for bertbase model: ['mandatory', 'obligatory', 'optional', 'illegal', 'voluntary']\n",
      "\n",
      "SS step: top-5 substitutes based on bertscores with Electra for bertbase model: ['mandatory', 'obligatory', 'voluntary', 'optional', 'mandated']\n",
      "\n",
      "SS step: top-5 substitutes based on bertscores with Bert for bertbase model: ['mandatory', 'obligatory', 'optional', 'legal', 'automatic']\n",
      "\n",
      "SS step: top-5 substitutes based on bertscores with Electra for bertbase model: ['mandatory', 'obligatory', 'voluntary', 'automatic', 'optional']\n",
      "\n",
      "Finding shared duplicates in the four top-5 lists ....\n",
      "SS step: shared duplicates in top-5 substitutes lists based on bertscores with Bert and Electra for both bertbase and electrabase models: ['mandatory', 'obligatory', 'optional']\n",
      "\n",
      "SS step: concatenated top-5 with prioritized shared duplicates among bertbase and electrabase bertscore results: ['mandatory', 'obligatory', 'optional', 'illegal', 'mandated', 'legal']\n",
      "\n",
      "SS step: final list bertscore based on prioritizing shared duplicates among bertbase and electrabase models: ['mandatory', 'obligatory', 'optional', 'illegal', 'mandated', 'legal', 'permitted', 'standard', 'forbidden', 'forbidden']\n",
      "\n",
      "------------------------------------------------------------\n",
      "SS step: top-5 substitutes based on bertscores with Bert for bertbase model: ['infused', 'reinforced', 'empowered', 'created', 'delivered']\n",
      "\n",
      "SS step: top-5 substitutes based on bertscores with Electra for bertbase model: ['infused', 'bred', 'empowered', 'reinforced', 'secured']\n",
      "\n",
      "SS step: top-5 substitutes based on bertscores with Bert for bertbase model: ['infused', 'fortified', 'created', 'blessed', 'lured']\n",
      "\n",
      "SS step: top-5 substitutes based on bertscores with Electra for bertbase model: ['impressed', 'infused', 'encouraged', 'lured', 'supplied']\n",
      "\n",
      "Finding shared duplicates in the four top-5 lists ....\n",
      "SS step: shared duplicates in top-5 substitutes lists based on bertscores with Bert and Electra for both bertbase and electrabase models: ['infused']\n",
      "\n",
      "SS step: concatenated top-5 with prioritized shared duplicates among bertbase and electrabase bertscore results: ['infused', 'delivered', 'bred', 'secured', 'fortified', 'blessed', 'impressed', 'encouraged', 'supplied']\n",
      "\n",
      "SS step: final list bertscore based on prioritizing shared duplicates among bertbase and electrabase models: ['infused', 'delivered', 'bred', 'secured', 'fortified', 'blessed', 'impressed', 'encouraged', 'supplied', 'created']\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 100\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sentence_with_substitutes_bertbase) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m# to make sure the list with substitutes is always filled\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformers\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msetLevel(logging\u001b[38;5;241m.\u001b[39mERROR)  \u001b[38;5;66;03m# to prevent the same warnings from being printed x times \u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     scores_bsBert_bertbase \u001b[38;5;241m=\u001b[39m \u001b[43mbert_score\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msentence_with_substitutes_bertbase\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentence_with_substitutes_bertbase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbert-base-uncased\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m     scores_bsElectra_bertbase \u001b[38;5;241m=\u001b[39m bert_score\u001b[38;5;241m.\u001b[39mscore([sentence]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(sentence_with_substitutes_bertbase), sentence_with_substitutes_bertbase, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoogle/electra-base-generator\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    102\u001b[0m     logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformers\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msetLevel(logging\u001b[38;5;241m.\u001b[39mWARNING) \u001b[38;5;66;03m# to reset the logging level back to printing warnings\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\bert_score\\score.py:123\u001b[0m, in \u001b[0;36mscore\u001b[1;34m(cands, refs, model_type, num_layers, verbose, idf, device, batch_size, nthreads, all_layers, lang, return_hash, rescale_with_baseline, baseline_path, use_fast_tokenizer)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalculating scores...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    122\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m--> 123\u001b[0m all_preds \u001b[38;5;241m=\u001b[39m \u001b[43mbert_cos_score_idf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43midf_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ref_group_boundaries \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m     max_preds \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\bert_score\\utils.py:616\u001b[0m, in \u001b[0;36mbert_cos_score_idf\u001b[1;34m(model, refs, hyps, tokenizer, idf_dict, verbose, batch_size, device, all_layers)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_start \u001b[38;5;129;01min\u001b[39;00m iter_range:\n\u001b[0;32m    615\u001b[0m     sen_batch \u001b[38;5;241m=\u001b[39m sentences[batch_start : batch_start \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m--> 616\u001b[0m     embs, masks, padded_idf \u001b[38;5;241m=\u001b[39m \u001b[43mget_bert_embedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43msen_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midf_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_layers\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    619\u001b[0m     embs \u001b[38;5;241m=\u001b[39m embs\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m    620\u001b[0m     masks \u001b[38;5;241m=\u001b[39m masks\u001b[38;5;241m.\u001b[39mcpu()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\bert_score\\utils.py:455\u001b[0m, in \u001b[0;36mget_bert_embedding\u001b[1;34m(all_sens, model, tokenizer, idf_dict, batch_size, device, all_layers)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(all_sens), batch_size):\n\u001b[1;32m--> 455\u001b[0m         batch_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mbert_encode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpadded_sens\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m            \u001b[49m\u001b[43mall_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m         embeddings\u001b[38;5;241m.\u001b[39mappend(batch_embedding)\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m batch_embedding\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\bert_score\\utils.py:351\u001b[0m, in \u001b[0;36mbert_encode\u001b[1;34m(model, x, attention_mask, all_layers)\u001b[0m\n\u001b[0;32m    349\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 351\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m all_layers:\n\u001b[0;32m    353\u001b[0m     emb \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(out[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1014\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1005\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1007\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1008\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1009\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1027\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:603\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    594\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    595\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    596\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    600\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    601\u001b[0m     )\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 603\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:531\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    528\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    529\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 531\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    534\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    536\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\transformers\\pytorch_utils.py:246\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:544\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m    543\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 544\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:456\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 456\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    458\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "    \n",
    "    # print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    #print(f\"Sentence: {sentence}\")\n",
    "    #print(f\"Complex word: {complex_word}\")\n",
    "    \n",
    "    \n",
    "    # for bertbase model:\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word_bertbase = sentence.replace(complex_word, lm_tokenizer_bertbase.mask_token)\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    sentences_concat_bertbase = f\"{sentence} {lm_tokenizer_bertbase.sep_token} {sentence_masked_word_bertbase}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline (removing elements without token_str key; as this gave errors in the ELECTRA models) .\n",
    "    top_k = 30\n",
    "    result_bertbase = fill_mask_bertbase(sentences_concat_bertbase, top_k=top_k)\n",
    "    substitutes_bertbase = [substitute[\"token_str\"] for substitute in result_bertbase if \"token_str\" in substitute]\n",
    "    #print(f\"Substitute Generation step: initial substitute list: {substitutes_bertbase}\\n\")\n",
    "\n",
    "\n",
    "    #2: Morphological Generation and Context Adaptation (Morphological Adaptation):  \n",
    "    ## a) remove noise in the substitutes, by ignoring generated substitutes that are empty or that have unwanted punctuation characters or that start with '##' (this returned errors with the ELECTRA model), and lowercase the substitutes (as some models don't lowercase by default)\n",
    "    ## and lowercase all substitutes. Use try/except statement to prevent other character-related problems to happen\n",
    "\n",
    "    punctuation_set = set(string.punctuation) - set('-') # retained hyphens in case tokenizers don't split on hyphenated compounds\n",
    "    punctuation_set.update({'“','”'})   # as these curly quotes appeared in the Electra (SG step) results but were not part of the string set\n",
    "\n",
    "    try:\n",
    "        substitutes_bertbase = [substitute[\"token_str\"].lower().strip() for substitute in result_bertbase if not any(char in punctuation_set for char in substitute[\"token_str\"]) # added .strip as roberta uses a leading space before each substitute\n",
    "                      and not substitute[\"token_str\"].startswith('##') and substitute[\"token_str\"].strip() != \"\"]\n",
    "        # print(f\"Morphological Adaptation step a): substitute list without unwanted punctuation characters for bertbase model: {substitutes_bertbase}\\n\")\n",
    "    except TypeError as error:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    ## b) remove duplicates within the substitute list from the substitute list (duplicates are likely for models that did not lowercase by default)\n",
    "    ## the last mentioned duplicate is removed on purpose, as this may probably be the (previously) uppercased variant of the lowercased substitute (lowercased subs are most likely higher ranked by the model)\n",
    "    substitutes_no_dupl_bertbase = []\n",
    "    for sub in substitutes_bertbase:\n",
    "        if sub not in substitutes_no_dupl_bertbase:\n",
    "            substitutes_no_dupl_bertbase.append(sub)\n",
    "    #print(f\"Morphological Adaptation step b): substitute list without duplicates of substitutes for bertbase model: {substitutes_no_dupl_bertbase}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    ## c) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "\n",
    "    ## first Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## then, remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word_bertbase = []\n",
    "    for substitute in substitutes_no_dupl_bertbase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word_bertbase.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step c): substitute list without duplicates of the complex word nor inflected forms of the complex word for bertbase model: {substitutes_no_dupl_complex_word_bertbase}\\n\")\n",
    "\n",
    "\n",
    "      ## d) remove antonyms of the complex word from the substitute list\n",
    "    ## step 1: get the antonyms of the complex word\n",
    "    antonyms_complex_word = []\n",
    "    for syn in wn.synsets(complex_word_lemma):\n",
    "        for lemma in syn.lemmas():\n",
    "            for antonym in lemma.antonyms():\n",
    "                    antonyms_complex_word.append(antonym.name())\n",
    "\n",
    "    print(f\"Antonyms for complex word '{complex_word}': {antonyms_complex_word}\\n\")\n",
    "\n",
    "    ## step 2: remove antonyms of the complex word from the list with substitutes\n",
    "    substitutes_no_antonyms_bertbase = []\n",
    "    for substitute in substitutes_no_dupl_complex_word_bertbase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma not in antonyms_complex_word:\n",
    "            substitutes_no_antonyms_bertbase.append(substitute)\n",
    "        else:\n",
    "            print(f\"Removed antonym: {substitute}\")\n",
    "    print(f\"Morphological Adaptation step d): substitute list without antonyms of the complex word for bertbase model: {substitutes_no_antonyms_bertbase}\\n\") \n",
    "    \n",
    "    \n",
    "    \n",
    "    #3: Substitute Selection (SS) by calculating Bert scores: \n",
    "\n",
    "    ## create sentence with the complex word replaced by the substitutes\n",
    "    sentence_with_substitutes_bertbase = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym_bertbase]\n",
    "    #print(f\"List with sentences where complex word is substituted for bertbase model: {sentence_with_substitutes_bertbase}\\n\")\n",
    "\n",
    "\n",
    "    ## calculate BERTScores, and rank the substitutes based on these scores\n",
    "    if len(sentence_with_substitutes_bertbase) > 0: # to make sure the list with substitutes is always filled\n",
    "        logging.getLogger('transformers').setLevel(logging.ERROR)  # to prevent the same warnings from being printed x times \n",
    "        scores_bsBert_bertbase = bert_score.score([sentence]*len(sentence_with_substitutes_bertbase), sentence_with_substitutes_bertbase, lang=\"en\", model_type='bert-base-uncased', verbose=False)\n",
    "        scores_bsElectra_bertbase = bert_score.score([sentence]*len(sentence_with_substitutes_bertbase), sentence_with_substitutes_bertbase, lang=\"en\", model_type='google/electra-base-generator', verbose=False)\n",
    "        logging.getLogger('transformers').setLevel(logging.WARNING) # to reset the logging level back to printing warnings\n",
    "        \n",
    "        # create a list of tuples, each tuple containing a substitute and its score\n",
    "        substitute_score_pairs_bsBert_bertbase = list(zip(substitutes_no_dupl_complex_word_no_antonym_bertbase, scores_bsBert_bertbase[0].tolist()))\n",
    "        substitute_score_pairs_bsElectra_bertbase = list(zip(substitutes_no_dupl_complex_word_no_antonym_bertbase, scores_bsElectra_bertbase[0].tolist()))\n",
    "\n",
    "        # sort the list of tuples by the scores (the second element of each tuple), in descending order\n",
    "        sorted_substitute_score_pairs_bsBert_bertbase = sorted(substitute_score_pairs_bsBert_bertbase, key=lambda x: x[1], reverse=True)\n",
    "        sorted_substitute_score_pairs_bsElectra_bertbase = sorted(substitute_score_pairs_bsElectra_bertbase, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # extract the list of substitutes from the sorted pairs\n",
    "        bertscore_ranked_substitutes_only_bsBert_bertbase = [substitute for substitute, _ in sorted_substitute_score_pairs_bsBert_bertbase]\n",
    "        #print(f\"substitutes based on bertscores with bertbase model: {bertscore_ranked_substitutes_only_bsBert_bertbase}\\n\")\n",
    "        bertscore_ranked_substitutes_only_bsElectra_bertbase = [substitute for substitute, _ in sorted_substitute_score_pairs_bsElectra_bertbase]\n",
    "        #print(f\"substitutes based on bertscores with Electra for bertbase model : {bertscore_ranked_substitutes_only_bsElectra_bertbase}\\n\")\n",
    "\n",
    "\n",
    "        # limit the substitutes to the 10 first ones for evaluation\n",
    "        top_10_substitutes_bsBert_bertbase = bertscore_ranked_substitutes_only_bsBert_bertbase[:10]\n",
    "        #print(f\"top-10 substitutes with Bert based on bertscores with Bert: {top_10_substitutes_bsBert_bertbase}\\n\")\n",
    "        top_10_substitutes_bsElectra_bertbase = bertscore_ranked_substitutes_only_bsElectra_bertbase[:10]\n",
    "        #print(f\"top-10 substitutes based on bertscores with Electra for bertbase model: {top_10_substitutes_bsElectra_bertbase}\\n\")\n",
    "\n",
    "    else:\n",
    "        top_10_substitutes_bsBert_bertbase  = []\n",
    "        top_10_substitutes_bsElectra_bertbase = []\n",
    "        \n",
    "    \n",
    "    # limit the substitutes to the 5 first ones for concatenation with the top-5 of other models\n",
    "    top_5_substitutes_bsBert_bertbase = top_10_substitutes_bsBert_bertbase[:5]\n",
    "    print(f\"SS step: top-5 substitutes based on bertscores with Bert for bertbase model: {top_5_substitutes_bsBert_bertbase}\\n\")\n",
    "    top_5_substitutes_bsElectra_bertbase = top_10_substitutes_bsElectra_bertbase[:5]\n",
    "    print(f\"SS step: top-5 substitutes based on bertscores with Electra for bertbase model: {top_5_substitutes_bsElectra_bertbase}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # for electrabase model:\n",
    "   \n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word_electrabase = sentence.replace(complex_word, lm_tokenizer_electrabase.mask_token)\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    sentences_concat_electrabase = f\"{sentence} {lm_tokenizer_electrabase.sep_token} {sentence_masked_word_electrabase}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline (removing elements without token_str key; as this gave errors in the ELECTRA models) .\n",
    "    top_k = 30\n",
    "    result_electrabase = fill_mask_electrabase(sentences_concat_electrabase, top_k=top_k)\n",
    "    substitutes_electrabase = [substitute[\"token_str\"] for substitute in result_electrabase if \"token_str\" in substitute]\n",
    "    #print(f\"Substitute Generation step: initial substitute list: {substitutes_electrabase}\\n\")\n",
    "\n",
    "\n",
    "    #2: Morphological Generation and Context Adaptation (Morphological Adaptation):  \n",
    "    ## a) remove noise in the substitutes, by ignoring generated substitutes that are empty or that have unwanted punctuation characters or that start with '##' (this returned errors with the ELECTRA model), and lowercase the substitutes (as some models don't lowercase by default)\n",
    "    ## and lowercase all substitutes. Use try/except statement to prevent other character-related problems to happen\n",
    "\n",
    "    punctuation_set = set(string.punctuation) - set('-') # retained hyphens in case tokenizers don't split on hyphenated compounds\n",
    "    punctuation_set.update({'“','”'})   # as these curly quotes appeared in the Electra (SG step) results but were not part of the string set\n",
    "\n",
    "    try:\n",
    "        substitutes_electrabase = [substitute[\"token_str\"].lower().strip() for substitute in result_electrabase if not any(char in punctuation_set for char in substitute[\"token_str\"]) # added .strip as roberta uses a leading space before each substitute\n",
    "                      and not substitute[\"token_str\"].startswith('##') and substitute[\"token_str\"].strip() != \"\"]\n",
    "        # print(f\"Morphological Adaptation step a): substitute list without unwanted punctuation characters for electrabase model: {substitutes_electrabase}\\n\")\n",
    "    except TypeError as error:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    ## b) remove duplicates within the substitute list from the substitute list (duplicates are likely for models that did not lowercase by default)\n",
    "    ## the last mentioned duplicate is removed on purpose, as this may probably be the (previously) uppercased variant of the lowercased substitute (lowercased subs are most likely higher ranked by the model)\n",
    "    substitutes_no_dupl_electrabase = []\n",
    "    for sub in substitutes_electrabase:\n",
    "        if sub not in substitutes_no_dupl_electrabase:\n",
    "            substitutes_no_dupl_electrabase.append(sub)\n",
    "    #print(f\"Morphological Adaptation step b): substitute list without duplicates of substitutes for electrabase model: {substitutes_no_dupl_electrabase}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    ## c) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "\n",
    "    ## first Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## then, remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word_electrabase = []\n",
    "    for substitute in substitutes_no_dupl_electrabase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word_electrabase.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step c): substitute list without duplicates of the complex word nor inflected forms of the complex word for electrabase model: {substitutes_no_dupl_complex_word_electrabase}\\n\")\n",
    "\n",
    "\n",
    "    ## d) remove antonyms of the complex word from the substitute list\n",
    "    ## step 1: get the antonyms of the complex word\n",
    "    antonyms_complex_word = []\n",
    "    for syn in wn.synsets(complex_word_lemma):\n",
    "        for lemma in syn.lemmas():\n",
    "            for antonym in lemma.antonyms():\n",
    "                    antonyms_complex_word.append(antonym.name())\n",
    "\n",
    "    print(f\"Antonyms for complex word '{complex_word}': {antonyms_complex_word}\\n\")\n",
    "\n",
    "    ## step 2: remove antonyms of the complex word from the list with substitutes\n",
    "    substitutes_no_antonyms_electrabase = []\n",
    "    for substitute in substitutes_no_dupl_complex_word_electrabase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma not in antonyms_complex_word:\n",
    "            substitutes_no_antonyms_electrabase.append(substitute)\n",
    "        else:\n",
    "            print(f\"Removed antonym: {substitute}\")\n",
    "    print(f\"Morphological Adaptation step d): substitute list without antonyms of the complex word for electrabase model: {substitutes_no_antonyms_electrabase}\\n\") \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #3: Substitute Selection (SS) by calculating Bert scores: \n",
    "\n",
    "    ## create sentence with the complex word replaced by the substitutes\n",
    "    sentence_with_substitutes_electrabase = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym_electrabase]\n",
    "    #print(f\"List with sentences where complex word is substituted for bertbase model: {sentence_with_substitutes_electrabase\\n\")\n",
    "\n",
    "\n",
    "    ## calculate BERTScores, and rank the substitutes based on these scores\n",
    "    if len(sentence_with_substitutes_electrabase) > 0: # to make sure the list with substitutes is always filled\n",
    "        logging.getLogger('transformers').setLevel(logging.ERROR)  # to prevent the same warnings from being printed x times \n",
    "        scores_bsBert_electrabase = bert_score.score([sentence]*len(sentence_with_substitutes_electrabase), sentence_with_substitutes_electrabase, lang=\"en\", model_type='bert-base-uncased', verbose=False)\n",
    "        scores_bsElectra_electrabase = bert_score.score([sentence]*len(sentence_with_substitutes_electrabase), sentence_with_substitutes_electrabase, lang=\"en\", model_type='google/electra-base-generator', verbose=False)\n",
    "        logging.getLogger('transformers').setLevel(logging.WARNING) # to reset the logging level back to printing warnings\n",
    "        \n",
    "        # create a list of tuples, each tuple containing a substitute and its score\n",
    "        substitute_score_pairs_bsBert_electrabase = list(zip(substitutes_no_dupl_complex_word_no_antonym_electrabase, scores_bsBert_electrabase[0].tolist()))\n",
    "        substitute_score_pairs_bsElectra_electrabase = list(zip(substitutes_no_dupl_complex_word_no_antonym_electrabase, scores_bsElectra_electrabase[0].tolist()))\n",
    "\n",
    "        # sort the list of tuples by the scores (the second element of each tuple), in descending order\n",
    "        sorted_substitute_score_pairs_bsBert_electrabase = sorted(substitute_score_pairs_bsBert_electrabase, key=lambda x: x[1], reverse=True)\n",
    "        sorted_substitute_score_pairs_bsElectra_electrabase = sorted(substitute_score_pairs_bsElectra_electrabase, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # extract the list of substitutes from the sorted pairs\n",
    "        bertscore_ranked_substitutes_only_bsBert_electrabase = [substitute for substitute, _ in sorted_substitute_score_pairs_bsBert_electrabase]\n",
    "        #print(f\"substitutes with Bert based on bertscores with Bert: {bertscore_ranked_substitutes_only_bsBert_electrabase}\\n\")\n",
    "        bertscore_ranked_substitutes_only_bsElectra_electrabase = [substitute for substitute, _ in sorted_substitute_score_pairs_bsElectra_electrabase]\n",
    "        #print(f\"substitutes based on bertscores with Electra for bert-base model : {bertscore_ranked_substitutes_only_bsElectra_electrabase}\\n\")\n",
    "\n",
    "\n",
    "        # limit the substitutes to the 10 first ones for evaluation\n",
    "        top_10_substitutes_bsBert_electrabase = bertscore_ranked_substitutes_only_bsBert_electrabase[:10]\n",
    "        #print(f\"top-10 substitutes with Bert based on bertscores with Bert: {top_10_substitutes_bsBert_electrabase}\\n\")\n",
    "        top_10_substitutes_bsElectra_electrabase = bertscore_ranked_substitutes_only_bsElectra_electrabase[:10]\n",
    "        #print(f\"top-10 substitutes based on bertscores with Electra for bert-base model: {top_10_substitutes_bsElectra_electrabase}\\n\")\n",
    "\n",
    "    else:\n",
    "        top_10_substitutes_bsBert_electrabase  = []\n",
    "        top_10_substitutes_bsElectra_electrabase = []\n",
    "        \n",
    "    \n",
    "   # limit the substitutes to the 5 first ones for concatenation with the top-5 of other models\n",
    "    top_5_substitutes_bsBert_electrabase = top_10_substitutes_bsBert_electrabase[:5]\n",
    "    #print(f\"SS step: top-5 substitutes based on bertscores with Bert for bertbase model: {top_5_substitutes_bsBert_electrabase}\\n\")\n",
    "    top_5_substitutes_bsElectra_electrabase = top_10_substitutes_bsElectra_electrabase[:5]\n",
    "    #print(f\"SS step: top-5 substitutes based on bertscores with Electra for bertbase model: {top_5_substitutes_bsElectra_electrabase}\\n\")\n",
    "\n",
    "   \n",
    "    # zip the four lists in to create a list that sticks to the original order of each sub list\n",
    "    #print('Finding shared duplicates in the four top-5 lists ....')\n",
    "\n",
    "    # create a dictionary to hold the counts\n",
    "    count_dict = {}\n",
    "\n",
    "    # combine all four lists into a list of lists for easy iteration\n",
    "    all_lists = [top_5_substitutes_bsBert_bertbase, top_5_substitutes_bsElectra_bertbase, top_5_substitutes_bsBert_electrabase, top_5_substitutes_bsElectra_electrabase]\n",
    "\n",
    "    # iterate through each list and count occurrences of each element\n",
    "    for lst in all_lists:\n",
    "        for elem in lst:\n",
    "            if elem in count_dict:\n",
    "                count_dict[elem] += 1\n",
    "            else:\n",
    "                count_dict[elem] = 1\n",
    "\n",
    "    # create a list of duplicates by including only those elements that appeared in all four lists\n",
    "    duplicates_all_models = [elem for elem, count in count_dict.items() if count == len(all_lists)]\n",
    "\n",
    "    #print(f\"SS step: shared duplicates in top-5 substitutes lists based on bertscores with Bert and Electra for both bertbase and electrabase models: {duplicates_all_models}\\n\")\n",
    "    \n",
    "    # create a list with non-duplicates\n",
    "    non_duplicates_all_models = [elem for elem, count in count_dict.items() if count == 1]\n",
    "    #print(f\"SS step: non-duplicates in top-5 substitutes lists based on bertscores with Bert and Electra for both bert-base and electra-base models: {non_duplicates_all_models}\\n\")\n",
    "    \n",
    "    #concatenate both lists (duplicates_all_models and non_duplicates_all_models), giving duplicates_all_models priority\n",
    "    top_5_concatenated = duplicates_all_models + non_duplicates_all_models\n",
    "    #print(f\"SS step: concatenated top-5 with prioritized shared duplicates among bertbase and electrabase bertscore results: {top_5_concatenated}\\n\")\n",
    "    \n",
    "    #create the \"second half\" lists (items 6th to 10th) from each of the original top 10 lists\n",
    "    second_half_bsBert_bertbase = top_10_substitutes_bsBert_bertbase[5:]\n",
    "    second_half_bsElectra_bertbase = top_10_substitutes_bsElectra_bertbase[5:]\n",
    "    second_half_bsBert_electrabase = top_10_substitutes_bsBert_electrabase[5:]\n",
    "    second_half_bsElectra_electrabase = top_10_substitutes_bsElectra_electrabase[5:]\n",
    "\n",
    "    # zip the \"second half\" lists\n",
    "    second_half_combined = [item for sublist in zip(second_half_bsBert_bertbase, second_half_bsElectra_bertbase, second_half_bsBert_electrabase, second_half_bsElectra_electrabase) for item in sublist]\n",
    "\n",
    "    # Exclude any items in second_half_combined that are already in top_5_concatenated\n",
    "    second_half_combined = [item for item in second_half_combined if item not in top_5_concatenated]\n",
    "\n",
    "    # Append these items to the final_list\n",
    "    top_5_concatenated += second_half_combined\n",
    "\n",
    "    # Trim the final_list to the top 10 items\n",
    "    final_list_bertscore_top5dup = top_5_concatenated[:10]\n",
    "\n",
    "    #print(f\"SS step: final list bertscore based on prioritizing shared duplicates among bertbase and electrabase models: {final_list_bertscore_top5dup}\\n\")\n",
    "\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    \n",
    "    \n",
    "    ## add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + final_list_bertscore_top5dup\n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file for evaluation\n",
    "substitutes_df.to_csv('./predictions/test/BertElectrabase_SG_MA_SS_bsBertElectra_top5dup.tsv', sep=\"\\t\", index=False, header=False)   \n",
    "print(\"BertElectrabase_SG_MA_SS_bsBertElectra_top5dup exported to csv in path './predictions/test/BertElectrabase_SG_MA_SS_bsBertElectra_top5dup.tsv'}\\n\")  \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a3d54e-e43a-417a-9cbb-b0ed8de19645",
   "metadata": {
    "id": "f0875320-495f-4e76-b891-9bebdb01717b"
   },
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/BertElectrabase_SG_MA_SS_bsBertElectra_top5dup.tsv --output_file ./output/test/BertElectrabase_SG_MA_SS_bsBertElectra_top5dup.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b895062-52c8-4b3b-9b17-0e76d33bed18",
   "metadata": {
    "id": "9b895062-52c8-4b3b-9b17-0e76d33bed18"
   },
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/BertElectrabase_SG_MA_SS_bsBertElectra_top5dup.tsv\n",
    "OUTPUT file = ./output/test/BertElectrabase_SG_MA_SS_bsBertElectra_top5dup.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.6075\n",
    "\n",
    "MAP@3 = 0.3797\n",
    "MAP@5 = 0.2643\n",
    "MAP@10 = 0.1577\n",
    "\n",
    "Potential@3 = 0.8091\n",
    "Potential@5 = 0.8413\n",
    "Potential@10 = 0.9005\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.2661\n",
    "Accuracy@2@top_gold_1 = 0.3897\n",
    "Accuracy@3@top_gold_1 = 0.4435\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QlzQ2E4z7dEI",
   "metadata": {
    "id": "QlzQ2E4z7dEI"
   },
   "source": [
    "##### top-5 duplicates for all 4 models (other order) _b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a082d6-1f29-4787-b8bb-2a062a499263",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 110117,
     "status": "ok",
     "timestamp": 1684241630884,
     "user": {
      "displayName": "Irma Tigchelaar",
      "userId": "16898548430591872778"
     },
     "user_tz": -120
    },
    "id": "e3a082d6-1f29-4787-b8bb-2a062a499263",
    "outputId": "48a61f1d-2327-4df7-b24d-fbffb3770f1b"
   },
   "outputs": [],
   "source": [
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "    \n",
    "    # print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    #print(f\"Sentence: {sentence}\")\n",
    "    #print(f\"Complex word: {complex_word}\")\n",
    "    \n",
    "    \n",
    "    # for bertbase model:\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word_bertbase = sentence.replace(complex_word, lm_tokenizer_bertbase.mask_token)\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    sentences_concat_bertbase = f\"{sentence} {lm_tokenizer_bertbase.sep_token} {sentence_masked_word_bertbase}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline (removing elements without token_str key; as this gave errors in the ELECTRA models) .\n",
    "    top_k = 30\n",
    "    result_bertbase = fill_mask_bertbase(sentences_concat_bertbase, top_k=top_k)\n",
    "    substitutes_bertbase = [substitute[\"token_str\"] for substitute in result_bertbase if \"token_str\" in substitute]\n",
    "    #print(f\"Substitute Generation step: initial substitute list: {substitutes_bertbase}\\n\")\n",
    "\n",
    "\n",
    "    #2: Morphological Generation and Context Adaptation (Morphological Adaptation):  \n",
    "    ## a) remove noise in the substitutes, by ignoring generated substitutes that are empty or that have unwanted punctuation characters or that start with '##' (this returned errors with the ELECTRA model), and lowercase the substitutes (as some models don't lowercase by default)\n",
    "    ## and lowercase all substitutes. Use try/except statement to prevent other character-related problems to happen\n",
    "\n",
    "    punctuation_set = set(string.punctuation) - set('-') # retained hyphens in case tokenizers don't split on hyphenated compounds\n",
    "    punctuation_set.update({'“','”'})   # as these curly quotes appeared in the Electra (SG step) results but were not part of the string set\n",
    "\n",
    "    try:\n",
    "        substitutes_bertbase = [substitute[\"token_str\"].lower().strip() for substitute in result_bertbase if not any(char in punctuation_set for char in substitute[\"token_str\"]) # added .strip as roberta uses a leading space before each substitute\n",
    "                      and not substitute[\"token_str\"].startswith('##') and substitute[\"token_str\"].strip() != \"\"]\n",
    "        # print(f\"Morphological Adaptation step a): substitute list without unwanted punctuation characters for bertbase model: {substitutes_bertbase}\\n\")\n",
    "    except TypeError as error:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    ## b) remove duplicates within the substitute list from the substitute list (duplicates are likely for models that did not lowercase by default)\n",
    "    ## the last mentioned duplicate is removed on purpose, as this may probably be the (previously) uppercased variant of the lowercased substitute (lowercased subs are most likely higher ranked by the model)\n",
    "    substitutes_no_dupl_bertbase = []\n",
    "    for sub in substitutes_bertbase:\n",
    "        if sub not in substitutes_no_dupl_bertbase:\n",
    "            substitutes_no_dupl_bertbase.append(sub)\n",
    "    #print(f\"Morphological Adaptation step b): substitute list without duplicates of substitutes for bertbase model: {substitutes_no_dupl_bertbase}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    ## c) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "\n",
    "    ## first Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## then, remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word_bertbase = []\n",
    "    for substitute in substitutes_no_dupl_bertbase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word_bertbase.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step c): substitute list without duplicates of the complex word nor inflected forms of the complex word for bertbase model: {substitutes_no_dupl_complex_word_bertbase}\\n\")\n",
    "\n",
    "\n",
    "     ## d) remove antonyms of the complex word from the substitute list\n",
    "    ## step 1: get the antonyms of the complex word\n",
    "    antonyms_complex_word = []\n",
    "    for syn in wn.synsets(complex_word_lemma):\n",
    "        for lemma in syn.lemmas():\n",
    "            for antonym in lemma.antonyms():\n",
    "                    antonyms_complex_word.append(antonym.name())\n",
    "\n",
    "    print(f\"Antonyms for complex word '{complex_word}': {antonyms_complex_word}\\n\")\n",
    "\n",
    "    ## step 2: remove antonyms of the complex word from the list with substitutes\n",
    "    substitutes_no_antonyms_bertbase = []\n",
    "    for substitute in substitutes_no_dupl_complex_word_bertbase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma not in antonyms_complex_word:\n",
    "            substitutes_no_antonyms_bertbase.append(substitute)\n",
    "        else:\n",
    "            print(f\"Removed antonym: {substitute}\")\n",
    "    print(f\"Morphological Adaptation step d): substitute list without antonyms of the complex word for bertbase model: {substitutes_no_antonyms_bertbase}\\n\") \n",
    "    \n",
    "    \n",
    "    \n",
    "    #3: Substitute Selection (SS) by calculating Bert scores: \n",
    "\n",
    "    ## create sentence with the complex word replaced by the substitutes\n",
    "    sentence_with_substitutes_bertbase = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym_bertbase]\n",
    "    #print(f\"List with sentences where complex word is substituted for bertbase model: {sentence_with_substitutes_bertbase}\\n\")\n",
    "\n",
    "\n",
    "    ## calculate BERTScores, and rank the substitutes based on these scores\n",
    "    if len(sentence_with_substitutes_bertbase) > 0: # to make sure the list with substitutes is always filled\n",
    "        logging.getLogger('transformers').setLevel(logging.ERROR)  # to prevent the same warnings from being printed x times \n",
    "        scores_bsBert_bertbase = bert_score.score([sentence]*len(sentence_with_substitutes_bertbase), sentence_with_substitutes_bertbase, lang=\"en\", model_type='bert-base-uncased', verbose=False)\n",
    "        scores_bsElectra_bertbase = bert_score.score([sentence]*len(sentence_with_substitutes_bertbase), sentence_with_substitutes_bertbase, lang=\"en\", model_type='google/electra-base-generator', verbose=False)\n",
    "        logging.getLogger('transformers').setLevel(logging.WARNING) # to reset the logging level back to printing warnings\n",
    "        \n",
    "        # create a list of tuples, each tuple containing a substitute and its score\n",
    "        substitute_score_pairs_bsBert_bertbase = list(zip(substitutes_no_dupl_complex_word_no_antonym_bertbase, scores_bsBert_bertbase[0].tolist()))\n",
    "        substitute_score_pairs_bsElectra_bertbase = list(zip(substitutes_no_dupl_complex_word_no_antonym_bertbase, scores_bsElectra_bertbase[0].tolist()))\n",
    "\n",
    "        # sort the list of tuples by the scores (the second element of each tuple), in descending order\n",
    "        sorted_substitute_score_pairs_bsBert_bertbase = sorted(substitute_score_pairs_bsBert_bertbase, key=lambda x: x[1], reverse=True)\n",
    "        sorted_substitute_score_pairs_bsElectra_bertbase = sorted(substitute_score_pairs_bsElectra_bertbase, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # extract the list of substitutes from the sorted pairs\n",
    "        bertscore_ranked_substitutes_only_bsBert_bertbase = [substitute for substitute, _ in sorted_substitute_score_pairs_bsBert_bertbase]\n",
    "        #print(f\"substitutes with Bert based on bertscores with Bert: {bertscore_ranked_substitutes_only_bsBert_bertbase}\\n\")\n",
    "        bertscore_ranked_substitutes_only_bsElectra_bertbase = [substitute for substitute, _ in sorted_substitute_score_pairs_bsElectra_bertbase]\n",
    "        #print(f\"substitutes based on bertscores with Electra for bert-base model : {bertscore_ranked_substitutes_only_bsElectra_bertbase}\\n\")\n",
    "\n",
    "\n",
    "        # limit the substitutes to the 10 first ones for evaluation\n",
    "        top_10_substitutes_bsBert_bertbase = bertscore_ranked_substitutes_only_bsBert_bertbase[:10]\n",
    "        #print(f\"top-10 substitutes with Bert based on bertscores with Bert: {top_10_substitutes_bsBert_bertbase}\\n\")\n",
    "        top_10_substitutes_bsElectra_bertbase = bertscore_ranked_substitutes_only_bsElectra_bertbase[:10]\n",
    "        #print(f\"top-10 substitutes based on bertscores with Electra for bert-base model: {top_10_substitutes_bsElectra_bertbase}\\n\")\n",
    "\n",
    "    else:\n",
    "        top_10_substitutes_bsBert_bertbase  = []\n",
    "        top_10_substitutes_bsElectra_bertbase = []\n",
    "        \n",
    "    \n",
    "    # limit the substitutes to the 5 first ones for concatenation with the top-5 of other models\n",
    "    top_5_substitutes_bsBert_bertbase = top_10_substitutes_bsBert_bertbase[:5]\n",
    "    #print(f\"SS step: top-5 substitutes based on bertscores with Bert for bert-base model: {top_5_substitutes_bsBert_bertbase}\\n\")\n",
    "    top_5_substitutes_bsElectra_bertbase = top_10_substitutes_bsElectra_bertbase[:5]\n",
    "    #print(f\"SS step: top-5 substitutes based on bertscores with Electra for bert-base model: {top_5_substitutes_bsElectra_bertbase}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # for electrabase model:\n",
    "   \n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word_electrabase = sentence.replace(complex_word, lm_tokenizer_electrabase.mask_token)\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    sentences_concat_electrabase = f\"{sentence} {lm_tokenizer_electrabase.sep_token} {sentence_masked_word_electrabase}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline (removing elements without token_str key; as this gave errors in the ELECTRA models) .\n",
    "    top_k = 30\n",
    "    result_electrabase = fill_mask_electrabase(sentences_concat_electrabase, top_k=top_k)\n",
    "    substitutes_electrabase = [substitute[\"token_str\"] for substitute in result_electrabase if \"token_str\" in substitute]\n",
    "    #print(f\"Substitute Generation step: initial substitute list: {substitutes_electrabase}\\n\")\n",
    "\n",
    "\n",
    "    #2: Morphological Generation and Context Adaptation (Morphological Adaptation):  \n",
    "    ## a) remove noise in the substitutes, by ignoring generated substitutes that are empty or that have unwanted punctuation characters or that start with '##' (this returned errors with the ELECTRA model), and lowercase the substitutes (as some models don't lowercase by default)\n",
    "    ## and lowercase all substitutes. Use try/except statement to prevent other character-related problems to happen\n",
    "\n",
    "    punctuation_set = set(string.punctuation) - set('-') # retained hyphens in case tokenizers don't split on hyphenated compounds\n",
    "    punctuation_set.update({'“','”'})   # as these curly quotes appeared in the Electra (SG step) results but were not part of the string set\n",
    "\n",
    "    try:\n",
    "        substitutes_electrabase = [substitute[\"token_str\"].lower().strip() for substitute in result_electrabase if not any(char in punctuation_set for char in substitute[\"token_str\"]) # added .strip as roberta uses a leading space before each substitute\n",
    "                      and not substitute[\"token_str\"].startswith('##') and substitute[\"token_str\"].strip() != \"\"]\n",
    "        # print(f\"Morphological Adaptation step a): substitute list without unwanted punctuation characters for bert-base model: {substitutes_electrabase}\\n\")\n",
    "    except TypeError as error:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    ## b) remove duplicates within the substitute list from the substitute list (duplicates are likely for models that did not lowercase by default)\n",
    "    ## the last mentioned duplicate is removed on purpose, as this may probably be the (previously) uppercased variant of the lowercased substitute (lowercased subs are most likely higher ranked by the model)\n",
    "    substitutes_no_dupl_electrabase = []\n",
    "    for sub in substitutes_electrabase:\n",
    "        if sub not in substitutes_no_dupl_electrabase:\n",
    "            substitutes_no_dupl_electrabase.append(sub)\n",
    "    #print(f\"Morphological Adaptation step b): substitute list without duplicates of substitutes for bert-base model: {substitutes_no_dupl_electrabase}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    ## c) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "\n",
    "    ## first Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## then, remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word_electrabase = []\n",
    "    for substitute in substitutes_no_dupl_electrabase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word_electrabase.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step c): substitute list without duplicates of the complex word nor inflected forms of the complex word for bert-base model: {substitutes_no_dupl_complex_word_electrabase}\\n\")\n",
    "\n",
    "\n",
    "   ## d) remove antonyms of the complex word from the substitute list\n",
    "    ## step 1: get the antonyms of the complex word\n",
    "    antonyms_complex_word = []\n",
    "    for syn in wn.synsets(complex_word_lemma):\n",
    "        for lemma in syn.lemmas():\n",
    "            for antonym in lemma.antonyms():\n",
    "                    antonyms_complex_word.append(antonym.name())\n",
    "\n",
    "    print(f\"Antonyms for complex word '{complex_word}': {antonyms_complex_word}\\n\")\n",
    "\n",
    "    ## step 2: remove antonyms of the complex word from the list with substitutes\n",
    "    substitutes_no_antonyms_electrabase = []\n",
    "    for substitute in substitutes_no_dupl_complex_word_electrabase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma not in antonyms_complex_word:\n",
    "            substitutes_no_antonyms_electrabase.append(substitute)\n",
    "        else:\n",
    "            print(f\"Removed antonym: {substitute}\")\n",
    "    print(f\"Morphological Adaptation step d): substitute list without antonyms of the complex word for electrabase model: {substitutes_no_antonyms_electrabase}\\n\") \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #3: Substitute Selection (SS) by calculating Bert scores: \n",
    "\n",
    "    ## create sentence with the complex word replaced by the substitutes\n",
    "    sentence_with_substitutes_electrabase = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym_electrabase]\n",
    "    #print(f\"List with sentences where complex word is substituted for bert-base model: {sentence_with_substitutes_electrabase\\n\")\n",
    "\n",
    "\n",
    "    ## calculate BERTScores, and rank the substitutes based on these scores\n",
    "    if len(sentence_with_substitutes_electrabase) > 0: # to make sure the list with substitutes is always filled\n",
    "        logging.getLogger('transformers').setLevel(logging.ERROR)  # to prevent the same warnings from being printed x times \n",
    "        scores_bsBert_electrabase = bert_score.score([sentence]*len(sentence_with_substitutes_electrabase), sentence_with_substitutes_electrabase, lang=\"en\", model_type='bert-base-uncased', verbose=False)\n",
    "        scores_bsElectra_electrabase = bert_score.score([sentence]*len(sentence_with_substitutes_electrabase), sentence_with_substitutes_electrabase, lang=\"en\", model_type='google/electra-base-generator', verbose=False)\n",
    "        logging.getLogger('transformers').setLevel(logging.WARNING) # to reset the logging level back to printing warnings\n",
    "        \n",
    "        # create a list of tuples, each tuple containing a substitute and its score\n",
    "        substitute_score_pairs_bsBert_electrabase = list(zip(substitutes_no_dupl_complex_word_no_antonym_electrabase, scores_bsBert_electrabase[0].tolist()))\n",
    "        substitute_score_pairs_bsElectra_electrabase = list(zip(substitutes_no_dupl_complex_word_no_antonym_electrabase, scores_bsElectra_electrabase[0].tolist()))\n",
    "\n",
    "        # sort the list of tuples by the scores (the second element of each tuple), in descending order\n",
    "        sorted_substitute_score_pairs_bsBert_electrabase = sorted(substitute_score_pairs_bsBert_electrabase, key=lambda x: x[1], reverse=True)\n",
    "        sorted_substitute_score_pairs_bsElectra_electrabase = sorted(substitute_score_pairs_bsElectra_electrabase, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # extract the list of substitutes from the sorted pairs\n",
    "        bertscore_ranked_substitutes_only_bsBert_electrabase = [substitute for substitute, _ in sorted_substitute_score_pairs_bsBert_electrabase]\n",
    "        #print(f\"substitutes with Bert based on bertscores with Bert: {bertscore_ranked_substitutes_only_bsBert_electrabase}\\n\")\n",
    "        bertscore_ranked_substitutes_only_bsElectra_electrabase = [substitute for substitute, _ in sorted_substitute_score_pairs_bsElectra_electrabase]\n",
    "        #print(f\"substitutes based on bertscores with Electra for bert-base model : {bertscore_ranked_substitutes_only_bsElectra_electrabase}\\n\")\n",
    "\n",
    "\n",
    "        # limit the substitutes to the 10 first ones for evaluation\n",
    "        top_10_substitutes_bsBert_electrabase = bertscore_ranked_substitutes_only_bsBert_electrabase[:10]\n",
    "        #print(f\"top-10 substitutes with Bert based on bertscores with Bert: {top_10_substitutes_bsBert_electrabase}\\n\")\n",
    "        top_10_substitutes_bsElectra_electrabase = bertscore_ranked_substitutes_only_bsElectra_electrabase[:10]\n",
    "        #print(f\"top-10 substitutes based on bertscores with Electra for bert-base model: {top_10_substitutes_bsElectra_electrabase}\\n\")\n",
    "\n",
    "    else:\n",
    "        top_10_substitutes_bsBert_electrabase  = []\n",
    "        top_10_substitutes_bsElectra_electrabase = []\n",
    "        \n",
    "    \n",
    "   # limit the substitutes to the 5 first ones for concatenation with the top-5 of other models\n",
    "    top_5_substitutes_bsBert_electrabase = top_10_substitutes_bsBert_electrabase[:5]\n",
    "    #print(f\"SS step: top-5 substitutes based on bertscores with Bert for bert-base model: {top_5_substitutes_bsBert_electrabase}\\n\")\n",
    "    top_5_substitutes_bsElectra_electrabase = top_10_substitutes_bsElectra_electrabase[:5]\n",
    "    #print(f\"SS step: top-5 substitutes based on bertscores with Electra for bert-base model: {top_5_substitutes_bsElectra_electrabase}\\n\")\n",
    "\n",
    "   \n",
    "    # zip the four lists in to create a list that sticks to the original order of each sub list\n",
    "    #print('Finding shared duplicates in the four top-5 lists ....')\n",
    "\n",
    "    # create a dictionary to hold the counts\n",
    "    count_dict = {}\n",
    "\n",
    "   \n",
    "    # combine all four lists into a list of lists for easy iteration\n",
    "    all_lists = [top_5_substitutes_bsBert_bertbase, top_5_substitutes_bsElectra_electrabase, top_5_substitutes_bsBert_electrabase, top_5_substitutes_bsElectra_bertbase]\n",
    "    print(all_lists)\n",
    "\n",
    "    # iterate through each list and count occurrences of each element\n",
    "    for lst in all_lists:\n",
    "        for elem in lst:\n",
    "            if elem in count_dict:\n",
    "                count_dict[elem] += 1\n",
    "            else:\n",
    "                count_dict[elem] = 1\n",
    "\n",
    "    # create a list of duplicates by including only those elements that appeared in all four lists\n",
    "    duplicates_all_models = [elem for elem, count in count_dict.items() if count == len(all_lists)]\n",
    "\n",
    "    #print(f\"SS step: shared duplicates in top-5 substitutes lists based on bertscores with Bert and Electra for both bertbase and electrabase models: {duplicates_all_models}\\n\")\n",
    "    \n",
    "    # create a list with non-duplicates\n",
    "    non_duplicates_all_models = [elem for elem, count in count_dict.items() if count == 1]\n",
    "    #print(f\"SS step: non-duplicates in top-5 substitutes lists based on bertscores with Bert and Electra for both bert-base and electra-base models: {non_duplicates_all_models}\\n\")\n",
    "    \n",
    "    #concatenate both lists (duplicates_all_models and non_duplicates_all_models), giving duplicates_all_models priority\n",
    "    top_5_concatenated = duplicates_all_models + non_duplicates_all_models\n",
    "    #print(f\"SS step: concatenated top-5 with prioritized shared duplicates among bert-base and electra-base bertscore results: {top_5_concatenated}\\n\")\n",
    "    \n",
    "    #create the \"second half\" lists (items 6th to 10th) from each of the original top 10 lists\n",
    "    second_half_bsBert_bertbase = top_10_substitutes_bsBert_bertbase[5:]\n",
    "    print(second_half_bsBert_bertbase)\n",
    "    second_half_bsElectra_electrabase = top_10_substitutes_bsElectra_electrabase[5:]\n",
    "    second_half_bsBert_electrabase = top_10_substitutes_bsBert_electrabase[5:]\n",
    "    second_half_bsElectra_bertbase = top_10_substitutes_bsElectra_bertbase[5:]\n",
    "    \n",
    "\n",
    "    # zip the \"second half\" lists\n",
    "    second_half_combined = [item for sublist in zip(second_half_bsBert_bertbase, second_half_bsElectra_electrabase, second_half_bsBert_electrabase, second_half_bsElectra_bertbase) for item in sublist]\n",
    "\n",
    "    # Exclude any items in second_half_combined that are already in top_5_concatenated\n",
    "    second_half_combined = [item for item in second_half_combined if item not in top_5_concatenated]\n",
    "\n",
    "    # Append these items to the final_list\n",
    "    top_5_concatenated += second_half_combined\n",
    "\n",
    "    # Trim the final_list to the top 10 items\n",
    "    final_list_bertscore_top5dup_b = top_5_concatenated[:10]\n",
    "\n",
    "    #print(f\"SS step: final list bertscore based on prioritizing shared duplicates among bert-base and electra-base models: {final_list_bertscore_top5dup_b}\\n\")\n",
    "\n",
    "\n",
    "    #print('------------------------------------------------------------')\n",
    "    \n",
    "    \n",
    "    ## add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + final_list_bertscore_top5dup_b\n",
    "\n",
    "# export the dataframe to a tsv file for evaluation\n",
    "substitutes_df.to_csv('.predictions/test/BertElectrabase_SG_MA_SS_bsBertElectra_top5dup_b.tsv', sep=\"\\t\", index=False, header=False)   \n",
    "print(\"BertElectrabase_SG_MA_SS_bsBertElectra_top5dup_b exported to csv in path './predictions/test/BertElectrabase_SG_MA_SS_bsBertElectra_top5dup_b.tsv'}\\n\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67169937-f669-4bc9-ac4a-971163a439b1",
   "metadata": {
    "id": "c05aa376-692b-4cb1-a6f9-2fce4ed91c3f"
   },
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/BertElectrabase_SG_MA_SS_bsBertElectra_top5dup_b.tsv --output_file ./output/test/BertElectrabase_SG_MA_SS_bsBertElectra_top5dup_b.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d6021c7-755d-4e5d-b657-e608444572af",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/BertElectrabase_SG_MA_SS_bsBertElectra_top5dup_b.tsv\n",
    "OUTPUT file = ./output/test/BertElectrabase_SG_MA_SS_bsBertElectra_top5dup_b.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.6048\n",
    "\n",
    "MAP@3 = 0.3744\n",
    "MAP@5 = 0.2626\n",
    "MAP@10 = 0.1567\n",
    "\n",
    "Potential@3 = 0.7956\n",
    "Potential@5 = 0.8413\n",
    "Potential@10 = 0.8951\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.2661\n",
    "Accuracy@2@top_gold_1 = 0.3897\n",
    "Accuracy@3@top_gold_1 = 0.4408"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mLgHY-bSIREo",
   "metadata": {
    "id": "mLgHY-bSIREo"
   },
   "source": [
    "### Including Robertabase (3 models in total: bertbase, electrabase, robertabase, with bertscores also from these models): not realized due to too much runtime on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MyQIIxSOIXCT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MyQIIxSOIXCT",
    "outputId": "e7e8f223-6dde-4a28-f085-5947891f0bf1"
   },
   "outputs": [],
   "source": [
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "    \n",
    "    # print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    #print(f\"Sentence: {sentence}\")\n",
    "    #print(f\"Complex word: {complex_word}\")\n",
    "    \n",
    "    \n",
    "    # for bertbase model:\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word_bertbase = sentence.replace(complex_word, lm_tokenizer_bertbase.mask_token)\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    sentences_concat_bertbase = f\"{sentence} {lm_tokenizer_bertbase.sep_token} {sentence_masked_word_bertbase}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline (removing elements without token_str key; as this gave errors in the ELECTRA models) .\n",
    "    top_k = 30\n",
    "    result_bertbase = fill_mask_bertbase(sentences_concat_bertbase, top_k=top_k)\n",
    "    substitutes_bertbase = [substitute[\"token_str\"] for substitute in result_bertbase if \"token_str\" in substitute]\n",
    "    #print(f\"Substitute Generation step: initial substitute list: {substitutes_bertbase}\\n\")\n",
    "\n",
    "\n",
    "    #2: Morphological Generation and Context Adaptation (Morphological Adaptation):  \n",
    "    ## a) remove noise in the substitutes, by ignoring generated substitutes that are empty or that have unwanted punctuation characters or that start with '##' (this returned errors with the ELECTRA model), and lowercase the substitutes (as some models don't lowercase by default)\n",
    "    ## and lowercase all substitutes. Use try/except statement to prevent other character-related problems to happen\n",
    "\n",
    "    punctuation_set = set(string.punctuation) - set('-') # retained hyphens in case tokenizers don't split on hyphenated compounds\n",
    "    punctuation_set.update({'“','”'})   # as these curly quotes appeared in the Electra (SG step) results but were not part of the string set\n",
    "\n",
    "    try:\n",
    "        substitutes_bertbase = [substitute[\"token_str\"].lower().strip() for substitute in result_bertbase if not any(char in punctuation_set for char in substitute[\"token_str\"]) # added .strip as roberta uses a leading space before each substitute\n",
    "                      and not substitute[\"token_str\"].startswith('##') and substitute[\"token_str\"].strip() != \"\"]\n",
    "        # print(f\"Morphological Adaptation step a): substitute list without unwanted punctuation characters for bertbase model: {substitutes_bertbase}\\n\")\n",
    "    except TypeError as error:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    ## b) remove duplicates within the substitute list from the substitute list (duplicates are likely for models that did not lowercase by default)\n",
    "    ## the last mentioned duplicate is removed on purpose, as this may probably be the (previously) uppercased variant of the lowercased substitute (lowercased subs are most likely higher ranked by the model)\n",
    "    substitutes_no_dupl_bertbase = []\n",
    "    for sub in substitutes_bertbase:\n",
    "        if sub not in substitutes_no_dupl_bertbase:\n",
    "            substitutes_no_dupl_bertbase.append(sub)\n",
    "    #print(f\"Morphological Adaptation step b): substitute list without duplicates of substitutes for bert-base model: {substitutes_no_dupl_bertbase}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    ## c) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "\n",
    "    ## first Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## then, remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word_bertbase = []\n",
    "    for substitute in substitutes_no_dupl_bertbase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word_bertbase.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step c): substitute list without duplicates of the complex word nor inflected forms of the complex word for bert-base model: {substitutes_no_dupl_complex_word_bertbase}\\n\")\n",
    "\n",
    "\n",
    "      ## d) remove antonyms of the complex word from the substitute list\n",
    "    ## step 1: get the antonyms of the complex word\n",
    "    antonyms_complex_word = []\n",
    "    for syn in wn.synsets(complex_word_lemma):\n",
    "        for lemma in syn.lemmas():\n",
    "            for antonym in lemma.antonyms():\n",
    "                    antonyms_complex_word.append(antonym.name())\n",
    "\n",
    "    print(f\"Antonyms for complex word '{complex_word}': {antonyms_complex_word}\\n\")\n",
    "\n",
    "    ## step 2: remove antonyms of the complex word from the list with substitutes\n",
    "    substitutes_no_antonyms_bertbase = []\n",
    "    for substitute in substitutes_no_dupl_complex_word_bertbase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma not in antonyms_complex_word:\n",
    "            substitutes_no_antonyms_bertbase.append(substitute)\n",
    "        else:\n",
    "            print(f\"Removed antonym: {substitute}\")\n",
    "    print(f\"Morphological Adaptation step d): substitute list without antonyms of the complex word for bertbase model: {substitutes_no_antonyms_bertbase}\\n\") \n",
    "    \n",
    "    \n",
    "    \n",
    "    #3: Substitute Selection (SS) by calculating Bert scores: \n",
    "\n",
    "    ## create sentence with the complex word replaced by the substitutes\n",
    "    sentence_with_substitutes_bertbase = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym_bertbase]\n",
    "    #print(f\"List with sentences where complex word is substituted for bert-base model: {sentence_with_substitutes_bertbase}\\n\")\n",
    "\n",
    "\n",
    "    ## calculate BERTScores, and rank the substitutes based on these scores\n",
    "    if len(sentence_with_substitutes_bertbase) > 0: # to make sure the list with substitutes is always filled\n",
    "        logging.getLogger('transformers').setLevel(logging.ERROR)  # to prevent the same warnings from being printed x times \n",
    "        scores_bsBert_bertbase = bert_score.score([sentence]*len(sentence_with_substitutes_bertbase), sentence_with_substitutes_bertbase, lang=\"en\", model_type='bert-base-uncased', verbose=False)\n",
    "        logging.getLogger('transformers').setLevel(logging.WARNING) # to reset the logging level back to printing warnings\n",
    "        \n",
    "        # create a list of tuples, each tuple containing a substitute and its score\n",
    "        substitute_score_pairs_bsBert_bertbase = list(zip(substitutes_no_dupl_complex_word_no_antonym_bertbase, scores_bsBert_bertbase[0].tolist()))\n",
    "\n",
    "        # sort the list of tuples by the scores (the second element of each tuple), in descending order\n",
    "        sorted_substitute_score_pairs_bsBert_bertbase = sorted(substitute_score_pairs_bsBert_bertbase, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # extract the list of substitutes from the sorted pairs\n",
    "        bertscore_ranked_substitutes_only_bsBert_bertbase = [substitute for substitute, _ in sorted_substitute_score_pairs_bsBert_bertbase]\n",
    "        #print(f\"substitutes with Bert based on bertscores with Bert: {bertscore_ranked_substitutes_only_bsBert_bertbase}\\n\")\n",
    "\n",
    "        # limit the substitutes to the 10 first ones for evaluation\n",
    "        top_10_substitutes_bsBert_bertbase = bertscore_ranked_substitutes_only_bsBert_bertbase[:10]\n",
    "        #print(f\"top-10 substitutes with Bert based on bertscores with Bert: {top_10_substitutes_bsBert_bertbase}\\n\")\n",
    "       \n",
    "\n",
    "    else:\n",
    "        top_10_substitutes_bsBert_bertbase  = []\n",
    "        \n",
    "    \n",
    "    # limit the substitutes to the 5 first ones for concatenation with the top-5 of other models\n",
    "    top_5_substitutes_bsBert_bertbase = top_10_substitutes_bsBert_bertbase[:5]\n",
    "    print(f\"SS step: top-5 substitutes based on bertscores with Bert for bert-base model: {top_5_substitutes_bsBert_bertbase}\\n\")\n",
    "       \n",
    "    \n",
    "    # for electrabase model:\n",
    "   \n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word_electrabase = sentence.replace(complex_word, lm_tokenizer_electrabase.mask_token)\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    sentences_concat_electrabase = f\"{sentence} {lm_tokenizer_electrabase.sep_token} {sentence_masked_word_electrabase}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline (removing elements without token_str key; as this gave errors in the ELECTRA models) .\n",
    "    top_k = 30\n",
    "    result_electrabase = fill_mask_electrabase(sentences_concat_electrabase, top_k=top_k)\n",
    "    substitutes_electrabase = [substitute[\"token_str\"] for substitute in result_electrabase if \"token_str\" in substitute]\n",
    "    #print(f\"Substitute Generation step: initial substitute list for electrabase model: {substitutes_electrabase}\\n\")\n",
    "\n",
    "\n",
    "    #2: Morphological Generation and Context Adaptation (Morphological Adaptation):  \n",
    "    ## a) remove noise in the substitutes, by ignoring generated substitutes that are empty or that have unwanted punctuation characters or that start with '##' (this returned errors with the ELECTRA model), and lowercase the substitutes (as some models don't lowercase by default)\n",
    "    ## and lowercase all substitutes. Use try/except statement to prevent other character-related problems to happen\n",
    "\n",
    "    punctuation_set = set(string.punctuation) - set('-') # retained hyphens in case tokenizers don't split on hyphenated compounds\n",
    "    punctuation_set.update({'“','”'})   # as these curly quotes appeared in the Electra (SG step) results but were not part of the string set\n",
    "\n",
    "    try:\n",
    "        substitutes_electrabase = [substitute[\"token_str\"].lower().strip() for substitute in result_electrabase if not any(char in punctuation_set for char in substitute[\"token_str\"]) # added .strip as roberta uses a leading space before each substitute\n",
    "                      and not substitute[\"token_str\"].startswith('##') and substitute[\"token_str\"].strip() != \"\"]\n",
    "        # print(f\"Morphological Adaptation step a): substitute list without unwanted punctuation characters for electrabase model: {substitutes_electrabase}\\n\")\n",
    "    except TypeError as error:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    ## b) remove duplicates within the substitute list from the substitute list (duplicates are likely for models that did not lowercase by default)\n",
    "    ## the last mentioned duplicate is removed on purpose, as this may probably be the (previously) uppercased variant of the lowercased substitute (lowercased subs are most likely higher ranked by the model)\n",
    "    substitutes_no_dupl_electrabase = []\n",
    "    for sub in substitutes_electrabase:\n",
    "        if sub not in substitutes_no_dupl_electrabase:\n",
    "            substitutes_no_dupl_electrabase.append(sub)\n",
    "    #print(f\"Morphological Adaptation step b): substitute list without duplicates of substitutes for electrabase model: {substitutes_no_dupl_electrabase}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    ## c) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "\n",
    "    ## first Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## then, remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word_electrabase = []\n",
    "    for substitute in substitutes_no_dupl_electrabase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word_electrabase.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step c): substitute list without duplicates of the complex word nor inflected forms of the complex word for electrabase model: {substitutes_no_dupl_complex_word_electrabase}\\n\")\n",
    "\n",
    "\n",
    "   ## d) remove antonyms of the complex word from the substitute list\n",
    "    ## step 1: get the antonyms of the complex word\n",
    "    antonyms_complex_word = []\n",
    "    for syn in wn.synsets(complex_word_lemma):\n",
    "        for lemma in syn.lemmas():\n",
    "            for antonym in lemma.antonyms():\n",
    "                    antonyms_complex_word.append(antonym.name())\n",
    "\n",
    "    print(f\"Antonyms for complex word '{complex_word}': {antonyms_complex_word}\\n\")\n",
    "\n",
    "    ## step 2: remove antonyms of the complex word from the list with substitutes\n",
    "    substitutes_no_antonyms_electrabase = []\n",
    "    for substitute in substitutes_no_dupl_complex_word_electrabase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma not in antonyms_complex_word:\n",
    "            substitutes_no_antonyms_electrabase.append(substitute)\n",
    "        else:\n",
    "            print(f\"Removed antonym: {substitute}\")\n",
    "    print(f\"Morphological Adaptation step d): substitute list without antonyms of the complex word for electrabase model: {substitutes_no_antonyms_electrabase}\\n\") \n",
    "\n",
    "\n",
    "    #3: Substitute Selection (SS) by calculating Bert scores: \n",
    "\n",
    "    ## create sentence with the complex word replaced by the substitutes\n",
    "    sentence_with_substitutes_electrabase = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym_electrabase]\n",
    "    #print(f\"List with sentences where complex word is substituted for electrabase model: {sentence_with_substitutes_electrabase\\n\")\n",
    "\n",
    "\n",
    "    ## calculate BERTScores, and rank the substitutes based on these scores\n",
    "    if len(sentence_with_substitutes_electrabase) > 0: # to make sure the list with substitutes is always filled\n",
    "        logging.getLogger('transformers').setLevel(logging.ERROR)  # to prevent the same warnings from being printed x times \n",
    "        scores_bsElectra_electrabase = bert_score.score([sentence]*len(sentence_with_substitutes_electrabase), sentence_with_substitutes_electrabase, lang=\"en\", model_type='google/electra-base-generator', verbose=False)\n",
    "        logging.getLogger('transformers').setLevel(logging.WARNING) # to reset the logging level back to printing warnings\n",
    "        \n",
    "        # create a list of tuples, each tuple containing a substitute and its score\n",
    "        substitute_score_pairs_bsElectra_electrabase = list(zip(substitutes_no_dupl_complex_word_no_antonym_electrabase, scores_bsElectra_electrabase[0].tolist()))\n",
    "\n",
    "        # sort the list of tuples by the scores (the second element of each tuple), in descending order\n",
    "        sorted_substitute_score_pairs_bsElectra_electrabase = sorted(substitute_score_pairs_bsElectra_electrabase, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # extract the list of substitutes from the sorted pairs\n",
    "        bertscore_ranked_substitutes_only_bsElectra_electrabase = [substitute for substitute, _ in sorted_substitute_score_pairs_bsElectra_electrabase]\n",
    "        #print(f\"substitutes based on bertscores with Electra for electrabase model : {bertscore_ranked_substitutes_only_bsElectra_electrabase}\\n\")\n",
    "\n",
    "\n",
    "        # limit the substitutes to the 10 first ones for evaluation\n",
    "        top_10_substitutes_bsElectra_electrabase = bertscore_ranked_substitutes_only_bsElectra_electrabase[:10]\n",
    "        #print(f\"top-10 substitutes based on bertscores with Electra for electrabase model: {top_10_substitutes_bsElectra_electrabase}\\n\")\n",
    "\n",
    "    else:\n",
    "        top_10_substitutes_bsElectra_electrabase = []\n",
    "        \n",
    "    \n",
    "   # limit the substitutes to the 5 first ones for concatenation with the top-5 of other models\n",
    "    top_5_substitutes_bsElectra_electrabase = top_10_substitutes_bsElectra_electrabase[:5]\n",
    "    print(f\"SS step: top-5 substitutes based on bertscores with Electra for electrabase model: {top_5_substitutes_bsElectra_electrabase}\\n\")\n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "    # for robertabase model:\n",
    "   \n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word_robertabase = sentence.replace(complex_word, lm_tokenizer_robertabase.mask_token)\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    sentences_concat_robertabase = f\"{sentence} {lm_tokenizer_robertabase.sep_token} {sentence_masked_word_robertabase}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline (removing elements without token_str key; as this gave errors in the ELECTRA models) .\n",
    "    top_k = 30\n",
    "    result_robertabase = fill_mask_robertabase(sentences_concat_robertabase, top_k=top_k)\n",
    "    substitutes_robertabase = [substitute[\"token_str\"] for substitute in result_robertabase if \"token_str\" in substitute]\n",
    "    #print(f\"Substitute Generation step: initial substitute list: {substitutes_robertabase}\\n\")\n",
    "\n",
    "\n",
    "    #2: Morphological Generation and Context Adaptation (Morphological Adaptation):  \n",
    "    ## a) remove noise in the substitutes, by ignoring generated substitutes that are empty or that have unwanted punctuation characters or that start with '##' (this returned errors with the ELECTRA model), and lowercase the substitutes (as some models don't lowercase by default)\n",
    "    ## and lowercase all substitutes. Use try/except statement to prevent other character-related problems to happen\n",
    "\n",
    "    punctuation_set = set(string.punctuation) - set('-') # retained hyphens in case tokenizers don't split on hyphenated compounds\n",
    "    punctuation_set.update({'“','”'})   # as these curly quotes appeared in the Electra (SG step) results but were not part of the string set\n",
    "\n",
    "    try:\n",
    "        substitutes_robertabase = [substitute[\"token_str\"].lower().strip() for substitute in result_robertabase if not any(char in punctuation_set for char in substitute[\"token_str\"]) # added .strip as roberta uses a leading space before each substitute\n",
    "                      and not substitute[\"token_str\"].startswith('##') and substitute[\"token_str\"].strip() != \"\"]\n",
    "        # print(f\"Morphological Adaptation step a): substitute list without unwanted punctuation characters for robertabase model: {substitutes_robertabase\\n\")\n",
    "    except TypeError as error:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## b) remove duplicates within the substitute list from the substitute list (duplicates are likely for models that did not lowercase by default)\n",
    "    ## the last mentioned duplicate is removed on purpose, as this may probably be the (previously) uppercased variant of the lowercased substitute (lowercased subs are most likely higher ranked by the model)\n",
    "    substitutes_no_dupl_robertabase= []\n",
    "    for sub in substitutes_robertabase:\n",
    "        if sub not in substitutes_no_dupl_robertabase:\n",
    "            substitutes_no_dupl_robertabase.append(sub)\n",
    "    #print(f\"Morphological Adaptation step b): substitute list without duplicates of substitutes for bert-base model: {substitutes_no_dupl_robertabase\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    ## c) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "\n",
    "    ## first Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## then, remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word_robertabase = []\n",
    "    for substitute in substitutes_no_dupl_robertabase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word_robertabase.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step c): substitute list without duplicates of the complex word nor inflected forms of the complex word for robertabase model: {substitutes_no_dupl_complex_word_robertabase}\\n\")\n",
    "\n",
    "\n",
    "    ## d) remove antonyms of the complex word from the substitute list\n",
    "    ## step 1: get the antonyms of the complex word\n",
    "    antonyms_complex_word = []\n",
    "    for syn in wn.synsets(complex_word_lemma):\n",
    "        for lemma in syn.lemmas():\n",
    "            for antonym in lemma.antonyms():\n",
    "                    antonyms_complex_word.append(antonym.name())\n",
    "\n",
    "    print(f\"Antonyms for complex word '{complex_word}': {antonyms_complex_word}\\n\")\n",
    "\n",
    "    ## step 2: remove antonyms of the complex word from the list with substitutes\n",
    "    substitutes_no_antonyms_robertabase = []\n",
    "    for substitute in substitutes_no_dupl_complex_word_robertabase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma not in antonyms_complex_word:\n",
    "            substitutes_no_antonyms_robertabase.append(substitute)\n",
    "        else:\n",
    "            print(f\"Removed antonym: {substitute}\")\n",
    "    print(f\"Morphological Adaptation step d): substitute list without antonyms of the complex word for robertabase model: {substitutes_no_antonyms_robertabase}\\n\") \n",
    "\n",
    " \n",
    "    #3: Substitute Selection (SS) by calculating Bert scores: \n",
    "\n",
    "    ## create sentence with the complex word replaced by the substitutes\n",
    "    sentence_with_substitutes_robertabase = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym_robertabase]\n",
    "    #print(f\"List with sentences where complex word is substituted for robertabase model: {sentence_with_substitutes_robertabase\\n\")\n",
    "\n",
    "\n",
    "    ## calculate BERTScores, and rank the substitutes based on these scores\n",
    "    if len(sentence_with_substitutes_robertabase) > 0: # to make sure the list with substitutes is always filled\n",
    "        logging.getLogger('transformers').setLevel(logging.ERROR)  # to prevent the same warnings from being printed x times \n",
    "        scores_bsRoberta_robertabase = bert_score.score([sentence]*len(sentence_with_substitutes_robertabase), sentence_with_substitutes_robertabase, lang=\"en\", model_type='roberta-base', verbose=False)\n",
    "        logging.getLogger('transformers').setLevel(logging.WARNING) # to reset the logging level back to printing warnings\n",
    "        \n",
    "        # create a list of tuples, each tuple containing a substitute and its score\n",
    "        substitute_score_pairs_bsRoberta_robertabase = list(zip(substitutes_no_dupl_complex_word_no_antonym_robertabase, scores_bsRoberta_robertabase[0].tolist()))\n",
    "       \n",
    "        # sort the list of tuples by the scores (the second element of each tuple), in descending order\n",
    "        sorted_substitute_score_pairs_bsRoberta_robertabase = sorted(substitute_score_pairs_bsRoberta_robertabase, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "\n",
    "        # extract the list of substitutes from the sorted pairs\n",
    "        bertscore_ranked_substitutes_only_bsRoberta_robertabase = [substitute for substitute, _ in sorted_substitute_score_pairs_bsRoberta_robertabase]\n",
    "        #print(f\"substitutes based on bertscores with Roberta for robertabase model: {bertscore_ranked_substitutes_only_bsRoberta_robertabase}\\n\")\n",
    "        \n",
    "\n",
    "\n",
    "        # limit the substitutes to the 10 first ones for evaluation\n",
    "        top_10_substitutes_bsRoberta_robertabase = bertscore_ranked_substitutes_only_bsRoberta_robertabase[:10]\n",
    "        #print(f\"top-10 substitutes based on bertscores with Roberta for robertabase model: {top_10_substitutes_bsRoberta_robertabase}\\n\")\n",
    "       \n",
    "\n",
    "    else:\n",
    "        top_10_substitutes_bsRoberta_robertabase  = []\n",
    "        \n",
    "    \n",
    "   # limit the substitutes to the 5 first ones for concatenation with the top-5 of other models\n",
    "    top_5_substitutes_bsRoberta_robertabase = top_10_substitutes_bsRoberta_robertabase[:5]\n",
    "    print(f\"SS step: top-5 substitutes based on bertscores with Roberta for robertabase model: {top_5_substitutes_bsRoberta_robertabase}\\n\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # concatenate best results of bertbase, electrabase, and robertabase models:\n",
    "    # zip the three lists to create a list that sticks to the original order of each sub list\n",
    "    #print('Finding shared duplicates in the three top-5 lists ....')\n",
    "\n",
    "    # create a dictionary to hold the counts\n",
    "    count_dict = {}\n",
    "\n",
    "    # combine all four lists into a list of lists for easy iteration\n",
    "    all_lists = [top_5_substitutes_bsBert_bertbase, top_5_substitutes_bsElectra_electrabase, top_5_substitutes_bsRoberta_robertabase]\n",
    "\n",
    "    # iterate through each list and count occurrences of each element\n",
    "    for lst in all_lists:\n",
    "        #print(f\"Current list: {lst}\")  \n",
    "        for elem in lst:\n",
    "            if elem in count_dict:\n",
    "                count_dict[elem] += 1\n",
    "            else:\n",
    "                count_dict[elem] = 1\n",
    "\n",
    "    # print the count_dict to see the counts of each element\n",
    "    #print(f\"Count dictionary: {count_dict}\")   \n",
    "\n",
    "    # create a list of duplicates by including only those elements that appeared in all three lists\n",
    "    duplicates_all_models = [elem for elem, count in count_dict.items() if count == len(all_lists)]\n",
    "\n",
    "    print(f\"SS step: shared duplicates in top-5 substitutes lists based on bertscores with Bert, Electra, and Roberta for bertbase, electrabase, and robertabase models: {duplicates_all_models}\\n\")\n",
    "    \n",
    "    # create a list with non-duplicates\n",
    "    non_duplicates_all_models = [elem for elem, count in count_dict.items() if count == 1]\n",
    "    #print(f\"SS step: non-duplicates in top-5 substitutes lists based on bertscores with Bert, Electra, and Roberta for bertbase, electrabase and robertabase models:  {non_duplicates_all_models}\\n\")\n",
    "    \n",
    "    #concatenate both lists (duplicates_all_models and non_duplicates_all_models), giving duplicates_all_models priority\n",
    "    top_5_concatenated = duplicates_all_models + non_duplicates_all_models\n",
    "    print(f\"SS step: concatenated top-5 with prioritized shared duplicates among bertbase, electrabase, and robertabase bertscore results: {top_5_concatenated}\\n\")\n",
    "    \n",
    "    #create the \"second half\" lists (items 6th to 10th) from each of the original top 10 lists\n",
    "    second_half_bsBert_bertbase = top_10_substitutes_bsBert_bertbase[5:]\n",
    "    second_half_bsElectra_electrabase = top_10_substitutes_bsElectra_electrabase[5:]\n",
    "    second_half_bsRoberta_robertabase = top_10_substitutes_bsRoberta_robertabase[5:]\n",
    "\n",
    "    # zip the \"second half\" lists\n",
    "    second_half_combined = [item for sublist in zip(second_half_bsBert_bertbase, second_half_bsElectra_electrabase, second_half_bsRoberta_robertabase)  for item in sublist]\n",
    "\n",
    "    # Exclude any items in second_half_combined that are already in top_5_concatenated\n",
    "    second_half_combined = [item for item in second_half_combined if item not in top_5_concatenated]\n",
    "\n",
    "    # Append these items to the final_list\n",
    "    top_5_concatenated += second_half_combined\n",
    "\n",
    "    # Trim the final_list to the top 10 items\n",
    "    final_list_bertscore_top5dup_3models = top_5_concatenated[:10]\n",
    "\n",
    "    print(f\"SS step: final list bertscore based on prioritizing shared duplicates among bertbase, electrabase, and robertabase models: {final_list_bertscore_top5dup_3models}\\n\")\n",
    "\n",
    "\n",
    "    print('------------------------------------------------------------')\n",
    "    \n",
    "    \n",
    "    ## add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + final_list_bertscore_top5dup_3models\n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file for evaluation\n",
    "substitutes_df.to_csv('./predictions/test/BertElectraRobertabase_SG_MA_SS_bsBertElectraRoberta_top5dup.tsv', sep=\"\\t\", index=False, header=False)   \n",
    "print(\"/BertElectraRobertabase_SG_MA_SS_bsBertElectraRoberta_top5dup exported to csv in path './predictions/test//BertElectraRobertabase_SG_MA_SS_bsBertElectraRoberta_top5dup.tsv'}\\n\")  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a4aff-f3aa-42db-b418-a67efd19cf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/BertElectraRobertabase_SG_MA_SS_bsBertElectraRoberta_top5dup.tsv --output_file ./output/test/BertElectraRobertabase_SG_MA_SS_bsBertElectraRoberta_top5dup.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42db65e8-03d6-40c3-a0f1-a50a64ab0c54",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/BertElectraRobertabase_SG_MA_SS_bsBertElectraRoberta_top5dup.tsv\n",
    "OUTPUT file = ./output/test/BertElectraRobertabase_SG_MA_SS_bsBertElectraRoberta_top5dup.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.5994\n",
    "\n",
    "MAP@3 = 0.3747\n",
    "MAP@5 = 0.2606\n",
    "MAP@10 = 0.1643\n",
    "\n",
    "Potential@3 = 0.7688\n",
    "Potential@5 = 0.8306\n",
    "Potential@10 = 0.9435\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.2876\n",
    "Accuracy@2@top_gold_1 = 0.387\n",
    "Accuracy@3@top_gold_1 = 0.4327"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fcdd00-6ca0-4476-829f-9261398b92d7",
   "metadata": {},
   "source": [
    "top 5 of best 2 models electrabase bsElectra and bertbase bsBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d0a246-25c1-4484-b4c9-3ed4a7001dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "    \n",
    "    # print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    #print(f\"Sentence: {sentence}\")\n",
    "    #print(f\"Complex word: {complex_word}\")\n",
    "    \n",
    "    \n",
    "    # for bertbase model:\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word_bertbase = sentence.replace(complex_word, lm_tokenizer_bertbase.mask_token)\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    sentences_concat_bertbase = f\"{sentence} {lm_tokenizer_bertbase.sep_token} {sentence_masked_word_bertbase}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline (removing elements without token_str key; as this gave errors in the ELECTRA models) .\n",
    "    top_k = 30\n",
    "    result_bertbase = fill_mask_bertbase(sentences_concat_bertbase, top_k=top_k)\n",
    "    substitutes_bertbase = [substitute[\"token_str\"] for substitute in result_bertbase if \"token_str\" in substitute]\n",
    "    #print(f\"Substitute Generation step: initial substitute list: {substitutes_bertbase}\\n\")\n",
    "\n",
    "\n",
    "    #2: Morphological Generation and Context Adaptation (Morphological Adaptation):  \n",
    "    ## a) remove noise in the substitutes, by ignoring generated substitutes that are empty or that have unwanted punctuation characters or that start with '##' (this returned errors with the ELECTRA model), and lowercase the substitutes (as some models don't lowercase by default)\n",
    "    ## and lowercase all substitutes. Use try/except statement to prevent other character-related problems to happen\n",
    "\n",
    "    punctuation_set = set(string.punctuation) - set('-') # retained hyphens in case tokenizers don't split on hyphenated compounds\n",
    "    punctuation_set.update({'“','”'})   # as these curly quotes appeared in the Electra (SG step) results but were not part of the string set\n",
    "\n",
    "    try:\n",
    "        substitutes_bertbase = [substitute[\"token_str\"].lower().strip() for substitute in result_bertbase if not any(char in punctuation_set for char in substitute[\"token_str\"]) # added .strip as roberta uses a leading space before each substitute\n",
    "                      and not substitute[\"token_str\"].startswith('##') and substitute[\"token_str\"].strip() != \"\"]\n",
    "        # print(f\"Morphological Adaptation step a): substitute list without unwanted punctuation characters for bertbase model: {substitutes_bertbase}\\n\")\n",
    "    except TypeError as error:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    ## b) remove duplicates within the substitute list from the substitute list (duplicates are likely for models that did not lowercase by default)\n",
    "    ## the last mentioned duplicate is removed on purpose, as this may probably be the (previously) uppercased variant of the lowercased substitute (lowercased subs are most likely higher ranked by the model)\n",
    "    substitutes_no_dupl_bertbase = []\n",
    "    for sub in substitutes_bertbase:\n",
    "        if sub not in substitutes_no_dupl_bertbase:\n",
    "            substitutes_no_dupl_bertbase.append(sub)\n",
    "    #print(f\"Morphological Adaptation step b): substitute list without duplicates of substitutes for bertbase model: {substitutes_no_dupl_bertbase}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    ## c) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "\n",
    "    ## first Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## then, remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word_bertbase = []\n",
    "    for substitute in substitutes_no_dupl_bertbase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word_bertbase.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step c): substitute list without duplicates of the complex word nor inflected forms of the complex word for bertbase model: {substitutes_no_dupl_complex_word_bertbase}\\n\")\n",
    "\n",
    "\n",
    "      ## d) remove antonyms of the complex word from the substitute list\n",
    "    ## step 1: get the antonyms of the complex word\n",
    "    antonyms_complex_word = []\n",
    "    for syn in wn.synsets(complex_word_lemma):\n",
    "        for lemma in syn.lemmas():\n",
    "            for antonym in lemma.antonyms():\n",
    "                    antonyms_complex_word.append(antonym.name())\n",
    "\n",
    "    print(f\"Antonyms for complex word '{complex_word}': {antonyms_complex_word}\\n\")\n",
    "\n",
    "    ## step 2: remove antonyms of the complex word from the list with substitutes\n",
    "    substitutes_no_antonyms_bertbase = []\n",
    "    for substitute in substitutes_no_dupl_complex_word_bertbase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma not in antonyms_complex_word:\n",
    "            substitutes_no_antonyms_bertbase.append(substitute)\n",
    "        else:\n",
    "            print(f\"Removed antonym: {substitute}\")\n",
    "    print(f\"Morphological Adaptation step d): substitute list without antonyms of the complex word for bertbase model: {substitutes_no_antonyms_bertbase}\\n\") \n",
    "    \n",
    "    \n",
    "    \n",
    "    #3: Substitute Selection (SS) by calculating Bert scores: \n",
    "\n",
    "    ## create sentence with the complex word replaced by the substitutes\n",
    "    sentence_with_substitutes_bertbase = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym_bertbase]\n",
    "    #print(f\"List with sentences where complex word is substituted for bertbase model: {sentence_with_substitutes_bertbase}\\n\")\n",
    "\n",
    "\n",
    "    ## calculate BERTScores, and rank the substitutes based on these scores\n",
    "    if len(sentence_with_substitutes_bertbase) > 0: # to make sure the list with substitutes is always filled\n",
    "        logging.getLogger('transformers').setLevel(logging.ERROR)  # to prevent the same warnings from being printed x times \n",
    "        scores_bsBert_bertbase = bert_score.score([sentence]*len(sentence_with_substitutes_bertbase), sentence_with_substitutes_bertbase, lang=\"en\", model_type='bert-base-uncased', verbose=False)\n",
    "        #scores_bsElectra_bertbase = bert_score.score([sentence]*len(sentence_with_substitutes_bertbase), sentence_with_substitutes_bertbase, lang=\"en\", model_type='google/electra-base-generator', verbose=False)\n",
    "        logging.getLogger('transformers').setLevel(logging.WARNING) # to reset the logging level back to printing warnings\n",
    "        \n",
    "        # create a list of tuples, each tuple containing a substitute and its score\n",
    "        substitute_score_pairs_bsBert_bertbase = list(zip(substitutes_no_dupl_complex_word_no_antonym_bertbase, scores_bsBert_bertbase[0].tolist()))\n",
    "        #substitute_score_pairs_bsElectra_bertbase = list(zip(substitutes_no_dupl_complex_word_no_antonym_bertbase, scores_bsElectra_bertbase[0].tolist()))\n",
    "\n",
    "        # sort the list of tuples by the scores (the second element of each tuple), in descending order\n",
    "        sorted_substitute_score_pairs_bsBert_bertbase = sorted(substitute_score_pairs_bsBert_bertbase, key=lambda x: x[1], reverse=True)\n",
    "        #sorted_substitute_score_pairs_bsElectra_bertbase = sorted(substitute_score_pairs_bsElectra_bertbase, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # extract the list of substitutes from the sorted pairs\n",
    "        bertscore_ranked_substitutes_only_bsBert_bertbase = [substitute for substitute, _ in sorted_substitute_score_pairs_bsBert_bertbase]\n",
    "        #print(f\"substitutes with Bert based on bertscores with Bert: {bertscore_ranked_substitutes_only_bsBert_bertbase}\\n\")\n",
    "        #bertscore_ranked_substitutes_only_bsElectra_bertbase = [substitute for substitute, _ in sorted_substitute_score_pairs_bsElectra_bertbase]\n",
    "        #print(f\"substitutes based on bertscores with Electra for bert-base model : {bertscore_ranked_substitutes_only_bsElectra_bertbase}\\n\")\n",
    "\n",
    "\n",
    "        # limit the substitutes to the 10 first ones for evaluation\n",
    "        top_10_substitutes_bsBert_bertbase = bertscore_ranked_substitutes_only_bsBert_bertbase[:10]\n",
    "        #print(f\"top-10 substitutes with Bert based on bertscores with Bert: {top_10_substitutes_bsBert_bertbase}\\n\")\n",
    "        #top_10_substitutes_bsElectra_bertbase = bertscore_ranked_substitutes_only_bsElectra_bertbase[:10]\n",
    "        #print(f\"top-10 substitutes based on bertscores with Electra for bert-base model: {top_10_substitutes_bsElectra_bertbase}\\n\")\n",
    "\n",
    "    else:\n",
    "        top_10_substitutes_bsBert_bertbase  = []\n",
    "        #top_10_substitutes_bsElectra_bertbase = []\n",
    "        \n",
    "    \n",
    "    # limit the substitutes to the 5 first ones for concatenation with the top-5 of other models\n",
    "    top_5_substitutes_bsBert_bertbase = top_10_substitutes_bsBert_bertbase[:5]\n",
    "    #print(f\"SS step: top-5 substitutes based on bertscores with Bert for bert-base model: {top_5_substitutes_bsBert_bertbase}\\n\")\n",
    "    #top_5_substitutes_bsElectra_bertbase = top_10_substitutes_bsElectra_bertbase[:5]\n",
    "    #print(f\"SS step: top-5 substitutes based on bertscores with Electra for bert-base model: {top_5_substitutes_bsElectra_bertbase}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # for electrabase model:\n",
    "   \n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word_electrabase = sentence.replace(complex_word, lm_tokenizer_electrabase.mask_token)\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    sentences_concat_electrabase = f\"{sentence} {lm_tokenizer_electrabase.sep_token} {sentence_masked_word_electrabase}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline (removing elements without token_str key; as this gave errors in the ELECTRA models) .\n",
    "    top_k = 30\n",
    "    result_electrabase = fill_mask_electrabase(sentences_concat_electrabase, top_k=top_k)\n",
    "    substitutes_electrabase = [substitute[\"token_str\"] for substitute in result_electrabase if \"token_str\" in substitute]\n",
    "    #print(f\"Substitute Generation step: initial substitute list: {substitutes_electrabase}\\n\")\n",
    "\n",
    "\n",
    "    #2: Morphological Generation and Context Adaptation (Morphological Adaptation):  \n",
    "    ## a) remove noise in the substitutes, by ignoring generated substitutes that are empty or that have unwanted punctuation characters or that start with '##' (this returned errors with the ELECTRA model), and lowercase the substitutes (as some models don't lowercase by default)\n",
    "    ## and lowercase all substitutes. Use try/except statement to prevent other character-related problems to happen\n",
    "\n",
    "    punctuation_set = set(string.punctuation) - set('-') # retained hyphens in case tokenizers don't split on hyphenated compounds\n",
    "    punctuation_set.update({'“','”'})   # as these curly quotes appeared in the Electra (SG step) results but were not part of the string set\n",
    "\n",
    "    try:\n",
    "        substitutes_electrabase = [substitute[\"token_str\"].lower().strip() for substitute in result_electrabase if not any(char in punctuation_set for char in substitute[\"token_str\"]) # added .strip as roberta uses a leading space before each substitute\n",
    "                      and not substitute[\"token_str\"].startswith('##') and substitute[\"token_str\"].strip() != \"\"]\n",
    "        # print(f\"Morphological Adaptation step a): substitute list without unwanted punctuation characters for bert-base model: {substitutes_electrabase}\\n\")\n",
    "    except TypeError as error:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    ## b) remove duplicates within the substitute list from the substitute list (duplicates are likely for models that did not lowercase by default)\n",
    "    ## the last mentioned duplicate is removed on purpose, as this may probably be the (previously) uppercased variant of the lowercased substitute (lowercased subs are most likely higher ranked by the model)\n",
    "    substitutes_no_dupl_electrabase = []\n",
    "    for sub in substitutes_electrabase:\n",
    "        if sub not in substitutes_no_dupl_electrabase:\n",
    "            substitutes_no_dupl_electrabase.append(sub)\n",
    "    #print(f\"Morphological Adaptation step b): substitute list without duplicates of substitutes for electrabase model: {substitutes_no_dupl_electrabase}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    ## c) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "\n",
    "    ## first Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## then, remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word_electrabase = []\n",
    "    for substitute in substitutes_no_dupl_electrabase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word_electrabase.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step c): substitute list without duplicates of the complex word nor inflected forms of the complex word for electrabase model: {substitutes_no_dupl_complex_word_electrabase}\\n\")\n",
    "\n",
    "\n",
    "   ## d) remove antonyms of the complex word from the substitute list\n",
    "    ## step 1: get the antonyms of the complex word\n",
    "    antonyms_complex_word = []\n",
    "    for syn in wn.synsets(complex_word_lemma):\n",
    "        for lemma in syn.lemmas():\n",
    "            for antonym in lemma.antonyms():\n",
    "                    antonyms_complex_word.append(antonym.name())\n",
    "\n",
    "    print(f\"Antonyms for complex word '{complex_word}': {antonyms_complex_word}\\n\")\n",
    "\n",
    "    ## step 2: remove antonyms of the complex word from the list with substitutes\n",
    "    substitutes_no_antonyms_electrabase = []\n",
    "    for substitute in substitutes_no_dupl_complex_word_electrabase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma not in antonyms_complex_word:\n",
    "            substitutes_no_antonyms_electrabase.append(substitute)\n",
    "        else:\n",
    "            print(f\"Removed antonym: {substitute}\")\n",
    "    print(f\"Morphological Adaptation step d): substitute list without antonyms of the complex word for electrabase model: {substitutes_no_antonyms_electrabase}\\n\") \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #3: Substitute Selection (SS) by calculating Bert scores: \n",
    "\n",
    "    ## create sentence with the complex word replaced by the substitutes\n",
    "    sentence_with_substitutes_electrabase = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym_electrabase]\n",
    "    #print(f\"List with sentences where complex word is substituted for electrabase model: {sentence_with_substitutes_electrabase\\n\")\n",
    "\n",
    "\n",
    "    ## calculate BERTScores, and rank the substitutes based on these scores\n",
    "    if len(sentence_with_substitutes_electrabase) > 0: # to make sure the list with substitutes is always filled\n",
    "        logging.getLogger('transformers').setLevel(logging.ERROR)  # to prevent the same warnings from being printed x times \n",
    "        #scores_bsBert_electrabase = bert_score.score([sentence]*len(sentence_with_substitutes_electrabase), sentence_with_substitutes_electrabase, lang=\"en\", model_type='bert-base-uncased', verbose=False)\n",
    "        scores_bsElectra_electrabase = bert_score.score([sentence]*len(sentence_with_substitutes_electrabase), sentence_with_substitutes_electrabase, lang=\"en\", model_type='google/electra-base-generator', verbose=False)\n",
    "        logging.getLogger('transformers').setLevel(logging.WARNING) # to reset the logging level back to printing warnings\n",
    "        \n",
    "        # create a list of tuples, each tuple containing a substitute and its score\n",
    "        #substitute_score_pairs_bsBert_electrabase = list(zip(substitutes_no_dupl_complex_word_no_antonym_electrabase, scores_bsBert_electrabase[0].tolist()))\n",
    "        substitute_score_pairs_bsElectra_electrabase = list(zip(substitutes_no_dupl_complex_word_no_antonym_electrabase, scores_bsElectra_electrabase[0].tolist()))\n",
    "\n",
    "        # sort the list of tuples by the scores (the second element of each tuple), in descending order\n",
    "        #sorted_substitute_score_pairs_bsBert_electrabase = sorted(substitute_score_pairs_bsBert_electrabase, key=lambda x: x[1], reverse=True)\n",
    "        sorted_substitute_score_pairs_bsElectra_electrabase = sorted(substitute_score_pairs_bsElectra_electrabase, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # extract the list of substitutes from the sorted pairs\n",
    "        #bertscore_ranked_substitutes_only_bsBert_electrabase = [substitute for substitute, _ in sorted_substitute_score_pairs_bsBert_electrabase]\n",
    "        #print(f\"substitutes with Bert based on bertscores with Bert: {bertscore_ranked_substitutes_only_bsBert_electrabase}\\n\")\n",
    "        bertscore_ranked_substitutes_only_bsElectra_electrabase = [substitute for substitute, _ in sorted_substitute_score_pairs_bsElectra_electrabase]\n",
    "        #print(f\"substitutes with Electra based on bertscores with Electra : {bertscore_ranked_substitutes_only_bsElectra_electrabase}\\n\")\n",
    "\n",
    "\n",
    "        # limit the substitutes to the 10 first ones for evaluation\n",
    "        #top_10_substitutes_bsBert_electrabase = bertscore_ranked_substitutes_only_bsBert_electrabase[:10]\n",
    "        #print(f\"top-10 substitutes with Bert based on bertscores with Bert: {top_10_substitutes_bsBert_electrabase}\\n\")\n",
    "        top_10_substitutes_bsElectra_electrabase = bertscore_ranked_substitutes_only_bsElectra_electrabase[:10]\n",
    "        #print(f\"top-10 substitutes with Electra based on bertscores with Electra: {top_10_substitutes_bsElectra_electrabase}\\n\")\n",
    "\n",
    "    else:\n",
    "        #top_10_substitutes_bsBert_electrabase  = []\n",
    "        top_10_substitutes_bsElectra_electrabase = []\n",
    "        \n",
    "    \n",
    "   # limit the substitutes to the 5 first ones for concatenation with the top-5 of other models\n",
    "    #top_5_substitutes_bsBert_electrabase = top_10_substitutes_bsBert_electrabase[:5]\n",
    "    #print(f\"SS step: top-5 substitutes based on bertscores with Bert for bert-base model: {top_5_substitutes_bsBert_electrabase}\\n\")\n",
    "    top_5_substitutes_bsElectra_electrabase = top_10_substitutes_bsElectra_electrabase[:5]\n",
    "    #print(f\"SS step: top-5 substitutes based on bertscores with Electra for electrabase model: {top_5_substitutes_bsElectra_electrabase}\\n\")\n",
    "\n",
    "   \n",
    "    # zip the four lists in to create a list that sticks to the original order of each sub list\n",
    "    #print('Finding shared duplicates in the four top-5 lists ....')\n",
    "\n",
    "    # create a dictionary to hold the counts\n",
    "    count_dict = {}\n",
    "\n",
    "   \n",
    "    # combine all four lists into a list of lists for easy iteration\n",
    "    #all_lists = [top_5_substitutes_bsElectra_electrabase, top_5_substitutes_bsBert_bertbase, top_5_substitutes_bsElectra_bertbase, top_5_substitutes_bsBert_electrabase]\n",
    "    all_lists = [top_5_substitutes_bsElectra_electrabase, top_5_substitutes_bsBert_bertbase]\n",
    "    #print(all_lists)\n",
    "\n",
    "    # iterate through each list and count occurrences of each element\n",
    "    for lst in all_lists:\n",
    "        for elem in lst:\n",
    "            if elem in count_dict:\n",
    "                count_dict[elem] += 1\n",
    "            else:\n",
    "                count_dict[elem] = 1\n",
    "\n",
    "    # create a list of duplicates by including only those elements that appeared in all four lists\n",
    "    duplicates_all_models = [elem for elem, count in count_dict.items() if count == len(all_lists)]\n",
    "\n",
    "    #print(f\"SS step: shared duplicates in top-5 substitutes lists based on bertscores with Bert and Electra for both bertbase and electrabase models: {duplicates_all_models}\\n\")\n",
    "    \n",
    "    # create a list with non-duplicates\n",
    "    non_duplicates_all_models = [elem for elem, count in count_dict.items() if count == 1]\n",
    "    #print(f\"SS step: non-duplicates in top-5 substitutes lists based on bertscores with Bert and Electra for both bertbase and electrabase models: {non_duplicates_all_models}\\n\")\n",
    "    \n",
    "    #concatenate both lists (duplicates_all_models and non_duplicates_all_models), giving duplicates_all_models priority\n",
    "    top_5_concatenated = duplicates_all_models + non_duplicates_all_models\n",
    "    #print(f\"SS step: concatenated top-5 with prioritized shared duplicates among bertbase and electrabase bertscore results: {top_5_concatenated}\\n\")\n",
    "    \n",
    "    #create the \"second half\" lists (items 6th to 10th) from each of the original top 10 lists\n",
    "    second_half_bsBert_bertbase = top_10_substitutes_bsBert_bertbase[5:]\n",
    "    second_half_bsElectra_electrabase = top_10_substitutes_bsElectra_electrabase[5:]\n",
    "    #second_half_bsBert_electrabase = top_10_substitutes_bsBert_electrabase[5:]\n",
    "    #second_half_bsElectra_bertbase = top_10_substitutes_bsElectra_bertbase[5:]\n",
    "    \n",
    "\n",
    "    # zip the \"second half\" lists\n",
    "    #second_half_combined = [item for sublist in zip(second_half_bsElectra_electrabase, second_half_bsBert_bertbase, second_half_bsElectra_bertbase, second_half_bsBert_electrabase) for item in sublist]\n",
    "    second_half_combined = [item for sublist in zip(second_half_bsElectra_electrabase, second_half_bsBert_bertbase) for item in sublist]\n",
    "    # Exclude any items in second_half_combined that are already in top_5_concatenated\n",
    "    second_half_combined = [item for item in second_half_combined if item not in top_5_concatenated]\n",
    "\n",
    "    # Append these items to the final_list\n",
    "    top_5_concatenated += second_half_combined\n",
    "\n",
    "    # Trim the final_list to the top 10 items\n",
    "    final_list_ElectraBertbase_SG_MA_SS_bsElectraBert_top5dup = top_5_concatenated[:10]\n",
    "\n",
    "    #print(f\"SS step: final list bertscore based on prioritizing shared duplicates among bert-base and electra-base models: {final_list_bertscore_top5dup_2models}\\n\")\n",
    "\n",
    "\n",
    "    #print('------------------------------------------------------------')\n",
    "    \n",
    "    \n",
    "    ## add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + final_list_ElectraBertbase_SG_MA_SS_bsElectraBert_top5dup\n",
    "\n",
    "# export the dataframe to a tsv file for evaluation\n",
    "substitutes_df.to_csv('./predictions/test/ElectraBertbase_SG_MA_SS_bsElectraBert_top5dup.tsv', sep=\"\\t\", index=False, header=False)   \n",
    "print(\"ElectraBertbase_SG_MA_SS_bsElectraBert_top5dup exported to csv in path './predictions/test/ElectraBertbase_SG_MA_SS_bsElectraBert_top5dup.tsv'}\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703f35de-69e0-4200-a0ad-e47e5b5f7562",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/ElectraBertbase_SG_MA_SS_bsElectraBert_top5dup.tsv --output_file ./output/test/ElectraBertbase_SG_MA_SS_bsElectraBert_top5dup.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de97a284-375d-4a8f-8920-bad5bad92647",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/ElectraBertbase_SG_MA_SS_bsElectraBert_top5dup.tsv\n",
    "OUTPUT file = ./output/test/ElectraBertbase_SG_MA_SS_bsElectraBert_top5dup.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.5752\n",
    "\n",
    "MAP@3 = 0.3838\n",
    "MAP@5 = 0.2745\n",
    "MAP@10 = 0.1767\n",
    "\n",
    "Potential@3 = 0.8145\n",
    "Potential@5 = 0.8602\n",
    "Potential@10 = 0.9435\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.25\n",
    "Accuracy@2@top_gold_1 = 0.3844\n",
    "Accuracy@3@top_gold_1 = 0.4435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400bb337-8602-4480-bd86-db2ed37d3f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cc777d7-be4f-43d2-94f4-bfc61fced867",
   "metadata": {},
   "source": [
    "top 5 of best 2 models bertbase bsBert and electrabase bsElectra (so, other order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647410b-d247-47e8-8c3a-77ce3d3fbfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "    \n",
    "    # print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    #print(f\"Sentence: {sentence}\")\n",
    "    #print(f\"Complex word: {complex_word}\")\n",
    "    \n",
    "    \n",
    "    # for bertbase model:\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word_bertbase = sentence.replace(complex_word, lm_tokenizer_bertbase.mask_token)\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    sentences_concat_bertbase = f\"{sentence} {lm_tokenizer_bertbase.sep_token} {sentence_masked_word_bertbase}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline (removing elements without token_str key; as this gave errors in the ELECTRA models) .\n",
    "    top_k = 30\n",
    "    result_bertbase = fill_mask_bertbase(sentences_concat_bertbase, top_k=top_k)\n",
    "    substitutes_bertbase = [substitute[\"token_str\"] for substitute in result_bertbase if \"token_str\" in substitute]\n",
    "    #print(f\"Substitute Generation step: initial substitute list: {substitutes_bertbase}\\n\")\n",
    "\n",
    "\n",
    "    #2: Morphological Generation and Context Adaptation (Morphological Adaptation):  \n",
    "    ## a) remove noise in the substitutes, by ignoring generated substitutes that are empty or that have unwanted punctuation characters or that start with '##' (this returned errors with the ELECTRA model), and lowercase the substitutes (as some models don't lowercase by default)\n",
    "    ## and lowercase all substitutes. Use try/except statement to prevent other character-related problems to happen\n",
    "\n",
    "    punctuation_set = set(string.punctuation) - set('-') # retained hyphens in case tokenizers don't split on hyphenated compounds\n",
    "    punctuation_set.update({'“','”'})   # as these curly quotes appeared in the Electra (SG step) results but were not part of the string set\n",
    "\n",
    "    try:\n",
    "        substitutes_bertbase = [substitute[\"token_str\"].lower().strip() for substitute in result_bertbase if not any(char in punctuation_set for char in substitute[\"token_str\"]) # added .strip as roberta uses a leading space before each substitute\n",
    "                      and not substitute[\"token_str\"].startswith('##') and substitute[\"token_str\"].strip() != \"\"]\n",
    "        # print(f\"Morphological Adaptation step a): substitute list without unwanted punctuation characters for bertbase model: {substitutes_bertbase}\\n\")\n",
    "    except TypeError as error:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    ## b) remove duplicates within the substitute list from the substitute list (duplicates are likely for models that did not lowercase by default)\n",
    "    ## the last mentioned duplicate is removed on purpose, as this may probably be the (previously) uppercased variant of the lowercased substitute (lowercased subs are most likely higher ranked by the model)\n",
    "    substitutes_no_dupl_bertbase = []\n",
    "    for sub in substitutes_bertbase:\n",
    "        if sub not in substitutes_no_dupl_bertbase:\n",
    "            substitutes_no_dupl_bertbase.append(sub)\n",
    "    #print(f\"Morphological Adaptation step b): substitute list without duplicates of substitutes for bertbase model: {substitutes_no_dupl_bertbase}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    ## c) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "\n",
    "    ## first Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## then, remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word_bertbase = []\n",
    "    for substitute in substitutes_no_dupl_bertbase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word_bertbase.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step c): substitute list without duplicates of the complex word nor inflected forms of the complex word for bertbase model: {substitutes_no_dupl_complex_word_bertbase}\\n\")\n",
    "\n",
    "\n",
    "     ## d) remove antonyms of the complex word from the substitute list\n",
    "    ## step 1: get the antonyms of the complex word\n",
    "    antonyms_complex_word = []\n",
    "    for syn in wn.synsets(complex_word_lemma):\n",
    "        for lemma in syn.lemmas():\n",
    "            for antonym in lemma.antonyms():\n",
    "                    antonyms_complex_word.append(antonym.name())\n",
    "\n",
    "    print(f\"Antonyms for complex word '{complex_word}': {antonyms_complex_word}\\n\")\n",
    "\n",
    "    ## step 2: remove antonyms of the complex word from the list with substitutes\n",
    "    substitutes_no_antonyms_bertbase = []\n",
    "    for substitute in substitutes_no_dupl_complex_word_bertbase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma not in antonyms_complex_word:\n",
    "            substitutes_no_antonyms_bertbase.append(substitute)\n",
    "        else:\n",
    "            print(f\"Removed antonym: {substitute}\")\n",
    "    print(f\"Morphological Adaptation step d): substitute list without antonyms of the complex word for bertbase model: {substitutes_no_antonyms_bertbase}\\n\") \n",
    "    \n",
    "    \n",
    "    \n",
    "    #3: Substitute Selection (SS) by calculating Bert scores: \n",
    "\n",
    "    ## create sentence with the complex word replaced by the substitutes\n",
    "    sentence_with_substitutes_bertbase = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym_bertbase]\n",
    "    #print(f\"List with sentences where complex word is substituted for bertbase model: {sentence_with_substitutes_bertbase}\\n\")\n",
    "\n",
    "\n",
    "    ## calculate BERTScores, and rank the substitutes based on these scores\n",
    "    if len(sentence_with_substitutes_bertbase) > 0: # to make sure the list with substitutes is always filled\n",
    "        logging.getLogger('transformers').setLevel(logging.ERROR)  # to prevent the same warnings from being printed x times \n",
    "        scores_bsBert_bertbase = bert_score.score([sentence]*len(sentence_with_substitutes_bertbase), sentence_with_substitutes_bertbase, lang=\"en\", model_type='bert-base-uncased', verbose=False)\n",
    "        #scores_bsElectra_bertbase = bert_score.score([sentence]*len(sentence_with_substitutes_bertbase), sentence_with_substitutes_bertbase, lang=\"en\", model_type='google/electra-base-generator', verbose=False)\n",
    "        logging.getLogger('transformers').setLevel(logging.WARNING) # to reset the logging level back to printing warnings\n",
    "        \n",
    "        # create a list of tuples, each tuple containing a substitute and its score\n",
    "        substitute_score_pairs_bsBert_bertbase = list(zip(substitutes_no_dupl_complex_word_no_antonym_bertbase, scores_bsBert_bertbase[0].tolist()))\n",
    "        #substitute_score_pairs_bsElectra_bertbase = list(zip(substitutes_no_dupl_complex_word_no_antonym_bertbase, scores_bsElectra_bertbase[0].tolist()))\n",
    "\n",
    "        # sort the list of tuples by the scores (the second element of each tuple), in descending order\n",
    "        sorted_substitute_score_pairs_bsBert_bertbase = sorted(substitute_score_pairs_bsBert_bertbase, key=lambda x: x[1], reverse=True)\n",
    "        #sorted_substitute_score_pairs_bsElectra_bertbase = sorted(substitute_score_pairs_bsElectra_bertbase, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # extract the list of substitutes from the sorted pairs\n",
    "        bertscore_ranked_substitutes_only_bsBert_bertbase = [substitute for substitute, _ in sorted_substitute_score_pairs_bsBert_bertbase]\n",
    "        #print(f\"substitutes with Bert based on bertscores with Bert: {bertscore_ranked_substitutes_only_bsBert_bertbase}\\n\")\n",
    "        #bertscore_ranked_substitutes_only_bsElectra_bertbase = [substitute for substitute, _ in sorted_substitute_score_pairs_bsElectra_bertbase]\n",
    "        #print(f\"substitutes based on bertscores with Electra for bert-base model : {bertscore_ranked_substitutes_only_bsElectra_bertbase}\\n\")\n",
    "\n",
    "\n",
    "        # limit the substitutes to the 10 first ones for evaluation\n",
    "        top_10_substitutes_bsBert_bertbase = bertscore_ranked_substitutes_only_bsBert_bertbase[:10]\n",
    "        #print(f\"top-10 substitutes with Bert based on bertscores with Bert: {top_10_substitutes_bsBert_bertbase}\\n\")\n",
    "        #top_10_substitutes_bsElectra_bertbase = bertscore_ranked_substitutes_only_bsElectra_bertbase[:10]\n",
    "        #print(f\"top-10 substitutes based on bertscores with Electra for bert-base model: {top_10_substitutes_bsElectra_bertbase}\\n\")\n",
    "\n",
    "    else:\n",
    "        top_10_substitutes_bsBert_bertbase  = []\n",
    "        #top_10_substitutes_bsElectra_bertbase = []\n",
    "        \n",
    "    \n",
    "    # limit the substitutes to the 5 first ones for concatenation with the top-5 of other models\n",
    "    top_5_substitutes_bsBert_bertbase = top_10_substitutes_bsBert_bertbase[:5]\n",
    "    #print(f\"SS step: top-5 substitutes based on bertscores with Bert for bert-base model: {top_5_substitutes_bsBert_bertbase}\\n\")\n",
    "    #top_5_substitutes_bsElectra_bertbase = top_10_substitutes_bsElectra_bertbase[:5]\n",
    "    #print(f\"SS step: top-5 substitutes based on bertscores with Electra for bert-base model: {top_5_substitutes_bsElectra_bertbase}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # for electrabase model:\n",
    "   \n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word_electrabase = sentence.replace(complex_word, lm_tokenizer_electrabase.mask_token)\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    sentences_concat_electrabase = f\"{sentence} {lm_tokenizer_electrabase.sep_token} {sentence_masked_word_electrabase}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline (removing elements without token_str key; as this gave errors in the ELECTRA models) .\n",
    "    top_k = 30\n",
    "    result_electrabase = fill_mask_electrabase(sentences_concat_electrabase, top_k=top_k)\n",
    "    substitutes_electrabase = [substitute[\"token_str\"] for substitute in result_electrabase if \"token_str\" in substitute]\n",
    "    #print(f\"Substitute Generation step: initial substitute list: {substitutes_electrabase}\\n\")\n",
    "\n",
    "\n",
    "    #2: Morphological Generation and Context Adaptation (Morphological Adaptation):  \n",
    "    ## a) remove noise in the substitutes, by ignoring generated substitutes that are empty or that have unwanted punctuation characters or that start with '##' (this returned errors with the ELECTRA model), and lowercase the substitutes (as some models don't lowercase by default)\n",
    "    ## and lowercase all substitutes. Use try/except statement to prevent other character-related problems to happen\n",
    "\n",
    "    punctuation_set = set(string.punctuation) - set('-') # retained hyphens in case tokenizers don't split on hyphenated compounds\n",
    "    punctuation_set.update({'“','”'})   # as these curly quotes appeared in the Electra (SG step) results but were not part of the string set\n",
    "\n",
    "    try:\n",
    "        substitutes_electrabase = [substitute[\"token_str\"].lower().strip() for substitute in result_electrabase if not any(char in punctuation_set for char in substitute[\"token_str\"]) # added .strip as roberta uses a leading space before each substitute\n",
    "                      and not substitute[\"token_str\"].startswith('##') and substitute[\"token_str\"].strip() != \"\"]\n",
    "        # print(f\"Morphological Adaptation step a): substitute list without unwanted punctuation characters for bert-base model: {substitutes_electrabase}\\n\")\n",
    "    except TypeError as error:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    ## b) remove duplicates within the substitute list from the substitute list (duplicates are likely for models that did not lowercase by default)\n",
    "    ## the last mentioned duplicate is removed on purpose, as this may probably be the (previously) uppercased variant of the lowercased substitute (lowercased subs are most likely higher ranked by the model)\n",
    "    substitutes_no_dupl_electrabase = []\n",
    "    for sub in substitutes_electrabase:\n",
    "        if sub not in substitutes_no_dupl_electrabase:\n",
    "            substitutes_no_dupl_electrabase.append(sub)\n",
    "    #print(f\"Morphological Adaptation step b): substitute list without duplicates of substitutes for electrabase model: {substitutes_no_dupl_electrabase}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    ## c) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "\n",
    "    ## first Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## then, remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word_electrabase = []\n",
    "    for substitute in substitutes_no_dupl_electrabase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word_electrabase.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step c): substitute list without duplicates of the complex word nor inflected forms of the complex word for electrabase model: {substitutes_no_dupl_complex_word_electrabase}\\n\")\n",
    "\n",
    "\n",
    "   ## d) remove antonyms of the complex word from the substitute list\n",
    "    ## step 1: get the antonyms of the complex word\n",
    "    antonyms_complex_word = []\n",
    "    for syn in wn.synsets(complex_word_lemma):\n",
    "        for lemma in syn.lemmas():\n",
    "            for antonym in lemma.antonyms():\n",
    "                    antonyms_complex_word.append(antonym.name())\n",
    "\n",
    "    print(f\"Antonyms for complex word '{complex_word}': {antonyms_complex_word}\\n\")\n",
    "\n",
    "    ## step 2: remove antonyms of the complex word from the list with substitutes\n",
    "    substitutes_no_antonyms_electrabase = []\n",
    "    for substitute in substitutes_no_dupl_complex_word_electrabase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma not in antonyms_complex_word:\n",
    "            substitutes_no_antonyms_electrabase.append(substitute)\n",
    "        else:\n",
    "            print(f\"Removed antonym: {substitute}\")\n",
    "    print(f\"Morphological Adaptation step d): substitute list without antonyms of the complex word for electrabase model: {substitutes_no_antonyms_electrabase}\\n\") \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #3: Substitute Selection (SS) by calculating Bert scores: \n",
    "\n",
    "    ## create sentence with the complex word replaced by the substitutes\n",
    "    sentence_with_substitutes_electrabase = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym_electrabase]\n",
    "    #print(f\"List with sentences where complex word is substituted for electrabase model: {sentence_with_substitutes_electrabase\\n\")\n",
    "\n",
    "\n",
    "    ## calculate BERTScores, and rank the substitutes based on these scores\n",
    "    if len(sentence_with_substitutes_electrabase) > 0: # to make sure the list with substitutes is always filled\n",
    "        logging.getLogger('transformers').setLevel(logging.ERROR)  # to prevent the same warnings from being printed x times \n",
    "        #scores_bsBert_electrabase = bert_score.score([sentence]*len(sentence_with_substitutes_electrabase), sentence_with_substitutes_electrabase, lang=\"en\", model_type='bert-base-uncased', verbose=False)\n",
    "        scores_bsElectra_electrabase = bert_score.score([sentence]*len(sentence_with_substitutes_electrabase), sentence_with_substitutes_electrabase, lang=\"en\", model_type='google/electra-base-generator', verbose=False)\n",
    "        logging.getLogger('transformers').setLevel(logging.WARNING) # to reset the logging level back to printing warnings\n",
    "        \n",
    "        # create a list of tuples, each tuple containing a substitute and its score\n",
    "        #substitute_score_pairs_bsBert_electrabase = list(zip(substitutes_no_dupl_complex_word_no_antonym_electrabase, scores_bsBert_electrabase[0].tolist()))\n",
    "        substitute_score_pairs_bsElectra_electrabase = list(zip(substitutes_no_dupl_complex_word_no_antonym_electrabase, scores_bsElectra_electrabase[0].tolist()))\n",
    "\n",
    "        # sort the list of tuples by the scores (the second element of each tuple), in descending order\n",
    "        #sorted_substitute_score_pairs_bsBert_electrabase = sorted(substitute_score_pairs_bsBert_electrabase, key=lambda x: x[1], reverse=True)\n",
    "        sorted_substitute_score_pairs_bsElectra_electrabase = sorted(substitute_score_pairs_bsElectra_electrabase, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # extract the list of substitutes from the sorted pairs\n",
    "        #bertscore_ranked_substitutes_only_bsBert_electrabase = [substitute for substitute, _ in sorted_substitute_score_pairs_bsBert_electrabase]\n",
    "        #print(f\"substitutes with Bert based on bertscores with Bert: {bertscore_ranked_substitutes_only_bsBert_electrabase}\\n\")\n",
    "        bertscore_ranked_substitutes_only_bsElectra_electrabase = [substitute for substitute, _ in sorted_substitute_score_pairs_bsElectra_electrabase]\n",
    "        #print(f\"substitutes with Electra based on bertscores with Electra : {bertscore_ranked_substitutes_only_bsElectra_electrabase}\\n\")\n",
    "\n",
    "\n",
    "        # limit the substitutes to the 10 first ones for evaluation\n",
    "        #top_10_substitutes_bsBert_electrabase = bertscore_ranked_substitutes_only_bsBert_electrabase[:10]\n",
    "        #print(f\"top-10 substitutes with Bert based on bertscores with Bert: {top_10_substitutes_bsBert_electrabase}\\n\")\n",
    "        top_10_substitutes_bsElectra_electrabase = bertscore_ranked_substitutes_only_bsElectra_electrabase[:10]\n",
    "        #print(f\"top-10 substitutes with Electra based on bertscores with Electra: {top_10_substitutes_bsElectra_electrabase}\\n\")\n",
    "\n",
    "    else:\n",
    "        #top_10_substitutes_bsBert_electrabase  = []\n",
    "        top_10_substitutes_bsElectra_electrabase = []\n",
    "        \n",
    "    \n",
    "   # limit the substitutes to the 5 first ones for concatenation with the top-5 of other models\n",
    "    #top_5_substitutes_bsBert_electrabase = top_10_substitutes_bsBert_electrabase[:5]\n",
    "    #print(f\"SS step: top-5 substitutes based on bertscores with Bert for bert-base model: {top_5_substitutes_bsBert_electrabase}\\n\")\n",
    "    top_5_substitutes_bsElectra_electrabase = top_10_substitutes_bsElectra_electrabase[:5]\n",
    "    #print(f\"SS step: top-5 substitutes based on bertscores with Electra for electrabase model: {top_5_substitutes_bsElectra_electrabase}\\n\")\n",
    "\n",
    "   \n",
    "    # zip the four lists in to create a list that sticks to the original order of each sub list\n",
    "    #print('Finding shared duplicates in the four top-5 lists ....')\n",
    "\n",
    "    # create a dictionary to hold the counts\n",
    "    count_dict = {}\n",
    "\n",
    "   \n",
    "    # combine all four lists into a list of lists for easy iteration\n",
    "    #all_lists = [top_5_substitutes_bsElectra_electrabase, top_5_substitutes_bsBert_bertbase, top_5_substitutes_bsElectra_bertbase, top_5_substitutes_bsBert_electrabase]\n",
    "    #all_lists = [top_5_substitutes_bsElectra_electrabase, top_5_substitutes_bsBert_bertbase]\n",
    "    all_lists = [top_5_substitutes_bsBert_bertbase, top_5_substitutes_bsElectra_electrabase] # try the other way around to see if score increases\n",
    "    #print(all_lists)\n",
    "\n",
    "    # iterate through each list and count occurrences of each element\n",
    "    for lst in all_lists:\n",
    "        for elem in lst:\n",
    "            if elem in count_dict:\n",
    "                count_dict[elem] += 1\n",
    "            else:\n",
    "                count_dict[elem] = 1\n",
    "\n",
    "    # create a list of duplicates by including only those elements that appeared in all four lists\n",
    "    duplicates_all_models = [elem for elem, count in count_dict.items() if count == len(all_lists)]\n",
    "\n",
    "    #print(f\"SS step: shared duplicates in top-5 substitutes lists based on bertscores with Bert and Electra for both bertbase and electrabase models: {duplicates_all_models}\\n\")\n",
    "    \n",
    "    # create a list with non-duplicates\n",
    "    non_duplicates_all_models = [elem for elem, count in count_dict.items() if count == 1]\n",
    "    #print(f\"SS step: non-duplicates in top-5 substitutes lists based on bertscores with Bert and Electra for both bertbase and electrabase models: {non_duplicates_all_models}\\n\")\n",
    "    \n",
    "    #concatenate both lists (duplicates_all_models and non_duplicates_all_models), giving duplicates_all_models priority\n",
    "    top_5_concatenated = duplicates_all_models + non_duplicates_all_models\n",
    "    #print(f\"SS step: concatenated top-5 with prioritized shared duplicates among bertbase and electrabase bertscore results: {top_5_concatenated}\\n\")\n",
    "    \n",
    "    #create the \"second half\" lists (items 6th to 10th) from each of the original top 10 lists\n",
    "    second_half_bsBert_bertbase = top_10_substitutes_bsBert_bertbase[5:]\n",
    "    second_half_bsElectra_electrabase = top_10_substitutes_bsElectra_electrabase[5:]\n",
    "    #second_half_bsBert_electrabase = top_10_substitutes_bsBert_electrabase[5:]\n",
    "    #second_half_bsElectra_bertbase = top_10_substitutes_bsElectra_bertbase[5:]\n",
    "    \n",
    "\n",
    "    # zip the \"second half\" lists\n",
    "    #second_half_combined = [item for sublist in zip(second_half_bsElectra_electrabase, second_half_bsBert_bertbase, second_half_bsElectra_bertbase, second_half_bsBert_electrabase) for item in sublist]\n",
    "    #second_half_combined = [item for sublist in zip(second_half_bsElectra_electrabase, second_half_bsBert_bertbase) for item in sublist]\n",
    "    second_half_combined = [item for sublist in zip(second_half_bsBert_bertbase, second_half_bsElectra_electrabase) for item in sublist] # try the other way around to see if score increases\n",
    "    # Exclude any items in second_half_combined that are already in top_5_concatenated\n",
    "    second_half_combined = [item for item in second_half_combined if item not in top_5_concatenated]\n",
    "\n",
    "    # Append these items to the final_list\n",
    "    top_5_concatenated += second_half_combined\n",
    "\n",
    "    # Trim the final_list to the top 10 items\n",
    "    final_list_BertElectrabase_SG_MA_SS_bsBertElectra_top5dup = top_5_concatenated[:10]\n",
    "\n",
    "    #print(f\"SS step: final list bertscore based on prioritizing shared duplicates among bert-base and electra-base models: {final_list_bertscore_top5dup_2models}\\n\")\n",
    "\n",
    "\n",
    "    #print('------------------------------------------------------------')\n",
    "    \n",
    "    \n",
    "    ## add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + final_list_BertElectrabase_SG_MA_SS_bsBertElectra_top5dup\n",
    "\n",
    "# export the dataframe to a tsv file for evaluation\n",
    "substitutes_df.to_csv('./predictions/test/BertElectrabase_SG_MA_SS_bsBertElectra_top5dup.tsv', sep=\"\\t\", index=False, header=False)   \n",
    "print(\"BertElectrabase_SG_MA_SS_bsBertElectra_top5dup exported to csv in path './predictions/test/BertElectrabase_SG_MA_SS_bsBertElectra_top5dup.tsv'}\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b6f8ff-c9e8-4e41-a1ec-e2cd1e71ee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/BertElectrabase_SG_MA_SS_bsBertElectra_top5dup.tsv --output_file ./output/test/BertElectrabase_SG_MA_SS_bsBertElectra_top5dup.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0247be-0fe1-4cec-8e47-4d20b73f1a71",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/BertElectrabase_SG_MA_SS_bsBertElectra_top5dup.tsv\n",
    "OUTPUT file = ./output/test/BertElectrabase_SG_MA_SS_bsBertElectra_top5dup.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.6129\n",
    "\n",
    "MAP@3 = 0.4142\n",
    "MAP@5 = 0.3035\n",
    "MAP@10 = 0.1859\n",
    "\n",
    "Potential@3 = 0.836\n",
    "Potential@5 = 0.8951\n",
    "Potential@10 = 0.9435\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.2715\n",
    "Accuracy@2@top_gold_1 = 0.4112\n",
    "Accuracy@3@top_gold_1 = 0.4784"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ce12a3-9cb1-4f5d-ab57-40693e4733a6",
   "metadata": {},
   "source": [
    "highest score so far!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff27fa7-609c-4132-94f8-a54486f6cb95",
   "metadata": {
    "id": "6ff27fa7-609c-4132-94f8-a54486f6cb95"
   },
   "source": [
    "To Do later:\n",
    "\n",
    "1. see if padding in case of <10 subs is the right way. Maybe better to pad with the first item (which is the most sem. fitting item) in the combined subs list? or generate more substitutes (or put the limit higher after generation)\n",
    "2. remove unsimilar substitutes, to account for removing e.g., voluntary from the list for 'compulsory' (maybe with equivalence scores or something word embedding scores?.\n",
    "2. explore wordnet co-hyponyms, and add/prioritize in list, together with synsets code (see old code). Think about how to prioritize, above or after the duplicates from all 4 models.\n",
    "3. remove substitutes like 'disguise' and 'dressing' (complex word = disguised); 'deployment' (complex word = deploy). Maybe by removing words that have the first 4 or 5 leftstrings the same as the complex word (that will remove words like disguise and deployment. but not dressing (can be a noun and a verb), as this only appears in the subst list together with dressed which is a good substitute). maybe see with Fitbert what it does? \n",
    "4. update the code with embeddings and BERTScore (applied to the combined list of all 4 systems), and see which of these work best. \n",
    "5. automate the code in a way that it selects all models automatically, one by one, and that all the separate variables are not needed.\n",
    "6. automate to test scores with different top-x for the concatenated list of all 4 models\n",
    "7. Automate to get the best top-x, based on the output scores for the task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d70321-7829-4886-8e8b-1f095bc59bdb",
   "metadata": {
    "id": "59d70321-7829-4886-8e8b-1f095bc59bdb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "007e6ba4510e4dde89f7325cb48fca5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "01ab0bfa52bd40bda4af3169cd15545b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "02ff42ab910c4145bd9510cc08f3b94f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03bc194d73f4486d89a3767e8d14f34c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0806ae913ce6408ca816b6f08a024925": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0816ce05ee17480596ea1bc14cf18096": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0850f9ebf8e5492cbf2634d79779256f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8f8d0a42b30c4e1b95c84272f01e241b",
       "IPY_MODEL_93f98b3afc034967a6ea6c16c4ad9cc2",
       "IPY_MODEL_89024962b9d1424a89b3bc403fbb424a"
      ],
      "layout": "IPY_MODEL_893e24b85ec64427b51d478770affbfc"
     }
    },
    "08c2983c2c3a4ac2bd879496c93ead15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "08ce1cdf1dad4dcd9f0f3b7a2ce50d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e43b65112a7c4c1fb9904ca5ac4f6734",
       "IPY_MODEL_d763da1a2d214656ae8cd198cf606281",
       "IPY_MODEL_6a27acb8a7b94efeb1bcf4ce2e476e82"
      ],
      "layout": "IPY_MODEL_f4649f0058484ebe81d02fe44d99f1b8"
     }
    },
    "0a0785c303fa40118a0c97ecb7734bb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0ce23f4cbb784dd5b21cd3737ddc1f7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0ce97a1f5fbd49d8a9efbb6d71d85fdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a6c9d2551734fd793cd20c75ef0439a",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0806ae913ce6408ca816b6f08a024925",
      "value": 898823
     }
    },
    "0e0e82acf52848f49aeb31f719ffd99b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c897070773441a394b3fba2f93b24f5",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5d36fa8e7ce940738f165692a26931e0",
      "value": 466062
     }
    },
    "0ebd0abc03ca4749bd9166c5d2223580": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "123e1d84f7f2493c93bc9458a74cc859": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1346c8efc182433a8dc87dd981618edd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_691f390e96e54f56b2902ef09e8eb78c",
      "placeholder": "​",
      "style": "IPY_MODEL_a7b1d432aafe47ceb6d9bb3185642c62",
      "value": " 662/662 [00:00&lt;00:00, 32.6kB/s]"
     }
    },
    "19420e1873db4e6a80baff6f72081ee5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab02e818a77c45f3838d42a96be08f3b",
      "placeholder": "​",
      "style": "IPY_MODEL_97bc704e816549f599a24bb6058c7be7",
      "value": " 27.0/27.0 [00:00&lt;00:00, 1.38kB/s]"
     }
    },
    "1c3e3b457a544715ae8f44285a2afbbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_87a83c5842df496ca091b32d05bf517c",
       "IPY_MODEL_c82ef727b14b4ee09fba8bbf950a8420",
       "IPY_MODEL_4366eecfeb8945adb82670e785a7419a"
      ],
      "layout": "IPY_MODEL_f3007c832f8f403ca83a59b3b03136e7"
     }
    },
    "1d2d40add1b243fe99a31d1fae53abe3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1df08871ac4145aba971e0d367a31249": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f1eda0d23b743f2b02b729a3a8c981b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c59414047aed4376af9ffc79759b9e32",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0ebd0abc03ca4749bd9166c5d2223580",
      "value": 231508
     }
    },
    "2585904371a048b3a105f951dd8f000f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93e988fc761648398baa05b3f914c0c7",
      "placeholder": "​",
      "style": "IPY_MODEL_ea791374e2374fc3a1cb6783d67e6b79",
      "value": " 232k/232k [00:00&lt;00:00, 5.93MB/s]"
     }
    },
    "272f204b67aa4e04864064b0853b1a36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "273ac09e03a44ee490fe4ba5b543f255": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4868510551cf413c916f4d9a04f30af4",
      "max": 501200538,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e87de82893af4558adec0d8b26bc6a1f",
      "value": 501200538
     }
    },
    "291707134e3d4b9c8a3f752d200b07b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2924c72cc2b04094942cf1f59560b7ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_969de54dd25c4c3aa734aef2b8545e29",
       "IPY_MODEL_0ce97a1f5fbd49d8a9efbb6d71d85fdb",
       "IPY_MODEL_d16fe136c8da4ced914add81a51d6383"
      ],
      "layout": "IPY_MODEL_49e23629175c449887d41d17e28445c5"
     }
    },
    "2b2bfbc0adfa4420a26abb692a7d97f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_acde8a206e4147da937e617ad3a9f44e",
       "IPY_MODEL_de0b051d9c5341de96c55029732f00cd",
       "IPY_MODEL_30e3b4f86172421d8d2b16e55ea1f52d"
      ],
      "layout": "IPY_MODEL_0816ce05ee17480596ea1bc14cf18096"
     }
    },
    "2bd6873d108e478cb9ef916a587408c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e55696bdbb5041979ddba03b2ebe9ddd",
      "placeholder": "​",
      "style": "IPY_MODEL_c88e4918710141399ca6bf0da79711e9",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "2bea8bd2dce64f50a287e2a7fae5e2ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a12efe760abe4863b6e54f2a060e73dc",
       "IPY_MODEL_499ec307428b41a78d27f9adabdeb53d",
       "IPY_MODEL_2585904371a048b3a105f951dd8f000f"
      ],
      "layout": "IPY_MODEL_6d8eeb989bf142faae600ae4c808f626"
     }
    },
    "2d79549080974206869c6230a6d47781": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e1394495d9341668c1bd6f7e7f82a61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_828a972e099c41e18ede59d36202084c",
      "placeholder": "​",
      "style": "IPY_MODEL_41a0f67728d7405a8dd10be01260f6db",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "30e3b4f86172421d8d2b16e55ea1f52d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_809ca7e36997464e8d21264062243447",
      "placeholder": "​",
      "style": "IPY_MODEL_486e869e704f4fef90a73b27cc497c0a",
      "value": " 466k/466k [00:00&lt;00:00, 2.56MB/s]"
     }
    },
    "31dfd1f132ee44c6bc9956aaa52236b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57f558e69b6a44e3ab7b49bbd1938f25",
      "max": 135011821,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d3fea5a42bc546378b89c451ec76e0a1",
      "value": 135011821
     }
    },
    "359e0ddbd64c4849be635b9b0e7c6d7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35f85c211de84640b106f79a44e4ba13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcbf0abd2e024ff5acd054f2baa1dcb6",
      "max": 662,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4343a16ac7c340afa3367ed08e390e3f",
      "value": 662
     }
    },
    "3676f73895064c30b2bf261c18cdf7d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "36fad96a013148c691f875e1e46c66e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8f5f7af0acb84bc9bde7a5518e714453",
       "IPY_MODEL_1f1eda0d23b743f2b02b729a3a8c981b",
       "IPY_MODEL_c342d762227344d6bfa3d711eb7b0508"
      ],
      "layout": "IPY_MODEL_60beb88d09334d148adaca3fa2a37f3f"
     }
    },
    "3bfee968b89c4580b57f66becd02ea71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f2c3ebccd9f4df299cd6fdbba8bf3e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41a0f67728d7405a8dd10be01260f6db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "433c92c35a0b46a68e415e33a9f41f1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4343a16ac7c340afa3367ed08e390e3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4366eecfeb8945adb82670e785a7419a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_359e0ddbd64c4849be635b9b0e7c6d7f",
      "placeholder": "​",
      "style": "IPY_MODEL_c986609b554b4f4494b1b847f872d08d",
      "value": " 456k/456k [00:00&lt;00:00, 2.47MB/s]"
     }
    },
    "45ff9d7363734a34bc412de20fd6eee5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4868510551cf413c916f4d9a04f30af4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "486e869e704f4fef90a73b27cc497c0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "49722bd776d04226b0fd5d19cab994ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f09b59a008b4454f9cd4a2d5311bff39",
      "placeholder": "​",
      "style": "IPY_MODEL_50b131102b424f3fad401baeae34648a",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "499ec307428b41a78d27f9adabdeb53d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_949024d006e447ebbe5dcc259bc22e9e",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f78c3b4355de482b9210b5469eb6f3e6",
      "value": 231508
     }
    },
    "49e23629175c449887d41d17e28445c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ea954c7b73145a2bc4abe31385ea8ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d930e25291e34f93a05fee9ac1f1b55a",
      "max": 27,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0ce23f4cbb784dd5b21cd3737ddc1f7f",
      "value": 27
     }
    },
    "4eba72a878014dacafefd044381ba0ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50b131102b424f3fad401baeae34648a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "52ef4af975fc414bb152fd12a65ce1d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57f558e69b6a44e3ab7b49bbd1938f25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a599bb760364152aebdd773c98b3d2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f93a1275f1ca4fb98df56c731f5582be",
       "IPY_MODEL_31dfd1f132ee44c6bc9956aaa52236b9",
       "IPY_MODEL_82e9a39bbb4b4a4684ffdd5f8a6a19d3"
      ],
      "layout": "IPY_MODEL_84e5997c68be4238b02847eaddadea83"
     }
    },
    "5bbf19d1e6d142a5b78de83c90929c09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c897070773441a394b3fba2f93b24f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d36fa8e7ce940738f165692a26931e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "60be5e10f54d475fab0a2d156c498ea0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_924cf2485a1b489fa7b2e6a556b33874",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e315d5141b104ee3a92c4757e142ae1e",
      "value": 570
     }
    },
    "60beb88d09334d148adaca3fa2a37f3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61705d7534234ef1b19daab67f44ca58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "617eb3551a1a4b1da486646d29c3a1d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "636dd18530fe4c6192b9e0872b73aa9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65bcb9e3844941d0bfe6393e55332576": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "691f390e96e54f56b2902ef09e8eb78c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69da3350d31040bab71fe71ff06c7f63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a27acb8a7b94efeb1bcf4ce2e476e82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a754cd1c79db4deabc642c752264db5c",
      "placeholder": "​",
      "style": "IPY_MODEL_bfcb3f06384b469fa74c513e03f02c20",
      "value": " 481/481 [00:00&lt;00:00, 27.1kB/s]"
     }
    },
    "6aa1b4caffa04e3bad3cf0fd336fb706": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6d8eeb989bf142faae600ae4c808f626": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e7b3a1ba67541a0bb58800028abed5f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f226b4607cf40ed849a1d7eff6ec9df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7080cf2b27064cd1bea2b76b34c45394": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72f3724479364b448a969d2c93388076": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a6c9d2551734fd793cd20c75ef0439a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "809ca7e36997464e8d21264062243447": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "828a972e099c41e18ede59d36202084c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82e9a39bbb4b4a4684ffdd5f8a6a19d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d79549080974206869c6230a6d47781",
      "placeholder": "​",
      "style": "IPY_MODEL_0a0785c303fa40118a0c97ecb7734bb3",
      "value": " 135M/135M [00:00&lt;00:00, 244MB/s]"
     }
    },
    "8314f6c9a28949b1b8d2865ab442aa5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84e5997c68be4238b02847eaddadea83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87a83c5842df496ca091b32d05bf517c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_007e6ba4510e4dde89f7325cb48fca5c",
      "placeholder": "​",
      "style": "IPY_MODEL_272f204b67aa4e04864064b0853b1a36",
      "value": "Downloading (…)olve/main/merges.txt: 100%"
     }
    },
    "89024962b9d1424a89b3bc403fbb424a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f2c3ebccd9f4df299cd6fdbba8bf3e0",
      "placeholder": "​",
      "style": "IPY_MODEL_f21f7c3e125842e1a6a905a78b33ee08",
      "value": " 28.0/28.0 [00:00&lt;00:00, 2.25kB/s]"
     }
    },
    "893e24b85ec64427b51d478770affbfc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bb8420357f441ea95520f9d94ace1a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8e7abec6ac454ebd9b061b90a9ab0c98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8f5f7af0acb84bc9bde7a5518e714453": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69da3350d31040bab71fe71ff06c7f63",
      "placeholder": "​",
      "style": "IPY_MODEL_01ab0bfa52bd40bda4af3169cd15545b",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "8f8d0a42b30c4e1b95c84272f01e241b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1514f8bad0f4b089d539ddd21086a57",
      "placeholder": "​",
      "style": "IPY_MODEL_291707134e3d4b9c8a3f752d200b07b3",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "902ccc54bf9b4ebb8d956efc0cd5f9c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90e2ae4c4f4d47eb826a34f567f6838f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4eba72a878014dacafefd044381ba0ec",
      "placeholder": "​",
      "style": "IPY_MODEL_6f226b4607cf40ed849a1d7eff6ec9df",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 16.4MB/s]"
     }
    },
    "92470004f26b4ffdb56226969f714d71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d2d40add1b243fe99a31d1fae53abe3",
      "placeholder": "​",
      "style": "IPY_MODEL_e865691b14644d909285cbb1d8dcf496",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "924cf2485a1b489fa7b2e6a556b33874": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9301272e564145839972eca8f77b70a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45ff9d7363734a34bc412de20fd6eee5",
      "placeholder": "​",
      "style": "IPY_MODEL_ffec2e6c5a234b00884a144bbf67e17f",
      "value": " 501M/501M [00:01&lt;00:00, 278MB/s]"
     }
    },
    "9394d24fc86d4af18c99eb7248b61c76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_92470004f26b4ffdb56226969f714d71",
       "IPY_MODEL_4ea954c7b73145a2bc4abe31385ea8ae",
       "IPY_MODEL_19420e1873db4e6a80baff6f72081ee5"
      ],
      "layout": "IPY_MODEL_123e1d84f7f2493c93bc9458a74cc859"
     }
    },
    "93e2f4de97ca4e06920a2d871aa49083": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93e988fc761648398baa05b3f914c0c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93f98b3afc034967a6ea6c16c4ad9cc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2f9568a58a04b68b7991514e05acd20",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e720c30050874212844d8194b03ddc75",
      "value": 28
     }
    },
    "940d8402983f4ceeb2d3db16162f5677": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "945c97bbec234e43b0c3630b6f01321a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "949024d006e447ebbe5dcc259bc22e9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "969de54dd25c4c3aa734aef2b8545e29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_945c97bbec234e43b0c3630b6f01321a",
      "placeholder": "​",
      "style": "IPY_MODEL_a95eb5420e68483a8c1016c722a5daad",
      "value": "Downloading (…)olve/main/vocab.json: 100%"
     }
    },
    "97bc704e816549f599a24bb6058c7be7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9cb9851c654843a3b3f62c4d7692906f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a12efe760abe4863b6e54f2a060e73dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1df08871ac4145aba971e0d367a31249",
      "placeholder": "​",
      "style": "IPY_MODEL_e751b622b2704ea68d9c7143eff50ce3",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "a754cd1c79db4deabc642c752264db5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7b1d432aafe47ceb6d9bb3185642c62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a88f4a91fe4f40eeab94aadf4af6fb4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8314f6c9a28949b1b8d2865ab442aa5d",
      "placeholder": "​",
      "style": "IPY_MODEL_65bcb9e3844941d0bfe6393e55332576",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "a95eb5420e68483a8c1016c722a5daad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab02e818a77c45f3838d42a96be08f3b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "acde8a206e4147da937e617ad3a9f44e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_902ccc54bf9b4ebb8d956efc0cd5f9c2",
      "placeholder": "​",
      "style": "IPY_MODEL_e655a0302c2840ca9080b888e15882a3",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "b01e1a59c1fe4b26893b532111cbe58a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3ba6e349ecc4a10ab6c93117f445956": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f743035e99b347e29f2c140c630c2ccc",
      "placeholder": "​",
      "style": "IPY_MODEL_636dd18530fe4c6192b9e0872b73aa9a",
      "value": " 570/570 [00:00&lt;00:00, 33.6kB/s]"
     }
    },
    "b715f972a1fa48708f79e956f1b33421": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b01e1a59c1fe4b26893b532111cbe58a",
      "placeholder": "​",
      "style": "IPY_MODEL_940d8402983f4ceeb2d3db16162f5677",
      "value": " 440M/440M [00:01&lt;00:00, 275MB/s]"
     }
    },
    "bbf92c4fada4456abe8e9563f25f731a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a88f4a91fe4f40eeab94aadf4af6fb4c",
       "IPY_MODEL_60be5e10f54d475fab0a2d156c498ea0",
       "IPY_MODEL_b3ba6e349ecc4a10ab6c93117f445956"
      ],
      "layout": "IPY_MODEL_f181616db242429795d21b51efc271b3"
     }
    },
    "bcd078cc7dcc4f579e5fddcad5fb16ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2e1394495d9341668c1bd6f7e7f82a61",
       "IPY_MODEL_d1e2a90376e34c779472c529a15b6b15",
       "IPY_MODEL_b715f972a1fa48708f79e956f1b33421"
      ],
      "layout": "IPY_MODEL_7080cf2b27064cd1bea2b76b34c45394"
     }
    },
    "bfcb3f06384b469fa74c513e03f02c20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c09b7b01f93d471e9d80ecf9759b2a13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c2f9568a58a04b68b7991514e05acd20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c342d762227344d6bfa3d711eb7b0508": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52ef4af975fc414bb152fd12a65ce1d1",
      "placeholder": "​",
      "style": "IPY_MODEL_dcaa9ae3027347229b3f3258aad015d1",
      "value": " 232k/232k [00:00&lt;00:00, 8.76MB/s]"
     }
    },
    "c45f7a5046ff4f15ad9e571c0571ed27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c59414047aed4376af9ffc79759b9e32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c82ef727b14b4ee09fba8bbf950a8420": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6e45467a442439eb034c7326f08cf4e",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3676f73895064c30b2bf261c18cdf7d3",
      "value": 456318
     }
    },
    "c88e4918710141399ca6bf0da79711e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c986609b554b4f4494b1b847f872d08d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cc9e4730cf954e00bff4ef0503758e07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce39aca40ebd4a93a784cfa8938c1d03",
      "placeholder": "​",
      "style": "IPY_MODEL_03bc194d73f4486d89a3767e8d14f34c",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "cdbdeff2209c4b958315cf5d71315cb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f545cc1f9c8f4b02b883bc6f0f2491b8",
       "IPY_MODEL_0e0e82acf52848f49aeb31f719ffd99b",
       "IPY_MODEL_ebdcb74a6a5c48c6bcdc1c92a19c8994"
      ],
      "layout": "IPY_MODEL_d1c3c9bd0f274a6f870af7c64e376c17"
     }
    },
    "ce39aca40ebd4a93a784cfa8938c1d03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfdcc443a71749fdb21a22c918fbaf00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cc9e4730cf954e00bff4ef0503758e07",
       "IPY_MODEL_273ac09e03a44ee490fe4ba5b543f255",
       "IPY_MODEL_9301272e564145839972eca8f77b70a4"
      ],
      "layout": "IPY_MODEL_c45f7a5046ff4f15ad9e571c0571ed27"
     }
    },
    "d16fe136c8da4ced914add81a51d6383": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bbf19d1e6d142a5b78de83c90929c09",
      "placeholder": "​",
      "style": "IPY_MODEL_f0ca52e1f04d44ac935a0da44580f9d1",
      "value": " 899k/899k [00:00&lt;00:00, 26.3MB/s]"
     }
    },
    "d1c3c9bd0f274a6f870af7c64e376c17": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1e2a90376e34c779472c529a15b6b15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d405e6b4bfdd4c3bbaba6ec2fea34408",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8e7abec6ac454ebd9b061b90a9ab0c98",
      "value": 440473133
     }
    },
    "d3fea5a42bc546378b89c451ec76e0a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d405e6b4bfdd4c3bbaba6ec2fea34408": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4ba16dec4184db9a5a4a9ead24a3e6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d763da1a2d214656ae8cd198cf606281": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08c2983c2c3a4ac2bd879496c93ead15",
      "max": 481,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c09b7b01f93d471e9d80ecf9759b2a13",
      "value": 481
     }
    },
    "d930e25291e34f93a05fee9ac1f1b55a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dadcaefa543b42d6b78d351f0388c072": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2bd6873d108e478cb9ef916a587408c8",
       "IPY_MODEL_eed76499db3b4fa2aadf72cf165fe4c8",
       "IPY_MODEL_90e2ae4c4f4d47eb826a34f567f6838f"
      ],
      "layout": "IPY_MODEL_02ff42ab910c4145bd9510cc08f3b94f"
     }
    },
    "dcaa9ae3027347229b3f3258aad015d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dcbf0abd2e024ff5acd054f2baa1dcb6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de0b051d9c5341de96c55029732f00cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4ba16dec4184db9a5a4a9ead24a3e6b",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f58d1cbfa5a7464c9c26d17642c2cc42",
      "value": 466062
     }
    },
    "e1514f8bad0f4b089d539ddd21086a57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e315d5141b104ee3a92c4757e142ae1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e43b65112a7c4c1fb9904ca5ac4f6734": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bfee968b89c4580b57f66becd02ea71",
      "placeholder": "​",
      "style": "IPY_MODEL_433c92c35a0b46a68e415e33a9f41f1a",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "e55696bdbb5041979ddba03b2ebe9ddd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e655a0302c2840ca9080b888e15882a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e720c30050874212844d8194b03ddc75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e751b622b2704ea68d9c7143eff50ce3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e865691b14644d909285cbb1d8dcf496": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e87de82893af4558adec0d8b26bc6a1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ea791374e2374fc3a1cb6783d67e6b79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea7de39db7c246b5be587183f1463623": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebdcb74a6a5c48c6bcdc1c92a19c8994": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93e2f4de97ca4e06920a2d871aa49083",
      "placeholder": "​",
      "style": "IPY_MODEL_9cb9851c654843a3b3f62c4d7692906f",
      "value": " 466k/466k [00:00&lt;00:00, 14.1MB/s]"
     }
    },
    "eed76499db3b4fa2aadf72cf165fe4c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61705d7534234ef1b19daab67f44ca58",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6aa1b4caffa04e3bad3cf0fd336fb706",
      "value": 1355863
     }
    },
    "f09b59a008b4454f9cd4a2d5311bff39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0ca52e1f04d44ac935a0da44580f9d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f181616db242429795d21b51efc271b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f21f7c3e125842e1a6a905a78b33ee08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f2d29fa1d9ce428dbd478b03e15f0d2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_49722bd776d04226b0fd5d19cab994ee",
       "IPY_MODEL_35f85c211de84640b106f79a44e4ba13",
       "IPY_MODEL_1346c8efc182433a8dc87dd981618edd"
      ],
      "layout": "IPY_MODEL_6e7b3a1ba67541a0bb58800028abed5f"
     }
    },
    "f3007c832f8f403ca83a59b3b03136e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4649f0058484ebe81d02fe44d99f1b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f545cc1f9c8f4b02b883bc6f0f2491b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea7de39db7c246b5be587183f1463623",
      "placeholder": "​",
      "style": "IPY_MODEL_617eb3551a1a4b1da486646d29c3a1d3",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "f58d1cbfa5a7464c9c26d17642c2cc42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f6e45467a442439eb034c7326f08cf4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f743035e99b347e29f2c140c630c2ccc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f78c3b4355de482b9210b5469eb6f3e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f93a1275f1ca4fb98df56c731f5582be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72f3724479364b448a969d2c93388076",
      "placeholder": "​",
      "style": "IPY_MODEL_8bb8420357f441ea95520f9d94ace1a2",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "ffec2e6c5a234b00884a144bbf67e17f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
