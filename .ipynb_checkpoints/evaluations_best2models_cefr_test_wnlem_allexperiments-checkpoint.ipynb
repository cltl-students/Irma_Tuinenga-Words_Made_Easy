{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22097079-bddc-4066-bcd6-981db0cde8bc",
   "metadata": {},
   "source": [
    "## test set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90382b18-1030-4f34-aaf6-4c5d2af4caab",
   "metadata": {},
   "source": [
    "### parse sentences and obtain PoS for complex word in new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2947f76a-77c9-40c0-aff5-be627f30102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "def get_treebank_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return 'JJ'\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return 'VB'\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return 'NN'\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return 'RB'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# open input file\n",
    "with open('./data/test/tsar2022_en_test_none_no_noise.tsv', 'r', encoding='utf-8') as infile:\n",
    "    reader = csv.reader(infile, delimiter='\\t')\n",
    "\n",
    "    # open output file\n",
    "    with open('./data/test/test_pos.tsv', 'w', encoding='utf-8') as outfile:\n",
    "        writer = csv.writer(outfile, delimiter='\\t')\n",
    "        \n",
    "        # loop over rows in the input file\n",
    "        for row in reader:\n",
    "            sentence = row[0]\n",
    "            complex_word = row[1]\n",
    "\n",
    "            # tokenize sentence and get POS tags\n",
    "            tagged_sentence = pos_tag(word_tokenize(sentence))\n",
    "\n",
    "            # find the POS of the complex word and write the sentence, complex word, and the pos tag of the complex word to the output file\n",
    "            for word, pos in tagged_sentence:\n",
    "                if word.lower() == complex_word.lower():\n",
    "                    # Get the Treebank POS and write to the output file\n",
    "                    treebank_pos = get_treebank_pos(pos)\n",
    "                    writer.writerow([sentence, complex_word, treebank_pos])\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de98bf0-793b-4975-91cf-725f1e60f77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a520fb4-7469-4a96-901d-017105cf43bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d07dbd-6832-4f84-8f03-0608788719f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86e47a95-bf30-4b15-9a9c-f5b075bb6dcc",
   "metadata": {},
   "source": [
    "## for CEFR-J dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53ed8a8-6947-400c-8070-148c5c7c36b7",
   "metadata": {},
   "source": [
    "### for model SG_MA_SS_bsRobertalarge_robertabase:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc9e169-bbd6-4a6d-93cc-6d582a4f82a8",
   "metadata": {},
   "source": [
    "### lemmatized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85d4b4f6-302e-4e52-bdc6-b2134c33bff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_robertabase_SR_cefrj_lem exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefrj/cefrj_all.tsv', sep='\\t', header=None, names=['word', 'cefr'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# convert the CEFR dataframe into a dictionary for efficient lookups\n",
    "cefr_dict = cefr_df.set_index('word')['cefr'].to_dict()\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_robertabase.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = [(original, cefr_dict.get(lemmatized, 7)) for original, lemmatized in substitutes_lemmatized]\n",
    "    #print(f\"substitutes with CEFR levels mapped to numerical values: {substitutes_cefr}\\n\")\n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked substitutes based on their CEFR level mapped to numerical values: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_robertabase_SR_cefrj_lem exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem.tsv'\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c099b9cd-d498-488f-903f-60237d26a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem.tsv --output_file ./output/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a1c17-ddc7-46b9-b959-da197892b338",
   "metadata": {},
   "outputs": [],
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.6236\n",
    "\n",
    "MAP@3 = 0.4301\n",
    "MAP@5 = 0.3268\n",
    "MAP@10 = 0.2036\n",
    "\n",
    "Potential@3 = 0.8467\n",
    "Potential@5 = 0.9247\n",
    "Potential@10 = 0.9677\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.2661\n",
    "Accuracy@2@top_gold_1 = 0.4059\n",
    "Accuracy@3@top_gold_1 = 0.4784"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1585801-1f7d-4c60-a5f4-b355b7364269",
   "metadata": {},
   "source": [
    "### with pos tag of the complex word taken into account:\n",
    "(each lemmatized substitute is mapped to its CEFR level and included only if the part of speech (POS) of the word (in ./cefrj/cefrj_all_treebank.tsv) matches the POS of the complex word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a16d648-fc7c-408f-a7b8-1bea505141eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_robertabase_SR_cefrj_lem_pos exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem_pos.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefrj/cefrj_all_treebank.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# read the pos tags of complex words\n",
    "complex_word_pos_df = pd.read_csv('./data/test/test_pos.tsv', sep='\\t', header=None, names=['sentence', 'complex_word', 'pos'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_robertabase.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "    \n",
    "    # Get the pos of the complex_word\n",
    "    complex_word_pos = complex_word_pos_df[complex_word_pos_df['complex_word'] == complex_word]['pos'].values[0]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = []\n",
    "    for original, lemmatized in substitutes_lemmatized:\n",
    "        # if the lemmatized substitute word is found in cefrj_all_treebank.tsv AND the POS tag of that word (in cefrj_all_treebank.tsv) is the same as the POS tag of the complex word:\n",
    "        if lemmatized in cefr_df['word'].values and cefr_df[cefr_df['word'] == lemmatized]['pos'].values[0] == complex_word_pos:\n",
    "            substitutes_cefr.append((original, cefr_df[cefr_df['word'] == lemmatized]['cefr'].values[0]))\n",
    "        else:\n",
    "            substitutes_cefr.append((original, 7))  # assign a high value if it doesn't have a CEFR level or if pos don't match\n",
    "         \n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked_cefr_subs: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem_pos.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_robertabase_SR_cefrj_lem_pos exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem_pos.tsv'\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e07d428-d774-4ca3-b65d-55ea9b9c82e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem_pos.tsv --output_file ./output/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem_pos.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "11bbc841-04e3-43a2-bff8-9ebdadbd4c09",
   "metadata": {},
   "source": [
    "\n",
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem_pos.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem_pos.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.4838\n",
    "\n",
    "MAP@3 = 0.3449\n",
    "MAP@5 = 0.2697\n",
    "MAP@10 = 0.1824\n",
    "\n",
    "Potential@3 = 0.7768\n",
    "Potential@5 = 0.8844\n",
    "Potential@10 = 0.9677\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.2069\n",
    "Accuracy@2@top_gold_1 = 0.3306\n",
    "Accuracy@3@top_gold_1 = 0.4139"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde24641-a8ce-4c17-beff-25eac790cf5d",
   "metadata": {},
   "source": [
    "### with pos tag of the substitutes taken into account:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58df6139-d12d-4dda-a560-1490a9e2ae9a",
   "metadata": {},
   "source": [
    "If the lemmatized version of the substitute is found in the 'cefrj_all_treebank.tsv' file, and\n",
    "If the POS tag of that word (as listed in 'cefrj_all_treebank.tsv') matches the POS tag of the original substitute word (as determined by parsing the sentence where the complex word is replaced by the original substitute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "699b99bb-140a-487a-a535-aeac1438b73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_robertabase_SR_cefrj_lem_possub_orig exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem_possub_orig.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefrj/cefrj_all_treebank.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_robertabase.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = []\n",
    "    for original, lemmatized in substitutes_lemmatized:\n",
    "        # get the pos of the original substitute by parsing the sentence where the complex word is replaced by the substitute\n",
    "        sub_sentence = sentence.replace(complex_word, original)\n",
    "        sub_pos = dict(pos_tag(word_tokenize(sub_sentence))).get(original)\n",
    "        # if the lemmatized substitute equals a word that is found in cefrj_all_treebank.tsv AND the POS tag of that word (in cefrj_all_treebank.tsv) is the same as the POS tag of the substitute:\n",
    "        if lemmatized in cefr_df['word'].values and cefr_df[cefr_df['word'] == lemmatized]['pos'].values[0] == sub_pos:\n",
    "            substitutes_cefr.append((original, cefr_df[cefr_df['word'] == lemmatized]['cefr'].values[0]))\n",
    "        else:\n",
    "            substitutes_cefr.append((original, 7))  # assign a high value if it doesn't have a CEFR level or if pos don't match\n",
    "\n",
    "         \n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked_cefr_subs: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem_possub_orig.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_robertabase_SR_cefrj_lem_possub_orig exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem_possub_orig.tsv'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de5087f-8cd7-46f6-a182-09e5d6515ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem_possub_orig.tsv --output_file ./output/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem_possub_orig.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd5382a3-9e85-4037-bdd0-4eb3be5781cf",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem_possub_orig.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_robertabase_SR_cefrj_lem_possub_orig.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.4946\n",
    "\n",
    "MAP@3 = 0.3506\n",
    "MAP@5 = 0.2747\n",
    "MAP@10 = 0.1838\n",
    "\n",
    "Potential@3 = 0.7822\n",
    "Potential@5 = 0.9032\n",
    "Potential@10 = 0.9677\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.2123\n",
    "Accuracy@2@top_gold_1 = 0.3387\n",
    "Accuracy@3@top_gold_1 = 0.4354\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ea6076-4989-4bb3-a38a-fbb308e9c972",
   "metadata": {},
   "source": [
    "### for model SG_MA_SS_bsRobertalarge_electralarge:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc2f09d-30ea-4e85-ad74-67946deee5e1",
   "metadata": {},
   "source": [
    "### lemmatized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c842d45-9134-446b-b08a-e2915247c291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_electralarge_SR_cefrj_lem exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem.tsv'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefrj/cefrj_all.tsv', sep='\\t', header=None, names=['word', 'cefr'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# convert the CEFR dataframe into a dictionary for efficient lookups\n",
    "cefr_dict = cefr_df.set_index('word')['cefr'].to_dict()\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_electralarge.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = [(original, cefr_dict.get(lemmatized, 7)) for original, lemmatized in substitutes_lemmatized]\n",
    "    #print(f\"substitutes with CEFR levels mapped to numerical values: {substitutes_cefr}\\n\")\n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked substitutes based on their CEFR level mapped to numerical values: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_electralarge_SR_cefrj_lem exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem.tsv'}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c8fe2-d3e1-4d85-bf14-d9903cf463c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem.tsv --output_file ./output/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5375de4-f974-46c5-90f2-c07b64c3c0bf",
   "metadata": {},
   "source": [
    "========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.5967\n",
    "\n",
    "MAP@3 = 0.429\n",
    "MAP@5 = 0.3263\n",
    "MAP@10 = 0.2014\n",
    "\n",
    "Potential@3 = 0.8467\n",
    "Potential@5 = 0.8978\n",
    "Potential@10 = 0.9462\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.258\n",
    "Accuracy@2@top_gold_1 = 0.4139\n",
    "Accuracy@3@top_gold_1 = 0.4865"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fb1c77-3054-4a8f-9f76-e10fbb42f0e0",
   "metadata": {},
   "source": [
    "### with pos tag of the complex word taken into account:\n",
    "(each lemmatized substitute is mapped to its CEFR level and included only if the part of speech (POS) of the word (in ./cefrj/cefrj_all_treebank.tsv) matches the POS of the complex word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8293fd0c-e26b-4e0a-9df9-7737e9c417c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_electralarge_SR_cefrj_lem_pos exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem_pos.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefrj/cefrj_all_treebank.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# read the pos tags of complex words\n",
    "complex_word_pos_df = pd.read_csv('./data/test/test_pos.tsv', sep='\\t', header=None, names=['sentence', 'complex_word', 'pos'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_electralarge.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "    \n",
    "    # Get the pos of the complex_word\n",
    "    complex_word_pos = complex_word_pos_df[complex_word_pos_df['complex_word'] == complex_word]['pos'].values[0]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = []\n",
    "    for original, lemmatized in substitutes_lemmatized:\n",
    "        # if the lemmatized substitute word is found in cefrj_all_treebank.tsv AND the POS tag of that word (in cefrj_all_treebank.tsv) is the same as the POS tag of the complex word:\n",
    "        if lemmatized in cefr_df['word'].values and cefr_df[cefr_df['word'] == lemmatized]['pos'].values[0] == complex_word_pos:\n",
    "            substitutes_cefr.append((original, cefr_df[cefr_df['word'] == lemmatized]['cefr'].values[0]))\n",
    "        else:\n",
    "            substitutes_cefr.append((original, 7))  # assign a high value if it doesn't have a CEFR level or if pos don't match\n",
    "         \n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked_cefr_subs: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem_pos.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_electralarge_SR_cefrj_lem_pos exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem_pos.tsv'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73826038-d89a-42ec-bc5f-2c5647992018",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem_pos.tsv --output_file ./output/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem_pos.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d6f383-1f7a-4bdb-8afe-f33612d16e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem_pos.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem_pos.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.4677\n",
    "\n",
    "MAP@3 = 0.3267\n",
    "MAP@5 = 0.2558\n",
    "MAP@10 = 0.1758\n",
    "\n",
    "Potential@3 = 0.7741\n",
    "Potential@5 = 0.8655\n",
    "Potential@10 = 0.9462\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1908\n",
    "Accuracy@2@top_gold_1 = 0.3064\n",
    "Accuracy@3@top_gold_1 = 0.3978"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2001fe-59d1-45b0-a08f-f3d47daf3b5e",
   "metadata": {},
   "source": [
    "### with pos tag of the substitutes taken into account:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e144c-b916-4882-be18-0f06a8d400a2",
   "metadata": {},
   "source": [
    "If the lemmatized version of the substitute is found in the 'cefrj_all_treebank.tsv' file, and\n",
    "If the POS tag of that word (as listed in 'cefrj_all_treebank.tsv') matches the POS tag of the original substitute word (as determined by parsing the sentence where the complex word is replaced by the original substitute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "275bcca7-2578-4923-925a-4ddeab782a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_electralarge_SR_cefrj_lem_possub_orig exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem_possub_orig.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefrj/cefrj_all_treebank.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_electralarge.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = []\n",
    "    for original, lemmatized in substitutes_lemmatized:\n",
    "        # get the pos of the original substitute by parsing the sentence where the complex word is replaced by the substitute\n",
    "        sub_sentence = sentence.replace(complex_word, original)\n",
    "        sub_pos = dict(pos_tag(word_tokenize(sub_sentence))).get(original)\n",
    "        # if the lemmatized substitute equals a word that is found in cefrj_all_treebank.tsv AND the POS tag of that word (in cefrj_all_treebank.tsv) is the same as the POS tag of the substitute:\n",
    "        if lemmatized in cefr_df['word'].values and cefr_df[cefr_df['word'] == lemmatized]['pos'].values[0] == sub_pos:\n",
    "            substitutes_cefr.append((original, cefr_df[cefr_df['word'] == lemmatized]['cefr'].values[0]))\n",
    "        else:\n",
    "            substitutes_cefr.append((original, 7))  # assign a high value if it doesn't have a CEFR level or if pos don't match\n",
    "\n",
    "         \n",
    "   \n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked_cefr_subs: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem_possub_orig.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_electralarge_SR_cefrj_lem_possub_orig exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem_possub_orig.tsv'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47446198-395d-4159-bace-bfebba10ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem_possub_orig.tsv --output_file ./output/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem_possub_orig.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d647513e-6965-4fd3-a479-742403392a90",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem_possub_orig.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_electralarge_SR_cefrj_lem_possub_orig.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.4408\n",
    "\n",
    "MAP@3 = 0.3218\n",
    "MAP@5 = 0.2568\n",
    "MAP@10 = 0.1752\n",
    "\n",
    "Potential@3 = 0.7983\n",
    "Potential@5 = 0.8844\n",
    "Potential@10 = 0.9462\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1854\n",
    "Accuracy@2@top_gold_1 = 0.2956\n",
    "Accuracy@3@top_gold_1 = 0.3978"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656259c9-8c8b-4c2c-88f7-6b4812ce9386",
   "metadata": {},
   "source": [
    "## for Uchida et al dataset (parsed sentences first in datafiles_changes.ipynb):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767e5b77-4bba-4dad-b5b5-0d25308b1eea",
   "metadata": {},
   "source": [
    "### for model SG_MA_SS_bsRobertalarge_robertabase:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5892df1-0c6b-4200-bc7e-ecb321ebc6f1",
   "metadata": {},
   "source": [
    "### lemmatized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3994bfc4-0c65-4a06-ae21-2978dd3174dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_robertabase_SR_cefruchida_lem exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefr/uchida_pos.tsv', sep='\\t', header=None, names=['word', 'pos','cefr'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# convert the CEFR dataframe into a dictionary for efficient lookups\n",
    "cefr_dict = cefr_df.set_index('word')['cefr'].to_dict()\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_robertabase.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = [(original, cefr_dict.get(lemmatized, 7)) for original, lemmatized in substitutes_lemmatized]\n",
    "    #print(f\"substitutes with CEFR levels mapped to numerical values: {substitutes_cefr}\\n\")\n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked substitutes based on their CEFR level mapped to numerical values: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "    \n",
    "    \n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_robertabase_SR_cefruchida_lem exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem.tsv'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b90e72-cb03-440c-81b3-fe8d85f1f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem.tsv --output_file ./output/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41f4b085-0c9c-4627-be1e-c97694edb5a2",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.4462\n",
    "\n",
    "MAP@3 = 0.3473\n",
    "MAP@5 = 0.2847\n",
    "MAP@10 = 0.1854\n",
    "\n",
    "Potential@3 = 0.8091\n",
    "Potential@5 = 0.9139\n",
    "Potential@10 = 0.9677\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1559\n",
    "Accuracy@2@top_gold_1 = 0.3037\n",
    "Accuracy@3@top_gold_1 = 0.4032"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f9dc72-1720-4612-8e4b-a935a15ef00f",
   "metadata": {},
   "source": [
    "### with pos tag of the complex word taken into account:\n",
    "(each lemmatized substitute is mapped to its CEFR level, and the specific CEFR level is included only if the part of speech (POS) of the word (in ./cefrj/cefrj_all_treebank.tsv) matches the POS of the complex word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d812602a-756b-4ef6-9a51-5bd20673ae10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_robertabase_SR_cefruchida_lem_pos exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem_pos.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefr/uchida_pos.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# read the pos tags of complex words\n",
    "complex_word_pos_df = pd.read_csv('./data/test/test_pos.tsv', sep='\\t', header=None, names=['sentence', 'complex_word', 'pos'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_robertabase.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "    \n",
    "    # Get the pos of the complex_word\n",
    "    complex_word_pos = complex_word_pos_df[complex_word_pos_df['complex_word'] == complex_word]['pos'].values[0]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = []\n",
    "    for original, lemmatized in substitutes_lemmatized:\n",
    "        # if the lemmatized substitute word is found in cefrj_all_treebank.tsv AND the POS tag of that word (in cefrj_all_treebank.tsv) is the same as the POS tag of the complex word:\n",
    "        if lemmatized in cefr_df['word'].values and cefr_df[cefr_df['word'] == lemmatized]['pos'].values[0] == complex_word_pos:\n",
    "            substitutes_cefr.append((original, cefr_df[cefr_df['word'] == lemmatized]['cefr'].values[0]))\n",
    "        else:\n",
    "            substitutes_cefr.append((original, 7))  # assign a high value if it doesn't have a CEFR level or if pos don't match\n",
    "         \n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked_cefr_subs: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new TSV file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem_pos.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_robertabase_SR_cefruchida_lem_pos exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem_pos.tsv'\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4af4f7e-43ff-4599-8457-8204e3c879f2",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem_pos.tsv --output_file ./output/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem_pos.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22f67d16-cd68-4794-9789-e6145e1444df",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem_pos.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem_pos.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.4865\n",
    "\n",
    "MAP@3 = 0.3649\n",
    "MAP@5 = 0.2946\n",
    "MAP@10 = 0.1898\n",
    "\n",
    "Potential@3 = 0.8252\n",
    "Potential@5 = 0.922\n",
    "Potential@10 = 0.9677\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1854\n",
    "Accuracy@2@top_gold_1 = 0.3306\n",
    "Accuracy@3@top_gold_1 = 0.4274\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04573e0-d122-4776-b6c3-8c213696f8f4",
   "metadata": {},
   "source": [
    "### with pos tag of the substitutes taken into account:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddd1e03-27d5-43da-8fb7-407f1c8c2920",
   "metadata": {},
   "source": [
    "If the lemmatized version of the substitute is found in the './cefr/uchida_pos.tsv' file, and\n",
    "If the POS tag of that word (as listed in './cefr/uchida_pos.tsv) matches the POS tag of the original substitute word (as determined by parsing the sentence where the complex word is replaced by the original substitute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61bdd186-4c79-4460-92d6-0f00cadec6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_robertabase_SR_cefruchida_lem_possub_orig exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem_possub_orig.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefr/uchida_pos.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_robertabase.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = []\n",
    "    for original, lemmatized in substitutes_lemmatized:\n",
    "        # get the pos of the original substitute by parsing the sentence where the complex word is replaced by the substitute\n",
    "        sub_sentence = sentence.replace(complex_word, original)\n",
    "        sub_pos = dict(pos_tag(word_tokenize(sub_sentence))).get(original)\n",
    "        # if the lemmatized substitute equals a word that is found in cefrj_all_treebank.tsv AND the POS tag of that word (in cefrj_all_treebank.tsv) is the same as the POS tag of the substitute:\n",
    "        if lemmatized in cefr_df['word'].values and cefr_df[cefr_df['word'] == lemmatized]['pos'].values[0] == sub_pos:\n",
    "            substitutes_cefr.append((original, cefr_df[cefr_df['word'] == lemmatized]['cefr'].values[0]))\n",
    "        else:\n",
    "            substitutes_cefr.append((original, 7))  # assign a high value if it doesn't have a CEFR level or if pos don't match\n",
    "\n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked_cefr_subs: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new TSV file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem_possub_orig.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_robertabase_SR_cefruchida_lem_possub_orig exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem_possub_orig.tsv'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd92cbdc-7ca8-4126-8d3c-adc74db90a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem_possub_orig.tsv --output_file ./output/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem_possub_orig.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3ee13d3-0174-4ec4-93ea-9100ee46aca1",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem_possub_orig.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lem_possub_orig.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.5\n",
    "\n",
    "MAP@3 = 0.3761\n",
    "MAP@5 = 0.2997\n",
    "MAP@10 = 0.1918\n",
    "\n",
    "Potential@3 = 0.8279\n",
    "Potential@5 = 0.9193\n",
    "Potential@10 = 0.9677\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1989\n",
    "Accuracy@2@top_gold_1 = 0.3387\n",
    "Accuracy@3@top_gold_1 = 0.4327"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e233f-8a9d-4991-8472-8e9ee6e518e2",
   "metadata": {},
   "source": [
    "### for model SG_MA_SS_bsRobertalarge_electralarge:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a221b9-6d41-4464-8cdf-40ad43e412e1",
   "metadata": {},
   "source": [
    "### lemmatized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8b0a6a1-16b5-4e02-866c-4e3e4d7c30e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_electralarge_SR_cefruchida_lem.tsv exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefr/uchida_pos.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# convert the CEFR dataframe into a dictionary for efficient lookups\n",
    "cefr_dict = cefr_df.set_index('word')['cefr'].to_dict()\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_electralarge.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = [(original, cefr_dict.get(lemmatized, 7)) for original, lemmatized in substitutes_lemmatized]\n",
    "    #print(f\"substitutes with CEFR levels mapped to numerical values: {substitutes_cefr}\\n\")\n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked substitutes based on their CEFR level mapped to numerical values: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_electralarge_SR_cefruchida_lem.tsv exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem.tsv'\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a63b48b-7f09-4ca6-ad11-0ebb4dd53397",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem.tsv --output_file ./output/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8f3689e-0b61-4ef2-a422-d3c71c4345af",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.4543\n",
    "\n",
    "MAP@3 = 0.3276\n",
    "MAP@5 = 0.2745\n",
    "MAP@10 = 0.1803\n",
    "\n",
    "Potential@3 = 0.7956\n",
    "Potential@5 = 0.8844\n",
    "Potential@10 = 0.9462\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1801\n",
    "Accuracy@2@top_gold_1 = 0.2876\n",
    "Accuracy@3@top_gold_1 = 0.3817\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66595bd5-d147-45c8-bf54-cc7053ccd579",
   "metadata": {},
   "source": [
    "### with pos tag of the complex word taken into account:\n",
    "(each lemmatized substitute is mapped to its CEFR level and included only if the part of speech (POS) of the word (in cefr/uchida_pos.tsv) matches the POS of the complex word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17db4e22-b6c3-4f22-93b5-b2e46fa162a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_electralarge_SR_cefruchida_lem_pos exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem_pos.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefr/uchida_pos.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# read the pos tags of complex words\n",
    "complex_word_pos_df = pd.read_csv('./data/test/test_pos.tsv', sep='\\t', header=None, names=['sentence', 'complex_word', 'pos'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_electralarge.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "    \n",
    "    # Get the pos of the complex_word\n",
    "    complex_word_pos = complex_word_pos_df[complex_word_pos_df['complex_word'] == complex_word]['pos'].values[0]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = []\n",
    "    for original, lemmatized in substitutes_lemmatized:\n",
    "        # if the lemmatized substitute word is found in cefrj_all_treebank.tsv AND the POS tag of that word (in cefrj_all_treebank.tsv) is the same as the POS tag of the complex word:\n",
    "        if lemmatized in cefr_df['word'].values and cefr_df[cefr_df['word'] == lemmatized]['pos'].values[0] == complex_word_pos:\n",
    "            substitutes_cefr.append((original, cefr_df[cefr_df['word'] == lemmatized]['cefr'].values[0]))\n",
    "        else:\n",
    "            substitutes_cefr.append((original, 7))  # assign a high value if it doesn't have a CEFR level or if pos don't match\n",
    "         \n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked_cefr_subs: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "\n",
    "# Create a new dataframe from the new lists and write it to a new TSV file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem_pos.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_electralarge_SR_cefruchida_lem_pos exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem_pos.tsv'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d29d80-347c-4013-91d1-8bbbb29ecfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem_pos.tsv --output_file ./output/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem_pos.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac743017-8021-40d0-8ef7-b2b780dce46f",
   "metadata": {},
   "source": [
    "========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem_pos.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem_pos.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.4677\n",
    "\n",
    "MAP@3 = 0.3434\n",
    "MAP@5 = 0.2821\n",
    "MAP@10 = 0.1832\n",
    "\n",
    "Potential@3 = 0.7983\n",
    "Potential@5 = 0.887\n",
    "Potential@10 = 0.9462\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1854\n",
    "Accuracy@2@top_gold_1 = 0.3037\n",
    "Accuracy@3@top_gold_1 = 0.4005\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dcce6e-3e31-4e12-a529-672a3f309d58",
   "metadata": {},
   "source": [
    "### with pos tag of the substitutes taken into account:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3197007a-b060-4b60-8939-f3cff236c18f",
   "metadata": {},
   "source": [
    "\n",
    "If the lemmatized version of the substitute is found in the './cefr/uchida_pos.tsv' file, and\n",
    "If the POS tag of that word (as listed in './cefr/uchida_pos.tsv) matches the POS tag of the original substitute word (as determined by parsing the sentence where the complex word is replaced by the original substitute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc18cf3d-2ad3-41de-9cd8-61e3bed1ce43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_electralarge_SR_cefruchida_lem_possub_orig exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem_possub_orig.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefr/uchida_pos.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_electralarge.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = []\n",
    "    for original, lemmatized in substitutes_lemmatized:\n",
    "        # get the pos of the original substitute by parsing the sentence where the complex word is replaced by the substitute\n",
    "        sub_sentence = sentence.replace(complex_word, original)\n",
    "        sub_pos = dict(pos_tag(word_tokenize(sub_sentence))).get(original)\n",
    "        # if the lemmatized substitute equals a word that is found in cefrj_all_treebank.tsv AND the POS tag of that word (in cefrj_all_treebank.tsv) is the same as the POS tag of the substitute:\n",
    "        if lemmatized in cefr_df['word'].values and cefr_df[cefr_df['word'] == lemmatized]['pos'].values[0] == sub_pos:\n",
    "            substitutes_cefr.append((original, cefr_df[cefr_df['word'] == lemmatized]['cefr'].values[0]))\n",
    "        else:\n",
    "            substitutes_cefr.append((original, 7))  # assign a high value if it doesn't have a CEFR level or if pos don't match\n",
    " \n",
    "   \n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked_cefr_subs: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new TSV file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem_possub_orig.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_electralarge_SR_cefruchida_lem_possub_orig exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem_possub_orig.tsv'\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e6b7f3-be74-4f8b-a1e8-0ecab297b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem_possub_orig.tsv --output_file ./output/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem_possub_orig.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9fec22dd-818a-4a7a-888a-0dfb4d28ea01",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem_possub_orig.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lem_possub_orig.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.4731\n",
    "\n",
    "MAP@3 = 0.3515\n",
    "MAP@5 = 0.2877\n",
    "MAP@10 = 0.1851\n",
    "\n",
    "Potential@3 = 0.8145\n",
    "Potential@5 = 0.8897\n",
    "Potential@10 = 0.9462\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1854\n",
    "Accuracy@2@top_gold_1 = 0.3252\n",
    "Accuracy@3@top_gold_1 = 0.4032\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c86be84-3a42-4c9a-9ec3-91ee39d1b888",
   "metadata": {},
   "source": [
    "### EFFLEX dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97872bc-a34e-442b-a765-fd2effde1c0e",
   "metadata": {},
   "source": [
    "### for model SG_MA_SS_bsRobertalarge_robertabase:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5316303-1a58-4a07-a608-e722bdb1518a",
   "metadata": {},
   "source": [
    "#### lemmatized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8434242e-95fe-40a2-bde5-3e3f8547aa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_robertabase_SR_cefrefflex_lem exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefr_efllex/EFLLex.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# convert the CEFR dataframe into a dictionary for efficient lookups\n",
    "cefr_dict = cefr_df.set_index('word')['cefr'].to_dict()\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_robertabase.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = [(original, cefr_dict.get(lemmatized, 7)) for original, lemmatized in substitutes_lemmatized]\n",
    "    #print(f\"substitutes with CEFR levels mapped to numerical values: {substitutes_cefr}\\n\")\n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked substitutes based on their CEFR level mapped to numerical values: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_robertabase_SR_cefrefflex_lem exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem.tsv'\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e791c0-dbc3-4ef8-810d-7d67914f20dc",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem.tsv --output_file ./output/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b44b53db-971d-4d5e-b378-3e87ab676d64",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.3951\n",
    "\n",
    "MAP@3 = 0.293\n",
    "MAP@5 = 0.2477\n",
    "MAP@10 = 0.1729\n",
    "\n",
    "Potential@3 = 0.7311\n",
    "Potential@5 = 0.9032\n",
    "Potential@10 = 0.9677\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1155\n",
    "Accuracy@2@top_gold_1 = 0.2607\n",
    "Accuracy@3@top_gold_1 = 0.3575"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4175a7da-01fb-4e6a-9b75-4c798aeebb72",
   "metadata": {},
   "source": [
    "### with pos tag of the complex word taken into account:\n",
    "(each lemmatized substitute is mapped to its CEFR level and included only if the part of speech (POS) of the word (in ./cefrj/cefrj_all_treebank.tsv) matches the POS of the complex word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c94eec39-6b86-46bc-85ef-0e1badd5d97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_robertabase_SR_cefrefflex_lem_pos exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem_pos.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefr_efllex/EFLLex.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5}\n",
    "\n",
    "# read the pos tags of complex words\n",
    "complex_word_pos_df = pd.read_csv('./data/test/test_pos.tsv', sep='\\t', header=None, names=['sentence', 'complex_word', 'pos'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_robertabase.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "    \n",
    "    # Get the pos of the complex_word\n",
    "    complex_word_pos = complex_word_pos_df[complex_word_pos_df['complex_word'] == complex_word]['pos'].values[0]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = []\n",
    "    for original, lemmatized in substitutes_lemmatized:\n",
    "        # if the lemmatized substitute word is found in cefr_efllex/EFLLex.tsv AND the POS tag of that word (in cefr_efllex/EFLLex.tsv) is the same as the POS tag of the complex word:\n",
    "        if lemmatized in cefr_df['word'].values and cefr_df[cefr_df['word'] == lemmatized]['pos'].values[0] == complex_word_pos:\n",
    "            substitutes_cefr.append((original, cefr_df[cefr_df['word'] == lemmatized]['cefr'].values[0]))\n",
    "        else:\n",
    "            substitutes_cefr.append((original, 7))  # assign a high value if it doesn't have a CEFR level or if pos don't match\n",
    "         \n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked_cefr_subs: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem_pos.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_robertabase_SR_cefrefflex_lem_pos exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem_pos.tsv'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38391fe3-3717-4815-a7a8-a0a2f05c1bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem_pos.tsv --output_file ./output/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem_pos.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77cc4e4a-9ed9-4e56-bfc1-510878f0243a",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem_pos.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem_pos.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.4435\n",
    "\n",
    "MAP@3 = 0.3261\n",
    "MAP@5 = 0.2582\n",
    "MAP@10 = 0.1777\n",
    "\n",
    "Potential@3 = 0.7526\n",
    "Potential@5 = 0.8978\n",
    "Potential@10 = 0.9677\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1612\n",
    "Accuracy@2@top_gold_1 = 0.2715\n",
    "Accuracy@3@top_gold_1 = 0.387"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5833ae3-3e8e-41e2-a1f4-035f19414b85",
   "metadata": {},
   "source": [
    "### with pos tag of the substitutes taken into account:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f410154a-4248-4fc5-a08e-fc8c2c88a657",
   "metadata": {},
   "source": [
    "\n",
    "If the lemmatized version of the substitute is found in the './cefr_efllex/EFLLex.tsv' file, and\n",
    "If the POS tag of that word (as listed in './cefr_efllex/EFLLex.tsv') matches the POS tag of the original substitute word (as determined by parsing the sentence where the complex word is replaced by the original substitute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00edfaa9-d063-4982-967c-603286ea5011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_robertabase_SR_cefrefflex_lem_possub_orig exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem_possub_orig.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefr_efllex/EFLLex.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_robertabase.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = []\n",
    "    for original, lemmatized in substitutes_lemmatized:\n",
    "        # get the pos of the original substitute by parsing the sentence where the complex word is replaced by the substitute\n",
    "        sub_sentence = sentence.replace(complex_word, original)\n",
    "        sub_pos = dict(pos_tag(word_tokenize(sub_sentence))).get(original)\n",
    "        # if the lemmatized substitute equals a word that is found in cefrj_all_treebank.tsv AND the POS tag of that word (in cefrj_all_treebank.tsv) is the same as the POS tag of the substitute:\n",
    "        if lemmatized in cefr_df['word'].values and cefr_df[cefr_df['word'] == lemmatized]['pos'].values[0] == sub_pos:\n",
    "            substitutes_cefr.append((original, cefr_df[cefr_df['word'] == lemmatized]['cefr'].values[0]))\n",
    "        else:\n",
    "            substitutes_cefr.append((original, 7))  # assign a high value if it doesn't have a CEFR level or if pos don't match\n",
    "\n",
    "         \n",
    "   \n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked_cefr_subs: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem_possub_orig.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_robertabase_SR_cefrefflex_lem_possub_orig exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem_possub_orig.tsv'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf44bb2-6afb-437f-a89e-0fffc59e2109",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem_possub_orig.tsv --output_file ./output/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem_possub_orig.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "89094354-aaa7-4d56-a5d6-709402168fba",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem_possub_orig.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_robertabase_SR_cefrefflex_lem_possub_orig.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.4543\n",
    "\n",
    "MAP@3 = 0.3297\n",
    "MAP@5 = 0.2657\n",
    "MAP@10 = 0.1799\n",
    "\n",
    "Potential@3 = 0.7661\n",
    "Potential@5 = 0.8924\n",
    "Potential@10 = 0.9677\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1612\n",
    "Accuracy@2@top_gold_1 = 0.301\n",
    "Accuracy@3@top_gold_1 = 0.4139"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f00fed-f14e-4bca-9d19-03bf473ff6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee66cad-3b53-4ec4-b719-ee8eee7702de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38d3ef88-3c0a-48e8-ba70-3e636b845458",
   "metadata": {},
   "source": [
    "### for model SG_MA_SS_bsRobertalarge_electralarge:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15a3536-d1f8-429d-a939-f8d856815a55",
   "metadata": {},
   "source": [
    "#### lemmatized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d1db2de-5cfe-48c1-91d4-7f2f2c82d0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_electralarge_SR_cefrefflex_lem exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefr_efllex/EFLLex.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# convert the CEFR dataframe into a dictionary for efficient lookups\n",
    "cefr_dict = cefr_df.set_index('word')['cefr'].to_dict()\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_electralarge.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = [(original, cefr_dict.get(lemmatized, 7)) for original, lemmatized in substitutes_lemmatized]\n",
    "    #print(f\"substitutes with CEFR levels mapped to numerical values: {substitutes_cefr}\\n\")\n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked substitutes based on their CEFR level mapped to numerical values: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_electralarge_SR_cefrefflex_lem exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem.tsv'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d77234b-51c8-4dd7-9f3f-e0f4a97eff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem.tsv --output_file ./output/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57593264-66c4-46f5-a45e-3bd326ac3ca5",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.3709\n",
    "\n",
    "MAP@3 = 0.274\n",
    "MAP@5 = 0.2394\n",
    "MAP@10 = 0.1661\n",
    "\n",
    "Potential@3 = 0.7043\n",
    "Potential@5 = 0.8655\n",
    "Potential@10 = 0.9462\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1129\n",
    "Accuracy@2@top_gold_1 = 0.2473\n",
    "Accuracy@3@top_gold_1 = 0.3548"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed11bb6-9101-4a0f-8026-0bc7c9afe2ed",
   "metadata": {},
   "source": [
    "### with pos tag of the complex word taken into account:\n",
    "(each lemmatized substitute is mapped to its CEFR level and included only if the part of speech (POS) of the word (in ./cefrj/cefrj_all_treebank.tsv) matches the POS of the complex word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79a9fe9e-93f0-4e1d-9fe3-2a0dd57c04c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_electralarge_SR_cefrefflex_lem_pos exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem_pos.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefr_efllex/EFLLex.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5}\n",
    "\n",
    "# read the pos tags of complex words\n",
    "complex_word_pos_df = pd.read_csv('./data/test/test_pos.tsv', sep='\\t', header=None, names=['sentence', 'complex_word', 'pos'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_electralarge.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "    \n",
    "    # Get the pos of the complex_word\n",
    "    complex_word_pos = complex_word_pos_df[complex_word_pos_df['complex_word'] == complex_word]['pos'].values[0]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = []\n",
    "    for original, lemmatized in substitutes_lemmatized:\n",
    "        # if the lemmatized substitute word is found in cefr_efllex/EFLLex.tsv AND the POS tag of that word (in cefr_efllex/EFLLex.tsv) is the same as the POS tag of the complex word:\n",
    "        if lemmatized in cefr_df['word'].values and cefr_df[cefr_df['word'] == lemmatized]['pos'].values[0] == complex_word_pos:\n",
    "            substitutes_cefr.append((original, cefr_df[cefr_df['word'] == lemmatized]['cefr'].values[0]))\n",
    "        else:\n",
    "            substitutes_cefr.append((original, 7))  # assign a high value if it doesn't have a CEFR level or if pos don't match\n",
    "         \n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked_cefr_subs: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem_pos.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_electralarge_SR_cefrefflex_lem_pos exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem_pos.tsv'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd1f4b5-4605-41db-80e8-308de0e94ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem_pos.tsv --output_file ./output/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem_pos.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5202ff8-fe28-434a-9c9c-0cb325a1a77d",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem_pos.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem_pos.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.4032\n",
    "\n",
    "MAP@3 = 0.3109\n",
    "MAP@5 = 0.2502\n",
    "MAP@10 = 0.172\n",
    "\n",
    "Potential@3 = 0.7473\n",
    "Potential@5 = 0.879\n",
    "Potential@10 = 0.9462\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1397\n",
    "Accuracy@2@top_gold_1 = 0.2822\n",
    "Accuracy@3@top_gold_1 = 0.3817\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bbe8c0-de6b-45f1-be70-4bd4d09f7281",
   "metadata": {},
   "source": [
    "#### with pos tag of substitutes taken into account:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fdb6c0-3377-4262-a2c2-daa63e1056ef",
   "metadata": {},
   "source": [
    "\n",
    "If the lemmatized version of the substitute is found in the './cefr_efllex/EFLLex.tsv' file, and\n",
    "If the POS tag of that word (as listed in './cefr_efllex/EFLLex.tsv') matches the POS tag of the original substitute word (as determined by parsing the sentence where the complex word is replaced by the original substitute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "657a2bf7-03e4-46e4-b38e-19543b46e32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_electralarge_SR_cefrefflex_lem_possub_orig exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem_possub_orig.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefr_efllex/EFLLex.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_electralarge.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = []\n",
    "    for original, lemmatized in substitutes_lemmatized:\n",
    "        # get the pos of the original substitute by parsing the sentence where the complex word is replaced by the substitute\n",
    "        sub_sentence = sentence.replace(complex_word, original)\n",
    "        sub_pos = dict(pos_tag(word_tokenize(sub_sentence))).get(original)\n",
    "        # if the lemmatized substitute equals a word that is found in cefrj_all_treebank.tsv AND the POS tag of that word (in cefrj_all_treebank.tsv) is the same as the POS tag of the substitute:\n",
    "        if lemmatized in cefr_df['word'].values and cefr_df[cefr_df['word'] == lemmatized]['pos'].values[0] == sub_pos:\n",
    "            substitutes_cefr.append((original, cefr_df[cefr_df['word'] == lemmatized]['cefr'].values[0]))\n",
    "        else:\n",
    "            substitutes_cefr.append((original, 7))  # assign a high value if it doesn't have a CEFR level or if pos don't match\n",
    "\n",
    "         \n",
    "   \n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked_cefr_subs: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem_possub_orig.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_electralarge_SR_cefrefflex_lem_possub_orig exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem_possub_orig.tsv'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be4d66-343c-443e-a332-2bc1b9633588",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem_possub_orig.tsv --output_file ./output/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem_possub_orig.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea852d7c-0658-4475-bb37-8bef0ca7fdd4",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem_possub_orig.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_electralarge_SR_cefrefflex_lem_possub_orig.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.4005\n",
    "\n",
    "MAP@3 = 0.3103\n",
    "MAP@5 = 0.2564\n",
    "MAP@10 = 0.1743\n",
    "\n",
    "Potential@3 = 0.7768\n",
    "Potential@5 = 0.887\n",
    "Potential@10 = 0.9462\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1451\n",
    "Accuracy@2@top_gold_1 = 0.301\n",
    "Accuracy@3@top_gold_1 = 0.4005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f98b0a-7c31-49b5-8742-b47865de41c6",
   "metadata": {},
   "source": [
    "### EVP dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e4daa5-ef1d-4835-a956-91e6b619296a",
   "metadata": {},
   "source": [
    "#### lemmatized:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde80e52-ac0b-41ec-81ff-1b1e014a8176",
   "metadata": {},
   "source": [
    "#### for model SG_MA_SS_bsRobertalarge_robertabase: no changes (Dataset contains a lot of phrases iso words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e61360a3-01cc-4619-91c9-b5ba0ce19a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_robertabase_SR_cefrevp_lem exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefr_evp/evp_american.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# convert the CEFR dataframe into a dictionary for efficient lookups\n",
    "cefr_dict = cefr_df.set_index(['word', 'pos'])['cefr'].to_dict()\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_robertabase.tsv', sep='\\t', header=None)\n",
    "\n",
    "\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = [(original, cefr_dict.get(lemmatized, 7)) for original, lemmatized in substitutes_lemmatized]\n",
    "    #print(f\"substitutes with CEFR levels mapped to numerical values: {substitutes_cefr}\\n\")\n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked substitutes based on their CEFR level mapped to numerical values: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "    \n",
    "    \n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_robertabase_SR_cefrevp_lem exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem.tsv'\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2446678b-62d1-4f00-86cc-a747db1d5168",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem.tsv --output_file ./output/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6bbbeb19-6010-4884-8596-90424b94dacb",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.6263\n",
    "\n",
    "MAP@3 = 0.4293\n",
    "MAP@5 = 0.3264\n",
    "MAP@10 = 0.2035\n",
    "\n",
    "Potential@3 = 0.8467\n",
    "Potential@5 = 0.9247\n",
    "Potential@10 = 0.9677\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.2715\n",
    "Accuracy@2@top_gold_1 = 0.4059\n",
    "Accuracy@3@top_gold_1 = 0.4784\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4605bafe-7d0b-4689-9521-dc5f3feb5724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "204ca5f9-d7a5-4734-8611-6ef308bb701b",
   "metadata": {},
   "source": [
    "#### with complex word pos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba9de9e4-f267-49cf-b25f-0c5ecf06e9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_robertabase_SR_cefrevp_lem_pos exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem_pos.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefr_evp/evp_american_treebank.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# read the pos tags of complex words\n",
    "complex_word_pos_df = pd.read_csv('./data/test/test_pos.tsv', sep='\\t', header=None, names=['sentence', 'complex_word', 'pos'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_robertabase.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "    \n",
    "    # Get the pos of the complex_word\n",
    "    complex_word_pos = complex_word_pos_df[complex_word_pos_df['complex_word'] == complex_word]['pos'].values[0]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = []\n",
    "    for original, lemmatized in substitutes_lemmatized:\n",
    "        # if the lemmatized substitute word is found in './cefr_evp/evp_american_treebank.tsv AND the POS tag of that word ('./cefr_evp/evp_american_treebank.tsv) is the same as the POS tag of the complex word:\n",
    "        if lemmatized in cefr_df['word'].values and cefr_df[cefr_df['word'] == lemmatized]['pos'].values[0] == complex_word_pos:\n",
    "            substitutes_cefr.append((original, cefr_df[cefr_df['word'] == lemmatized]['cefr'].values[0]))\n",
    "        else:\n",
    "            substitutes_cefr.append((original, 7))  # assign a high value if it doesn't have a CEFR level or if pos don't match\n",
    "         \n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked_cefr_subs: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "    \n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem_pos.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_robertabase_SR_cefrevp_lem_pos exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem_pos.tsv'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73c9fd1-1f83-47e9-84ac-2010ade0b879",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem_pos.tsv --output_file ./output/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem_pos.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "865b71ab-63de-49ac-93eb-1704684fd1b7",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem_pos.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem_pos.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.4811\n",
    "\n",
    "MAP@3 = 0.3307\n",
    "MAP@5 = 0.2659\n",
    "MAP@10 = 0.1806\n",
    "\n",
    "Potential@3 = 0.7688\n",
    "Potential@5 = 0.887\n",
    "Potential@10 = 0.9677\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1935\n",
    "Accuracy@2@top_gold_1 = 0.3306\n",
    "Accuracy@3@top_gold_1 = 0.4301"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb14d4-fe8f-43b1-8a16-7e59ddd35f7d",
   "metadata": {},
   "source": [
    "### with pos tag of the substitutes taken into account:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a315526-6f5e-4eb7-bdbf-a8cb1453205d",
   "metadata": {},
   "source": [
    "\n",
    "If the lemmatized version of the substitute is found in the './cefr_evp/evp_american_treebank.tsv' file, and\n",
    "If the POS tag of that word (as listed in './cefr_evp/evp_american_treebank.tsv') matches the POS tag of the original substitute word (as determined by parsing the sentence where the complex word is replaced by the original substitute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e9a4b71-f645-4e6d-ab76-5221f7b9e8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_robertabase_SR_cefrevp_lem_possub_orig exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem_possub_orig.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefr_evp/evp_american_treebank.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_robertabase.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = []\n",
    "    for original, lemmatized in substitutes_lemmatized:\n",
    "        # get the pos of the original substitute by parsing the sentence where the complex word is replaced by the substitute\n",
    "        sub_sentence = sentence.replace(complex_word, original)\n",
    "        sub_pos = dict(pos_tag(word_tokenize(sub_sentence))).get(original)\n",
    "        # if the lemmatized substitute equals a word that is found in cefrj_all_treebank.tsv AND the POS tag of that word (in cefrj_all_treebank.tsv) is the same as the POS tag of the substitute:\n",
    "        if lemmatized in cefr_df['word'].values and cefr_df[cefr_df['word'] == lemmatized]['pos'].values[0] == sub_pos:\n",
    "            substitutes_cefr.append((original, cefr_df[cefr_df['word'] == lemmatized]['cefr'].values[0]))\n",
    "        else:\n",
    "            substitutes_cefr.append((original, 7))  # assign a high value if it doesn't have a CEFR level or if pos don't match\n",
    "\n",
    "         \n",
    "   \n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked_cefr_subs: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem_possub_orig.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_robertabase_SR_cefrevp_lem_possub_orig exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem_possub_orig.tsv'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319e24e8-fc3e-47f1-aacc-08b63b80f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem_possub_orig.tsv --output_file ./output/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem_possub_orig.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35314c3b-b36c-470a-bc63-a54fa5b8c11d",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem_possub_orig.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_robertabase_SR_cefrevp_lem_possub_orig.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.5134\n",
    "\n",
    "MAP@3 = 0.3461\n",
    "MAP@5 = 0.2754\n",
    "MAP@10 = 0.1842\n",
    "\n",
    "Potential@3 = 0.7741\n",
    "Potential@5 = 0.9032\n",
    "Potential@10 = 0.9677\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1962\n",
    "Accuracy@2@top_gold_1 = 0.3306\n",
    "Accuracy@3@top_gold_1 = 0.4274"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449257eb-2a36-4bec-baaa-e79276d1709d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5d1ca61-31da-46c2-9dd4-b3190a7fa826",
   "metadata": {},
   "source": [
    "#### for model SG_MA_SS_bsRobertalarge_electralarge: no changes (dataset contains a lot of phrases iso words)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4249242f-6e2b-47ad-8060-6c78d58a2911",
   "metadata": {},
   "source": [
    "### lemmatized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f893f5a9-2b11-49d2-9926-d8a791976ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_electralarge_SR_cefrevp_lem exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefrevp_lem.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefr_evp/evp_american.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# convert the CEFR dataframe into a dictionary for efficient lookups\n",
    "cefr_dict = cefr_df.set_index(['word', 'pos'])['cefr'].to_dict()\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_electralarge.tsv', sep='\\t', header=None)\n",
    "\n",
    "\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = [(original, cefr_dict.get(lemmatized, 7)) for original, lemmatized in substitutes_lemmatized]\n",
    "    #print(f\"substitutes with CEFR levels mapped to numerical values: {substitutes_cefr}\\n\")\n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked substitutes based on their CEFR level mapped to numerical values: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "    \n",
    "    \n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrevp_lem.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_electralarge_SR_cefrevp_lem exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefrevp_lem.tsv'\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ee714e-1ea9-4e28-8f46-117960218647",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test//SS_bsRobertalarge_electralarge_SR_cefrevp_lem.tsv --output_file ./output/test//SS_bsRobertalarge_electralarge_SR_cefrevp_lem.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4c73dc9-52f3-46ca-9cce-ee0fbceb42ef",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test//SS_bsRobertalarge_electralarge_SR_cefrevp_lem.tsv\n",
    "OUTPUT file = ./output/test//SS_bsRobertalarge_electralarge_SR_cefrevp_lem.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.5967\n",
    "\n",
    "MAP@3 = 0.4283\n",
    "MAP@5 = 0.3264\n",
    "MAP@10 = 0.2014\n",
    "\n",
    "Potential@3 = 0.8467\n",
    "Potential@5 = 0.8978\n",
    "Potential@10 = 0.9462\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.2607\n",
    "Accuracy@2@top_gold_1 = 0.4139\n",
    "Accuracy@3@top_gold_1 = 0.4865\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd6e65e-5f23-46e9-8e1f-1c8ac6f47f64",
   "metadata": {},
   "source": [
    "#### with complex word pos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5ce1863-36ed-4904-b0ea-de6a4412414a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_electralarge_SR_cefrevp_lem_pos exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefrevp_lem_pos.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefr_evp/evp_american_treebank.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# read the pos tags of complex words\n",
    "complex_word_pos_df = pd.read_csv('./data/test/test_pos.tsv', sep='\\t', header=None, names=['sentence', 'complex_word', 'pos'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_electralarge.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "    \n",
    "    # Get the pos of the complex_word\n",
    "    complex_word_pos = complex_word_pos_df[complex_word_pos_df['complex_word'] == complex_word]['pos'].values[0]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = []\n",
    "    for original, lemmatized in substitutes_lemmatized:\n",
    "        # if the lemmatized substitute word is found in './cefr_evp/evp_american_treebank.tsv AND the POS tag of that word ('./cefr_evp/evp_american_treebank.tsv) is the same as the POS tag of the complex word:\n",
    "        if lemmatized in cefr_df['word'].values and cefr_df[cefr_df['word'] == lemmatized]['pos'].values[0] == complex_word_pos:\n",
    "            substitutes_cefr.append((original, cefr_df[cefr_df['word'] == lemmatized]['cefr'].values[0]))\n",
    "        else:\n",
    "            substitutes_cefr.append((original, 7))  # assign a high value if it doesn't have a CEFR level or if pos don't match\n",
    "         \n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked_cefr_subs: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "    \n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrevp_lem_pos.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_electralarge_SR_cefrevp_lem_pos exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefrevp_lem_pos.tsv'\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44516fe-654d-4f59-bd84-05e049126139",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrevp_lem_pos.tsv --output_file ./output/test/SS_bsRobertalarge_electralarge_SR_cefrevp_lem_pos.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d4ba447-daf3-4279-b2a2-dd824e77214d",
   "metadata": {},
   "source": [
    "\n",
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrevp_lem_pos.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_electralarge_SR_cefrevp_lem_pos.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.4516\n",
    "\n",
    "MAP@3 = 0.313\n",
    "MAP@5 = 0.2538\n",
    "MAP@10 = 0.1741\n",
    "\n",
    "Potential@3 = 0.7634\n",
    "Potential@5 = 0.887\n",
    "Potential@10 = 0.9462\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1639\n",
    "Accuracy@2@top_gold_1 = 0.3091\n",
    "Accuracy@3@top_gold_1 = 0.4059"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b104bd5f-8bf1-41ed-adaa-301dd7478860",
   "metadata": {},
   "source": [
    "### with pos tag of the substitutes taken into account:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88d0d5a-f4f0-4a48-a21e-584140569b0b",
   "metadata": {},
   "source": [
    "If the lemmatized version of the substitute is found in the './cefr_evp/evp_american_treebank.tsv' file, and\n",
    "If the POS tag of that word (as listed in './cefr_evp/evp_american_treebank.tsv') matches the POS tag of the original substitute word (as determined by parsing the sentence where the complex word is replaced by the original substitute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "770ac5a7-222d-4926-bfb1-390997381775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_electralarge_SR_cefrevp_lem_possub_orig exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefrevp_lem_possub_orig.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "# initialize the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# read the CEFR levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefr_evp/evp_american_treebank.tsv', sep='\\t', header=None, names=['word', 'pos', 'cefr'])\n",
    "\n",
    "# define a mapping from CEFR levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the CEFR levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_electralarge.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its CEFR level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, lemmatizer.lemmatize(sub)) for sub in substitutes]\n",
    "\n",
    "    # map each lemmatized substitute to its CEFR level, or to a high number if it doesn't have a CEFR level\n",
    "    substitutes_cefr = []\n",
    "    for original, lemmatized in substitutes_lemmatized:\n",
    "        # get the pos of the original substitute by parsing the sentence where the complex word is replaced by the substitute\n",
    "        sub_sentence = sentence.replace(complex_word, original)\n",
    "        sub_pos = dict(pos_tag(word_tokenize(sub_sentence))).get(original)\n",
    "        # if the lemmatized substitute equals a word that is found in cefrj_all_treebank.tsv AND the POS tag of that word (in cefrj_all_treebank.tsv) is the same as the POS tag of the substitute:\n",
    "        if lemmatized in cefr_df['word'].values and cefr_df[cefr_df['word'] == lemmatized]['pos'].values[0] == sub_pos:\n",
    "            substitutes_cefr.append((original, cefr_df[cefr_df['word'] == lemmatized]['cefr'].values[0]))\n",
    "        else:\n",
    "            substitutes_cefr.append((original, 7))  # assign a high value if it doesn't have a CEFR level or if pos don't match\n",
    "\n",
    "         \n",
    "   \n",
    "\n",
    "    # sort the substitutes based on their CEFR levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    #print(f\"ranked_cefr_subs: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrevp_lem_possub_orig.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_electralarge_SR_cefrevp_lem_possub_orig exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefrevp_lem_possub_orig.tsv'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a67d190-df46-4c0e-acde-37d1dc1c04f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrevp_lem_possub_orig.tsv --output_file ./output/test/SS_bsRobertalarge_electralarge_SR_cefrevp_lem_possub_orig.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "48e329c8-c56b-48c5-9914-26f28e69109e",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrevp_lem_possub_orig.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_electralarge_SR_cefrevp_lem_possub_orig.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.4354\n",
    "\n",
    "MAP@3 = 0.3182\n",
    "MAP@5 = 0.2582\n",
    "MAP@10 = 0.1758\n",
    "\n",
    "Potential@3 = 0.793\n",
    "Potential@5 = 0.8897\n",
    "Potential@10 = 0.9462\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1639\n",
    "Accuracy@2@top_gold_1 = 0.2983\n",
    "Accuracy@3@top_gold_1 = 0.4005"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
