{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b0ad47d-aef9-4d79-ac41-de890e0748ea",
   "metadata": {},
   "source": [
    "### All code below uses concatenated sentence pairs in the Substitute Generation step in order to generate similar substitutes (as opposed to generation of fitting substitutes only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f41c8337-c877-47d0-9b9d-2464ac9f76a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from fitbert import FitBert\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# read the tsv file\n",
    "filename = \"./data/trial/tsar2022_en_trial_none.tsv\"\n",
    "data = pd.read_csv(filename, sep='\\t', header=None, names=[\"sentence\", \"complex_word\"])\n",
    "\n",
    "# create an empty dataframe to store the substitutes for evaluation\n",
    "substitutes_df = pd.DataFrame(columns=[\"sentence\", \"complex_word\"] + [f\"substitute_{i+1}\" for i in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a8f51-26e4-4f17-a64c-aa3545a1450d",
   "metadata": {},
   "source": [
    "### RoBERTa-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d9baa00-f810-4bb4-a3b9-a1affa7e6ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the tokenizer and the models\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "lm_model = AutoModelForMaskedLM.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# create a fill-mask pipeline \n",
    "fill_mask = pipeline(\"fill-mask\", lm_model, tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2245941-e389-4ff0-b88e-e43dc3da5a21",
   "metadata": {},
   "source": [
    "#### Only Substitute Generation with Roberta-base (k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ae349b7-d595-4172-a002-19437478b341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "SG step: generated substitutes: ['compulsory', 'mandatory', 'obligatory', 'voluntary', 'required', 'optional', 'obliged', 'uniform', 'necessary', 'available']\n",
      "\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "SG step: generated substitutes: ['infused', 'injected', 'endowed', 'illed', 'inst', 'furnished', 'supplied', 'bolstered', 'implanted', 'impressed']\n",
      "\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "SG step: generated substitutes: ['maniac', 'criminals', 'riors', 'hawks', 'heads', 'killers', 'gangs', 'lords', 'thugs', 'devils']\n",
      "\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "SG step: generated substitutes: ['observers', 'monitors', 'spectators', 'witnesses', 'observer', 'observes', 'visitors', 'viewers', 'reporters', 'inspectors']\n",
      "\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "SG step: generated substitutes: ['rapnel', 'bullet', 'gunshot', 'stab', 'radiation', 'projectile', 'crippling', 'shotgun', 'mortar', 'stun']\n",
      "\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "SG step: generated substitutes: ['disguised', 'dressed', 'veiled', 'masked', 'concealed', 'hidden', 'disguise', 'clothed', 'clad', 'posed']\n",
      "\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "SG step: generated substitutes: ['off', 'extension', 'opposite', 'outpost', 'off', 'out', 'affiliate', 'offspring', 'overthrow', 'element']\n",
      "\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "SG step: generated substitutes: ['classical', 'harmonic', 'musical', 'sym', 'music', 'instrumental', 'piano', 'lyric', 'jazz', 'modern']\n",
      "\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "SG step: generated substitutes: ['deploy', 'deployed', 'deployment', 'utilize', 'mobilize', 'employ', 'deploying', 'dispatch', 'equip', 'deploy']\n",
      "\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "SG step: generated substitutes: ['authorities', 'officials', 'authorities', 'authority', 'investigators', 'counterparts', 'police', 'agencies', 'administrators', 'forces']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"<mask>\")  # RoBERTa uses <mask> instead of [MASK]\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    tokenizer = fill_mask.tokenizer\n",
    "    sentences_concat = f\"{sentence} {tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 10\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes = [substitute[\"token_str\"].lower().lstrip() for substitute in result]   # and use .lstrip to remove the leading space, as Roberta tokenizes by default with a space in front of the word\n",
    "    print(f\"SG step: generated substitutes: {substitutes}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + substitutes\n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the dataframe\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/RobertaBase_SG.tsv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c163f2b2-1016-4be3-8743-07891f2edfd2",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file ./predictions/trial/RobertaBase_SG.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "465cfb86-8b96-4d4e-8331-bbf74eee965c",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/RobertaBase_SG.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.4\n",
    "\n",
    "MAP@3 = 0.2833\n",
    "MAP@5 = 0.233\n",
    "MAP@10 = 0.136\n",
    "\n",
    "Potential@3 = 0.7\n",
    "Potential@5 = 0.9\n",
    "Potential@10 = 0.9\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.4\n",
    "Accuracy@2@top_gold_1 = 0.5\n",
    "Accuracy@3@top_gold_1 = 0.6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c108c86-4fb8-41a1-91b9-7e8306cf30ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result: worse than BERT-base, appr. the same as BERT-large. However, Potential is good. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f466c47-3400-4f9f-8adc-5ecf4e0ea082",
   "metadata": {},
   "source": [
    "#### Substitute Generation with RoBERTa-base, and Substitute Selection steps a-c (k=30, limited to 10 after step 2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65a443c2-1ef7-45ed-85bd-a1705380b637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07352cfa-8ba5-447a-be18-84eda2b0f4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "SG step: generated substitutes: ['compulsory', 'mandatory', 'obligatory', 'voluntary', 'required', 'optional', 'obliged', 'uniform', 'necessary', 'available', 'mandated', 'sufficient', 'routine', 'forced', 'customary', 'prerequisite', 'feasible', 'indispensable', 'forthcoming', 'universal', 'requirement', 'involuntary', 'obligated', 'compelled', 'conditional', 'enforced', 'contingent', 'possible', 'compulsion', 'mandatory']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['compulsory', 'mandatory', 'obligatory', 'voluntary', 'required', 'optional', 'obliged', 'uniform', 'necessary', 'available', 'mandated', 'sufficient', 'routine', 'forced', 'customary', 'prerequisite', 'feasible', 'indispensable', 'forthcoming', 'universal', 'requirement', 'involuntary', 'obligated', 'compelled', 'conditional', 'enforced', 'contingent', 'possible', 'compulsion']\n",
      "\n",
      "complex_word_lemma for complex word 'compulsory': compulsory\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['mandatory', 'obligatory', 'voluntary', 'required', 'optional', 'obliged', 'uniform', 'necessary', 'available', 'mandated', 'sufficient', 'routine', 'forced', 'customary', 'prerequisite', 'feasible', 'indispensable', 'forthcoming', 'universal', 'requirement', 'involuntary', 'obligated', 'compelled', 'conditional', 'enforced', 'contingent', 'possible', 'compulsion']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['mandatory', 'obligatory', 'voluntary', 'required', 'optional', 'obliged', 'uniform', 'necessary', 'available', 'mandated', 'sufficient', 'routine', 'forced', 'customary', 'prerequisite', 'feasible', 'indispensable', 'forthcoming', 'universal', 'requirement', 'involuntary', 'obligated', 'compelled', 'conditional', 'enforced', 'contingent', 'possible', 'compulsion']\n",
      "\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "SG step: generated substitutes: ['infused', 'injected', 'endowed', 'illed', 'inst', 'furnished', 'supplied', 'bolstered', 'implanted', 'impressed', 'reinforced', 'invested', 'provided', 'filled', 'reassured', 'undermined', 'filled', 'pumped', 'struck', 'augmented', 'enriched', 'stirred', 'vested', 'imb', 'intoxicated', 'seeded', 'misled', 'stunned', 'inspired', 'inflated']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['infused', 'injected', 'endowed', 'illed', 'inst', 'furnished', 'supplied', 'bolstered', 'implanted', 'impressed', 'reinforced', 'invested', 'provided', 'filled', 'reassured', 'undermined', 'pumped', 'struck', 'augmented', 'enriched', 'stirred', 'vested', 'imb', 'intoxicated', 'seeded', 'misled', 'stunned', 'inspired', 'inflated']\n",
      "\n",
      "complex_word_lemma for complex word 'instilled': instill\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['infused', 'injected', 'endowed', 'illed', 'inst', 'furnished', 'supplied', 'bolstered', 'implanted', 'impressed', 'reinforced', 'invested', 'provided', 'filled', 'reassured', 'undermined', 'pumped', 'struck', 'augmented', 'enriched', 'stirred', 'vested', 'imb', 'intoxicated', 'seeded', 'misled', 'stunned', 'inspired', 'inflated']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['infused', 'injected', 'endowed', 'illed', 'inst', 'furnished', 'supplied', 'bolstered', 'implanted', 'impressed', 'reinforced', 'invested', 'provided', 'filled', 'reassured', 'undermined', 'pumped', 'struck', 'augmented', 'enriched', 'stirred', 'vested', 'imb', 'intoxicated', 'seeded', 'misled', 'stunned', 'inspired', 'inflated']\n",
      "\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "SG step: generated substitutes: ['maniac', 'criminals', 'riors', 'hawks', 'heads', 'killers', 'gangs', 'lords', 'thugs', 'devils', 'drums', 'murderers', 'fighters', 'monsters', 'fools', 'villains', 'idiots', 'machines', 'demons', 'doctors', 'planes', 'igans', 'bosses', 'nazis', 'beasts', 'fascists', 'children', 'nerds', 'extremists', 'parasites']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['maniac', 'criminals', 'riors', 'hawks', 'heads', 'killers', 'gangs', 'lords', 'thugs', 'devils', 'drums', 'murderers', 'fighters', 'monsters', 'fools', 'villains', 'idiots', 'machines', 'demons', 'doctors', 'planes', 'igans', 'bosses', 'nazis', 'beasts', 'fascists', 'children', 'nerds', 'extremists', 'parasites']\n",
      "\n",
      "complex_word_lemma for complex word 'maniacs': maniac\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['criminals', 'riors', 'hawks', 'heads', 'killers', 'gangs', 'lords', 'thugs', 'devils', 'drums', 'murderers', 'fighters', 'monsters', 'fools', 'villains', 'idiots', 'machines', 'demons', 'doctors', 'planes', 'igans', 'bosses', 'nazis', 'beasts', 'fascists', 'children', 'nerds', 'extremists', 'parasites']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['criminals', 'riors', 'hawks', 'heads', 'killers', 'gangs', 'lords', 'thugs', 'devils', 'drums', 'murderers', 'fighters', 'monsters', 'fools', 'villains', 'idiots', 'machines', 'demons', 'doctors', 'planes', 'igans', 'bosses', 'nazis', 'beasts', 'fascists', 'children', 'nerds', 'extremists', 'parasites']\n",
      "\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "SG step: generated substitutes: ['observers', 'monitors', 'spectators', 'witnesses', 'observer', 'observes', 'visitors', 'viewers', 'reporters', 'inspectors', 'commentators', 'investigators', 'participants', 'analysts', 'cameras', 'outsiders', 'demonstrators', 'activists', 'journalists', 'experts', 'authorities', 'observations', 'eyes', 'supporters', 'observing', 'residents', 'protesters', 'responders', 'parties', 'followers']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['observers', 'monitors', 'spectators', 'witnesses', 'observer', 'observes', 'visitors', 'viewers', 'reporters', 'inspectors', 'commentators', 'investigators', 'participants', 'analysts', 'cameras', 'outsiders', 'demonstrators', 'activists', 'journalists', 'experts', 'authorities', 'observations', 'eyes', 'supporters', 'observing', 'residents', 'protesters', 'responders', 'parties', 'followers']\n",
      "\n",
      "complex_word_lemma for complex word 'observers': observer\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['monitors', 'spectators', 'witnesses', 'observes', 'visitors', 'viewers', 'reporters', 'inspectors', 'commentators', 'investigators', 'participants', 'analysts', 'cameras', 'outsiders', 'demonstrators', 'activists', 'journalists', 'experts', 'authorities', 'observations', 'eyes', 'supporters', 'observing', 'residents', 'protesters', 'responders', 'parties', 'followers']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['monitors', 'spectators', 'witnesses', 'observes', 'visitors', 'viewers', 'reporters', 'inspectors', 'commentators', 'investigators', 'participants', 'analysts', 'cameras', 'outsiders', 'demonstrators', 'activists', 'journalists', 'experts', 'authorities', 'observations', 'eyes', 'supporters', 'observing', 'residents', 'protesters', 'responders', 'parties', 'followers']\n",
      "\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "SG step: generated substitutes: ['rapnel', 'bullet', 'gunshot', 'stab', 'radiation', 'projectile', 'crippling', 'shotgun', 'mortar', 'stun', 'explosive', 'stray', 'shell', 'bomb', 'microscopic', 'fragmentation', 'cartridge', 'grenade', 'rocket', 'torpedo', 'piercing', 'unidentified', 'ammunition', 'insurgent', 'similar', 'blast', 'bullets', 'slug', 'terrorist', 'pillow']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['rapnel', 'bullet', 'gunshot', 'stab', 'radiation', 'projectile', 'crippling', 'shotgun', 'mortar', 'stun', 'explosive', 'stray', 'shell', 'bomb', 'microscopic', 'fragmentation', 'cartridge', 'grenade', 'rocket', 'torpedo', 'piercing', 'unidentified', 'ammunition', 'insurgent', 'similar', 'blast', 'bullets', 'slug', 'terrorist', 'pillow']\n",
      "\n",
      "complex_word_lemma for complex word 'shrapnel': shrapnel\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['rapnel', 'bullet', 'gunshot', 'stab', 'radiation', 'projectile', 'crippling', 'shotgun', 'mortar', 'stun', 'explosive', 'stray', 'shell', 'bomb', 'microscopic', 'fragmentation', 'cartridge', 'grenade', 'rocket', 'torpedo', 'piercing', 'unidentified', 'ammunition', 'insurgent', 'similar', 'blast', 'bullets', 'slug', 'terrorist', 'pillow']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['rapnel', 'bullet', 'gunshot', 'stab', 'radiation', 'projectile', 'crippling', 'shotgun', 'mortar', 'stun', 'explosive', 'stray', 'shell', 'bomb', 'microscopic', 'fragmentation', 'cartridge', 'grenade', 'rocket', 'torpedo', 'piercing', 'unidentified', 'ammunition', 'insurgent', 'similar', 'blast', 'bullets', 'slug', 'terrorist', 'pillow']\n",
      "\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "SG step: generated substitutes: ['disguised', 'dressed', 'veiled', 'masked', 'concealed', 'hidden', 'disguise', 'clothed', 'clad', 'posed', 'covered', 'cloaked', 'shrouded', 'wrapped', 'posing', 'hiding', 'trained', 'camoufl', 'presented', 'known', 'smuggled', 'staged', 'draped', 'described', 'decorated', 'armed', 'buried', 'camouflage', 'marked', 'hid']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['disguised', 'dressed', 'veiled', 'masked', 'concealed', 'hidden', 'disguise', 'clothed', 'clad', 'posed', 'covered', 'cloaked', 'shrouded', 'wrapped', 'posing', 'hiding', 'trained', 'camoufl', 'presented', 'known', 'smuggled', 'staged', 'draped', 'described', 'decorated', 'armed', 'buried', 'camouflage', 'marked', 'hid']\n",
      "\n",
      "complex_word_lemma for complex word 'disguised': disguised\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['dressed', 'veiled', 'masked', 'concealed', 'hidden', 'disguise', 'clothed', 'clad', 'posed', 'covered', 'cloaked', 'shrouded', 'wrapped', 'posing', 'hiding', 'trained', 'camoufl', 'presented', 'known', 'smuggled', 'staged', 'draped', 'described', 'decorated', 'armed', 'buried', 'camouflage', 'marked', 'hid']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['dressed', 'veiled', 'masked', 'concealed', 'hidden', 'disguise', 'clothed', 'clad', 'posed', 'covered', 'cloaked', 'shrouded', 'wrapped', 'posing', 'hiding', 'trained', 'camoufl', 'presented', 'known', 'smuggled', 'staged', 'draped', 'described', 'decorated', 'armed', 'buried', 'camouflage', 'marked', 'hid']\n",
      "\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "SG step: generated substitutes: ['off', 'extension', 'opposite', 'outpost', 'off', 'out', 'affiliate', 'offspring', 'overthrow', 'element', 'outside', 'echo', 'expansion', 'imprint', 'arm', 'ideology', 'overhaul', 'branch', 'opposition', 'evolution', 'indication', 'upset', 'archetype', 'extend', 'independent', 'alternative', 'example', 'instance', 'embrace', 'adjunct']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['off', 'extension', 'opposite', 'outpost', 'out', 'affiliate', 'offspring', 'overthrow', 'element', 'outside', 'echo', 'expansion', 'imprint', 'arm', 'ideology', 'overhaul', 'branch', 'opposition', 'evolution', 'indication', 'upset', 'archetype', 'extend', 'independent', 'alternative', 'example', 'instance', 'embrace', 'adjunct']\n",
      "\n",
      "complex_word_lemma for complex word 'offshoot': offshoot\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['off', 'extension', 'opposite', 'outpost', 'out', 'affiliate', 'offspring', 'overthrow', 'element', 'outside', 'echo', 'expansion', 'imprint', 'arm', 'ideology', 'overhaul', 'branch', 'opposition', 'evolution', 'indication', 'upset', 'archetype', 'extend', 'independent', 'alternative', 'example', 'instance', 'embrace', 'adjunct']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['off', 'extension', 'opposite', 'outpost', 'out', 'affiliate', 'offspring', 'overthrow', 'element', 'outside', 'echo', 'expansion', 'imprint', 'arm', 'ideology', 'overhaul', 'branch', 'opposition', 'evolution', 'indication', 'upset', 'archetype', 'extend', 'independent', 'alternative', 'example', 'instance', 'embrace', 'adjunct']\n",
      "\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "SG step: generated substitutes: ['classical', 'harmonic', 'musical', 'sym', 'music', 'instrumental', 'piano', 'lyric', 'jazz', 'modern', 'dramatic', 'major', 'vocal', 'composing', 'concert', 'opera', 'sonic', 'formal', 'popular', 'early', 'composition', 'english', 'singing', 'standard', 'trumpet', 'keyboard', 'contemporary', 'orchestra', 'technical', 'onic']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['classical', 'harmonic', 'musical', 'sym', 'music', 'instrumental', 'piano', 'lyric', 'jazz', 'modern', 'dramatic', 'major', 'vocal', 'composing', 'concert', 'opera', 'sonic', 'formal', 'popular', 'early', 'composition', 'english', 'singing', 'standard', 'trumpet', 'keyboard', 'contemporary', 'orchestra', 'technical', 'onic']\n",
      "\n",
      "complex_word_lemma for complex word 'symphonic': symphonic\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['classical', 'harmonic', 'musical', 'sym', 'music', 'instrumental', 'piano', 'lyric', 'jazz', 'modern', 'dramatic', 'major', 'vocal', 'composing', 'concert', 'opera', 'sonic', 'formal', 'popular', 'early', 'composition', 'english', 'singing', 'standard', 'trumpet', 'keyboard', 'contemporary', 'orchestra', 'technical', 'onic']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['classical', 'harmonic', 'musical', 'sym', 'music', 'instrumental', 'piano', 'lyric', 'jazz', 'modern', 'dramatic', 'major', 'vocal', 'composing', 'concert', 'opera', 'sonic', 'formal', 'popular', 'early', 'composition', 'english', 'singing', 'standard', 'trumpet', 'keyboard', 'contemporary', 'orchestra', 'technical', 'onic']\n",
      "\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "SG step: generated substitutes: ['deploy', 'deployed', 'deployment', 'utilize', 'mobilize', 'employ', 'deploying', 'dispatch', 'equip', 'deploy', 'ploy', 'use', 'activate', 'recruit', 'transport', 'operate', 'withdraw', 'install', 'locate', 'commit', 'construct', 'summon', 'expend', 'send', 'reserve', 'possess', 'cultivate', 'adopt', 'engage', 'unleash']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['deploy', 'deployed', 'deployment', 'utilize', 'mobilize', 'employ', 'deploying', 'dispatch', 'equip', 'ploy', 'use', 'activate', 'recruit', 'transport', 'operate', 'withdraw', 'install', 'locate', 'commit', 'construct', 'summon', 'expend', 'send', 'reserve', 'possess', 'cultivate', 'adopt', 'engage', 'unleash']\n",
      "\n",
      "complex_word_lemma for complex word 'deploy': deploy\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['deployment', 'utilize', 'mobilize', 'employ', 'dispatch', 'equip', 'ploy', 'use', 'activate', 'recruit', 'transport', 'operate', 'withdraw', 'install', 'locate', 'commit', 'construct', 'summon', 'expend', 'send', 'reserve', 'possess', 'cultivate', 'adopt', 'engage', 'unleash']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['deployment', 'utilize', 'mobilize', 'employ', 'dispatch', 'equip', 'ploy', 'use', 'activate', 'recruit', 'transport', 'operate', 'withdraw', 'install', 'locate', 'commit', 'construct', 'summon', 'expend', 'send', 'reserve', 'possess', 'cultivate', 'adopt', 'engage', 'unleash']\n",
      "\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "SG step: generated substitutes: ['authorities', 'officials', 'authorities', 'authority', 'investigators', 'counterparts', 'police', 'agencies', 'administrators', 'forces', 'prosecutors', 'officers', 'authorities', 'entities', 'intelligence', 'jurisdictions', 'individuals', 'detainees', 'institutions', 'affairs', 'demonstrators', 'superiors', 'victims', 'regulators', 'concerns', 'ministers', 'figures', 'suspects', 'sources', 'assistance']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['authorities', 'officials', 'authority', 'investigators', 'counterparts', 'police', 'agencies', 'administrators', 'forces', 'prosecutors', 'officers', 'entities', 'intelligence', 'jurisdictions', 'individuals', 'detainees', 'institutions', 'affairs', 'demonstrators', 'superiors', 'victims', 'regulators', 'concerns', 'ministers', 'figures', 'suspects', 'sources', 'assistance']\n",
      "\n",
      "complex_word_lemma for complex word 'authorities': authority\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['officials', 'investigators', 'counterparts', 'police', 'agencies', 'administrators', 'forces', 'prosecutors', 'officers', 'entities', 'intelligence', 'jurisdictions', 'individuals', 'detainees', 'institutions', 'affairs', 'demonstrators', 'superiors', 'victims', 'regulators', 'concerns', 'ministers', 'figures', 'suspects', 'sources', 'assistance']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['officials', 'investigators', 'counterparts', 'police', 'agencies', 'administrators', 'forces', 'prosecutors', 'officers', 'entities', 'intelligence', 'jurisdictions', 'individuals', 'detainees', 'institutions', 'affairs', 'demonstrators', 'superiors', 'victims', 'regulators', 'concerns', 'ministers', 'figures', 'suspects', 'sources', 'assistance']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"<mask>\")   # RoBERTa uses <mask> instead of [MASK]\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    tokenizer = fill_mask.tokenizer\n",
    "    sentences_concat = f\"{sentence} {tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "   \n",
    "   ## lowercase and print the top-k substitutes\n",
    "    substitutes = [substitute[\"token_str\"].lower().lstrip() for substitute in result]   # and use .lstrip to remove the leading space, as Roberta tokenizes by default with a space in front of the word\n",
    "    print(f\"SG step: generated substitutes: {substitutes}\\n\")\n",
    "    \n",
    "    \n",
    "     # 2. Substitute Selection (SS):   \n",
    "    \n",
    "    # a) remove duplicates within the substitute list from the substitute list \n",
    "    \n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl:\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    print(f\"SS step: a) substitute list without duplicates: {substitutes_no_dupl}\\n\")\n",
    "\n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    print(f\"SS step: b) substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    print(f\"SS step: c): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "    \n",
    "        \n",
    "     \n",
    "    \n",
    "    # limit the substitutes to the 10 first ones for evaluation\n",
    "    top_10_substitutes = substitutes_no_dupl_complex_word_no_antonym[:10]\n",
    "    \n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + top_10_substitutes\n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the dataframe\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/RobertaBase_SG_SS_abc.tsv\", sep=\"\\t\", index=False, header=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9121c1fe-ebf4-4527-922a-a145d2236ce9",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file ./predictions/trial/RobertaBase_SG_SS_abc.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a38adca4-18e5-4936-9016-d61603f20634",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/RobertaBase_SG_SS_abc.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.4\n",
    "\n",
    "MAP@3 = 0.2944\n",
    "MAP@5 = 0.2376\n",
    "MAP@10 = 0.1506\n",
    "\n",
    "Potential@3 = 0.8\n",
    "Potential@5 = 0.9\n",
    "Potential@10 = 0.9\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.4\n",
    "Accuracy@2@top_gold_1 = 0.5\n",
    "Accuracy@3@top_gold_1 = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e562583-b633-4c44-8025-9184040d1f4d",
   "metadata": {},
   "source": [
    "Result: slightly better than without this step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0d1e28-ddfa-430a-8fd0-63eb12f8eda9",
   "metadata": {},
   "source": [
    "#### Substitute Generation with Roberta-base, and Substitute Selection steps a-c, and the resulting list with FitBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e56180e-f0b4-4d35-aab9-8098a3021cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FitBERT mainly seems to look at syntactic fit\n",
    "import fitbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92ad8f9b-0be0-48d0-bbe7-5fed5a2f582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "using custom model: ['RobertaForMaskedLM']\n",
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "SG step: generated substitutes: ['compulsory', 'mandatory', 'obligatory', 'voluntary', 'required', 'optional', 'obliged', 'uniform', 'necessary', 'available', 'mandated', 'sufficient', 'routine', 'forced', 'customary', 'prerequisite', 'feasible', 'indispensable', 'forthcoming', 'universal', 'requirement', 'involuntary', 'obligated', 'compelled', 'conditional', 'enforced', 'contingent', 'possible', 'compulsion', 'mandatory']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['compulsory', 'mandatory', 'obligatory', 'voluntary', 'required', 'optional', 'obliged', 'uniform', 'necessary', 'available', 'mandated', 'sufficient', 'routine', 'forced', 'customary', 'prerequisite', 'feasible', 'indispensable', 'forthcoming', 'universal', 'requirement', 'involuntary', 'obligated', 'compelled', 'conditional', 'enforced', 'contingent', 'possible', 'compulsion']\n",
      "\n",
      "complex_word_lemma for complex word 'compulsory': compulsory\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['mandatory', 'obligatory', 'voluntary', 'required', 'optional', 'obliged', 'uniform', 'necessary', 'available', 'mandated', 'sufficient', 'routine', 'forced', 'customary', 'prerequisite', 'feasible', 'indispensable', 'forthcoming', 'universal', 'requirement', 'involuntary', 'obligated', 'compelled', 'conditional', 'enforced', 'contingent', 'possible', 'compulsion']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['mandatory', 'obligatory', 'voluntary', 'required', 'optional', 'obliged', 'uniform', 'necessary', 'available', 'mandated', 'sufficient', 'routine', 'forced', 'customary', 'prerequisite', 'feasible', 'indispensable', 'forthcoming', 'universal', 'requirement', 'involuntary', 'obligated', 'compelled', 'conditional', 'enforced', 'contingent', 'possible', 'compulsion']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['forced', 'requirement', 'universal', 'forthcoming', 'obligatory', 'sufficient', 'prerequisite', 'available', 'enforced', 'uniform', 'required', 'customary', 'necessary', 'obliged', 'compulsion', 'indispensable', 'optional', 'mandatory', 'contingent', 'possible', 'compelled', 'conditional', 'feasible', 'routine', 'voluntary', 'mandated', 'obligated', 'involuntary']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "SG step: generated substitutes: ['infused', 'injected', 'endowed', 'illed', 'inst', 'furnished', 'supplied', 'bolstered', 'implanted', 'impressed', 'reinforced', 'invested', 'provided', 'filled', 'reassured', 'undermined', 'filled', 'pumped', 'struck', 'augmented', 'enriched', 'stirred', 'vested', 'imb', 'intoxicated', 'seeded', 'misled', 'stunned', 'inspired', 'inflated']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['infused', 'injected', 'endowed', 'illed', 'inst', 'furnished', 'supplied', 'bolstered', 'implanted', 'impressed', 'reinforced', 'invested', 'provided', 'filled', 'reassured', 'undermined', 'pumped', 'struck', 'augmented', 'enriched', 'stirred', 'vested', 'imb', 'intoxicated', 'seeded', 'misled', 'stunned', 'inspired', 'inflated']\n",
      "\n",
      "complex_word_lemma for complex word 'instilled': instill\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['infused', 'injected', 'endowed', 'illed', 'inst', 'furnished', 'supplied', 'bolstered', 'implanted', 'impressed', 'reinforced', 'invested', 'provided', 'filled', 'reassured', 'undermined', 'pumped', 'struck', 'augmented', 'enriched', 'stirred', 'vested', 'imb', 'intoxicated', 'seeded', 'misled', 'stunned', 'inspired', 'inflated']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['infused', 'injected', 'endowed', 'illed', 'inst', 'furnished', 'supplied', 'bolstered', 'implanted', 'impressed', 'reinforced', 'invested', 'provided', 'filled', 'reassured', 'undermined', 'pumped', 'struck', 'augmented', 'enriched', 'stirred', 'vested', 'imb', 'intoxicated', 'seeded', 'misled', 'stunned', 'inspired', 'inflated']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['provided', 'illed', 'furnished', 'endowed', 'supplied', 'struck', 'stirred', 'implanted', 'inst', 'intoxicated', 'augmented', 'seeded', 'misled', 'inspired', 'undermined', 'enriched', 'injected', 'bolstered', 'filled', 'inflated', 'reinforced', 'infused', 'invested', 'reassured', 'imb', 'impressed', 'pumped', 'stunned', 'vested']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "SG step: generated substitutes: ['maniac', 'criminals', 'riors', 'hawks', 'heads', 'killers', 'gangs', 'lords', 'thugs', 'devils', 'drums', 'murderers', 'fighters', 'monsters', 'fools', 'villains', 'idiots', 'machines', 'demons', 'doctors', 'planes', 'igans', 'bosses', 'nazis', 'beasts', 'fascists', 'children', 'nerds', 'extremists', 'parasites']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['maniac', 'criminals', 'riors', 'hawks', 'heads', 'killers', 'gangs', 'lords', 'thugs', 'devils', 'drums', 'murderers', 'fighters', 'monsters', 'fools', 'villains', 'idiots', 'machines', 'demons', 'doctors', 'planes', 'igans', 'bosses', 'nazis', 'beasts', 'fascists', 'children', 'nerds', 'extremists', 'parasites']\n",
      "\n",
      "complex_word_lemma for complex word 'maniacs': maniac\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['criminals', 'riors', 'hawks', 'heads', 'killers', 'gangs', 'lords', 'thugs', 'devils', 'drums', 'murderers', 'fighters', 'monsters', 'fools', 'villains', 'idiots', 'machines', 'demons', 'doctors', 'planes', 'igans', 'bosses', 'nazis', 'beasts', 'fascists', 'children', 'nerds', 'extremists', 'parasites']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['criminals', 'riors', 'hawks', 'heads', 'killers', 'gangs', 'lords', 'thugs', 'devils', 'drums', 'murderers', 'fighters', 'monsters', 'fools', 'villains', 'idiots', 'machines', 'demons', 'doctors', 'planes', 'igans', 'bosses', 'nazis', 'beasts', 'fascists', 'children', 'nerds', 'extremists', 'parasites']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['nerds', 'monsters', 'hawks', 'killers', 'riors', 'drums', 'lords', 'beasts', 'murderers', 'machines', 'thugs', 'villains', 'criminals', 'children', 'gangs', 'extremists', 'heads', 'igans', 'devils', 'fighters', 'idiots', 'demons', 'bosses', 'fools', 'fascists', 'doctors', 'planes', 'parasites', 'nazis']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "SG step: generated substitutes: ['observers', 'monitors', 'spectators', 'witnesses', 'observer', 'observes', 'visitors', 'viewers', 'reporters', 'inspectors', 'commentators', 'investigators', 'participants', 'analysts', 'cameras', 'outsiders', 'demonstrators', 'activists', 'journalists', 'experts', 'authorities', 'observations', 'eyes', 'supporters', 'observing', 'residents', 'protesters', 'responders', 'parties', 'followers']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['observers', 'monitors', 'spectators', 'witnesses', 'observer', 'observes', 'visitors', 'viewers', 'reporters', 'inspectors', 'commentators', 'investigators', 'participants', 'analysts', 'cameras', 'outsiders', 'demonstrators', 'activists', 'journalists', 'experts', 'authorities', 'observations', 'eyes', 'supporters', 'observing', 'residents', 'protesters', 'responders', 'parties', 'followers']\n",
      "\n",
      "complex_word_lemma for complex word 'observers': observer\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['monitors', 'spectators', 'witnesses', 'observes', 'visitors', 'viewers', 'reporters', 'inspectors', 'commentators', 'investigators', 'participants', 'analysts', 'cameras', 'outsiders', 'demonstrators', 'activists', 'journalists', 'experts', 'authorities', 'observations', 'eyes', 'supporters', 'observing', 'residents', 'protesters', 'responders', 'parties', 'followers']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['monitors', 'spectators', 'witnesses', 'observes', 'visitors', 'viewers', 'reporters', 'inspectors', 'commentators', 'investigators', 'participants', 'analysts', 'cameras', 'outsiders', 'demonstrators', 'activists', 'journalists', 'experts', 'authorities', 'observations', 'eyes', 'supporters', 'observing', 'residents', 'protesters', 'responders', 'parties', 'followers']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['eyes', 'residents', 'spectators', 'observations', 'visitors', 'monitors', 'responders', 'journalists', 'participants', 'parties', 'witnesses', 'viewers', 'reporters', 'authorities', 'supporters', 'observing', 'followers', 'investigators', 'experts', 'demonstrators', 'activists', 'protesters', 'analysts', 'inspectors', 'commentators', 'cameras', 'observes', 'outsiders']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "SG step: generated substitutes: ['rapnel', 'bullet', 'gunshot', 'stab', 'radiation', 'projectile', 'crippling', 'shotgun', 'mortar', 'stun', 'explosive', 'stray', 'shell', 'bomb', 'microscopic', 'fragmentation', 'cartridge', 'grenade', 'rocket', 'torpedo', 'piercing', 'unidentified', 'ammunition', 'insurgent', 'similar', 'blast', 'bullets', 'slug', 'terrorist', 'pillow']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['rapnel', 'bullet', 'gunshot', 'stab', 'radiation', 'projectile', 'crippling', 'shotgun', 'mortar', 'stun', 'explosive', 'stray', 'shell', 'bomb', 'microscopic', 'fragmentation', 'cartridge', 'grenade', 'rocket', 'torpedo', 'piercing', 'unidentified', 'ammunition', 'insurgent', 'similar', 'blast', 'bullets', 'slug', 'terrorist', 'pillow']\n",
      "\n",
      "complex_word_lemma for complex word 'shrapnel': shrapnel\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['rapnel', 'bullet', 'gunshot', 'stab', 'radiation', 'projectile', 'crippling', 'shotgun', 'mortar', 'stun', 'explosive', 'stray', 'shell', 'bomb', 'microscopic', 'fragmentation', 'cartridge', 'grenade', 'rocket', 'torpedo', 'piercing', 'unidentified', 'ammunition', 'insurgent', 'similar', 'blast', 'bullets', 'slug', 'terrorist', 'pillow']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['rapnel', 'bullet', 'gunshot', 'stab', 'radiation', 'projectile', 'crippling', 'shotgun', 'mortar', 'stun', 'explosive', 'stray', 'shell', 'bomb', 'microscopic', 'fragmentation', 'cartridge', 'grenade', 'rocket', 'torpedo', 'piercing', 'unidentified', 'ammunition', 'insurgent', 'similar', 'blast', 'bullets', 'slug', 'terrorist', 'pillow']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['explosive', 'radiation', 'ammunition', 'microscopic', 'similar', 'shotgun', 'piercing', 'bomb', 'mortar', 'projectile', 'gunshot', 'grenade', 'pillow', 'slug', 'unidentified', 'stray', 'rapnel', 'insurgent', 'stun', 'blast', 'stab', 'crippling', 'terrorist', 'rocket', 'bullet', 'fragmentation', 'cartridge', 'shell', 'bullets', 'torpedo']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "SG step: generated substitutes: ['disguised', 'dressed', 'veiled', 'masked', 'concealed', 'hidden', 'disguise', 'clothed', 'clad', 'posed', 'covered', 'cloaked', 'shrouded', 'wrapped', 'posing', 'hiding', 'trained', 'camoufl', 'presented', 'known', 'smuggled', 'staged', 'draped', 'described', 'decorated', 'armed', 'buried', 'camouflage', 'marked', 'hid']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['disguised', 'dressed', 'veiled', 'masked', 'concealed', 'hidden', 'disguise', 'clothed', 'clad', 'posed', 'covered', 'cloaked', 'shrouded', 'wrapped', 'posing', 'hiding', 'trained', 'camoufl', 'presented', 'known', 'smuggled', 'staged', 'draped', 'described', 'decorated', 'armed', 'buried', 'camouflage', 'marked', 'hid']\n",
      "\n",
      "complex_word_lemma for complex word 'disguised': disguised\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['dressed', 'veiled', 'masked', 'concealed', 'hidden', 'disguise', 'clothed', 'clad', 'posed', 'covered', 'cloaked', 'shrouded', 'wrapped', 'posing', 'hiding', 'trained', 'camoufl', 'presented', 'known', 'smuggled', 'staged', 'draped', 'described', 'decorated', 'armed', 'buried', 'camouflage', 'marked', 'hid']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['dressed', 'veiled', 'masked', 'concealed', 'hidden', 'disguise', 'clothed', 'clad', 'posed', 'covered', 'cloaked', 'shrouded', 'wrapped', 'posing', 'hiding', 'trained', 'camoufl', 'presented', 'known', 'smuggled', 'staged', 'draped', 'described', 'decorated', 'armed', 'buried', 'camouflage', 'marked', 'hid']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['hid', 'hidden', 'draped', 'marked', 'clothed', 'clad', 'known', 'posing', 'shrouded', 'cloaked', 'dressed', 'decorated', 'veiled', 'covered', 'trained', 'described', 'armed', 'disguise', 'presented', 'concealed', 'hiding', 'buried', 'camoufl', 'smuggled', 'staged', 'posed', 'masked', 'wrapped', 'camouflage']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "SG step: generated substitutes: ['off', 'extension', 'opposite', 'outpost', 'off', 'out', 'affiliate', 'offspring', 'overthrow', 'element', 'outside', 'echo', 'expansion', 'imprint', 'arm', 'ideology', 'overhaul', 'branch', 'opposition', 'evolution', 'indication', 'upset', 'archetype', 'extend', 'independent', 'alternative', 'example', 'instance', 'embrace', 'adjunct']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['off', 'extension', 'opposite', 'outpost', 'out', 'affiliate', 'offspring', 'overthrow', 'element', 'outside', 'echo', 'expansion', 'imprint', 'arm', 'ideology', 'overhaul', 'branch', 'opposition', 'evolution', 'indication', 'upset', 'archetype', 'extend', 'independent', 'alternative', 'example', 'instance', 'embrace', 'adjunct']\n",
      "\n",
      "complex_word_lemma for complex word 'offshoot': offshoot\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['off', 'extension', 'opposite', 'outpost', 'out', 'affiliate', 'offspring', 'overthrow', 'element', 'outside', 'echo', 'expansion', 'imprint', 'arm', 'ideology', 'overhaul', 'branch', 'opposition', 'evolution', 'indication', 'upset', 'archetype', 'extend', 'independent', 'alternative', 'example', 'instance', 'embrace', 'adjunct']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['off', 'extension', 'opposite', 'outpost', 'out', 'affiliate', 'offspring', 'overthrow', 'element', 'outside', 'echo', 'expansion', 'imprint', 'arm', 'ideology', 'overhaul', 'branch', 'opposition', 'evolution', 'indication', 'upset', 'archetype', 'extend', 'independent', 'alternative', 'example', 'instance', 'embrace', 'adjunct']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['outside', 'echo', 'branch', 'opposition', 'off', 'arm', 'offspring', 'element', 'overthrow', 'alternative', 'indication', 'expansion', 'embrace', 'opposite', 'extension', 'out', 'adjunct', 'instance', 'upset', 'extend', 'imprint', 'independent', 'ideology', 'example', 'overhaul', 'evolution', 'affiliate', 'archetype', 'outpost']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "SG step: generated substitutes: ['classical', 'harmonic', 'musical', 'sym', 'music', 'instrumental', 'piano', 'lyric', 'jazz', 'modern', 'dramatic', 'major', 'vocal', 'composing', 'concert', 'opera', 'sonic', 'formal', 'popular', 'early', 'composition', 'english', 'singing', 'standard', 'trumpet', 'keyboard', 'contemporary', 'orchestra', 'technical', 'onic']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['classical', 'harmonic', 'musical', 'sym', 'music', 'instrumental', 'piano', 'lyric', 'jazz', 'modern', 'dramatic', 'major', 'vocal', 'composing', 'concert', 'opera', 'sonic', 'formal', 'popular', 'early', 'composition', 'english', 'singing', 'standard', 'trumpet', 'keyboard', 'contemporary', 'orchestra', 'technical', 'onic']\n",
      "\n",
      "complex_word_lemma for complex word 'symphonic': symphonic\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['classical', 'harmonic', 'musical', 'sym', 'music', 'instrumental', 'piano', 'lyric', 'jazz', 'modern', 'dramatic', 'major', 'vocal', 'composing', 'concert', 'opera', 'sonic', 'formal', 'popular', 'early', 'composition', 'english', 'singing', 'standard', 'trumpet', 'keyboard', 'contemporary', 'orchestra', 'technical', 'onic']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['classical', 'harmonic', 'musical', 'sym', 'music', 'instrumental', 'piano', 'lyric', 'jazz', 'modern', 'dramatic', 'major', 'vocal', 'composing', 'concert', 'opera', 'sonic', 'formal', 'popular', 'early', 'composition', 'english', 'singing', 'standard', 'trumpet', 'keyboard', 'contemporary', 'orchestra', 'technical', 'onic']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['standard', 'contemporary', 'music', 'english', 'musical', 'keyboard', 'jazz', 'modern', 'popular', 'major', 'instrumental', 'piano', 'early', 'singing', 'dramatic', 'lyric', 'technical', 'onic', 'trumpet', 'orchestra', 'formal', 'opera', 'sonic', 'composition', 'concert', 'vocal', 'sym', 'classical', 'composing', 'harmonic']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "SG step: generated substitutes: ['deploy', 'deployed', 'deployment', 'utilize', 'mobilize', 'employ', 'deploying', 'dispatch', 'equip', 'deploy', 'ploy', 'use', 'activate', 'recruit', 'transport', 'operate', 'withdraw', 'install', 'locate', 'commit', 'construct', 'summon', 'expend', 'send', 'reserve', 'possess', 'cultivate', 'adopt', 'engage', 'unleash']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['deploy', 'deployed', 'deployment', 'utilize', 'mobilize', 'employ', 'deploying', 'dispatch', 'equip', 'ploy', 'use', 'activate', 'recruit', 'transport', 'operate', 'withdraw', 'install', 'locate', 'commit', 'construct', 'summon', 'expend', 'send', 'reserve', 'possess', 'cultivate', 'adopt', 'engage', 'unleash']\n",
      "\n",
      "complex_word_lemma for complex word 'deploy': deploy\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['deployment', 'utilize', 'mobilize', 'employ', 'dispatch', 'equip', 'ploy', 'use', 'activate', 'recruit', 'transport', 'operate', 'withdraw', 'install', 'locate', 'commit', 'construct', 'summon', 'expend', 'send', 'reserve', 'possess', 'cultivate', 'adopt', 'engage', 'unleash']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['deployment', 'utilize', 'mobilize', 'employ', 'dispatch', 'equip', 'ploy', 'use', 'activate', 'recruit', 'transport', 'operate', 'withdraw', 'install', 'locate', 'commit', 'construct', 'summon', 'expend', 'send', 'reserve', 'possess', 'cultivate', 'adopt', 'engage', 'unleash']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['equip', 'install', 'use', 'send', 'operate', 'reserve', 'construct', 'transport', 'ploy', 'locate', 'summon', 'withdraw', 'deployment', 'unleash', 'recruit', 'utilize', 'activate', 'possess', 'mobilize', 'employ', 'expend', 'cultivate', 'commit', 'dispatch', 'adopt', 'engage']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "SG step: generated substitutes: ['authorities', 'officials', 'authorities', 'authority', 'investigators', 'counterparts', 'police', 'agencies', 'administrators', 'forces', 'prosecutors', 'officers', 'authorities', 'entities', 'intelligence', 'jurisdictions', 'individuals', 'detainees', 'institutions', 'affairs', 'demonstrators', 'superiors', 'victims', 'regulators', 'concerns', 'ministers', 'figures', 'suspects', 'sources', 'assistance']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['authorities', 'officials', 'authority', 'investigators', 'counterparts', 'police', 'agencies', 'administrators', 'forces', 'prosecutors', 'officers', 'entities', 'intelligence', 'jurisdictions', 'individuals', 'detainees', 'institutions', 'affairs', 'demonstrators', 'superiors', 'victims', 'regulators', 'concerns', 'ministers', 'figures', 'suspects', 'sources', 'assistance']\n",
      "\n",
      "complex_word_lemma for complex word 'authorities': authority\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['officials', 'investigators', 'counterparts', 'police', 'agencies', 'administrators', 'forces', 'prosecutors', 'officers', 'entities', 'intelligence', 'jurisdictions', 'individuals', 'detainees', 'institutions', 'affairs', 'demonstrators', 'superiors', 'victims', 'regulators', 'concerns', 'ministers', 'figures', 'suspects', 'sources', 'assistance']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['officials', 'investigators', 'counterparts', 'police', 'agencies', 'administrators', 'forces', 'prosecutors', 'officers', 'entities', 'intelligence', 'jurisdictions', 'individuals', 'detainees', 'institutions', 'affairs', 'demonstrators', 'superiors', 'victims', 'regulators', 'concerns', 'ministers', 'figures', 'suspects', 'sources', 'assistance']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['figures', 'forces', 'police', 'sources', 'agencies', 'jurisdictions', 'concerns', 'assistance', 'ministers', 'affairs', 'individuals', 'administrators', 'officers', 'entities', 'detainees', 'institutions', 'officials', 'investigators', 'victims', 'prosecutors', 'suspects', 'superiors', 'intelligence', 'counterparts', 'demonstrators', 'regulators']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# instantiate a FitBert model\n",
    "fb_model = FitBert(lm_model)\n",
    "\n",
    "\n",
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"<mask>\")    # RoBERTa uses <mask> instead of [MASK]\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    tokenizer = fill_mask.tokenizer\n",
    "    sentences_concat = f\"{sentence} {tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes = [substitute[\"token_str\"].lower().lstrip() for substitute in result]   # and use .lstrip to remove the leading space, as Roberta tokenizes by default with a space in front of the word\n",
    "    print(f\"SG step: generated substitutes: {substitutes}\\n\")\n",
    "    \n",
    "    \n",
    "    # 2. Substitute Selection (SS):   \n",
    "    \n",
    "    # a) remove duplicates within the substitute list from the substitute list \n",
    "    \n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl:\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    print(f\"SS step: a) substitute list without duplicates: {substitutes_no_dupl}\\n\")\n",
    "\n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    print(f\"SS step: b) substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    print(f\"SS step: c): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "    \n",
    "    \n",
    "    # d) apply FITBERT to the list of substitutes\n",
    "    sentence_fitbert_masked = sentence_masked_word.replace(\"<mask>\", \"***mask***\")    # fitbert uses ***mask*** instead of [MASK] or <mask> \n",
    "    sentences_concat_fitbert = f\"{sentence} {tokenizer.sep_token} {sentence_fitbert_masked}\"\n",
    "    \n",
    "    ranked_substitutes = fb_model.rank(sentences_concat_fitbert, substitutes_no_dupl_complex_word_no_antonym)\n",
    "    print(f\"SS step: d) ranked substitutes using FitBert: {ranked_substitutes}\\n\")\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------------------')\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # limit the substitutes to the 10 first ones for evaluation\n",
    "    top_10_substitutes = ranked_substitutes[:10]\n",
    "    \n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + top_10_substitutes\n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the dataframe\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/RobertaBase_SG_SS_abc_fb.tsv\", sep=\"\\t\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0e58dc-f952-4dd0-8e16-b28d321ac37c",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file ./predictions/trial/RobertaBase_SG_SS_abc_fb.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "90548025-2477-4863-8e28-1f9874089151",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/RobertaBase_SG_SS_abc_fb.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.2\n",
    "\n",
    "MAP@3 = 0.1611\n",
    "MAP@5 = 0.1186\n",
    "MAP@10 = 0.0643\n",
    "\n",
    "Potential@3 = 0.8\n",
    "Potential@5 = 0.9\n",
    "Potential@10 = 1.0\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.0\n",
    "Accuracy@2@top_gold_1 = 0.0\n",
    "Accuracy@3@top_gold_1 = 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aec21e3-4306-4b18-857c-332e59e2ed4d",
   "metadata": {},
   "source": [
    "Result:  results are a lot worse than any other result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dbf939-28ef-4f7a-91a3-7c8a1ec648dc",
   "metadata": {},
   "source": [
    "#### Substitute Generation with ROBERTA-base, and Substitute Selection steps a-c, and the resulting list with contextualized embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25885e02-9df3-437d-9ae0-29b610d28016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00dc9a0b-b74c-4b19-a7cf-ceda9e7cfe86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "SG step: generated substitutes: ['compulsory', 'mandatory', 'obligatory', 'voluntary', 'required', 'optional', 'obliged', 'uniform', 'necessary', 'available', 'mandated', 'sufficient', 'routine', 'forced', 'customary', 'prerequisite', 'feasible', 'indispensable', 'forthcoming', 'universal', 'requirement', 'involuntary', 'obligated', 'compelled', 'conditional', 'enforced', 'contingent', 'possible', 'compulsion', 'mandatory']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['compulsory', 'mandatory', 'obligatory', 'voluntary', 'required', 'optional', 'obliged', 'uniform', 'necessary', 'available', 'mandated', 'sufficient', 'routine', 'forced', 'customary', 'prerequisite', 'feasible', 'indispensable', 'forthcoming', 'universal', 'requirement', 'involuntary', 'obligated', 'compelled', 'conditional', 'enforced', 'contingent', 'possible', 'compulsion']\n",
      "\n",
      "complex_word_lemma for complex word 'compulsory': compulsory\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['mandatory', 'obligatory', 'voluntary', 'required', 'optional', 'obliged', 'uniform', 'necessary', 'available', 'mandated', 'sufficient', 'routine', 'forced', 'customary', 'prerequisite', 'feasible', 'indispensable', 'forthcoming', 'universal', 'requirement', 'involuntary', 'obligated', 'compelled', 'conditional', 'enforced', 'contingent', 'possible', 'compulsion']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['mandatory', 'obligatory', 'voluntary', 'required', 'optional', 'obliged', 'uniform', 'necessary', 'available', 'mandated', 'sufficient', 'routine', 'forced', 'customary', 'prerequisite', 'feasible', 'indispensable', 'forthcoming', 'universal', 'requirement', 'involuntary', 'obligated', 'compelled', 'conditional', 'enforced', 'contingent', 'possible', 'compulsion']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked substitutes in context, based on cosine similarity scores: ['mandatory', 'voluntary', 'required', 'obligatory', 'optional', 'routine', 'obliged', 'necessary', 'forced', 'sufficient', 'mandated', 'possible', 'available', 'requirement', 'feasible', 'enforced', 'indispensable', 'customary', 'conditional', 'forthcoming', 'prerequisite', 'compelled', 'uniform', 'involuntary', 'contingent', 'compulsion', 'universal', 'obligated']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "SG step: generated substitutes: ['infused', 'injected', 'endowed', 'illed', 'inst', 'furnished', 'supplied', 'bolstered', 'implanted', 'impressed', 'reinforced', 'invested', 'provided', 'filled', 'reassured', 'undermined', 'filled', 'pumped', 'struck', 'augmented', 'enriched', 'stirred', 'vested', 'imb', 'intoxicated', 'seeded', 'misled', 'stunned', 'inspired', 'inflated']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['infused', 'injected', 'endowed', 'illed', 'inst', 'furnished', 'supplied', 'bolstered', 'implanted', 'impressed', 'reinforced', 'invested', 'provided', 'filled', 'reassured', 'undermined', 'pumped', 'struck', 'augmented', 'enriched', 'stirred', 'vested', 'imb', 'intoxicated', 'seeded', 'misled', 'stunned', 'inspired', 'inflated']\n",
      "\n",
      "complex_word_lemma for complex word 'instilled': instill\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['infused', 'injected', 'endowed', 'illed', 'inst', 'furnished', 'supplied', 'bolstered', 'implanted', 'impressed', 'reinforced', 'invested', 'provided', 'filled', 'reassured', 'undermined', 'pumped', 'struck', 'augmented', 'enriched', 'stirred', 'vested', 'imb', 'intoxicated', 'seeded', 'misled', 'stunned', 'inspired', 'inflated']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['infused', 'injected', 'endowed', 'illed', 'inst', 'furnished', 'supplied', 'bolstered', 'implanted', 'impressed', 'reinforced', 'invested', 'provided', 'filled', 'reassured', 'undermined', 'pumped', 'struck', 'augmented', 'enriched', 'stirred', 'vested', 'imb', 'intoxicated', 'seeded', 'misled', 'stunned', 'inspired', 'inflated']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked substitutes in context, based on cosine similarity scores: ['filled', 'stirred', 'inspired', 'infused', 'bolstered', 'injected', 'provided', 'supplied', 'struck', 'furnished', 'reassured', 'stunned', 'impressed', 'pumped', 'undermined', 'reinforced', 'vested', 'endowed', 'misled', 'intoxicated', 'implanted', 'augmented', 'invested', 'enriched', 'inst', 'seeded', 'inflated', 'illed', 'imb']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "SG step: generated substitutes: ['maniac', 'criminals', 'riors', 'hawks', 'heads', 'killers', 'gangs', 'lords', 'thugs', 'devils', 'drums', 'murderers', 'fighters', 'monsters', 'fools', 'villains', 'idiots', 'machines', 'demons', 'doctors', 'planes', 'igans', 'bosses', 'nazis', 'beasts', 'fascists', 'children', 'nerds', 'extremists', 'parasites']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['maniac', 'criminals', 'riors', 'hawks', 'heads', 'killers', 'gangs', 'lords', 'thugs', 'devils', 'drums', 'murderers', 'fighters', 'monsters', 'fools', 'villains', 'idiots', 'machines', 'demons', 'doctors', 'planes', 'igans', 'bosses', 'nazis', 'beasts', 'fascists', 'children', 'nerds', 'extremists', 'parasites']\n",
      "\n",
      "complex_word_lemma for complex word 'maniacs': maniac\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['criminals', 'riors', 'hawks', 'heads', 'killers', 'gangs', 'lords', 'thugs', 'devils', 'drums', 'murderers', 'fighters', 'monsters', 'fools', 'villains', 'idiots', 'machines', 'demons', 'doctors', 'planes', 'igans', 'bosses', 'nazis', 'beasts', 'fascists', 'children', 'nerds', 'extremists', 'parasites']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['criminals', 'riors', 'hawks', 'heads', 'killers', 'gangs', 'lords', 'thugs', 'devils', 'drums', 'murderers', 'fighters', 'monsters', 'fools', 'villains', 'idiots', 'machines', 'demons', 'doctors', 'planes', 'igans', 'bosses', 'nazis', 'beasts', 'fascists', 'children', 'nerds', 'extremists', 'parasites']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked substitutes in context, based on cosine similarity scores: ['criminals', 'thugs', 'children', 'lords', 'hawks', 'killers', 'gangs', 'idiots', 'fighters', 'machines', 'drums', 'murderers', 'nazis', 'demons', 'monsters', 'extremists', 'heads', 'villains', 'beasts', 'doctors', 'bosses', 'parasites', 'devils', 'fools', 'fascists', 'nerds', 'planes', 'riors', 'igans']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "SG step: generated substitutes: ['observers', 'monitors', 'spectators', 'witnesses', 'observer', 'observes', 'visitors', 'viewers', 'reporters', 'inspectors', 'commentators', 'investigators', 'participants', 'analysts', 'cameras', 'outsiders', 'demonstrators', 'activists', 'journalists', 'experts', 'authorities', 'observations', 'eyes', 'supporters', 'observing', 'residents', 'protesters', 'responders', 'parties', 'followers']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['observers', 'monitors', 'spectators', 'witnesses', 'observer', 'observes', 'visitors', 'viewers', 'reporters', 'inspectors', 'commentators', 'investigators', 'participants', 'analysts', 'cameras', 'outsiders', 'demonstrators', 'activists', 'journalists', 'experts', 'authorities', 'observations', 'eyes', 'supporters', 'observing', 'residents', 'protesters', 'responders', 'parties', 'followers']\n",
      "\n",
      "complex_word_lemma for complex word 'observers': observer\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['monitors', 'spectators', 'witnesses', 'observes', 'visitors', 'viewers', 'reporters', 'inspectors', 'commentators', 'investigators', 'participants', 'analysts', 'cameras', 'outsiders', 'demonstrators', 'activists', 'journalists', 'experts', 'authorities', 'observations', 'eyes', 'supporters', 'observing', 'residents', 'protesters', 'responders', 'parties', 'followers']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['monitors', 'spectators', 'witnesses', 'observes', 'visitors', 'viewers', 'reporters', 'inspectors', 'commentators', 'investigators', 'participants', 'analysts', 'cameras', 'outsiders', 'demonstrators', 'activists', 'journalists', 'experts', 'authorities', 'observations', 'eyes', 'supporters', 'observing', 'residents', 'protesters', 'responders', 'parties', 'followers']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked substitutes in context, based on cosine similarity scores: ['monitors', 'inspectors', 'participants', 'visitors', 'experts', 'spectators', 'investigators', 'witnesses', 'outsiders', 'observations', 'analysts', 'activists', 'authorities', 'residents', 'viewers', 'responders', 'eyes', 'commentators', 'cameras', 'observing', 'observes', 'supporters', 'parties', 'journalists', 'protesters', 'reporters', 'followers', 'demonstrators']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "SG step: generated substitutes: ['rapnel', 'bullet', 'gunshot', 'stab', 'radiation', 'projectile', 'crippling', 'shotgun', 'mortar', 'stun', 'explosive', 'stray', 'shell', 'bomb', 'microscopic', 'fragmentation', 'cartridge', 'grenade', 'rocket', 'torpedo', 'piercing', 'unidentified', 'ammunition', 'insurgent', 'similar', 'blast', 'bullets', 'slug', 'terrorist', 'pillow']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['rapnel', 'bullet', 'gunshot', 'stab', 'radiation', 'projectile', 'crippling', 'shotgun', 'mortar', 'stun', 'explosive', 'stray', 'shell', 'bomb', 'microscopic', 'fragmentation', 'cartridge', 'grenade', 'rocket', 'torpedo', 'piercing', 'unidentified', 'ammunition', 'insurgent', 'similar', 'blast', 'bullets', 'slug', 'terrorist', 'pillow']\n",
      "\n",
      "complex_word_lemma for complex word 'shrapnel': shrapnel\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['rapnel', 'bullet', 'gunshot', 'stab', 'radiation', 'projectile', 'crippling', 'shotgun', 'mortar', 'stun', 'explosive', 'stray', 'shell', 'bomb', 'microscopic', 'fragmentation', 'cartridge', 'grenade', 'rocket', 'torpedo', 'piercing', 'unidentified', 'ammunition', 'insurgent', 'similar', 'blast', 'bullets', 'slug', 'terrorist', 'pillow']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['rapnel', 'bullet', 'gunshot', 'stab', 'radiation', 'projectile', 'crippling', 'shotgun', 'mortar', 'stun', 'explosive', 'stray', 'shell', 'bomb', 'microscopic', 'fragmentation', 'cartridge', 'grenade', 'rocket', 'torpedo', 'piercing', 'unidentified', 'ammunition', 'insurgent', 'similar', 'blast', 'bullets', 'slug', 'terrorist', 'pillow']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked substitutes in context, based on cosine similarity scores: ['bomb', 'grenade', 'bullet', 'explosive', 'gunshot', 'blast', 'shell', 'mortar', 'shotgun', 'projectile', 'crippling', 'stun', 'rocket', 'radiation', 'piercing', 'stab', 'fragmentation', 'microscopic', 'bullets', 'stray', 'insurgent', 'slug', 'torpedo', 'cartridge', 'pillow', 'unidentified', 'ammunition', 'terrorist', 'similar', 'rapnel']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "SG step: generated substitutes: ['disguised', 'dressed', 'veiled', 'masked', 'concealed', 'hidden', 'disguise', 'clothed', 'clad', 'posed', 'covered', 'cloaked', 'shrouded', 'wrapped', 'posing', 'hiding', 'trained', 'camoufl', 'presented', 'known', 'smuggled', 'staged', 'draped', 'described', 'decorated', 'armed', 'buried', 'camouflage', 'marked', 'hid']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['disguised', 'dressed', 'veiled', 'masked', 'concealed', 'hidden', 'disguise', 'clothed', 'clad', 'posed', 'covered', 'cloaked', 'shrouded', 'wrapped', 'posing', 'hiding', 'trained', 'camoufl', 'presented', 'known', 'smuggled', 'staged', 'draped', 'described', 'decorated', 'armed', 'buried', 'camouflage', 'marked', 'hid']\n",
      "\n",
      "complex_word_lemma for complex word 'disguised': disguised\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['dressed', 'veiled', 'masked', 'concealed', 'hidden', 'disguise', 'clothed', 'clad', 'posed', 'covered', 'cloaked', 'shrouded', 'wrapped', 'posing', 'hiding', 'trained', 'camoufl', 'presented', 'known', 'smuggled', 'staged', 'draped', 'described', 'decorated', 'armed', 'buried', 'camouflage', 'marked', 'hid']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['dressed', 'veiled', 'masked', 'concealed', 'hidden', 'disguise', 'clothed', 'clad', 'posed', 'covered', 'cloaked', 'shrouded', 'wrapped', 'posing', 'hiding', 'trained', 'camoufl', 'presented', 'known', 'smuggled', 'staged', 'draped', 'described', 'decorated', 'armed', 'buried', 'camouflage', 'marked', 'hid']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked substitutes in context, based on cosine similarity scores: ['masked', 'cloaked', 'clad', 'clothed', 'dressed', 'shrouded', 'concealed', 'posing', 'covered', 'armed', 'wrapped', 'draped', 'veiled', 'hiding', 'hidden', 'decorated', 'trained', 'posed', 'hid', 'known', 'disguise', 'marked', 'presented', 'staged', 'described', 'camouflage', 'camoufl', 'smuggled', 'buried']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "SG step: generated substitutes: ['off', 'extension', 'opposite', 'outpost', 'off', 'out', 'affiliate', 'offspring', 'overthrow', 'element', 'outside', 'echo', 'expansion', 'imprint', 'arm', 'ideology', 'overhaul', 'branch', 'opposition', 'evolution', 'indication', 'upset', 'archetype', 'extend', 'independent', 'alternative', 'example', 'instance', 'embrace', 'adjunct']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['off', 'extension', 'opposite', 'outpost', 'out', 'affiliate', 'offspring', 'overthrow', 'element', 'outside', 'echo', 'expansion', 'imprint', 'arm', 'ideology', 'overhaul', 'branch', 'opposition', 'evolution', 'indication', 'upset', 'archetype', 'extend', 'independent', 'alternative', 'example', 'instance', 'embrace', 'adjunct']\n",
      "\n",
      "complex_word_lemma for complex word 'offshoot': offshoot\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['off', 'extension', 'opposite', 'outpost', 'out', 'affiliate', 'offspring', 'overthrow', 'element', 'outside', 'echo', 'expansion', 'imprint', 'arm', 'ideology', 'overhaul', 'branch', 'opposition', 'evolution', 'indication', 'upset', 'archetype', 'extend', 'independent', 'alternative', 'example', 'instance', 'embrace', 'adjunct']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['off', 'extension', 'opposite', 'outpost', 'out', 'affiliate', 'offspring', 'overthrow', 'element', 'outside', 'echo', 'expansion', 'imprint', 'arm', 'ideology', 'overhaul', 'branch', 'opposition', 'evolution', 'indication', 'upset', 'archetype', 'extend', 'independent', 'alternative', 'example', 'instance', 'embrace', 'adjunct']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked substitutes in context, based on cosine similarity scores: ['affiliate', 'extension', 'offspring', 'arm', 'outpost', 'independent', 'element', 'opposite', 'adjunct', 'echo', 'imprint', 'alternative', 'expansion', 'opposition', 'example', 'embrace', 'branch', 'evolution', 'overthrow', 'instance', 'indication', 'ideology', 'archetype', 'outside', 'off', 'upset', 'overhaul', 'extend', 'out']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "SG step: generated substitutes: ['classical', 'harmonic', 'musical', 'sym', 'music', 'instrumental', 'piano', 'lyric', 'jazz', 'modern', 'dramatic', 'major', 'vocal', 'composing', 'concert', 'opera', 'sonic', 'formal', 'popular', 'early', 'composition', 'english', 'singing', 'standard', 'trumpet', 'keyboard', 'contemporary', 'orchestra', 'technical', 'onic']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['classical', 'harmonic', 'musical', 'sym', 'music', 'instrumental', 'piano', 'lyric', 'jazz', 'modern', 'dramatic', 'major', 'vocal', 'composing', 'concert', 'opera', 'sonic', 'formal', 'popular', 'early', 'composition', 'english', 'singing', 'standard', 'trumpet', 'keyboard', 'contemporary', 'orchestra', 'technical', 'onic']\n",
      "\n",
      "complex_word_lemma for complex word 'symphonic': symphonic\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['classical', 'harmonic', 'musical', 'sym', 'music', 'instrumental', 'piano', 'lyric', 'jazz', 'modern', 'dramatic', 'major', 'vocal', 'composing', 'concert', 'opera', 'sonic', 'formal', 'popular', 'early', 'composition', 'english', 'singing', 'standard', 'trumpet', 'keyboard', 'contemporary', 'orchestra', 'technical', 'onic']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['classical', 'harmonic', 'musical', 'sym', 'music', 'instrumental', 'piano', 'lyric', 'jazz', 'modern', 'dramatic', 'major', 'vocal', 'composing', 'concert', 'opera', 'sonic', 'formal', 'popular', 'early', 'composition', 'english', 'singing', 'standard', 'trumpet', 'keyboard', 'contemporary', 'orchestra', 'technical', 'onic']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked substitutes in context, based on cosine similarity scores: ['musical', 'sym', 'concert', 'instrumental', 'classical', 'orchestra', 'formal', 'music', 'popular', 'lyric', 'standard', 'composing', 'dramatic', 'composition', 'contemporary', 'vocal', 'major', 'technical', 'harmonic', 'modern', 'sonic', 'singing', 'english', 'opera', 'onic', 'piano', 'trumpet', 'jazz', 'early', 'keyboard']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "SG step: generated substitutes: ['deploy', 'deployed', 'deployment', 'utilize', 'mobilize', 'employ', 'deploying', 'dispatch', 'equip', 'deploy', 'ploy', 'use', 'activate', 'recruit', 'transport', 'operate', 'withdraw', 'install', 'locate', 'commit', 'construct', 'summon', 'expend', 'send', 'reserve', 'possess', 'cultivate', 'adopt', 'engage', 'unleash']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['deploy', 'deployed', 'deployment', 'utilize', 'mobilize', 'employ', 'deploying', 'dispatch', 'equip', 'ploy', 'use', 'activate', 'recruit', 'transport', 'operate', 'withdraw', 'install', 'locate', 'commit', 'construct', 'summon', 'expend', 'send', 'reserve', 'possess', 'cultivate', 'adopt', 'engage', 'unleash']\n",
      "\n",
      "complex_word_lemma for complex word 'deploy': deploy\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['deployment', 'utilize', 'mobilize', 'employ', 'dispatch', 'equip', 'ploy', 'use', 'activate', 'recruit', 'transport', 'operate', 'withdraw', 'install', 'locate', 'commit', 'construct', 'summon', 'expend', 'send', 'reserve', 'possess', 'cultivate', 'adopt', 'engage', 'unleash']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['deployment', 'utilize', 'mobilize', 'employ', 'dispatch', 'equip', 'ploy', 'use', 'activate', 'recruit', 'transport', 'operate', 'withdraw', 'install', 'locate', 'commit', 'construct', 'summon', 'expend', 'send', 'reserve', 'possess', 'cultivate', 'adopt', 'engage', 'unleash']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked substitutes in context, based on cosine similarity scores: ['dispatch', 'install', 'activate', 'unleash', 'adopt', 'employ', 'recruit', 'engage', 'send', 'operate', 'use', 'mobilize', 'construct', 'equip', 'summon', 'commit', 'withdraw', 'possess', 'deployment', 'reserve', 'cultivate', 'transport', 'ploy', 'utilize', 'locate', 'expend']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "SG step: generated substitutes: ['authorities', 'officials', 'authorities', 'authority', 'investigators', 'counterparts', 'police', 'agencies', 'administrators', 'forces', 'prosecutors', 'officers', 'authorities', 'entities', 'intelligence', 'jurisdictions', 'individuals', 'detainees', 'institutions', 'affairs', 'demonstrators', 'superiors', 'victims', 'regulators', 'concerns', 'ministers', 'figures', 'suspects', 'sources', 'assistance']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['authorities', 'officials', 'authority', 'investigators', 'counterparts', 'police', 'agencies', 'administrators', 'forces', 'prosecutors', 'officers', 'entities', 'intelligence', 'jurisdictions', 'individuals', 'detainees', 'institutions', 'affairs', 'demonstrators', 'superiors', 'victims', 'regulators', 'concerns', 'ministers', 'figures', 'suspects', 'sources', 'assistance']\n",
      "\n",
      "complex_word_lemma for complex word 'authorities': authority\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['officials', 'investigators', 'counterparts', 'police', 'agencies', 'administrators', 'forces', 'prosecutors', 'officers', 'entities', 'intelligence', 'jurisdictions', 'individuals', 'detainees', 'institutions', 'affairs', 'demonstrators', 'superiors', 'victims', 'regulators', 'concerns', 'ministers', 'figures', 'suspects', 'sources', 'assistance']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['officials', 'investigators', 'counterparts', 'police', 'agencies', 'administrators', 'forces', 'prosecutors', 'officers', 'entities', 'intelligence', 'jurisdictions', 'individuals', 'detainees', 'institutions', 'affairs', 'demonstrators', 'superiors', 'victims', 'regulators', 'concerns', 'ministers', 'figures', 'suspects', 'sources', 'assistance']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked substitutes in context, based on cosine similarity scores: ['police', 'officials', 'counterparts', 'prosecutors', 'investigators', 'entities', 'officers', 'forces', 'detainees', 'intelligence', 'assistance', 'ministers', 'institutions', 'administrators', 'regulators', 'suspects', 'demonstrators', 'agencies', 'sources', 'individuals', 'jurisdictions', 'superiors', 'affairs', 'victims', 'figures', 'concerns']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculates similarity between the original sentence and the sentences with candidate substitutes that were retrieved in the SG step \n",
    "# creates a list with sentences with substitute words filled in (commented out for oversight purposes)\n",
    "\n",
    "\n",
    "def calculate_similarity_scores(sentence, sentence_with_substitutes):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "    tf_model = TFAutoModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "    def embed_text(text):\n",
    "        tokens = tokenizer(text, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "        outputs = tf_model(**tokens)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        embeddings = tf.nn.l2_normalize(embeddings, axis=1)\n",
    "        return embeddings\n",
    "\n",
    "    original_sentence_embedding = embed_text(sentence)\n",
    "    substitute_sentence_embeddings = embed_text(sentence_with_substitutes)\n",
    "\n",
    "    cosine_similarity = np.inner(original_sentence_embedding, substitute_sentence_embeddings)\n",
    "    similarity_scores = cosine_similarity[0]\n",
    "\n",
    "    return similarity_scores\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"<mask>\")   # RoBERTa uses <mask> instead of [MASK]\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    tokenizer = fill_mask.tokenizer\n",
    "    sentences_concat = f\"{sentence} {tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes = [substitute[\"token_str\"].lower().lstrip() for substitute in result]   # and use .lstrip to remove the leading space, as Roberta tokenizes by default with a space in front of the word\n",
    "    print(f\"SG step: generated substitutes: {substitutes}\\n\")\n",
    "    \n",
    "    \n",
    "    # 2. Substitute Selection (SS):   \n",
    "    \n",
    "    # a) remove duplicates within the substitute list from the substitute list \n",
    "    \n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl:\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    print(f\"SS step: a) substitute list without duplicates: {substitutes_no_dupl}\\n\")\n",
    "\n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    print(f\"SS step: b) substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    print(f\"SS step: c): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "    \n",
    "    \n",
    "    # create sentence with the complex word replaced by the substitutes\n",
    "    sentence_with_substitutes = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym]\n",
    "    #print(f\"List with sentences where complex word is substituted: {sentence_with_substitutes}\\n\")\n",
    "    \n",
    "    \n",
    "    # d) calculate cosine similarity scores, and rank the substitutes based on their similarity score\n",
    "    similarity_scores = calculate_similarity_scores(sentence, sentence_with_substitutes)\n",
    "    #print(f\"Similarity scores: {similarity_scores}\\n\")\n",
    "    ranked_substitutes_withscores = sorted(zip(substitutes_no_dupl_complex_word_no_antonym, similarity_scores), key=lambda x: x[1], reverse=True)\n",
    "    #print(f\"SS step d) Ranked substitutes in context, including similarity scores: {ranked_substitutes}\\n\")\n",
    "    ranked_substitutes = [substitute for substitute, score in ranked_substitutes_withscores]\n",
    "    print(f\"Ranked substitutes in context, based on cosine similarity scores: {ranked_substitutes}\\n\")\n",
    "        \n",
    "    print('-----------------------------------------------------------------------------------------')\n",
    "    print()\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    # limit the substitutes to the 10 first ones for evaluation\n",
    "    top_10_substitutes = ranked_substitutes[:10]\n",
    "    \n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + top_10_substitutes\n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the dataframe\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/RobertaBase_SG_SS_abc_ce.tsv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639db7a8-ecaf-4a36-a009-c4a8bf516293",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file ./predictions/trial/RobertaBase_SG_SS_abc_ce.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ac2d866-2924-44f9-81be-d816cade47da",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/RobertaBase_SG_SS_abc_ce.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.6\n",
    "\n",
    "MAP@3 = 0.2999\n",
    "MAP@5 = 0.2369\n",
    "MAP@10 = 0.1501\n",
    "\n",
    "Potential@3 = 0.6\n",
    "Potential@5 = 0.7\n",
    "Potential@10 = 0.9\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.2\n",
    "Accuracy@2@top_gold_1 = 0.3\n",
    "Accuracy@3@top_gold_1 = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "779d98e6-c618-48cb-ac73-300b8de99cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result: a lot better on MAP@1 (from 0.4 to 0.6)  than with the other approaches in this notebook so far. other map results are similar, potential 3 and 5 lower, and accuracy1 2 and 3 also lower. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbfacb9-6901-4185-bb24-f4ad090c40e5",
   "metadata": {},
   "source": [
    "#### Substitute Generation with RoBERTa-Base, and Substitute Selection steps a-c, and the resulting list with BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "803957f2-7f87-40fc-8e5c-d1dc13d646bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert_score\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "058d6196-729f-4dbc-9631-e9878af053c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "SG step: generated substitutes: ['compulsory', 'mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['compulsory', 'mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n",
      "complex_word_lemma for complex word 'compulsory': compulsory\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['mandatory', 'voluntary', 'obligatory', 'routine', 'mandated', 'required', 'enforced', 'necessary', 'redundant', 'practicable', 'preferable', 'strict', 'forced', 'demanded', 'relevant', 'obliged', 'indispensable', 'vital', 'bureaucratic', 'lax', 'plain', 'gradual', 'mandate', 'clandestine', 'continuous', 'statutory', 'habitual', 'ministerial', 'lifelong']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "SG step: generated substitutes: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n",
      "complex_word_lemma for complex word 'instilled': instill\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['infused', 'injected', 'filled', 'flooded', 'stoked', 'pumped', 'revived', 'gifted', 'vested', 'provided', 'reassured', 'infected', 'impressed', 'thrilled', 'insulated', 'endowed', 'stocked', 'hit', 'sprinkled', 'assured', 'elevated', 'penetrated', 'vaccinated', 'implanted', 'installed', 'invested', 'infiltrated', 'inst', 'illed', 'inject']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "SG step: generated substitutes: ['maniac', 'criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'fighters', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'killers', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['maniac', 'criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n",
      "complex_word_lemma for complex word 'maniacs': maniac\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['criminals', 'thugs', 'killers', 'lords', 'partisans', 'gangs', 'militias', 'combatants', 'mercenaries', 'fighters', 'squads', 'factions', 'murderers', 'perpetrators', 'troops', 'monsters', 'chiefs', 'commanders', 'helmets', 'gunmen', 'hunters', 'fascists', 'jihadists', 'assassins', 'detainees', 'crimes', 'killings']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "SG step: generated substitutes: ['observers', 'monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'observer', 'supervisors', 'analysts', 'operators', 'responders', 'observer', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['observers', 'monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'observer', 'supervisors', 'analysts', 'operators', 'responders', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n",
      "complex_word_lemma for complex word 'observers': observer\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'supervisors', 'analysts', 'operators', 'responders', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'supervisors', 'analysts', 'operators', 'responders', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['monitors', 'investigators', 'experts', 'reporters', 'inspectors', 'participants', 'responders', 'advisors', 'visitors', 'witnesses', 'reinforcements', 'officials', 'analysts', 'outsiders', 'operators', 'bystanders', 'organizers', 'demonstrators', 'followers', 'educators', 'opponents', 'dissidents', 'observations', 'airstrikes', 'supervisors', 'observed', 'observes']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "SG step: generated substitutes: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n",
      "complex_word_lemma for complex word 'shrapnel': shrapnel\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['bullet', 'gunshot', 'knife', 'stab', 'gun', 'multiple', 'blast', 'explosive', 'shot', 'several', 'shock', 'sniper', 'grenade', 'unspecified', 'mortar', 'the', 'shell', 'spear', 'arrow', 'shotgun', 'projectile', 'gunshots', 'rifle', 'gunfire', 'stray', 'dagger', 'sh', 'blaster', 'rapnel', 'a']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "SG step: generated substitutes: ['disguised', 'cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['disguised', 'cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n",
      "complex_word_lemma for complex word 'disguised': disguised\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['masked', 'clothed', 'cloaked', 'dressed', 'concealed', 'veiled', 'clad', 'shrouded', 'wrapped', 'adorned', 'styled', 'posed', 'fitted', 'branded', 'displayed', 'imprisoned', 'formed', 'dispersed', 'organised', 'united', 'framed', 'disguise', 'packaged', 'revealed', 'armoured', 'portrayed', 'frightened', 'recognised', 'disgu']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "SG step: generated substitutes: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n",
      "complex_word_lemma for complex word 'offshoot': offshoot\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['extension', 'incarnation', 'affiliate', 'offspring', 'adherent', 'outpost', 'arm', 'adjunct', 'example', 'iteration', 'ally', 'branch', 'embryo', 'affiliation', 'extremist', 'embrace', 'adaptation', 'outlet', 'enclave', 'subset', 'acronym', 'orthodoxy', 'off', 'outline', 'affiliated', 'insurgency', 'outreach', 'shoot', 'undercut']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "SG step: generated substitutes: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'musical', 'contemporary', 'formal', 'analytic']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'contemporary', 'formal', 'analytic']\n",
      "\n",
      "complex_word_lemma for complex word 'symphonic': symphonic\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'contemporary', 'formal', 'analytic']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'contemporary', 'formal', 'analytic']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['concert', 'classical', 'instrumental', 'musical', 'onic', 'harmonic', 'formal', 'dramatic', 'modern', 'traditional', 'popular', 'vocal', 'contemporary', 'historical', 'general', 'canonical', 'music', 'analytic', 'romantic', 'theoretical', 'piano', 'the', 'sym', 'or', 'of', 'and', 'in', ',', '</s>']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "SG step: generated substitutes: ['deploy', 'deployed', 'deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'deploying', 'deploy', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['deploy', 'deployed', 'deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'deploying', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n",
      "complex_word_lemma for complex word 'deploy': deploy\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['dispatch', 'employ', 'mobilize', 'launch', 'deliver', 'recruit', 'operate', 'use', 'send', 'construct', 'transport', 'contract', 'secure', 'expend', 'command', 'wield', 'maneuver', 'move', 'patrol', 'withdraw', 'deployment', 'disperse', 'combat', 'tether', 'monitor', 'ploy']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "SG step: generated substitutes: ['authorities', 'police', 'officials', 'authorities', 'authority', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'authorities', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['authorities', 'police', 'officials', 'authority', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n",
      "complex_word_lemma for complex word 'authorities': authority\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['police', 'officials', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['police', 'officials', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['officials', 'police', 'investigators', 'regulators', 'governments', 'prosecutors', 'courts', 'forces', 'officers', 'institutions', 'representatives', 'policemen', 'residents', 'paramedics', 'employees', 'individuals', 'bodies', 'neighbours', 'detainees', 'colleagues', 'superiors', 'regimes', 'authors', 'arrests', 'applications', 'requirements']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"<mask>\")    # RoBERTa uses <mask> instead of [MASK]\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    tokenizer = fill_mask.tokenizer\n",
    "    sentences_concat = f\"{sentence} {tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes = [substitute[\"token_str\"].lower().lstrip() for substitute in result]   # and use .lstrip to remove the leading space, as Roberta tokenizes by default with a space in front of the word\n",
    "    print(f\"SG step: generated substitutes: {substitutes}\\n\")\n",
    "    \n",
    "    \n",
    "    # 2. Substitute Selection (SS):   \n",
    "    \n",
    "    # a) remove duplicates within the substitute list from the substitute list \n",
    "    \n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl:\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    print(f\"SS step: a) substitute list without duplicates: {substitutes_no_dupl}\\n\")\n",
    "\n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    print(f\"SS step: b) substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    print(f\"SS step: c): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "    \n",
    "    \n",
    "    # create sentences with the complex word replaced by the substitutes\n",
    "    sentences_with_substitutes = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym]\n",
    "    #print(f\"SG step: sentences with substitutes: {sentences_with_substitutes}\\n\")\n",
    "    \n",
    "          \n",
    "    # d) use BERTScore for sorting\n",
    "    scores = bert_score.score([sentence]*len(sentences_with_substitutes), sentences_with_substitutes, lang=\"en\", model_type='roberta-base', verbose=False)\n",
    "    ranked_substitutes = [substitute for _, substitute in sorted(zip(scores[0].tolist(), substitutes_no_dupl_complex_word_no_antonym), reverse=True)]\n",
    "    print(f\"SS step: d) substitute list sorted by descending BERTScore: {ranked_substitutes}\\n\")\n",
    "\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------------------')\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # limit the substitutes to the 10 first ones for evaluation\n",
    "    top_10_substitutes = ranked_substitutes[:10]\n",
    "    \n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + top_10_substitutes\n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the dataframe\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/RobertaBase_SG_SS_abc_bs.tsv\", sep=\"\\t\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1564aa-d6fa-4dc5-844d-7f24252c473c",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file ./predictions/trial/RobertaBase_SG_SS_abc_bs.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0416e647-4f5e-4d0a-89c9-12943227598d",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/RobertaBase_SG_SS_abc_bs.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.5\n",
    "\n",
    "MAP@3 = 0.2611\n",
    "MAP@5 = 0.1986\n",
    "MAP@10 = 0.1316\n",
    "\n",
    "Potential@3 = 0.6\n",
    "Potential@5 = 0.8\n",
    "Potential@10 = 0.8\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.4\n",
    "Accuracy@2@top_gold_1 = 0.4\n",
    "Accuracy@3@top_gold_1 = 0.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794e899f-7749-43b4-90d0-f92e125c8046",
   "metadata": {},
   "source": [
    "all map metrics (including map1) lower than with ce, but better than without ce. Potential one lower, one higher, one the same.  Accuracy 2 lower, one the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ef875a-5d61-4501-9b47-f3f5635c2382",
   "metadata": {},
   "source": [
    "### RoBERTa-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "044ee468-d1d1-43d0-9f52-0c81a436815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize the tokenizer and the models\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\")\n",
    "lm_model = AutoModelForMaskedLM.from_pretrained(\"roberta-large\")\n",
    "\n",
    "# create a fill-mask pipeline \n",
    "fill_mask = pipeline(\"fill-mask\", lm_model, tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee1f666-df46-41e9-bf46-86f811c4581d",
   "metadata": {},
   "source": [
    "#### Only Substitute Generation with RoBERTa-large (k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba263a4a-ecca-434b-b8a2-9aa20d1be64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "SG step: generated substitutes: ['compulsory', 'mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant']\n",
      "\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "SG step: generated substitutes: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed']\n",
      "\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "SG step: generated substitutes: ['maniac', 'criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions']\n",
      "\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "SG step: generated substitutes: ['observers', 'monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'observer', 'supervisors', 'analysts']\n",
      "\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "SG step: generated substitutes: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell']\n",
      "\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "SG step: generated substitutes: ['disguised', 'cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed']\n",
      "\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "SG step: generated substitutes: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'off']\n",
      "\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "SG step: generated substitutes: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano']\n",
      "\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "SG step: generated substitutes: ['deploy', 'deployed', 'deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'deploying', 'deploy', 'maneuver']\n",
      "\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "SG step: generated substitutes: ['authorities', 'police', 'officials', 'authorities', 'authority', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"<mask>\")  # RoBERTa uses <mask> instead of [MASK]\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    tokenizer = fill_mask.tokenizer\n",
    "    sentences_concat = f\"{sentence} {tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 10\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes = [substitute[\"token_str\"].lower().lstrip() for substitute in result]   # and use .lstrip to remove the leading space, as Roberta tokenizes by default with a space in front of the word\n",
    "    print(f\"SG step: generated substitutes: {substitutes}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + substitutes\n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the dataframe\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/RobertaLarge_SG.tsv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9c2448-06d4-4b6d-bb41-9238180bcffd",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file ./predictions/trial/RobertaLarge_SG.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "734f15ff-9d9a-4971-a5f5-556f56718fe0",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/RobertaLarge_SG.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.5\n",
    "\n",
    "MAP@3 = 0.2944\n",
    "MAP@5 = 0.2016\n",
    "MAP@10 = 0.1067\n",
    "\n",
    "Potential@3 = 0.7\n",
    "Potential@5 = 0.7\n",
    "Potential@10 = 0.8\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.3\n",
    "Accuracy@2@top_gold_1 = 0.4\n",
    "Accuracy@3@top_gold_1 = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfa8b247-5b18-461d-a136-aecd3659a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result: better than roberta-base on MAP1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06c1ddc-4d5b-4f11-a300-378b93c477f6",
   "metadata": {},
   "source": [
    "#### Substitute Generation with RoBERTa-large, and Substitute Selection steps a-c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "142aceeb-93ee-40c0-88b8-e636a3c3c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "712dcc8f-3382-4c17-a87f-703783aaeaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "SG step: generated substitutes: ['compulsory', 'mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['compulsory', 'mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n",
      "complex_word_lemma for complex word 'compulsory': compulsory\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "SG step: generated substitutes: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n",
      "complex_word_lemma for complex word 'instilled': instill\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "SG step: generated substitutes: ['maniac', 'criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'fighters', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'killers', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['maniac', 'criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n",
      "complex_word_lemma for complex word 'maniacs': maniac\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "SG step: generated substitutes: ['observers', 'monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'observer', 'supervisors', 'analysts', 'operators', 'responders', 'observer', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['observers', 'monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'observer', 'supervisors', 'analysts', 'operators', 'responders', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n",
      "complex_word_lemma for complex word 'observers': observer\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'supervisors', 'analysts', 'operators', 'responders', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'supervisors', 'analysts', 'operators', 'responders', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "SG step: generated substitutes: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n",
      "complex_word_lemma for complex word 'shrapnel': shrapnel\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "SG step: generated substitutes: ['disguised', 'cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['disguised', 'cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n",
      "complex_word_lemma for complex word 'disguised': disguised\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "SG step: generated substitutes: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n",
      "complex_word_lemma for complex word 'offshoot': offshoot\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "SG step: generated substitutes: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'musical', 'contemporary', 'formal', 'analytic']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'contemporary', 'formal', 'analytic']\n",
      "\n",
      "complex_word_lemma for complex word 'symphonic': symphonic\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'contemporary', 'formal', 'analytic']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'contemporary', 'formal', 'analytic']\n",
      "\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "SG step: generated substitutes: ['deploy', 'deployed', 'deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'deploying', 'deploy', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['deploy', 'deployed', 'deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'deploying', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n",
      "complex_word_lemma for complex word 'deploy': deploy\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "SG step: generated substitutes: ['authorities', 'police', 'officials', 'authorities', 'authority', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'authorities', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['authorities', 'police', 'officials', 'authority', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n",
      "complex_word_lemma for complex word 'authorities': authority\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['police', 'officials', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['police', 'officials', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"<mask>\")   # RoBERTa uses <mask> instead of [MASK]\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    tokenizer = fill_mask.tokenizer\n",
    "    sentences_concat = f\"{sentence} {tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes = [substitute[\"token_str\"].lower().lstrip() for substitute in result]   # and use .lstrip to remove the leading space, as Roberta tokenizes by default with a space in front of the word\n",
    "    print(f\"SG step: generated substitutes: {substitutes}\\n\")\n",
    "    \n",
    "    \n",
    "    # 2. Substitute Selection (SS):   \n",
    "    \n",
    "    # a) remove duplicates within the substitute list from the substitute list \n",
    "    \n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl:\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    print(f\"SS step: a) substitute list without duplicates: {substitutes_no_dupl}\\n\")\n",
    "\n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    print(f\"SS step: b) substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    print(f\"SS step: c): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "    \n",
    "     \n",
    "    \n",
    "    # limit the substitutes to the 10 first ones for evaluation\n",
    "    top_10_substitutes = substitutes_no_dupl_complex_word_no_antonym[:10]\n",
    "    \n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + top_10_substitutes\n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the dataframe\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/RobertaLarge_SG_SS_abc.tsv\", sep=\"\\t\", index=False, header=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce51cf4a-5cd2-484c-bec2-dd87341e3830",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file ./predictions/trial/RobertaLarge_SG_SS_abc.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3de9c2a-cb65-4a81-9e4b-a730e8f57cb4",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/RobertaLarge_SG_SS_abc.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.5\n",
    "\n",
    "MAP@3 = 0.2944\n",
    "MAP@5 = 0.2056\n",
    "MAP@10 = 0.1192\n",
    "\n",
    "Potential@3 = 0.7\n",
    "Potential@5 = 0.8\n",
    "Potential@10 = 0.8\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.3\n",
    "Accuracy@2@top_gold_1 = 0.4\n",
    "Accuracy@3@top_gold_1 = 0.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b08fd5a8-1d39-4efc-a806-2dcec37bcc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slightly higher or the same results than without this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f74394-73dd-4ee8-bd02-8c8b6a2935cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71e2839f-8d4a-47c4-a77c-ce5b25900722",
   "metadata": {},
   "source": [
    "#### Substitute Generation with RoBERTa-large, and Substitute Selection steps a-c, and the resulting list with FitBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc8cb0a4-d6b7-4286-90d2-b1db81bc722f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "using custom model: ['RobertaForMaskedLM']\n",
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "SG step: generated substitutes: ['compulsory', 'mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['compulsory', 'mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n",
      "complex_word_lemma for complex word 'compulsory': compulsory\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['forced', 'obliged', 'bureaucratic', 'statutory', 'mandatory', 'gradual', 'mandate', 'continuous', 'demanded', 'indispensable', 'relevant', 'necessary', 'vital', 'obligatory', 'lifelong', 'preferable', 'practicable', 'enforced', 'redundant', 'habitual', 'voluntary', 'plain', 'lax', 'required', 'routine', 'ministerial', 'strict', 'mandated', 'clandestine']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "SG step: generated substitutes: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n",
      "complex_word_lemma for complex word 'instilled': instill\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['assured', 'hit', 'thrilled', 'reassured', 'provided', 'gifted', 'implanted', 'endowed', 'infiltrated', 'injected', 'flooded', 'illed', 'infused', 'elevated', 'infected', 'pumped', 'inject', 'inst', 'insulated', 'penetrated', 'installed', 'vaccinated', 'filled', 'invested', 'sprinkled', 'impressed', 'stocked', 'revived', 'vested', 'stoked']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "SG step: generated substitutes: ['maniac', 'criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'fighters', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'killers', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['maniac', 'criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n",
      "complex_word_lemma for complex word 'maniacs': maniac\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['hunters', 'combatants', 'factions', 'killers', 'thugs', 'partisans', 'criminals', 'monsters', 'commanders', 'gunmen', 'mercenaries', 'troops', 'murderers', 'helmets', 'jihadists', 'squads', 'detainees', 'gangs', 'lords', 'chiefs', 'crimes', 'fascists', 'fighters', 'assassins', 'perpetrators', 'killings', 'militias']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "SG step: generated substitutes: ['observers', 'monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'observer', 'supervisors', 'analysts', 'operators', 'responders', 'observer', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['observers', 'monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'observer', 'supervisors', 'analysts', 'operators', 'responders', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n",
      "complex_word_lemma for complex word 'observers': observer\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'supervisors', 'analysts', 'operators', 'responders', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'supervisors', 'analysts', 'operators', 'responders', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['monitors', 'opponents', 'observations', 'participants', 'responders', 'witnesses', 'educators', 'visitors', 'investigators', 'dissidents', 'observed', 'bystanders', 'demonstrators', 'officials', 'reinforcements', 'followers', 'analysts', 'reporters', 'advisors', 'organizers', 'experts', 'supervisors', 'airstrikes', 'inspectors', 'observes', 'operators', 'outsiders']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "SG step: generated substitutes: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n",
      "complex_word_lemma for complex word 'shrapnel': shrapnel\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['explosive', 'sh', 'the', 'a', 'grenade', 'mortar', 'stray', 'rapnel', 'multiple', 'projectile', 'gunshots', 'gunshot', 'knife', 'gun', 'arrow', 'several', 'gunfire', 'stab', 'dagger', 'shotgun', 'spear', 'rifle', 'shell', 'shock', 'sniper', 'bullet', 'blaster', 'blast', 'unspecified', 'shot']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "SG step: generated substitutes: ['disguised', 'cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['disguised', 'cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n",
      "complex_word_lemma for complex word 'disguised': disguised\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['styled', 'armoured', 'clad', 'clothed', 'fitted', 'organised', 'framed', 'united', 'disgu', 'shrouded', 'adorned', 'veiled', 'formed', 'dressed', 'branded', 'concealed', 'posed', 'recognised', 'frightened', 'masked', 'wrapped', 'cloaked', 'dispersed', 'displayed', 'imprisoned', 'packaged', 'revealed', 'portrayed', 'disguise']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "SG step: generated substitutes: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n",
      "complex_word_lemma for complex word 'offshoot': offshoot\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['branch', 'incarnation', 'off', 'adaptation', 'undercut', 'arm', 'affiliated', 'ally', 'extension', 'offspring', 'embrace', 'outreach', 'affiliation', 'subset', 'adherent', 'outlet', 'acronym', 'adjunct', 'outline', 'example', 'insurgency', 'enclave', 'extremist', 'orthodoxy', 'outpost', 'affiliate', 'shoot', 'embryo', 'iteration']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "SG step: generated substitutes: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'musical', 'contemporary', 'formal', 'analytic']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'contemporary', 'formal', 'analytic']\n",
      "\n",
      "complex_word_lemma for complex word 'symphonic': symphonic\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'contemporary', 'formal', 'analytic']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'contemporary', 'formal', 'analytic']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['the', 'popular', '</s>', ',', 'modern', 'musical', 'instrumental', 'piano', 'general', 'and', 'contemporary', 'or', 'in', 'dramatic', 'analytic', 'vocal', 'onic', 'traditional', 'music', 'of', 'romantic', 'concert', 'sym', 'classical', 'theoretical', 'harmonic', 'historical', 'canonical', 'formal']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "SG step: generated substitutes: ['deploy', 'deployed', 'deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'deploying', 'deploy', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['deploy', 'deployed', 'deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'deploying', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n",
      "complex_word_lemma for complex word 'deploy': deploy\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['maneuver', 'launch', 'tether', 'employ', 'command', 'contract', 'withdraw', 'monitor', 'secure', 'use', 'deployment', 'operate', 'transport', 'ploy', 'move', 'send', 'deliver', 'construct', 'patrol', 'mobilize', 'recruit', 'disperse', 'combat', 'expend', 'dispatch', 'wield']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "SG step: generated substitutes: ['authorities', 'police', 'officials', 'authorities', 'authority', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'authorities', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['authorities', 'police', 'officials', 'authority', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n",
      "complex_word_lemma for complex word 'authorities': authority\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['police', 'officials', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['police', 'officials', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['colleagues', 'representatives', 'courts', 'bodies', 'forces', 'residents', 'investigators', 'officers', 'requirements', 'institutions', 'authors', 'officials', 'regimes', 'neighbours', 'employees', 'superiors', 'police', 'policemen', 'applications', 'governments', 'prosecutors', 'detainees', 'arrests', 'individuals', 'paramedics', 'regulators']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# instantiate a FitBert model\n",
    "fb_model = FitBert(lm_model)\n",
    "\n",
    "\n",
    "\n",
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"<mask>\")  # RoBERTa uses <mask> instead of [MASK]\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    tokenizer = fill_mask.tokenizer\n",
    "    sentences_concat = f\"{sentence} {tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes = [substitute[\"token_str\"].lower().lstrip() for substitute in result]   # and use .lstrip to remove the leading space, as Roberta tokenizes by default with a space in front of the word\n",
    "    print(f\"SG step: generated substitutes: {substitutes}\\n\")\n",
    "    \n",
    "    \n",
    "    # 2. Substitute Selection (SS):   \n",
    "    \n",
    "    # a) remove duplicates within the substitute list from the substitute list \n",
    "    \n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl:\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    print(f\"SS step: a) substitute list without duplicates: {substitutes_no_dupl}\\n\")\n",
    "\n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    print(f\"SS step: b) substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    print(f\"SS step: c): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # d) apply FITBERT to the list of substitutes\n",
    "    sentence_fitbert_masked = sentence_masked_word.replace(\"<mask>\", \"***mask***\")   # fitbert uses ***mask*** instead of [MASK] or <mask> \n",
    "    sentences_concat_fitbert = f\"{sentence} {tokenizer.sep_token} {sentence_fitbert_masked}\"\n",
    "    \n",
    "    ranked_substitutes = fb_model.rank(sentences_concat_fitbert, substitutes_no_dupl_complex_word_no_antonym)\n",
    "    print(f\"SS step: d) ranked substitutes using FitBert: {ranked_substitutes}\\n\")\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------------------')\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # limit the substitutes to the 10 first ones for evaluation\n",
    "    top_10_substitutes = ranked_substitutes[:10]\n",
    "    \n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + top_10_substitutes\n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the dataframe\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/RobertaLarge_SG_SS_abc_fb.tsv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056848ac-0668-41fd-b6b6-59d4f4120e82",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file ./predictions/trial/RobertaLarge_SG_SS_abc_fb.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4464f32-8d9a-40c9-ac81-9c5eae9ea7c8",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/RobertaLarge_SG_SS_abc_fb.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.3\n",
    "\n",
    "MAP@3 = 0.1166\n",
    "MAP@5 = 0.088\n",
    "MAP@10 = 0.053\n",
    "\n",
    "Potential@3 = 0.4\n",
    "Potential@5 = 0.4\n",
    "Potential@10 = 0.8\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1\n",
    "Accuracy@2@top_gold_1 = 0.1\n",
    "Accuracy@3@top_gold_1 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f3a61d8-2cfc-437a-a7de-e44f0d5586cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result: bad results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fe0e88-bb89-4a27-b668-72036c4abd28",
   "metadata": {},
   "source": [
    "#### Substitute Generation with RoBERTa-large, and Substitute Selection steps a-c, and the resulting list with contextualized embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69a0ff52-f8d3-43b4-b482-be631d39c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bba05efd-80b0-4e42-9b27-5742b22bc4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "SG step: generated substitutes: ['compulsory', 'mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['compulsory', 'mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n",
      "complex_word_lemma for complex word 'compulsory': compulsory\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-large were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked substitutes, based on cosine similarity scores in context: ['mandatory', 'required', 'necessary', 'voluntary', 'demanded', 'vital', 'forced', 'preferable', 'enforced', 'mandated', 'redundant', 'obliged', 'obligatory', 'indispensable', 'routine', 'strict', 'relevant', 'gradual', 'practicable', 'bureaucratic', 'lax', 'plain', 'statutory', 'continuous', 'habitual', 'clandestine', 'mandate', 'lifelong', 'ministerial']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "SG step: generated substitutes: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n",
      "complex_word_lemma for complex word 'instilled': instill\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-large were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked substitutes, based on cosine similarity scores in context: ['reassured', 'thrilled', 'revived', 'assured', 'impressed', 'filled', 'provided', 'flooded', 'hit', 'injected', 'infected', 'invested', 'gifted', 'pumped', 'stocked', 'elevated', 'infused', 'implanted', 'stoked', 'vested', 'endowed', 'vaccinated', 'infiltrated', 'insulated', 'sprinkled', 'penetrated', 'installed', 'inject', 'inst', 'illed']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "SG step: generated substitutes: ['maniac', 'criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'fighters', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'killers', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['maniac', 'criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n",
      "complex_word_lemma for complex word 'maniacs': maniac\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-large were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked substitutes, based on cosine similarity scores in context: ['criminals', 'troops', 'killers', 'crimes', 'fighters', 'perpetrators', 'lords', 'combatants', 'factions', 'squads', 'partisans', 'assassins', 'commanders', 'gangs', 'murderers', 'monsters', 'militias', 'helmets', 'killings', 'mercenaries', 'detainees', 'jihadists', 'hunters', 'thugs', 'chiefs', 'fascists', 'gunmen']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "SG step: generated substitutes: ['observers', 'monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'observer', 'supervisors', 'analysts', 'operators', 'responders', 'observer', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['observers', 'monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'observer', 'supervisors', 'analysts', 'operators', 'responders', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n",
      "complex_word_lemma for complex word 'observers': observer\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'supervisors', 'analysts', 'operators', 'responders', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'supervisors', 'analysts', 'operators', 'responders', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-large were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked substitutes, based on cosine similarity scores in context: ['monitors', 'demonstrators', 'visitors', 'experts', 'observations', 'witnesses', 'inspectors', 'opponents', 'investigators', 'advisors', 'airstrikes', 'participants', 'responders', 'reporters', 'reinforcements', 'bystanders', 'outsiders', 'followers', 'analysts', 'dissidents', 'officials', 'educators', 'organizers', 'operators', 'supervisors', 'observed', 'observes']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "SG step: generated substitutes: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n",
      "complex_word_lemma for complex word 'shrapnel': shrapnel\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-large were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked substitutes, based on cosine similarity scores in context: ['projectile', 'bullet', 'gunshot', 'shotgun', 'gunshots', 'multiple', 'unspecified', 'several', 'gunfire', 'dagger', 'sniper', 'mortar', 'shock', 'gun', 'the', 'rifle', 'knife', 'explosive', 'stab', 'arrow', 'shot', 'grenade', 'blast', 'stray', 'spear', 'shell', 'sh', 'rapnel', 'blaster', 'a']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "SG step: generated substitutes: ['disguised', 'cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['disguised', 'cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n",
      "complex_word_lemma for complex word 'disguised': disguised\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-large were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked substitutes, based on cosine similarity scores in context: ['dressed', 'masked', 'clad', 'adorned', 'clothed', 'cloaked', 'wrapped', 'shrouded', 'veiled', 'concealed', 'posed', 'formed', 'styled', 'dispersed', 'united', 'displayed', 'disguise', 'portrayed', 'framed', 'imprisoned', 'frightened', 'recognised', 'revealed', 'branded', 'organised', 'fitted', 'packaged', 'armoured', 'disgu']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "SG step: generated substitutes: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n",
      "complex_word_lemma for complex word 'offshoot': offshoot\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-large were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked substitutes, based on cosine similarity scores in context: ['affiliate', 'iteration', 'arm', 'extension', 'adherent', 'incarnation', 'ally', 'outpost', 'offspring', 'example', 'acronym', 'outlet', 'branch', 'adaptation', 'affiliation', 'embryo', 'embrace', 'orthodoxy', 'extremist', 'enclave', 'insurgency', 'adjunct', 'outline', 'off', 'outreach', 'subset', 'affiliated', 'undercut', 'shoot']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "SG step: generated substitutes: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'musical', 'contemporary', 'formal', 'analytic']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'contemporary', 'formal', 'analytic']\n",
      "\n",
      "complex_word_lemma for complex word 'symphonic': symphonic\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'contemporary', 'formal', 'analytic']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'contemporary', 'formal', 'analytic']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-large were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked substitutes, based on cosine similarity scores in context: ['musical', 'classical', 'music', 'popular', 'general', 'harmonic', 'modern', 'instrumental', 'traditional', 'formal', 'concert', 'canonical', 'contemporary', 'dramatic', 'romantic', 'the', 'vocal', 'historical', 'analytic', 'theoretical', 'piano', 'sym', 'of', 'onic', 'in', 'and', 'or', ',', '</s>']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "SG step: generated substitutes: ['deploy', 'deployed', 'deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'deploying', 'deploy', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['deploy', 'deployed', 'deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'deploying', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n",
      "complex_word_lemma for complex word 'deploy': deploy\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-large were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked substitutes, based on cosine similarity scores in context: ['send', 'use', 'operate', 'deliver', 'launch', 'construct', 'move', 'mobilize', 'employ', 'withdraw', 'contract', 'command', 'dispatch', 'patrol', 'secure', 'monitor', 'recruit', 'wield', 'transport', 'maneuver', 'expend', 'deployment', 'combat', 'disperse', 'ploy', 'tether']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "SG step: generated substitutes: ['authorities', 'police', 'officials', 'authorities', 'authority', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'authorities', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['authorities', 'police', 'officials', 'authority', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n",
      "complex_word_lemma for complex word 'authorities': authority\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['police', 'officials', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['police', 'officials', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-large were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked substitutes, based on cosine similarity scores in context: ['officials', 'police', 'prosecutors', 'courts', 'policemen', 'residents', 'investigators', 'detainees', 'governments', 'institutions', 'forces', 'regulators', 'officers', 'employees', 'representatives', 'paramedics', 'individuals', 'bodies', 'neighbours', 'regimes', 'arrests', 'colleagues', 'superiors', 'authors', 'applications', 'requirements']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculates similarity between the original sentence and the sentences with candidate substitutes that were retrieved in the SG step \n",
    "# creates a list with sentences with substitute words filled in (commented out for oversight purposes)\n",
    "\n",
    "\n",
    "def calculate_similarity_scores(sentence, sentence_with_substitutes):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\")\n",
    "    tf_model = TFAutoModel.from_pretrained(\"roberta-large\")\n",
    "\n",
    "    def embed_text(text):\n",
    "        tokens = tokenizer(text, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "        outputs = tf_model(**tokens)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        embeddings = tf.nn.l2_normalize(embeddings, axis=1)\n",
    "        return embeddings\n",
    "\n",
    "    original_sentence_embedding = embed_text(sentence)\n",
    "    substitute_sentence_embeddings = embed_text(sentence_with_substitutes)\n",
    "\n",
    "    cosine_similarity = np.inner(original_sentence_embedding, substitute_sentence_embeddings)\n",
    "    similarity_scores = cosine_similarity[0]\n",
    "\n",
    "    return similarity_scores\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"<mask>\")   # RoBERTa uses <mask> instead of [MASK]\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    tokenizer = fill_mask.tokenizer\n",
    "    sentences_concat = f\"{sentence} {tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes = [substitute[\"token_str\"].lower().lstrip() for substitute in result]   # and use .lstrip to remove the leading space, as Roberta tokenizes by default with a space in front of the word\n",
    "    print(f\"SG step: generated substitutes: {substitutes}\\n\")\n",
    "    \n",
    "    \n",
    "    # 2. Substitute Selection (SS):   \n",
    "    \n",
    "    # a) remove duplicates within the substitute list from the substitute list \n",
    "    \n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl:\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    print(f\"SS step: a) substitute list without duplicates: {substitutes_no_dupl}\\n\")\n",
    "\n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    print(f\"SS step: b) substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    print(f\"SS step: c): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "     \n",
    "    \n",
    "    # create sentence with the complex word replaced by the substitutes\n",
    "    sentence_with_substitutes = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym]\n",
    "    #print(f\"List with sentences where complex word is substituted: {sentence_with_substitutes}\\n\")\n",
    "    \n",
    "    \n",
    "    # d) calculate cosine similarity scores, and rank the substitutes based on their similarity score\n",
    "    similarity_scores = calculate_similarity_scores(sentence, sentence_with_substitutes)\n",
    "    #print(f\"Similarity scores: {similarity_scores}\\n\")\n",
    "    ranked_substitutes_withscores = sorted(zip(substitutes_no_dupl_complex_word_no_antonym, similarity_scores), key=lambda x: x[1], reverse=True)\n",
    "    #print(f\"SS step d) Ranked substitutes, including similarity scores in context: {ranked_substitutes}\\n\")\n",
    "    ranked_substitutes = [substitute for substitute, score in ranked_substitutes_withscores]\n",
    "    print(f\"Ranked substitutes, based on cosine similarity scores in context: {ranked_substitutes}\\n\")\n",
    "        \n",
    "    print('-----------------------------------------------------------------------------------------')\n",
    "    print()\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    # limit the substitutes to the 10 first ones for evaluation\n",
    "    top_10_substitutes = ranked_substitutes[:10]\n",
    "    \n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + top_10_substitutes\n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the dataframe\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/RobertaLarge_SG_SS_abc_ce.tsv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7831da8-d32f-4306-957c-67f0ac8f0433",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file ./predictions/trial/RobertaLarge_SG_SS_abc_ce.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e88e1a7-8da9-4da7-9334-6647c781fd93",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/RobertaLarge_SG_SS_abc_ce.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.5\n",
    "\n",
    "MAP@3 = 0.35\n",
    "MAP@5 = 0.226\n",
    "MAP@10 = 0.1378\n",
    "\n",
    "Potential@3 = 0.6\n",
    "Potential@5 = 0.7\n",
    "Potential@10 = 0.8\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.5\n",
    "Accuracy@2@top_gold_1 = 0.6\n",
    "Accuracy@3@top_gold_1 = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c6dfa0-a2ea-4c23-92e1-7c15ea78aa4b",
   "metadata": {},
   "source": [
    "results: MAP 3 5 and 10 slightly better than without this step (map1 the same), potential 3 and 5 slightly worse (pot 10 the same), accuracy 1 and 2 are better, 3 is same. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db604ffd-e9c7-4f41-a8da-92f598292792",
   "metadata": {},
   "source": [
    "#### Substitute Generation with RoBERTa-Large, and Substitute Selection steps a-c, and the resulting list with BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c552c17e-e34f-4278-852c-a3fa4b941f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert_score\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab9e6497-030b-4c74-9c1a-ed0f8f662aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "SG step: generated substitutes: ['compulsory', 'mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['compulsory', 'mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n",
      "complex_word_lemma for complex word 'compulsory': compulsory\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['mandatory', 'required', 'mandated', 'necessary', 'voluntary', 'enforced', 'obligatory', 'forced', 'preferable', 'vital', 'routine', 'demanded', 'indispensable', 'redundant', 'relevant', 'obliged', 'gradual', 'strict', 'practicable', 'bureaucratic', 'lax', 'statutory', 'continuous', 'plain', 'mandate', 'clandestine', 'habitual', 'ministerial', 'lifelong']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "SG step: generated substitutes: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n",
      "complex_word_lemma for complex word 'instilled': instill\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['infused', 'filled', 'injected', 'stoked', 'flooded', 'assured', 'provided', 'pumped', 'reassured', 'gifted', 'endowed', 'infected', 'revived', 'stocked', 'impressed', 'thrilled', 'hit', 'invested', 'sprinkled', 'infiltrated', 'elevated', 'penetrated', 'installed', 'vested', 'insulated', 'implanted', 'vaccinated', 'illed', 'inject', 'inst']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "SG step: generated substitutes: ['maniac', 'criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'fighters', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'killers', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['maniac', 'criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n",
      "complex_word_lemma for complex word 'maniacs': maniac\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['criminals', 'lords', 'troops', 'commanders', 'fighters', 'killers', 'crimes', 'chiefs', 'perpetrators', 'thugs', 'combatants', 'assassins', 'factions', 'gangs', 'killings', 'partisans', 'murderers', 'squads', 'monsters', 'militias', 'mercenaries', 'jihadists', 'gunmen', 'detainees', 'helmets', 'hunters', 'fascists']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "SG step: generated substitutes: ['observers', 'monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'observer', 'supervisors', 'analysts', 'operators', 'responders', 'observer', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['observers', 'monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'observer', 'supervisors', 'analysts', 'operators', 'responders', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n",
      "complex_word_lemma for complex word 'observers': observer\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'supervisors', 'analysts', 'operators', 'responders', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'supervisors', 'analysts', 'operators', 'responders', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['monitors', 'inspectors', 'investigators', 'responders', 'advisors', 'experts', 'observations', 'reporters', 'witnesses', 'officials', 'opponents', 'analysts', 'educators', 'dissidents', 'participants', 'visitors', 'outsiders', 'reinforcements', 'bystanders', 'demonstrators', 'operators', 'followers', 'airstrikes', 'organizers', 'observed', 'supervisors', 'observes']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "SG step: generated substitutes: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n",
      "complex_word_lemma for complex word 'shrapnel': shrapnel\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['bullet', 'stab', 'gunshot', 'projectile', 'knife', 'gunfire', 'multiple', 'blast', 'several', 'sniper', 'gun', 'mortar', 'dagger', 'gunshots', 'shell', 'grenade', 'shotgun', 'shot', 'explosive', 'unspecified', 'rifle', 'arrow', 'shock', 'spear', 'the', 'stray', 'rapnel', 'blaster', 'sh', 'a']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "SG step: generated substitutes: ['disguised', 'cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['disguised', 'cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n",
      "complex_word_lemma for complex word 'disguised': disguised\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['masked', 'concealed', 'clothed', 'cloaked', 'dressed', 'clad', 'veiled', 'shrouded', 'adorned', 'wrapped', 'posed', 'styled', 'formed', 'portrayed', 'displayed', 'united', 'dispersed', 'fitted', 'organised', 'disguise', 'branded', 'imprisoned', 'framed', 'recognised', 'revealed', 'frightened', 'packaged', 'armoured', 'disgu']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "SG step: generated substitutes: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n",
      "complex_word_lemma for complex word 'offshoot': offshoot\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['extension', 'affiliate', 'arm', 'offspring', 'iteration', 'incarnation', 'outpost', 'adaptation', 'ally', 'branch', 'adjunct', 'embryo', 'adherent', 'affiliation', 'acronym', 'enclave', 'embrace', 'example', 'outlet', 'extremist', 'orthodoxy', 'outline', 'off', 'subset', 'affiliated', 'insurgency', 'outreach', 'shoot', 'undercut']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "SG step: generated substitutes: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'musical', 'contemporary', 'formal', 'analytic']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'contemporary', 'formal', 'analytic']\n",
      "\n",
      "complex_word_lemma for complex word 'symphonic': symphonic\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'contemporary', 'formal', 'analytic']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'contemporary', 'formal', 'analytic']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['classical', 'musical', 'dramatic', 'harmonic', 'formal', 'concert', 'contemporary', 'instrumental', 'music', 'general', 'popular', 'modern', 'traditional', 'historical', 'canonical', 'romantic', 'theoretical', 'the', 'analytic', 'onic', 'piano', 'of', 'vocal', 'in', 'or', 'and', 'sym', ',', '</s>']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "SG step: generated substitutes: ['deploy', 'deployed', 'deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'deploying', 'deploy', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['deploy', 'deployed', 'deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'deploying', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n",
      "complex_word_lemma for complex word 'deploy': deploy\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['mobilize', 'dispatch', 'employ', 'use', 'launch', 'operate', 'send', 'deliver', 'command', 'construct', 'secure', 'contract', 'patrol', 'transport', 'recruit', 'move', 'maneuver', 'wield', 'expend', 'monitor', 'disperse', 'withdraw', 'deployment', 'combat', 'ploy', 'tether']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "SG step: generated substitutes: ['authorities', 'police', 'officials', 'authorities', 'authority', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'authorities', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['authorities', 'police', 'officials', 'authority', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n",
      "complex_word_lemma for complex word 'authorities': authority\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['police', 'officials', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['police', 'officials', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['police', 'officials', 'investigators', 'prosecutors', 'policemen', 'courts', 'residents', 'forces', 'detainees', 'governments', 'officers', 'regulators', 'institutions', 'neighbours', 'representatives', 'regimes', 'employees', 'individuals', 'paramedics', 'colleagues', 'bodies', 'superiors', 'authors', 'arrests', 'applications', 'requirements']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"<mask>\")    # RoBERTa uses <mask> instead of [MASK]\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    tokenizer = fill_mask.tokenizer\n",
    "    sentences_concat = f\"{sentence} {tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes = [substitute[\"token_str\"].lower().lstrip() for substitute in result]   # and use .lstrip to remove the leading space, as Roberta tokenizes by default with a space in front of the word\n",
    "    print(f\"SG step: generated substitutes: {substitutes}\\n\")\n",
    "    \n",
    "    \n",
    "    # 2. Substitute Selection (SS):   \n",
    "    \n",
    "    # a) remove duplicates within the substitute list from the substitute list \n",
    "    \n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl:\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    print(f\"SS step: a) substitute list without duplicates: {substitutes_no_dupl}\\n\")\n",
    "\n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    print(f\"SS step: b) substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    print(f\"SS step: c): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "    \n",
    "    \n",
    "    # create sentences with the complex word replaced by the substitutes\n",
    "    sentences_with_substitutes = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym]\n",
    "    #print(f\"SG step: sentences with substitutes: {sentences_with_substitutes}\\n\")\n",
    "    \n",
    "          \n",
    "    # d) use BERTScore for sorting\n",
    "    scores = bert_score.score([sentence]*len(sentences_with_substitutes), sentences_with_substitutes, lang=\"en\", model_type='roberta-large', verbose=False)\n",
    "    ranked_substitutes = [substitute for _, substitute in sorted(zip(scores[0].tolist(), substitutes_no_dupl_complex_word_no_antonym), reverse=True)]\n",
    "    print(f\"SS step: d) substitute list sorted by descending BERTScore: {ranked_substitutes}\\n\")\n",
    "\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------------------')\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # limit the substitutes to the 10 first ones for evaluation\n",
    "    top_10_substitutes = ranked_substitutes[:10]\n",
    "    \n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + top_10_substitutes\n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the dataframe\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/RobertaLarge_SG_SS_abc_bs.tsv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b344c10-9cb6-4b97-bf0b-9042d427cda7",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file ./predictions/trial/RobertaLarge_SG_SS_abc_bs.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63e44041-e0f0-4522-9570-4100f857fe19",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/RobertaLarge_SG_SS_abc_bs.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.5\n",
    "\n",
    "MAP@3 = 0.3277\n",
    "MAP@5 = 0.2556\n",
    "MAP@10 = 0.1499\n",
    "\n",
    "Potential@3 = 0.7\n",
    "Potential@5 = 0.7\n",
    "Potential@10 = 0.9\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.3\n",
    "Accuracy@2@top_gold_1 = 0.6\n",
    "Accuracy@3@top_gold_1 = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175a9e0c-e307-4a9e-ba91-2382ebe5bd21",
   "metadata": {},
   "source": [
    "comparable (some worse, some better) with regular embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61398c6-5a81-4294-99ee-773ad567fb43",
   "metadata": {},
   "source": [
    "### Conclusion so far"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f98fc-0e7b-41c8-a303-01a02ab42cd7",
   "metadata": {},
   "source": [
    "SS Step a, b, c for both Roberta models: keep them in Subs.Selection method as they do help a bit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b80ed2-275c-4de2-914d-09332d1b2e10",
   "metadata": {},
   "source": [
    "SS Step FitBERT: remove, due to low scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e681874-061c-4525-a1dd-36a5ec38ace1",
   "metadata": {},
   "source": [
    "SS Step context. emb and Bertscore: keep in Subs selection, but differences are subtile and not always better "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dee9fb-0ddc-4f00-b02b-4a0bba247322",
   "metadata": {},
   "source": [
    "Best performing on MAP@1: RobertaBase_SG_SS_abc_ce (see below)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a17d982c-9b53-4412-b26a-e741685f0618",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/RobertaBase_SG_SS_abc_ce.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.6\n",
    "\n",
    "MAP@3 = 0.2999\n",
    "MAP@5 = 0.2369\n",
    "MAP@10 = 0.1501\n",
    "\n",
    "Potential@3 = 0.6\n",
    "Potential@5 = 0.7\n",
    "Potential@10 = 0.9\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.2\n",
    "Accuracy@2@top_gold_1 = 0.3\n",
    "Accuracy@3@top_gold_1 = 0.4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
