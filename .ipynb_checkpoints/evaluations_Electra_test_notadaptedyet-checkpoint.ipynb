{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0085fb59-3709-4063-b22e-73a011dbb414",
   "metadata": {},
   "source": [
    "#### Evaluations for Electra for the test set (373 sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5683d06d-2380-4e93-bd91-fa8787d8f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# read the tsv file\n",
    "filename = \"./data/test/tsar2022_en_test_none_no_noise.tsv\"\n",
    "data = pd.read_csv(filename, sep='\\t', header=None, names=[\"sentence\", \"complex_word\"])\n",
    "\n",
    "# create an empty dataframe to store the top-10 substitutes for evaluation\n",
    "substitutes_df = pd.DataFrame(columns=[\"sentence\", \"complex_word\"] + [f\"substitute_{i+1}\" for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ca8ccf-1610-4639-9442-7f0cb211dc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc147290-d88e-4c2b-94bc-9e21f266759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code below is used for morphological adjustments in step MA\n",
    "from nltk.corpus import wordnet as wn\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46dbbc20-f729-4e8e-82bf-67373cba2f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code below is used when word embeddings are used in step SS\n",
    "from transformers import TFAutoModel\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15c75960-7777-4ac2-a607-15725beaedf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code below is used when Bertscore is used in step SS \n",
    "import bert_score\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0527d02f-e481-4940-ace4-3f3b81786576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the display.max_rows option to None to display all rows instead of limiting it to 50 \n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffa3af3-857e-4db9-99b4-38c34eff6a23",
   "metadata": {},
   "source": [
    "#### Electra-base-generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6f19cfd-81d2-4e7a-b664-c070d9df5d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tokenizer and the model\n",
    "lm_tokenizer = AutoTokenizer.from_pretrained(\"google/electra-base-generator\")\n",
    "lm_model = AutoModelForMaskedLM.from_pretrained(\"google/electra-base-generator\")\n",
    "\n",
    "\n",
    "# Instantiate the fill-mask pipeline with the ELECTRA model\n",
    "fill_mask = pipeline(\"fill-mask\", lm_model, tokenizer = lm_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0727fad-27a5-4bd5-bbbe-247db133f613",
   "metadata": {},
   "source": [
    "#### Substitute Generation and Morphological Adaptation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a039b4f1-3fff-4647-9327-188e9d861160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: prototype\n",
      "top-10 substitutes SG and MA: ['model', 'precursor', 'designer', 'dummy', 'pilot', 'catalyst', 'forerunner', 'nucleus', 'candidate', 'design']\n",
      "\n",
      "Complex word: authoritarian\n",
      "top-10 substitutes SG and MA: ['aggressive', 'powerful', 'conservative', 'independent', 'popular', 'corrupt', 'competitive', 'democratic', 'confident', 'violent']\n",
      "\n",
      "Complex word: collision\n",
      "top-10 substitutes SG and MA: ['crash', 'accident', 'incident', 'wreck', 'disaster', 'impact', 'encounter', 'event', 'attack', 'tragedy']\n",
      "\n",
      "Complex word: pupates\n",
      "top-10 substitutes SG and MA: ['lives', 'emerges', 'dies', 'feeds', 'grows', 'remains', 'burrows', 'survives', 'leaves', 'hides']\n",
      "\n",
      "Complex word: discontent\n",
      "top-10 substitutes SG and MA: ['dissatisfaction', 'unrest', 'anger', 'revolt', 'resentment', 'uncertainty', 'rebellion', 'confusion', 'agitation', 'frustration']\n",
      "\n",
      "Complex word: decomposes\n",
      "top-10 substitutes SG and MA: ['reacts', 'converts', 'changes', 'binds', 'transforms', 'turns', 'responds', 'bonds', 'acts', 'expands']\n",
      "\n",
      "Complex word: descent\n",
      "top-10 substitutes SG and MA: ['ascent', 'flight', 'takeoff', 'descend', 'climb', 'descending', 'landing', 'jump', 'journey', 'fall']\n",
      "\n",
      "Complex word: sectarian\n",
      "top-10 substitutes SG and MA: ['ethnic', 'religious', 'sect', 'these', 'tribal', 'those', 'regional', 'communal', 'racial', 'two']\n",
      "\n",
      "Complex word: sectarian\n",
      "top-10 substitutes SG and MA: ['religious', 'political', 'ethnic', 'ideological', 'economic', 'communal', 'social', 'cultural', 'regional', 'military']\n",
      "\n",
      "Complex word: offshoot\n",
      "top-10 substitutes SG and MA: ['ally', 'affiliate', 'opponent', 'enemy', 'alliance', 'associate', 'arm', 'antagonist', 'element', 'umbrella']\n",
      "\n",
      "Complex word: decree\n",
      "top-10 substitutes SG and MA: ['order', 'proclamation', 'edict', 'law', 'decision', 'request', 'ordinance', 'consent', 'vote', 'fiat']\n",
      "\n",
      "Complex word: detonating\n",
      "top-10 substitutes SG and MA: ['triggering', 'exploding', 'hitting', 'destroying', 'damaging', 'dropping', 'firing', 'delivering', 'creating', 'producing']\n",
      "\n",
      "Complex word: deficit\n",
      "top-10 substitutes SG and MA: ['surplus', 'gap', 'figure', 'increase', 'debt', 'balance', 'budget', 'spending', 'growth', 'reduction']\n",
      "\n",
      "Complex word: canopy\n",
      "top-10 substitutes SG and MA: ['roof', 'window', 'curtain', 'seat', 'blanket', 'bridge', 'door', 'hood', 'shield', 'flap']\n",
      "\n",
      "Complex word: condolences\n",
      "top-10 substitutes SG and MA: ['apologies', 'sympathy', 'support', 'gratitude', 'concern', 'thanks', 'prayers', 'apology', 'appreciation', 'wishes']\n",
      "\n",
      "Complex word: benchmark\n",
      "top-10 substitutes SG and MA: ['the', 'new', 'all', 'existing', 'current', 'key', 'most', 'some', 'cheap', 'standard']\n",
      "\n",
      "Complex word: auspicious\n",
      "top-10 substitutes SG and MA: ['special', 'all', 'many', 'rare', 'romantic', 'ceremonial', 'these', 'specific', 'religious', 'certain']\n",
      "\n",
      "Complex word: suspiciously\n",
      "top-10 substitutes SG and MA: ['strangely', 'aggressively', 'curiously', 'seriously', 'closely', 'badly', 'suspicious', 'casually', 'fairly', 'well']\n",
      "\n",
      "Complex word: established\n",
      "top-10 substitutes SG and MA: ['existing', 'new', 'old', 'official', 'local', 'establishment', 'original', 'proposed', 'open', 'initial']\n",
      "\n",
      "Complex word: scrutiny\n",
      "top-10 substitutes SG and MA: ['review', 'oversight', 'inspection', 'consideration', 'investigation', 'attention', 'examination', 'testing', 'questioning', 'surveillance']\n",
      "\n",
      "Complex word: regime\n",
      "top-10 substitutes SG and MA: ['government', 'rule', 'policies', 'administration', 'overthrow', 'dictatorship', 'plan', 'actions', 'position', 'leadership']\n",
      "\n",
      "Complex word: snipers\n",
      "top-10 substitutes SG and MA: ['tanks', 'soldiers', 'helicopters', 'guards', 'police', 'insurgents', 'bombs', 'rockets', 'guns', 'gunmen']\n",
      "\n",
      "Complex word: precautions\n",
      "top-10 substitutes SG and MA: ['caution', 'risks', 'responsibility', 'care', 'action', 'warnings', 'measures', 'it', 'advice', 'risk']\n",
      "\n",
      "Complex word: systemic\n",
      "top-10 substitutes SG and MA: ['institutional', 'regional', 'local', 'wholesale', 'chain', 'chronic', 'global', 'retail', 'generic', 'central']\n",
      "\n",
      "Complex word: anchored\n",
      "top-10 substitutes SG and MA: ['docked', 'sunk', 'caught', 'launched', 'towed', 'held', 'bound', 'grounded', 'tied', 'located']\n",
      "\n",
      "Complex word: accolade\n",
      "top-10 substitutes SG and MA: ['award', 'honor', 'opportunity', 'honour', 'awards', 'event', 'invitation', 'achievement', 'endowment', 'order']\n",
      "\n",
      "Complex word: uprising\n",
      "top-10 substitutes SG and MA: ['rebellion', 'revolt', 'revolution', 'insurrection', 'conflict', 'crisis', 'mutiny', 'insurgency', 'resistance', 'war']\n",
      "\n",
      "Complex word: offender\n",
      "top-10 substitutes SG and MA: ['officer', 'inmate', 'individual', 'employee', 'offense', 'offence', 'attacker', 'adult', 'accused', 'intruder']\n",
      "\n",
      "Complex word: bulging\n",
      "top-10 substitutes SG and MA: ['swelling', 'bursting', 'filled', 'filling', 'flush', 'struggling', 'exploding', 'flooding', 'complete', 'loaded']\n",
      "\n",
      "Complex word: encodes\n",
      "top-10 substitutes SG and MA: ['contains', 'binds', 'stores', 'represents', 'carries', 'produces', 'comprises', 'includes', 'has', 'expresses']\n",
      "\n",
      "Complex word: mythological\n",
      "top-10 substitutes SG and MA: ['mythical', 'fictional', 'historical', 'mythology', 'human', 'cartoon', 'supernatural', 'title', 'epic', 'model']\n",
      "\n",
      "Complex word: romanized\n",
      "top-10 substitutes SG and MA: ['uses', 'translated', 'translates', 'named', 'explains', 'classified', 'converts', 'traces', 'mixes', 'used']\n",
      "\n",
      "Complex word: residences\n",
      "top-10 substitutes SG and MA: ['homes', 'dwellings', 'houses', 'households', 'housing', 'apartments', 'residents', 'home', 'neighborhoods', 'residential']\n",
      "\n",
      "Complex word: ringleaders\n",
      "top-10 substitutes SG and MA: ['men', 'others', 'members', 'victims', 'officers', 'crew', 'four', 'five', 'suspects', 'recruits']\n",
      "\n",
      "Complex word: compound\n",
      "top-10 substitutes SG and MA: ['complex', 'building', 'facility', 'base', 'headquarters', 'residence', 'stadium', 'property', 'house', 'mansion']\n",
      "\n",
      "Complex word: pre-positioned\n",
      "top-10 substitutes SG and MA: ['positioned', 'placed', 'deployed', 'located', 'mounted', 'situated', 'sited', 'hidden', 'stationed', 'concealed']\n",
      "\n",
      "Complex word: exclusion\n",
      "top-10 substitutes SG and MA: ['disqualification', 'removal', 'departure', 'expulsion', 'withdrawal', 'absence', 'exemption', 'interference', 'excluded', 'inclusion']\n",
      "\n",
      "Complex word: recognized\n",
      "top-10 substitutes SG and MA: ['accepted', 'honored', 'acknowledged', 'known', 'recognised', 'certified', 'considered', 'respected', 'treated', 'celebrated']\n",
      "\n",
      "Complex word: toxins\n",
      "top-10 substitutes SG and MA: ['chemicals', 'bacteria', 'viruses', 'parasites', 'poison', 'pollution', 'diseases', 'venom', 'dust', 'substances']\n",
      "\n",
      "Complex word: nominated\n",
      "top-10 substitutes SG and MA: ['shortlisted', 'selected', 'honored', 'chosen', 'awarded', 'presented', 'accepted', 'named', 'recognized', 'finalist']\n",
      "\n",
      "Complex word: unprecedented\n",
      "top-10 substitutes SG and MA: ['extraordinary', 'extensive', 'outrageous', 'enormous', 'ongoing', 'aggressive', 'incredible', 'excessive', 'international', 'absolute']\n",
      "\n",
      "Complex word: erring\n",
      "top-10 substitutes SG and MA: ['fleeing', 'remaining', 'other', 'pursuing', 'retreating', 'advancing', 'returning', 'departing', 'invading', 'approaching']\n",
      "\n",
      "Complex word: monsters\n",
      "top-10 substitutes SG and MA: ['zombies', 'dragons', 'mutants', 'humans', 'creatures', 'beasts', 'giants', 'demons', 'heroes', 'vampires']\n",
      "\n",
      "Complex word: detainees\n",
      "top-10 substitutes SG and MA: ['prisoners', 'people', 'inmates', 'captives', 'those', 'prisoner', 'soldiers', 'individuals', 'hostages', 'students']\n",
      "\n",
      "Complex word: harassing\n",
      "top-10 substitutes SG and MA: ['killing', 'attacking', 'kidnapping', 'insulting', 'aiding', 'shooting', 'targeting', 'murdering', 'beating', 'poisoning']\n",
      "\n",
      "Complex word: conflicting\n",
      "top-10 substitutes SG and MA: ['no', 'mixed', 'also', 'insufficient', 'strong', 'little', 'inconsistent', 'contradictory', 'not', 'more']\n",
      "\n",
      "Complex word: announced\n",
      "top-10 substitutes SG and MA: ['confirmed', 'declared', 'reported', 'proclaimed', 'disclosed', 'acknowledged', 'revealed', 'celebrated', 'stated', 'pronounced']\n",
      "\n",
      "Complex word: cementing\n",
      "top-10 substitutes SG and MA: ['securing', 'ending', 'extending', 'signing', 'completing', 'including', 'restoring', 'announcing', 'promising', 'sealing']\n",
      "\n",
      "Complex word: unleashing\n",
      "top-10 substitutes SG and MA: ['using', 'employing', 'recruiting', 'revealing', 'sending', 'targeting', 'feeding', 'developing', 'exposing', 'pursuing']\n",
      "\n",
      "Complex word: scrutiny\n",
      "top-10 substitutes SG and MA: ['examination', 'attention', 'review', 'consideration', 'inspection', 'investigation', 'analysis', 'criticism', 'questioning', 'evaluation']\n",
      "\n",
      "Complex word: suspiciously\n",
      "top-10 substitutes SG and MA: ['aggressively', 'seriously', 'suspicious', 'strangely', 'menacing', 'badly', 'casually', 'closely', 'curiously', 'remotely']\n",
      "\n",
      "Complex word: originated\n",
      "top-10 substitutes SG and MA: ['started', 'began', 'evolved', 'came', 'developed', 'arose', 'grew', 'starts', 'was', 'arrived']\n",
      "\n",
      "Complex word: replica\n",
      "top-10 substitutes SG and MA: ['replacement', 'duplicate', 'restoration', 'design', 'reproduction', 'sculptor', 'redesign', 'model', 'reconstruction', 'sculpture']\n",
      "\n",
      "Complex word: discredits\n",
      "top-10 substitutes SG and MA: ['hurts', 'insults', 'attacks', 'ignores', 'exploits', 'damages', 'abuses', 'influences', 'affects', 'shocks']\n",
      "\n",
      "Complex word: vicious\n",
      "top-10 substitutes SG and MA: ['brutal', 'violent', 'bloody', 'murderous', 'ruthless', 'savage', 'destructive', 'deadly', 'devastating', 'nasty']\n",
      "\n",
      "Complex word: strained\n",
      "top-10 substitutes SG and MA: ['complicated', 'weakened', 'hampered', 'worsened', 'troubled', 'aggravated', 'damaged', 'strengthened', 'hurt', 'interrupted']\n",
      "\n",
      "Complex word: enacted\n",
      "top-10 substitutes SG and MA: ['implemented', 'conducted', 'initiated', 'performed', 'made', 'instituted', 'completed', 'undertaken', 'signed', 'passed']\n",
      "\n",
      "Complex word: primed\n",
      "top-10 substitutes SG and MA: ['infected', 'injected', 'hungry', 'trained', 'target', 'trapped', 'exposed', 'wild', 'captured', 'targeted']\n",
      "\n",
      "Complex word: probe\n",
      "top-10 substitutes SG and MA: ['investigation', 'inquiry', 'look', 'search', 'dig', 'review', 'way', 'peek', 'study', 'trial']\n",
      "\n",
      "Complex word: aviator\n",
      "top-10 substitutes SG and MA: ['officer', 'engineer', 'ensign', 'instructor', 'astronaut', 'admiral', 'pilot', 'american', 'lieutenant', 'agent']\n",
      "\n",
      "Complex word: acquiring\n",
      "top-10 substitutes SG and MA: ['purchasing', 'obtaining', 'receiving', 'gaining', 'buying', 'getting', 'losing', 'acquisition', 'additional', 'retaining']\n",
      "\n",
      "Complex word: restive\n",
      "top-10 substitutes SG and MA: ['northern', 'southern', 'eastern', 'western', 'northwestern', 'central', 'northeastern', 'southwestern', 'neighboring', 'north']\n",
      "\n",
      "Complex word: repression\n",
      "top-10 substitutes SG and MA: ['persecution', 'torture', 'oppression', 'detention', 'harassment', 'exploitation', 'imprisonment', 'treatment', 'abuses', 'suppression']\n",
      "\n",
      "Complex word: vulnerability\n",
      "top-10 substitutes SG and MA: ['risk', 'vulnerable', 'threat', 'sensitivity', 'trauma', 'isolation', 'exposure', 'resistance', 'complexity', 'strength']\n",
      "\n",
      "Complex word: equipment\n",
      "top-10 substitutes SG and MA: ['apparatus', 'tools', 'instruments', 'materials', 'instrumentation', 'hardware', 'devices', 'technology', 'systems', 'techniques']\n",
      "\n",
      "Complex word: stemming\n",
      "top-10 substitutes SG and MA: ['arising', 'resulting', 'originating', 'emerging', 'drawn', 'rising', 'coming', 'generated', 'derived', 'raised']\n",
      "\n",
      "Complex word: existence\n",
      "top-10 substitutes SG and MA: ['presence', 'formation', 'occurrence', 'absence', 'disappearance', 'discovery', 'nature', 'emergence', 'creation', 'possibility']\n",
      "\n",
      "Complex word: adequate\n",
      "top-10 substitutes SG and MA: ['sufficient', 'appropriate', 'enough', 'proper', 'necessary', 'effective', 'good', 'any', 'satisfactory', 'credible']\n",
      "\n",
      "Complex word: genuinely\n",
      "top-10 substitutes SG and MA: ['truly', 'really', 'actually', 'sincerely', 'absolutely', 'clearly', 'definitely', 'also', 'obviously', 'simply']\n",
      "\n",
      "Complex word: proportion\n",
      "top-10 substitutes SG and MA: ['percentage', 'number', 'amount', 'population', 'majority', 'ratio', 'portion', 'share', 'level', 'numbers']\n",
      "\n",
      "Complex word: motive\n",
      "top-10 substitutes SG and MA: ['reason', 'date', 'cause', 'motivation', 'source', 'location', 'reasons', 'time', 'timing', 'purpose']\n",
      "\n",
      "Complex word: determination\n",
      "top-10 substitutes SG and MA: ['decision', 'ability', 'efforts', 'failure', 'commitment', 'willingness', 'resolve', 'readiness', 'decisions', 'refusal']\n",
      "\n",
      "Complex word: bloodshed\n",
      "top-10 substitutes SG and MA: ['fighting', 'process', 'crisis', 'plan', 'violence', 'effort', 'conflict', 'war', 'action', 'dialogue']\n",
      "\n",
      "Complex word: credibility\n",
      "top-10 substitutes SG and MA: ['confidence', 'legitimacy', 'credible', 'transparency', 'reputation', 'courage', 'competence', 'authenticity', 'trust', 'prestige']\n",
      "\n",
      "Complex word: exclusion\n",
      "top-10 substitutes SG and MA: ['inclusion', 'removal', 'limitation', 'exemption', 'eligibility', 'restriction', 'departure', 'elimination', 'entry', 'exception']\n",
      "\n",
      "Complex word: craven\n",
      "top-10 substitutes SG and MA: ['reckless', 'bad', 'disturbing', 'dangerous', 'failing', 'damaging', 'boring', 'irritating', 'evil', 'savage']\n",
      "\n",
      "Complex word: usher\n",
      "top-10 substitutes SG and MA: ['bring', 'ushered', 'lead', 'enter', 'put', 'result', 'call', 'assist', 'act', 'invest']\n",
      "\n",
      "Complex word: anonymity\n",
      "top-10 substitutes SG and MA: ['condition', 'comment', 'privacy', 'release', 'court', 'calm', 'security', 'silence', 'safety', 'anonymous']\n",
      "\n",
      "Complex word: emerged\n",
      "top-10 substitutes SG and MA: ['arose', 'came', 'returned', 'appeared', 'escaped', 'awoke', 'jumped', 'ran', 'walked', 'stepped']\n",
      "\n",
      "Complex word: indignation\n",
      "top-10 substitutes SG and MA: ['anger', 'solidarity', 'protest', 'frustration', 'support', 'defiance', 'concern', 'sympathy', 'discontent', 'resistance']\n",
      "\n",
      "Complex word: re-enacting\n",
      "top-10 substitutes SG and MA: ['ending', 'discussing', 'performing', 'publishing', 'executing', 'presenting', 'doing', 'staging', 'continuing', 'airing']\n",
      "\n",
      "Complex word: detained\n",
      "top-10 substitutes SG and MA: ['held', 'imprisoned', 'jailed', 'living', 'hiding', 'staying', 'missing', 'stranded', 'trapped', 'arrested']\n",
      "\n",
      "Complex word: diplomatic\n",
      "top-10 substitutes SG and MA: ['political', 'possible', 'peaceful', 'negotiated', 'military', 'formal', 'permanent', 'peace', 'trade', 'direct']\n",
      "\n",
      "Complex word: troublemakers\n",
      "top-10 substitutes SG and MA: ['politicians', 'criminals', 'people', 'friends', 'terrorists', 'stupid', 'honest', 'not', 'rich', 'corrupt']\n",
      "\n",
      "Complex word: abdomen\n",
      "top-10 substitutes SG and MA: ['belly', 'stomach', 'chest', 'body', 'torso', 'legs', 'breasts', 'face', 'head', 'arms']\n",
      "\n",
      "Complex word: pursuit\n",
      "top-10 substitutes SG and MA: ['stalking', 'hunting', 'seeking', 'hunt', 'chase', 'search', 'chasing', 'exploration', 'activity', 'pursuing']\n",
      "\n",
      "Complex word: inclusion\n",
      "top-10 substitutes SG and MA: ['participation', 'exclusion', 'presence', 'entry', 'acceptance', 'addition', 'placement', 'selection', 'use', 'incorporation']\n",
      "\n",
      "Complex word: acquire\n",
      "top-10 substitutes SG and MA: ['purchase', 'buy', 'sell', 'get', 'acquisition', 'obtain', 'use', 'offer', 'own', 'take']\n",
      "\n",
      "Complex word: confidential\n",
      "top-10 substitutes SG and MA: ['released', 'published', 'final', 'disclosed', 'classified', 'secret', 'closed', 'anonymous', 'available', 'complete']\n",
      "\n",
      "Complex word: attentively\n",
      "top-10 substitutes SG and MA: ['carefully', 'also', 'first', 'always', 'clearly', 'thoroughly', 'only', 'properly', 'immediately', 'then']\n",
      "\n",
      "Complex word: bombardment\n",
      "top-10 substitutes SG and MA: ['attacks', 'fighting', 'offensive', 'attack', 'operations', 'raids', 'operation', 'clashes', 'assault', 'harassment']\n",
      "\n",
      "Complex word: colonies\n",
      "top-10 substitutes SG and MA: ['species', 'populations', 'specimens', 'plantations', 'remnants', 'settlements', 'nests', 'forests', 'communities', 'islands']\n",
      "\n",
      "Complex word: partially\n",
      "top-10 substitutes SG and MA: ['partly', 'completely', 'fully', 'also', 'further', 'totally', 'temporarily', 'slightly', 'not', 'severely']\n",
      "\n",
      "Complex word: segregation\n",
      "top-10 substitutes SG and MA: ['discrimination', 'division', 'integration', 'detention', 'separation', 'segregated', 'censorship', 'education', 'union', 'hearing']\n",
      "\n",
      "Complex word: residence\n",
      "top-10 substitutes SG and MA: ['house', 'home', 'building', 'apartment', 'mansion', 'dwelling', 'office', 'room', 'property', 'household']\n",
      "\n",
      "Complex word: sanctions\n",
      "top-10 substitutes SG and MA: ['-', 'says', 'inspectors', 'resolutions', 'rules', 'insists', 'condemnation', 'penalties', 'monitors', 'pressure']\n",
      "\n",
      "Complex word: threatened\n",
      "top-10 substitutes SG and MA: ['attacked', 'harassed', 'assaulted', 'battered', 'raped', 'violated', 'stalked', 'targeted', 'vulnerable', 'compromised']\n",
      "\n",
      "Complex word: intimidate\n",
      "top-10 substitutes SG and MA: ['manipulate', 'undermine', 'influence', 'provoke', 'disrupt', 'silence', 'sabotage', 'infiltrate', 'isolate', 'attack']\n",
      "\n",
      "Complex word: sought\n",
      "top-10 substitutes SG and MA: ['won', 'requested', 'claimed', 'for', 'obtained', 'demanded', 'received', 'gained', 'took', 'contested']\n",
      "\n",
      "Complex word: bureau\n",
      "top-10 substitutes SG and MA: ['government', 'bureaucracy', 'agency', 'party', 'committee', 'department', 'system', 'board', 'program', 'organization']\n",
      "\n",
      "Complex word: anonymity\n",
      "top-10 substitutes SG and MA: ['comment', 'condition', 'privacy', 'security', 'release', 'silence', 'confidential', 'court', 'calm', 'such']\n",
      "\n",
      "Complex word: acclaimed\n",
      "top-10 substitutes SG and MA: ['praised', 'lauded', 'respected', 'promoted', 'acknowledged', 'revered', 'appointed', 'recognized', 'considered', 'elected']\n",
      "\n",
      "Complex word: enquiries\n",
      "top-10 substitutes SG and MA: ['investigation', 'investigations', 'inquiries', 'charges', 'questioning', 'inquiry', 'trial', 'prosecution', 'appeal', 'discovery']\n",
      "\n",
      "Complex word: commissioned\n",
      "top-10 substitutes SG and MA: ['ordered', 'asked', 'instructed', 'sent', 'commanded', 'directed', 'inspired', 'appointed', 'called', 'ordained']\n",
      "\n",
      "Complex word: scrapped\n",
      "top-10 substitutes SG and MA: ['cancelled', 'abandoned', 'rejected', 'canceled', 'approved', 'removed', 'postponed', 'dropped', 'replaced', 'eliminated']\n",
      "\n",
      "Complex word: successive\n",
      "top-10 substitutes SG and MA: ['consecutive', 'subsequent', 'separate', 'different', 'more', 'other', 'previous', 'additional', 'such', 'straight']\n",
      "\n",
      "Complex word: degenerate\n",
      "top-10 substitutes SG and MA: ['turn', 'evolve', 'develop', 'transform', 'lead', 'grow', 'spiral', 'explode', 'descend', 'fall']\n",
      "\n",
      "Complex word: offender\n",
      "top-10 substitutes SG and MA: ['inmate', 'officer', 'attacker', 'offence', 'offense', 'adult', 'arrest', 'intruder', 'enemy', 'individual']\n",
      "\n",
      "Complex word: touted\n",
      "top-10 substitutes SG and MA: ['praised', 'cited', 'criticized', 'denounced', 'repeated', 'mentioned', 'questioned', 'lauded', 'defended', 'mocked']\n",
      "\n",
      "Complex word: anonymity\n",
      "top-10 substitutes SG and MA: ['comment', 'condition', 'privacy', 'security', 'secrecy', 'release', 'calm', 'unknown', 'silence', 'such']\n",
      "\n",
      "Complex word: purifying\n",
      "top-10 substitutes SG and MA: ['changing', 'transforming', 'cleansing', 'destroying', 'controlling', 'preserving', 'altering', 'killing', 'influencing', 'protecting']\n",
      "\n",
      "Complex word: announced\n",
      "top-10 substitutes SG and MA: ['said', 'confirmed', 'revealed', 'reported', 'stated', 'disclosed', 'admitted', 'declared', 'indicated', 'finalized']\n",
      "\n",
      "Complex word: residing\n",
      "top-10 substitutes SG and MA: ['living', 'present', 'working', 'located', 'employed', 'incorporated', 'together', 'alone', 'lived', 'active']\n",
      "\n",
      "Complex word: plundering\n",
      "top-10 substitutes SG and MA: ['destroying', 'looting', 'stealing', 'selling', 'burning', 'damaging', 'removing', 'shipping', 'burying', 'seizing']\n",
      "\n",
      "Complex word: clemency\n",
      "top-10 substitutes SG and MA: ['immunity', 'it', 'bail', 'citizenship', 'asylum', 'amnesty', 'detention', 'that', 'residency', 'consent']\n",
      "\n",
      "Complex word: enduring\n",
      "top-10 substitutes SG and MA: ['lasting', 'sustained', 'persistent', 'continued', 'timeless', 'compelling', 'intrinsic', 'ongoing', 'striking', 'lifetime']\n",
      "\n",
      "Complex word: sanctuary\n",
      "top-10 substitutes SG and MA: ['refuge', 'shelter', 'haven', 'place', 'paradise', 'home', 'mecca', 'prison', 'space', 'habitat']\n",
      "\n",
      "Complex word: demonstrations\n",
      "top-10 substitutes SG and MA: ['rallies', 'protests', 'rally', 'marches', 'protest', 'events', 'movements', 'gatherings', 'parties', 'movement']\n",
      "\n",
      "Complex word: allege\n",
      "top-10 substitutes SG and MA: ['admit', 'commit', 'deny', 'investigate', 'condemn', 'advocate', 'acknowledge', 'report', 'oppose', 'accuse']\n",
      "\n",
      "Complex word: unsanctioned\n",
      "top-10 substitutes SG and MA: ['impromptu', 'illegal', 'unarmed', 'organized', 'open', 'opposition', 'unauthorized', 'emergency', 'unsuccessful', 'outdoor']\n",
      "\n",
      "Complex word: bloodshed\n",
      "top-10 substitutes SG and MA: ['violence', 'war', 'slaughter', 'carnage', 'deaths', 'unrest', 'conflict', 'killings', 'fighting', 'massacre']\n",
      "\n",
      "Complex word: adversary\n",
      "top-10 substitutes SG and MA: ['opponent', 'enemy', 'ally', 'attacker', 'opposition', 'agent', 'outsider', 'antagonist', 'intruder', 'individual']\n",
      "\n",
      "Complex word: alleged\n",
      "top-10 substitutes SG and MA: ['suspected', 'the', 'widespread', 'illegal', 'attempted', 'potential', 'possible', 'fake', 'reported', 'official']\n",
      "\n",
      "Complex word: enigmatic\n",
      "top-10 substitutes SG and MA: ['enigma', 'cryptic', 'ambiguous', 'elegant', 'mysterious', 'obscure', 'elusive', 'distant', 'unmarked', 'eccentric']\n",
      "\n",
      "Complex word: renderings\n",
      "top-10 substitutes SG and MA: ['rendering', 'images', 'drawings', 'render', 'the', 'views', '3d', 'versions', 'an', 'depictions']\n",
      "\n",
      "Complex word: warily\n",
      "top-10 substitutes SG and MA: ['enthusiastically', 'warmly', 'also', 'openly', 'strongly', 'generally', 'cautiously', 'clearly', 'initially', 'pointedly']\n",
      "\n",
      "Complex word: evaluated\n",
      "top-10 substitutes SG and MA: ['tested', 'assessed', 'treated', 'monitored', 'examined', 'considered', 'hospitalized', 'inspected', 'arrested', 'investigated']\n",
      "\n",
      "Complex word: nobility\n",
      "top-10 substitutes SG and MA: ['nobles', 'gentry', 'aristocracy', 'peasants', 'people', 'inhabitants', 'populace', 'citizens', 'wealthy', 'clergy']\n",
      "\n",
      "Complex word: surpassed\n",
      "top-10 substitutes SG and MA: ['exceeded', 'matched', 'followed', 'broken', 'met', 'preceded', 'and', 'topped', 'achieved', 'but']\n",
      "\n",
      "Complex word: asserted\n",
      "top-10 substitutes SG and MA: ['claimed', 'denied', 'proclaimed', 'affirmed', 'questioned', 'defended', 'demonstrated', 'challenged', 'assumed', 'stated']\n",
      "\n",
      "Complex word: colonies\n",
      "top-10 substitutes SG and MA: ['them', 'colonists', 'cells', 'it', 'eggs', 'us', 'these', 'populations', 'one', 'plants']\n",
      "\n",
      "Complex word: erupted\n",
      "top-10 substitutes SG and MA: ['began', 'escalated', 'started', 'flared', 'ensued', 'raged', 'intensified', 'arose', 'occurred', 'continued']\n",
      "\n",
      "Complex word: deployed\n",
      "top-10 substitutes SG and MA: ['mobilized', 'dispatched', 'recruited', 'sent', 'employed', 'hired', 'provided', 'used', 'assigned', 'enlisted']\n",
      "\n",
      "Complex word: militiamen\n",
      "top-10 substitutes SG and MA: ['gunmen', 'men', 'militia', 'bandits', 'militants', 'soldiers', 'insurgents', 'rebels', 'militias', 'police']\n",
      "\n",
      "Complex word: carnage\n",
      "top-10 substitutes SG and MA: ['violence', 'slaughter', 'chaos', 'misery', 'mayhem', 'devastation', 'catastrophe', 'destruction', 'outrage', 'war']\n",
      "\n",
      "Complex word: stint\n",
      "top-10 substitutes SG and MA: ['time', 'experience', 'stay', 'appearance', 'arrest', 'outing', 'year', 'trial', 'career', 'week']\n",
      "\n",
      "Complex word: repossessed\n",
      "top-10 substitutes SG and MA: ['their', 'the', 'distressed', 'rental', 'such', 'private', 'public', 'mortgage', 'investment', 'new']\n",
      "\n",
      "Complex word: investigating\n",
      "top-10 substitutes SG and MA: ['probing', 'examining', 'in', 'suspects', 'on', 'after', 'studying', 'following', 'regarding', 'and']\n",
      "\n",
      "Complex word: atrocities\n",
      "top-10 substitutes SG and MA: ['crimes', 'genocide', 'horrors', 'abuses', 'murders', 'wars', 'acts', 'attacks', 'killings', 'actions']\n",
      "\n",
      "Complex word: underlying\n",
      "top-10 substitutes SG and MA: ['actual', 'core', 'overall', 'current', 'real', 'fundamental', 'prevailing', 'base', 'intrinsic', 'implied']\n",
      "\n",
      "Complex word: introduced\n",
      "top-10 substitutes SG and MA: ['reintroduced', 'released', 'exported', 'added', 'sold', 'brought', 'imported', 'transferred', 'admitted', 'adopted']\n",
      "\n",
      "Complex word: adamantly\n",
      "top-10 substitutes SG and MA: ['strongly', 'also', 'openly', 'bitterly', 'firmly', 'fiercely', 'directly', 'explicitly', 'specifically', 'personally']\n",
      "\n",
      "Complex word: candidacy\n",
      "top-10 substitutes SG and MA: ['campaign', 'candidate', 'nomination', 'candidates', 'race', 'platform', 'party', 'nominee', 'administration', 'presidency']\n",
      "\n",
      "Complex word: disputed\n",
      "top-10 substitutes SG and MA: ['contested', 'claimed', 'asserted', 'claims', 'denied', 'challenged', 'sought', 'held', 'claim', 'questioned']\n",
      "\n",
      "Complex word: auctioneers\n",
      "top-10 substitutes SG and MA: ['dealers', 'sellers', 'buyers', 'collectors', 'galleries', 'specialists', 'owners', 'producers', 'hunters', 'enthusiasts']\n",
      "\n",
      "Complex word: bloodshed\n",
      "top-10 substitutes SG and MA: ['violence', 'fighting', 'slaughter', 'carnage', 'looting', 'riots', 'killings', 'killing', 'bleeding', 'riot']\n",
      "\n",
      "Complex word: relinquish\n",
      "top-10 substitutes SG and MA: ['leave', 'use', 'clear', 'defend', 'exercise', 'regain', 'occupy', 'raise', 'balance', 'maintain']\n",
      "\n",
      "Complex word: indicating\n",
      "top-10 substitutes SG and MA: ['saying', 'stating', 'and', 'explaining', 'warning', 'suggesting', 'claiming', 'confirming', 'announcing', 'asking']\n",
      "\n",
      "Complex word: organisers\n",
      "top-10 substitutes SG and MA: ['organizers', 'also', 'team', 'has', 'workers', 'holders', 'officials', 'crew', 'had', 'promoters']\n",
      "\n",
      "Complex word: clearance\n",
      "top-10 substitutes SG and MA: ['approval', 'permission', 'authorization', 'certification', 'permit', 'acceptance', 'removal', 'entry', 'registration', 'security']\n",
      "\n",
      "Complex word: sympathy\n",
      "top-10 substitutes SG and MA: ['solidarity', 'support', 'empathy', 'compassion', 'relief', 'concern', 'respect', 'help', 'gratitude', 'pity']\n",
      "\n",
      "Complex word: composition\n",
      "top-10 substitutes SG and MA: ['music', 'instrument', 'piece', 'material', 'song', 'melody', 'work', 'image', 'arrangement', 'structure']\n",
      "\n",
      "Complex word: sanctions\n",
      "top-10 substitutes SG and MA: ['penalties', 'restrictions', 'measures', 'pressure', 'punishments', 'pressures', 'tariffs', 'rules', 'punishment', 'incentives']\n",
      "\n",
      "Complex word: executed\n",
      "top-10 substitutes SG and MA: ['hanged', 'killed', 'arrested', 'beheaded', 'assassinated', 'murdered', 'jailed', 'imprisoned', 'released', 'convicted']\n",
      "\n",
      "Complex word: flashpoint\n",
      "top-10 substitutes SG and MA: ['the', 'remote', 'target', 'large', 'isolated', 'small', 'mission', 'observation', 'field', 'strategic']\n",
      "\n",
      "Complex word: assumption\n",
      "top-10 substitutes SG and MA: ['hypothesis', 'expectation', 'belief', 'guess', 'idea', 'prediction', 'impression', 'claim', 'assessment', 'observation']\n",
      "\n",
      "Complex word: apparent\n",
      "top-10 substitutes SG and MA: ['obvious', 'actual', 'explicit', 'alleged', 'unspecified', 'unidentified', 'angry', 'additional', 'evident', 'identified']\n",
      "\n",
      "Complex word: appealed\n",
      "top-10 substitutes SG and MA: ['called', 'asked', 'arranged', 'pressed', 'applied', 'pleaded', 'petitioned', 'refused', 'requested', 'lobbied']\n",
      "\n",
      "Complex word: casualties\n",
      "top-10 substitutes SG and MA: ['fatalities', 'deaths', 'losses', 'injuries', 'victims', 'wounded', 'dead', 'injured', 'survivors', 'killed']\n",
      "\n",
      "Complex word: qualify\n",
      "top-10 substitutes SG and MA: ['compete', 'play', 'sign', 'qualified', 'prepare', 'register', 'pitch', 'train', 'apply', 'form']\n",
      "\n",
      "Complex word: acquisition\n",
      "top-10 substitutes SG and MA: ['deal', 'transaction', 'purchase', 'agreement', 'merger', 'project', 'company', 'offer', 'move', 'venture']\n",
      "\n",
      "Complex word: pedestal\n",
      "top-10 substitutes SG and MA: ['platform', 'mount', 'bench', 'stand', 'altar', 'plate', 'stage', 'scale', 'shelf', 'row']\n",
      "\n",
      "Complex word: sustained\n",
      "top-10 substitutes SG and MA: ['strong', 'persistent', 'severe', 'intense', 'prolonged', 'frequent', 'heavy', 'serious', 'active', 'recent']\n",
      "\n",
      "Complex word: prevailing\n",
      "top-10 substitutes SG and MA: ['participating', 'dominant', 'prevalent', 'living', 'present', 'reigning', 'working', 'winning', 'engaging', 'staying']\n",
      "\n",
      "Complex word: imposing\n",
      "top-10 substitutes SG and MA: ['enforcing', 'placing', 'creating', 'putting', 'forcing', 'establishing', 'asserting', 'applying', 'projecting', 'setting']\n",
      "\n",
      "Complex word: Initially\n",
      "top-10 substitutes SG and MA: ['originally', 'previously', 'first', 'subsequently', 'later', 'eventually', 'recently', 'traditionally', 'briefly', 'currently']\n",
      "\n",
      "Complex word: regime\n",
      "top-10 substitutes SG and MA: ['government', 'people', 'authorities', 'state', 'president', 'opposition', 'population', 'leadership', 'side', 'leader']\n",
      "\n",
      "Complex word: dominated\n",
      "top-10 substitutes SG and MA: ['controlled', 'ruled', 'led', 'governed', 'supported', 'backed', 'run', 'occupied', 'owned', 'represented']\n",
      "\n",
      "Complex word: authorized\n",
      "top-10 substitutes SG and MA: ['allowed', 'empowered', 'ordered', 'permitted', 'requested', 'authorised', 'approved', 'required', 'directed', 'sanctioned']\n",
      "\n",
      "Complex word: slated\n",
      "top-10 substitutes SG and MA: ['scheduled', 'likely', 'expected', 'going', 'about', 'due', 'planning', 'set', 'supposed', 'planned']\n",
      "\n",
      "Complex word: regrettable\n",
      "top-10 substitutes SG and MA: ['unfortunate', 'terrible', 'major', 'tragic', 'very', 'serious', 'horrible', 'costly', 'critical', 'great']\n",
      "\n",
      "Complex word: regime\n",
      "top-10 substitutes SG and MA: ['government', 'security', 'police', 'military', 'opposition', 'junta', 'the', 'local', 'army', 'paramilitary']\n",
      "\n",
      "Complex word: demonstrations\n",
      "top-10 substitutes SG and MA: ['protests', 'rallies', 'marches', 'events', 'disturbances', 'results', 'clashes', 'elections', 'speeches', 'riots']\n",
      "\n",
      "Complex word: summonsed\n",
      "top-10 substitutes SG and MA: ['summoned', 'ordered', 'scheduled', 'allowed', 'called', 'appointed', 'asked', 'confirmed', 'invited', 'requested']\n",
      "\n",
      "Complex word: sentiment\n",
      "top-10 substitutes SG and MA: ['rhetoric', 'anger', 'feelings', 'protest', 'resentment', 'reaction', 'feeling', 'attitudes', 'opinion', 'mood']\n",
      "\n",
      "Complex word: surveillance\n",
      "top-10 substitutes SG and MA: ['spy', 'spying', 'monitoring', 'observation', 'interrogation', 'reconnaissance', 'control', 'fishing', 'patrol', 'investigative']\n",
      "\n",
      "Complex word: preliminary\n",
      "top-10 substitutes SG and MA: ['the', 'final', 'initial', 'provisional', 'official', 'unofficial', 'partial', 'interim', 'mixed', 'new']\n",
      "\n",
      "Complex word: plethora\n",
      "top-10 substitutes SG and MA: ['variety', 'number', 'range', 'multitude', 'host', 'wealth', 'myriad', 'series', 'suite', 'selection']\n",
      "\n",
      "Complex word: implemented\n",
      "top-10 substitutes SG and MA: ['enforced', 'adopted', 'enacted', 'executed', 'applied', 'approved', 'implementation', 'achieved', 'finalized', 'negotiated']\n",
      "\n",
      "Complex word: concentration\n",
      "top-10 substitutes SG and MA: ['location', 'quantity', 'disposition', 'variety', 'density', 'placement', 'number', 'level', 'intensity', 'disposal']\n",
      "\n",
      "Complex word: controversial\n",
      "top-10 substitutes SG and MA: ['contentious', 'problematic', 'conservative', 'unpopular', 'interesting', 'taboo', 'political', 'debated', 'popular', 'provocative']\n",
      "\n",
      "Complex word: acquisition\n",
      "top-10 substitutes SG and MA: ['transaction', 'purchase', 'deal', 'sale', 'merger', 'takeover', 'agreement', 'contract', 'project', 'auction']\n",
      "\n",
      "Complex word: outlining\n",
      "top-10 substitutes SG and MA: ['on', 'explaining', 'about', 'defining', 'detailing', 'for', 'regarding', 'describing', 'supporting', 'discussing']\n",
      "\n",
      "Complex word: approximately\n",
      "top-10 substitutes SG and MA: ['about', 'roughly', 'some', 'nearly', 'located', 'almost', 'around', 'over', 'just', 'only']\n",
      "\n",
      "Complex word: pinnacle\n",
      "top-10 substitutes SG and MA: ['peak', 'summit', 'highest', 'top', 'apex', 'high', 'maximum', 'tallest', 'spire', 'low']\n",
      "\n",
      "Complex word: uprising\n",
      "top-10 substitutes SG and MA: ['rebellion', 'revolt', 'insurrection', 'fighting', 'violence', 'insurgency', 'protests', 'conflict', 'offensive', 'unrest']\n",
      "\n",
      "Complex word: overt\n",
      "top-10 substitutes SG and MA: ['inappropriate', 'excessive', 'indirect', 'awkward', 'over', 'improper', 'extreme', 'short', 'uneven', 'accidental']\n",
      "\n",
      "Complex word: probe\n",
      "top-10 substitutes SG and MA: ['investigation', 'inquiry', 'look', 'search', 'dig', 'way', 'review', 'peek', 'study', 'research']\n",
      "\n",
      "Complex word: herald\n",
      "top-10 substitutes SG and MA: ['promote', 'announce', 'see', 'represent', 'witness', 'celebrate', 'forge', 'predict', 'signal', 'propose']\n",
      "\n",
      "Complex word: disgraceful\n",
      "top-10 substitutes SG and MA: ['humiliating', 'unacceptable', 'dangerous', 'rude', 'foolish', 'bad', 'unsafe', 'improper', 'impossible', 'ridiculous']\n",
      "\n",
      "Complex word: ominous\n",
      "top-10 substitutes SG and MA: ['vague', 'cryptic', 'strange', 'disturbing', 'ambiguous', 'urgent', 'false', 'sinister', 'concerned', 'suspicious']\n",
      "\n",
      "Complex word: indication\n",
      "top-10 substitutes SG and MA: ['indicator', 'assertion', 'explanation', 'evidence', 'assurance', 'indicating', 'idea', 'sign', 'admission', 'announcement']\n",
      "\n",
      "Complex word: attributed\n",
      "top-10 substitutes SG and MA: ['credited', 'cited', 'ascribed', 'claimed', 'reported', 'noted', 'attested', 'blamed', 'given', 'described']\n",
      "\n",
      "Complex word: impeachment\n",
      "top-10 substitutes SG and MA: ['removal', 'resignation', 'confirmation', 'prosecution', 'nomination', 'execution', 'selection', 'election', 'pardon', 'murder']\n",
      "\n",
      "Complex word: infamous\n",
      "top-10 substitutes SG and MA: ['notorious', 'famous', 'common', 'notable', 'prominent', 'controversial', 'extreme', 'outrageous', 'powerful', 'serious']\n",
      "\n",
      "Complex word: annul\n",
      "top-10 substitutes SG and MA: ['amend', 'approve', 'review', 'cancel', 'announce', 'confirm', 'observe', 'modify', 'verify', 'monitor']\n",
      "\n",
      "Complex word: disassociate\n",
      "top-10 substitutes SG and MA: ['separate', 'distance', 'distinguish', 'isolate', 'differentiate', 'remove', 'protect', 'exclude', 'conceal', 'distract']\n",
      "\n",
      "Complex word: electoral\n",
      "top-10 substitutes SG and MA: ['election', 'political', 'democratic', 'such', 'presidential', 'national', 'voter', 'economic', 'legislative', 'voting']\n",
      "\n",
      "Complex word: emissions\n",
      "top-10 substitutes SG and MA: ['levels', 'concentrations', 'footprints', 'outputs', 'constituents', 'reductions', 'effects', 'counterparts', 'gases', 'results']\n",
      "\n",
      "Complex word: eligibility\n",
      "top-10 substitutes SG and MA: ['qualifying', 'entry', 'applications', 'eligible', 'acceptance', 'application', 'qualification', 'enrollment', 'funding', 'applying']\n",
      "\n",
      "Complex word: bombardment\n",
      "top-10 substitutes SG and MA: ['attack', 'raid', 'bombing', 'blast', 'fighting', 'incident', 'attacks', 'explosion', 'explosions', 'blasts']\n",
      "\n",
      "Complex word: crippling\n",
      "top-10 substitutes SG and MA: ['getting', 'the', 'its', 'many', 'more', 'some', 'massive', 'other', 'further', 'devastating']\n",
      "\n",
      "Complex word: regime\n",
      "top-10 substitutes SG and MA: ['administration', 'government', 'rule', 'junta', 'dictatorship', 'cabinet', 'leadership', 'rulers', 'army', 'authorities']\n",
      "\n",
      "Complex word: mandated\n",
      "top-10 substitutes SG and MA: ['approved', 'authorized', 'introduced', 'enacted', 'proposed', 'announced', 'required', 'recommended', 'requested', 'passed']\n",
      "\n",
      "Complex word: rendition\n",
      "top-10 substitutes SG and MA: ['version', 'interpretation', 'portrayal', 'rendering', 'representation', 'performance', 'depiction', 'treatment', 'portrait', 'imitation']\n",
      "\n",
      "Complex word: morph\n",
      "top-10 substitutes SG and MA: ['plunge', 'turn', 'spiral', 'develop', 'move', 'descend', 'evolve', 'fade', 'explode', 'tap']\n",
      "\n",
      "Complex word: authorized\n",
      "top-10 substitutes SG and MA: ['allowed', 'authorised', 'permitted', 'able', 'required', 'invited', 'available', 'licensed', 'requested', 'willing']\n",
      "\n",
      "Complex word: internship\n",
      "top-10 substitutes SG and MA: ['intern', 'application', 'assignment', 'interview', 'opportunity', 'apprenticeship', 'experience', 'employment', 'audition', 'extension']\n",
      "\n",
      "Complex word: tragedy\n",
      "top-10 substitutes SG and MA: ['disaster', 'catastrophe', 'crisis', 'miracle', 'panic', 'war', 'storm', 'loss', 'death', 'earthquake']\n",
      "\n",
      "Complex word: monitoring\n",
      "top-10 substitutes SG and MA: ['investigating', 'watching', 'observing', 'reviewing', 'checking', 'inspecting', 'assessing', 'examining', 'studying', 'tracking']\n",
      "\n",
      "Complex word: provisioning\n",
      "top-10 substitutes SG and MA: ['delivery', 'financial', 'management', 'payment', 'banking', 'financing', 'distribution', 'service', 'expansion', 'services']\n",
      "\n",
      "Complex word: downplayed\n",
      "top-10 substitutes SG and MA: ['maintained', 'challenged', 'played', 'defended', 'taken', 'upheld', 'ignored', 'retained', 'exploited', 'had']\n",
      "\n",
      "Complex word: tragedy\n",
      "top-10 substitutes SG and MA: ['disaster', 'catastrophe', 'loss', 'event', 'crisis', 'drama', 'story', 'problem', 'crime', 'incident']\n",
      "\n",
      "Complex word: authoritarian\n",
      "top-10 substitutes SG and MA: ['aggressive', 'powerful', 'conservative', 'independent', 'democratic', 'popular', 'corrupt', 'violent', 'competitive', 'political']\n",
      "\n",
      "Complex word: prohibits\n",
      "top-10 substitutes SG and MA: ['outlaws', 'prevents', 'bars', 'allows', 'permits', 'regulates', 'protects', 'limits', 'blocks', 'controls']\n",
      "\n",
      "Complex word: prevailing\n",
      "top-10 substitutes SG and MA: ['participating', 'dominant', 'prevalent', 'living', 'present', 'working', 'reigning', 'winning', 'engaging', 'staying']\n",
      "\n",
      "Complex word: skittish\n",
      "top-10 substitutes SG and MA: ['arrogant', 'selfish', 'bald', 'determined', 'reckless', 'reserved', 'stupid', 'humble', 'angry', 'shy']\n",
      "\n",
      "Complex word: obliged\n",
      "top-10 substitutes SG and MA: ['asked', 'ordered', 'allowed', 'forced', 'requested', 'authorised', 'instructed', 'required', 'urged', 'advised']\n",
      "\n",
      "Complex word: ouster\n",
      "top-10 substitutes SG and MA: ['overthrow', 'removal', 'return', 'resignation', 'downfall', 'fall', 'arrest', 'capture', 'dismissal', 'release']\n",
      "\n",
      "Complex word: mainstream\n",
      "top-10 substitutes SG and MA: ['more', 'global', 'widespread', 'international', 'major', 'its', 'some', 'full', 'significant', 'worldwide']\n",
      "\n",
      "Complex word: appealing\n",
      "top-10 substitutes SG and MA: ['asking', 'waiting', 'looking', 'searching', 'calling', 'pushing', 'pressing', 'begging', 'demanding', 'seeking']\n",
      "\n",
      "Complex word: surveillance\n",
      "top-10 substitutes SG and MA: ['spy', 'security', 'monitoring', 'control', 'reconnaissance', 'intelligence', 'observation', 'patrol', 'interrogation', 'guard']\n",
      "\n",
      "Complex word: cooperated\n",
      "top-10 substitutes SG and MA: ['collaborated', 'worked', 'participated', 'agreed', 'engaged', 'assisted', 'operated', 'partnered', 'reported', 'continued']\n",
      "\n",
      "Complex word: sought\n",
      "top-10 substitutes SG and MA: ['requested', 'received', 'demanded', 'gotten', 'offered', 'wanted', 'needed', 'obtained', 'refused', 'taken']\n",
      "\n",
      "Complex word: debris\n",
      "top-10 substitutes SG and MA: ['rubble', 'trash', 'wreckage', 'material', 'garbage', 'dirt', 'junk', 'dust', 'waste', 'wood']\n",
      "\n",
      "Complex word: sanctions\n",
      "top-10 substitutes SG and MA: ['penalties', 'measures', 'punishments', 'resolutions', 'condemnation', 'punishment', 'charges', 'fines', 'tariffs', 'strikes']\n",
      "\n",
      "Complex word: acquisition\n",
      "top-10 substitutes SG and MA: ['purchase', 'deal', 'transaction', 'agreement', 'merger', 'takeover', 'offer', 'announcement', 'investment', 'move']\n",
      "\n",
      "Complex word: pledges\n",
      "top-10 substitutes SG and MA: ['promises', 'guarantees', 'includes', 'provides', 'establishes', 'builds', 'supports', 'states', 'confirms', 'offers']\n",
      "\n",
      "Complex word: debris\n",
      "top-10 substitutes SG and MA: ['wreckage', 'rubble', 'body', 'material', 'trash', 'object', 'matter', 'waste', 'garbage', 'dust']\n",
      "\n",
      "Complex word: suspicious\n",
      "top-10 substitutes SG and MA: ['wary', 'aware', 'fearful', 'frightened', 'afraid', 'skeptical', 'suspected', 'cautious', 'suspect', 'conscious']\n",
      "\n",
      "Complex word: condolences\n",
      "top-10 substitutes SG and MA: ['messages', 'pleas', 'message', 'prayers', 'sympathy', 'calls', 'orders', 'apologies', 'requests', 'complaints']\n",
      "\n",
      "Complex word: impeach\n",
      "Error occurred: list indices must be integers or slices, not str\n",
      "top-10 substitutes SG and MA: []\n",
      "\n",
      "Complex word: unleashed\n",
      "top-10 substitutes SG and MA: ['created', 'triggered', 'initiated', 'ignited', 'launched', 'induced', 'sparked', 'brought', 'spawned', 'provoked']\n",
      "\n",
      "Complex word: inaugural\n",
      "top-10 substitutes SG and MA: ['first', 'second', 'founding', 'senior', 'fourth', 'last', 'third', 'final', 'youngest', 'next']\n",
      "\n",
      "Complex word: ongoing\n",
      "top-10 substitutes SG and MA: ['internal', 'important', 'increasing', 'enormous', 'intense', 'acute', 'open', 'immediate', 'urgent', 'interesting']\n",
      "\n",
      "Complex word: hostility\n",
      "top-10 substitutes SG and MA: ['suspicion', 'skepticism', 'distrust', 'hatred', 'resentment', 'bitterness', 'anger', 'opposition', 'concern', 'violence']\n",
      "\n",
      "Complex word: incurred\n",
      "top-10 substitutes SG and MA: ['suffered', 'involved', 'caused', 'brought', 'generated', 'paid', 'cost', 'inflicted', 'posed', 'created']\n",
      "\n",
      "Complex word: quelled\n",
      "top-10 substitutes SG and MA: ['suppressed', 'started', 'stopped', 'halted', 'resumed', 'intensified', 'continued', 'launched', 'dispersed', 'subdued']\n",
      "\n",
      "Complex word: detained\n",
      "top-10 substitutes SG and MA: ['arrested', 'tortured', 'jailed', 'imprisoned', 'released', 'deported', 'killed', 'executed', 'robbed', 'captured']\n",
      "\n",
      "Complex word: insurgents\n",
      "top-10 substitutes SG and MA: ['militants', 'rebels', 'fighters', 'guerrillas', 'groups', 'residents', 'leaders', 'refugees', 'militias', 'forces']\n",
      "\n",
      "Complex word: distinct\n",
      "top-10 substitutes SG and MA: ['distinctive', 'unique', 'striking', 'characteristic', 'expressive', 'particular', 'signature', 'artistic', 'simple', 'classic']\n",
      "\n",
      "Complex word: defected\n",
      "top-10 substitutes SG and MA: ['fled', 'returned', 'escaped', 'resigned', 'died', 'surrendered', 'left', 'disappeared', 'fallen', 'retired']\n",
      "\n",
      "Complex word: critically\n",
      "top-10 substitutes SG and MA: ['seriously', 'gravely', 'severely', 'very', 'extremely', 'deeply', 'profoundly', 'still', 'physically', 'dangerously']\n",
      "\n",
      "Complex word: authorities\n",
      "top-10 substitutes SG and MA: ['officials', 'sources', 'police', 'staff', 'officers', 'prosecutors', 'investigators', 'agents', 'guards', 'personnel']\n",
      "\n",
      "Complex word: regime\n",
      "top-10 substitutes SG and MA: ['government', 'administration', 'dictatorship', 'army', 'rule', 'leadership', 'ou', 'junta', 'forces', 'party']\n",
      "\n",
      "Complex word: envisions\n",
      "top-10 substitutes SG and MA: ['allows', 'proposes', 'supports', 'plans', 'permits', 'extends', 'advocates', 'offers', 'opposes', 'guarantees']\n",
      "\n",
      "Complex word: estimate\n",
      "top-10 substitutes SG and MA: ['figure', 'estimation', 'average', 'forecast', 'number', 'assessment', 'rate', 'count', 'one', 'total']\n",
      "\n",
      "Complex word: significance\n",
      "top-10 substitutes SG and MA: ['importance', 'meaning', 'symbolism', 'impact', 'context', 'magnitude', 'relevance', 'implications', 'value', 'timing']\n",
      "\n",
      "Complex word: neighbouring\n",
      "top-10 substitutes SG and MA: ['neighboring', 'both', 'northern', 'southern', 'nearby', 'central', 'between', 'eastern', 'western', 'the']\n",
      "\n",
      "Complex word: insurgents\n",
      "top-10 substitutes SG and MA: ['rebels', 'militants', 'insurgency', 'afghanistan', 'taliban', 'civilians', 'terrorists', 'iraq', 'isis', 'convoys']\n",
      "\n",
      "Complex word: clemency\n",
      "top-10 substitutes SG and MA: ['amnesty', 'him', 'it', 'immunity', 'citizenship', 'them', 'probation', 'privilege', 'service', 'merit']\n",
      "\n",
      "Complex word: authorities\n",
      "top-10 substitutes SG and MA: ['they', 'officials', 'police', 'prosecutors', 'deputies', 'officers', 'investigators', 'residents', 'witnesses', 'sheriff']\n",
      "\n",
      "Complex word: obscene\n",
      "top-10 substitutes SG and MA: ['offensive', 'inappropriate', 'vulgar', 'insulting', 'pornographic', 'abusive', 'provocative', 'inflammatory', 'ridiculous', 'foul']\n",
      "\n",
      "Complex word: bespoke\n",
      "top-10 substitutes SG and MA: ['further', 'additional', 'varied', 'special', 'educational', 'live', 'exciting', 'intensive', 'excellent', 'advance']\n",
      "\n",
      "Complex word: instrument\n",
      "top-10 substitutes SG and MA: ['organ', 'arrangement', 'act', 'apparatus', 'asset', 'equipment', 'institution', 'amount', 'arm', 'agreement']\n",
      "\n",
      "Complex word: emerge\n",
      "top-10 substitutes SG and MA: ['appear', 'arrive', 'arise', 'form', 'fall', 'disappear', 'occur', 'rise', 'remain', 'come']\n",
      "\n",
      "Complex word: insurgency\n",
      "top-10 substitutes SG and MA: ['insurgents', 'taliban', 'campaign', 'government', 'army', 'military', 'uprising', 'rebellion', 'militia', 'militants']\n",
      "\n",
      "Complex word: emerge\n",
      "top-10 substitutes SG and MA: ['graduate', 'rise', 'arise', 'recover', 'learn', 'arrive', 'come', 'exit', 'break', 'evolve']\n",
      "\n",
      "Complex word: ensued\n",
      "top-10 substitutes SG and MA: ['occurred', 'followed', 'ended', 'culminated', 'began', 'continued', 'commenced', 'erupted', 'unfolded', 'concluded']\n",
      "\n",
      "Complex word: regime\n",
      "top-10 substitutes SG and MA: ['program', 'programme', 'government', 'administration', 'scheme', 'sanctions', 'system', 'policy', 'period', 'law']\n",
      "\n",
      "Complex word: unearthed\n",
      "top-10 substitutes SG and MA: ['found', 'discovered', 'excavated', 'uncovered', 'recovered', 'rediscovered', 'collected', 'detected', 'buried', 'identified']\n",
      "\n",
      "Complex word: strategic\n",
      "top-10 substitutes SG and MA: ['tactical', 'historic', 'military', 'strategy', 'economic', 'new', 'comprehensive', 'security', 'critical', 'regional']\n",
      "\n",
      "Complex word: metropolitan\n",
      "top-10 substitutes SG and MA: ['urban', 'city', 'metro', 'rural', 'central', 'surrounding', 'downtown', 'municipal', 'local', 'capital']\n",
      "\n",
      "Complex word: exhibitions\n",
      "top-10 substitutes SG and MA: ['works', 'collections', 'shows', 'displays', 'demonstrations', 'exhibits', 'installations', 'performances', 'studies', 'paintings']\n",
      "\n",
      "Complex word: prospects\n",
      "top-10 substitutes SG and MA: ['chances', 'potential', 'possibilities', 'opportunities', 'outlook', 'odds', 'possibility', 'hope', 'hopes', 'chance']\n",
      "\n",
      "Complex word: surveillance\n",
      "top-10 substitutes SG and MA: ['reconnaissance', 'spy', 'observation', 'monitoring', 'patrol', 'security', 'intelligence', 'control', 'spying', 'radar']\n",
      "\n",
      "Complex word: preoccupied\n",
      "top-10 substitutes SG and MA: ['concerned', 'obsessed', 'distracted', 'consumed', 'bothered', 'troubled', 'affected', 'occupied', 'fascinated', 'motivated']\n",
      "\n",
      "Complex word: conservative\n",
      "top-10 substitutes SG and MA: ['liberal', 'radical', 'moderate', 'the', 'sunni', 'tory', 'traditional', 'senior', 'young', 'western']\n",
      "\n",
      "Complex word: documented\n",
      "top-10 substitutes SG and MA: ['reported', 'uncovered', 'identified', 'confirmed', 'recorded', 'involved', 'pending', 'here', 'resolved', 'settled']\n",
      "\n",
      "Complex word: awoken\n",
      "top-10 substitutes SG and MA: ['awakened', 'woken', 'startled', 'woke', 'disturbed', 'alerted', 'shaken', 'attacked', 'interrupted', 'injured']\n",
      "\n",
      "Complex word: inadequate\n",
      "top-10 substitutes SG and MA: ['insufficient', 'poor', 'improper', 'inappropriate', 'adequate', 'excessive', 'ineffective', 'incomplete', 'lack', 'limited']\n",
      "\n",
      "Complex word: challenging\n",
      "top-10 substitutes SG and MA: ['demanding', 'opposing', 'defending', 'asserting', 'supporting', 'claiming', 'criticizing', 'rejecting', 'against', 'regarding']\n",
      "\n",
      "Complex word: assassinated\n",
      "top-10 substitutes SG and MA: ['killed', 'shot', 'arrested', 'kidnapped', 'captured', 'abducted', 'accompanied', 'attacked', 'detained', 'targeted']\n",
      "\n",
      "Complex word: datum\n",
      "top-10 substitutes SG and MA: ['mean', 'ground', 'dat', 'mark', 'point', 'signal', 'estimate', 'altitude', 'map', 'area']\n",
      "\n",
      "Complex word: eligible\n",
      "top-10 substitutes SG and MA: ['ineligible', 'qualified', 'approved', 'accepted', 'available', 'qualify', 'eligibility', 'enrolled', 'required', 'authorized']\n",
      "\n",
      "Complex word: roamed\n",
      "top-10 substitutes SG and MA: ['buzzed', 'circled', 'scanned', 'littered', 'lined', 'raked', 'swept', 'lit', 'covered', 'dotted']\n",
      "\n",
      "Complex word: diplomatically\n",
      "top-10 substitutes SG and MA: ['for', 'such', 'effectively', 'formally', 'as', 'successfully', 'again', 'to', 'this', 'peacefully']\n",
      "\n",
      "Complex word: conjure\n",
      "top-10 substitutes SG and MA: ['set', 'build', 'open', 'make', 'give', 'put', 'forge', 'stir', 'create', 'draw']\n",
      "\n",
      "Complex word: commemorating\n",
      "top-10 substitutes SG and MA: ['marking', 'celebrating', 'honoring', 'on', 'for', 'representing', 'marked', 'of', 'at', 'remembering']\n",
      "\n",
      "Complex word: legislaton\n",
      "top-10 substitutes SG and MA: ['act', 'legislation', 'protests', 'law', 'laws', 'movement', 'action', 'rights', 'activists', 'acts']\n",
      "\n",
      "Complex word: dissidents\n",
      "top-10 substitutes SG and MA: ['prisoners', 'civilians', 'refugees', 'rebels', 'people', 'minorities', 'activists', 'detainees', 'women', 'protesters']\n",
      "\n",
      "Complex word: problematic\n",
      "top-10 substitutes SG and MA: ['bad', 'useful', 'necessary', 'unacceptable', 'good', 'negative', 'desirable', 'positive', 'unnecessary', 'redundant']\n",
      "\n",
      "Complex word: ingested\n",
      "top-10 substitutes SG and MA: ['ate', 'consumed', 'took', 'mixed', 'tasted', 'absorbed', 'swallowed', 'injected', 'extracted', 'soaked']\n",
      "\n",
      "Complex word: definitive\n",
      "top-10 substitutes SG and MA: ['complete', 'comprehensive', 'final', 'full', 'total', 'partial', 'clear', 'definite', 'permanent', 'quick']\n",
      "\n",
      "Complex word: compiled\n",
      "top-10 substitutes SG and MA: ['obtained', 'collected', 'gathered', 'released', 'provided', 'received', 'generated', 'analyzed', 'produced', 'accumulated']\n",
      "\n",
      "Complex word: criteria\n",
      "top-10 substitutes SG and MA: ['standards', 'requirements', 'threshold', 'standard', 'guidelines', 'requirement', 'expectations', 'conditions', 'goals', 'rules']\n",
      "\n",
      "Complex word: crippling\n",
      "top-10 substitutes SG and MA: ['getting', 'the', 'many', 'making', 'falling', 'some', 'more', 'damaging', 'other', 'hitting']\n",
      "\n",
      "Complex word: unsanctioned\n",
      "top-10 substitutes SG and MA: ['impromptu', 'opposition', 'illegal', 'unarmed', 'anarchist', 'open', 'overnight', 'outdoor', 'underground', 'organized']\n",
      "\n",
      "Complex word: traumatised\n",
      "top-10 substitutes SG and MA: ['devastated', 'distressed', 'horrified', 'shocked', 'upset', 'distraught', 'sad', 'relieved', 'troubled', 'confused']\n",
      "\n",
      "Complex word: bole\n",
      "top-10 substitutes SG and MA: ['trunk', 'tree', 'pattern', 'structure', 'crown', 'canopy', 'base', 'shape', 'crest', 'branch']\n",
      "\n",
      "Complex word: ignited\n",
      "top-10 substitutes SG and MA: ['erupted', 'sparked', 'escalated', 'intensified', 'culminated', 'flared', 'raged', 'fueled', 'ended', 'began']\n",
      "\n",
      "Complex word: pertaining\n",
      "top-10 substitutes SG and MA: ['relating', 'due', 'related', 'as', 'referring', 'regarding', 'pointing', 'leading', 'referred', 'owing']\n",
      "\n",
      "Complex word: operative\n",
      "top-10 substitutes SG and MA: ['agent', 'informant', 'active', 'ally', 'affiliate', 'activist', 'officer', 'employee', 'expert', 'aide']\n",
      "\n",
      "Complex word: sole\n",
      "top-10 substitutes SG and MA: ['final', 'true', 'real', 'single', 'permanent', 'definitive', 'major', 'ultimate', 'further', 'legitimate']\n",
      "\n",
      "Complex word: collaborated\n",
      "top-10 substitutes SG and MA: ['worked', 'partnered', 'assisted', 'helped', 'contributed', 'experimented', 'combined', 'teamed', 'agreed', 'continued']\n",
      "\n",
      "Complex word: trophies\n",
      "top-10 substitutes SG and MA: ['titles', 'awards', 'games', 'medals', 'championships', 'tournaments', 'matches', 'prizes', 'times', 'competitions']\n",
      "\n",
      "Complex word: backlash\n",
      "top-10 substitutes SG and MA: ['protest', 'revolt', 'retaliation', 'reaction', 'retribution', 'resistance', 'counter', 'bias', 'back', 'defense']\n",
      "\n",
      "Complex word: counteractions\n",
      "top-10 substitutes SG and MA: ['attacks', 'actions', 'attack', 'retaliation', 'action', 'intervention', 'strikes', 'resistance', 'response', 'counterattack']\n",
      "\n",
      "Complex word: impasse\n",
      "top-10 substitutes SG and MA: ['differences', 'agreement', 'disagreements', 'disagreement', 'crisis', 'difficulties', 'dispute', 'negotiations', 'failure', 'opposition']\n",
      "\n",
      "Complex word: defiance\n",
      "top-10 substitutes SG and MA: ['support', 'spite', 'violation', 'anticipation', 'protest', 'favor', 'opposition', 'breach', 'pursuit', 'defense']\n",
      "\n",
      "Complex word: implied\n",
      "top-10 substitutes SG and MA: ['indicated', 'said', 'stated', 'suggested', 'announced', 'hinted', 'assumed', 'confirmed', 'claimed', 'promised']\n",
      "\n",
      "Complex word: marred\n",
      "top-10 substitutes SG and MA: ['tainted', 'overshadowed', 'delayed', 'marked', 'clouded', 'plagued', 'hampered', 'complicated', 'affected', 'triggered']\n",
      "\n",
      "Complex word: departure\n",
      "top-10 substitutes SG and MA: ['retirement', 'death', 'resignation', 'return', 'leave', 'tenure', 'leaving', 'appointment', 'absence', 'graduation']\n",
      "\n",
      "Complex word: compound\n",
      "top-10 substitutes SG and MA: ['building', 'complex', 'facility', 'residence', 'house', 'truck', 'warehouse', 'base', 'hotel', 'restaurant']\n",
      "\n",
      "Complex word: unprecedented\n",
      "top-10 substitutes SG and MA: ['enormous', 'ongoing', 'intense', 'immense', 'overwhelming', 'international', 'outright', 'extensive', 'extraordinary', 'increasing']\n",
      "\n",
      "Complex word: enacted\n",
      "top-10 substitutes SG and MA: ['implemented', 'introduced', 'passed', 'instituted', 'adopted', 'done', 'proposed', 'created', 'repealed', 'achieved']\n",
      "\n",
      "Complex word: enactment\n",
      "top-10 substitutes SG and MA: ['introduction', 'release', 'passage', 'creation', 'independence', 'implementation', 'abolition', 'inauguration', 'inception', 'election']\n",
      "\n",
      "Complex word: evacuation\n",
      "top-10 substitutes SG and MA: ['departure', 'return', 'expulsion', 'release', 'withdrawal', 'removal', 'arrival', 'closure', 'surrender', 'escape']\n",
      "\n",
      "Complex word: prediction\n",
      "top-10 substitutes SG and MA: ['forecast', 'estimate', 'predict', 'prophecy', 'report', 'warning', 'announcement', 'scenario', 'statement', 'predicting']\n",
      "\n",
      "Complex word: acquisition\n",
      "top-10 substitutes SG and MA: ['purchase', 'takeover', 'sale', 'use', 'acquiring', 'ownership', 'approval', 'creation', 'transfer', 'possession']\n",
      "\n",
      "Complex word: investigate\n",
      "top-10 substitutes SG and MA: ['probe', 'investigation', 'search', 'examine', 'monitor', 'explore', 'watch', 'hunt', 'pursue', 'inspect']\n",
      "\n",
      "Complex word: slumped\n",
      "top-10 substitutes SG and MA: ['slipped', 'fallen', 'dropped', 'slid', 'plunged', 'gained', 'risen', 'shed', 'lost', 'tumbled']\n",
      "\n",
      "Complex word: ambushed\n",
      "top-10 substitutes SG and MA: ['kidnapped', 'captured', 'attacked', 'abducted', 'killed', 'shot', 'wounded', 'raped', 'intercepted', 'assaulted']\n",
      "\n",
      "Complex word: conclusion\n",
      "top-10 substitutes SG and MA: ['end', 'outcome', 'completion', 'point', 'start', 'finish', 'goal', 'result', 'one', 'decision']\n",
      "\n",
      "Complex word: rebound\n",
      "top-10 substitutes SG and MA: ['recovery', 'rally', 'comeback', 'reversal', 'correction', 'boost', 'performance', 'return', 'revival', 'fall']\n",
      "\n",
      "Complex word: diagnosed\n",
      "top-10 substitutes SG and MA: ['identified', 'developed', 'resolved', 'discovered', 'cured', 'many', 'treated', 'addressed', 'experienced', 'born']\n",
      "\n",
      "Complex word: boycott\n",
      "top-10 substitutes SG and MA: ['cancel', 'delay', 'disrupt', 'skip', 'support', 'reject', 'watch', 'hold', 'attend', 'suspend']\n",
      "\n",
      "Complex word: campaigning\n",
      "top-10 substitutes SG and MA: ['fighting', 'lobbying', 'preparation', 'preparations', 'training', 'voting', 'support', 'action', 'propaganda', 'planning']\n",
      "\n",
      "Complex word: assassinated\n",
      "top-10 substitutes SG and MA: ['deposed', 'defeated', 'killed', 'executed', 'murdered', 'slain', 'captured', 'beheaded', 'elected', 'ousted']\n",
      "\n",
      "Complex word: detonated\n",
      "top-10 substitutes SG and MA: ['exploded', 'found', 'destroyed', 'discovered', 'killed', 'parked', 'attacked', 'launched', 'struck', 'deployed']\n",
      "\n",
      "Complex word: clamoring\n",
      "top-10 substitutes SG and MA: ['searching', 'asking', 'waiting', 'looking', 'seeking', 'yearning', 'fighting', 'pushing', 'longing', 'calling']\n",
      "\n",
      "Complex word: credibility\n",
      "top-10 substitutes SG and MA: ['legitimacy', 'confidence', 'support', 'reputation', 'strength', 'security', 'courage', 'competence', 'integrity', 'prestige']\n",
      "\n",
      "Complex word: outskirts\n",
      "top-10 substitutes SG and MA: ['edge', 'streets', 'periphery', 'corner', 'perimeter', 'doorstep', 'fringe', 'outside', 'edges', 'side']\n",
      "\n",
      "Complex word: elite\n",
      "top-10 substitutes SG and MA: ['establishment', 'party', 'junta', 'minority', 'class', 'dynasty', 'people', 'majority', 'family', 'monarchy']\n",
      "\n",
      "Complex word: vulnerable\n",
      "top-10 substitutes SG and MA: ['susceptible', 'prone', 'exposed', 'sensitive', 'resistant', 'subject', 'open', 'immune', 'subjected', 'responsive']\n",
      "\n",
      "Complex word: reaffirmed\n",
      "top-10 substitutes SG and MA: ['reiterated', 'confirmed', 'affirmed', 'defended', 'stressed', 'reinforced', 'maintained', 'supported', 'repeated', 'stated']\n",
      "\n",
      "Complex word: harassed\n",
      "top-10 substitutes SG and MA: ['attacked', 'assaulted', 'insulted', 'confronted', 'chased', 'tortured', 'humiliated', 'pursued', 'questioned', 'threatened']\n",
      "\n",
      "Complex word: safeguarding\n",
      "top-10 substitutes SG and MA: ['protecting', 'guarding', 'defending', 'securing', 'protect', 'preserving', 'maintaining', 'ensuring', 'keeping', 'enforcing']\n",
      "\n",
      "Complex word: subsidiaries\n",
      "top-10 substitutes SG and MA: ['offices', 'operations', 'branches', 'headquarters', 'affiliates', 'facilities', 'ties', 'business', 'premises', 'interests']\n",
      "\n",
      "Complex word: imprecise\n",
      "top-10 substitutes SG and MA: ['expensive', 'limited', 'large', 'small', 'dense', 'heavy', 'sharp', 'bulky', 'short', 'narrow']\n",
      "\n",
      "Complex word: surged\n",
      "top-10 substitutes SG and MA: ['continued', 'raged', 'erupted', 'escalated', 'increased', 'intensified', 'grew', 'flared', 'mounted', 'rose']\n",
      "\n",
      "Complex word: repealing\n",
      "top-10 substitutes SG and MA: ['ending', 'reforming', 'eliminating', 'replacing', 'removing', 'changing', 'restoring', 'extending', 'cutting', 'reducing']\n",
      "\n",
      "Complex word: obvious\n",
      "top-10 substitutes SG and MA: ['direct', 'apparent', 'clear', 'actual', 'explicit', 'real', 'immediate', 'significant', 'causal', 'possible']\n",
      "\n",
      "Complex word: resilience\n",
      "top-10 substitutes SG and MA: ['strength', 'effectiveness', 'progress', 'success', 'intensity', 'stability', 'future', 'severity', 'persistence', 'performance']\n",
      "\n",
      "Complex word: revert\n",
      "top-10 substitutes SG and MA: ['return', 'turn', 'retreat', 'fall', 'default', 'convert', 'resort', 'transition', 'shift', 'end']\n",
      "\n",
      "Complex word: vicinity\n",
      "top-10 substitutes SG and MA: ['region', 'area', 'neighborhood', 'neighbourhood', 'surroundings', 'territory', 'proximity', 'locality', 'country', 'society']\n",
      "\n",
      "Complex word: riposte\n",
      "top-10 substitutes SG and MA: ['blow', 'threat', 'reference', 'betrayal', 'response', 'nod', 'coup', 'reaction', 'tribute', 'toast']\n",
      "\n",
      "Complex word: accumulation\n",
      "top-10 substitutes SG and MA: ['deposition', 'removal', 'absorption', 'formation', 'decomposition', 'growth', 'disappearance', 'melting', 'storage', 'deposit']\n",
      "\n",
      "Complex word: sustained\n",
      "top-10 substitutes SG and MA: ['repeated', 'severe', 'prolonged', 'serious', 'extensive', 'frequent', 'continued', 'widespread', 'persistent', 'heavy']\n",
      "\n",
      "Complex word: vacationing\n",
      "top-10 substitutes SG and MA: ['staying', 'living', 'traveling', 'visiting', 'sleeping', 'camping', 'working', 'residing', 'lodging', 'away']\n",
      "\n",
      "Complex word: allegations\n",
      "top-10 substitutes SG and MA: ['accusations', 'charges', 'claims', 'suspicions', 'accusation', 'reports', 'rumours', 'rumors', 'complaints', 'evidence']\n",
      "\n",
      "Complex word: integral\n",
      "top-10 substitutes SG and MA: ['important', 'integrated', 'essential', 'active', 'independent', 'incorporated', 'entire', 'autonomous', 'extra', 'additional']\n",
      "\n",
      "Complex word: monument\n",
      "top-10 substitutes SG and MA: ['memorial', 'shrine', 'statue', 'tribute', 'plaque', 'temple', 'grave', 'mausoleum', 'chapel', 'museum']\n",
      "\n",
      "Complex word: homicides\n",
      "top-10 substitutes SG and MA: ['ever', 'murders', 'one', 'deaths', 'cases', 'ones', 'incidents', 'killings', 'crimes', 'crime']\n",
      "\n",
      "Complex word: fatalities\n",
      "top-10 substitutes SG and MA: ['deaths', 'victims', 'bodies', 'incidents', 'individuals', 'people', 'men', 'murders', 'casualties', 'killers']\n",
      "\n",
      "Complex word: underscores\n",
      "top-10 substitutes SG and MA: ['highlights', 'illustrates', 'highlighted', 'reveals', 'addresses', 'demonstrates', 'shows', 'raises', 'explains', 'presents']\n",
      "\n",
      "Complex word: annul\n",
      "top-10 substitutes SG and MA: ['cancel', 'announce', 'amend', 'observe', 'terminate', 'modify', 'review', 'check', 'contest', 'approve']\n",
      "\n",
      "Complex word: deployed\n",
      "top-10 substitutes SG and MA: ['stationed', 'mobilized', 'killed', 'based', 'serving', 'posted', 'sent', 'held', 'trained', 'present']\n",
      "\n",
      "Complex word: revered\n",
      "top-10 substitutes SG and MA: ['popular', 'sacred', 'traditional', 'holy', 'famous', 'favorite', 'prominent', 'common', 'celebrated', 'beloved']\n",
      "\n",
      "Complex word: evade\n",
      "top-10 substitutes SG and MA: ['avoid', 'escape', 'obtain', 'achieve', 'attain', 'gain', 'verify', 'reach', 'get', 'dodge']\n",
      "\n",
      "Complex word: alleged\n",
      "top-10 substitutes SG and MA: ['suspected', 'attempted', 'widespread', 'possible', 'illegal', 'fake', 'potential', 'the', 'official', 'reported']\n",
      "\n",
      "Complex word: indignation\n",
      "top-10 substitutes SG and MA: ['anger', 'outrage', 'discontent', 'concern', 'protest', 'sentiment', 'opinion', 'alarm', 'dissatisfaction', 'tension']\n",
      "\n",
      "Complex word: lingering\n",
      "top-10 substitutes SG and MA: ['renewed', 'growing', 'continuing', 'persistent', 'heightened', 'recurring', 'fresh', 'deep', 'residual', 'looming']\n",
      "\n",
      "Complex word: barren\n",
      "top-10 substitutes SG and MA: ['flat', 'vast', 'uninhabited', 'fertile', 'virgin', 'lonely', 'dry', 'desert', 'coral', 'plain']\n",
      "\n",
      "Complex word: falsifications\n",
      "top-10 substitutes SG and MA: ['errors', 'irregularities', 'mistakes', 'scandals', 'problems', 'allegations', 'accusations', 'complaints', 'attacks', 'insults']\n",
      "\n",
      "Complex word: incubated\n",
      "top-10 substitutes SG and MA: ['launched', 'occurring', 'located', 'planned', 'recorded', 'targeted', 'contained', 'held', 'triggered', 'conducted']\n",
      "\n",
      "Complex word: flashpoints\n",
      "top-10 substitutes SG and MA: ['points', 'sites', 'locations', 'events', 'targets', 'places', 'venues', 'times', 'centres', 'rallies']\n",
      "\n",
      "Complex word: prejudiced\n",
      "top-10 substitutes SG and MA: ['biased', 'racist', 'unfair', 'offended', 'disadvantaged', 'beaten', 'wrong', 'favored', 'invalid', 'bias']\n",
      "\n",
      "Complex word: conferred\n",
      "top-10 substitutes SG and MA: ['bestowed', 'awarded', 'granted', 'imposed', 'offered', 'exercised', 'given', 'served', 'earned', 'reserved']\n",
      "\n",
      "Complex word: alighting\n",
      "top-10 substitutes SG and MA: ['arriving', 'flying', 'landing', 'staying', 'driving', 'returning', 'appearing', 'stopping', 'traveling', 'being']\n",
      "\n",
      "Complex word: illegitimate\n",
      "top-10 substitutes SG and MA: ['legitimate', 'fraudulent', 'unlawful', 'false', 'illegal', 'illicit', 'innocent', 'new', 'fake', 'unacceptable']\n",
      "\n",
      "Complex word: extend\n",
      "top-10 substitutes SG and MA: ['express', 'offer', 'give', 'send', 'open', 'convey', 'direct', 'spread', 'communicate', 'relay']\n",
      "\n",
      "Complex word: subsequently\n",
      "top-10 substitutes SG and MA: ['later', 'was', 'then', 'ultimately', 'initially', 'also', 'eventually', 'immediately', 'afterwards', 'thereafter']\n",
      "\n",
      "Complex word: detained\n",
      "top-10 substitutes SG and MA: ['arrested', 'held', 'jailed', 'released', 'imprisoned', 'questioned', 'captured', 'seized', 'freed', 'incarcerated']\n",
      "\n",
      "Complex word: commenced\n",
      "top-10 substitutes SG and MA: ['began', 'resumed', 'continued', 'started', 'completed', 'finished', 'begun', 'undertook', 'ended', 'begins']\n",
      "\n",
      "Complex word: intentions\n",
      "top-10 substitutes SG and MA: ['intent', 'plans', 'hopes', 'hope', 'thoughts', 'goal', 'plan', 'idea', 'option', 'possibility']\n",
      "\n",
      "Complex word: disruptive\n",
      "top-10 substitutes SG and MA: ['disrupt', 'offensive', 'destructive', 'inappropriate', 'constructive', 'harmful', 'disruption', 'critical', 'unwanted', 'disturbing']\n",
      "\n",
      "Complex word: outskirts\n",
      "top-10 substitutes SG and MA: ['edge', 'side', 'suburbs', 'fringe', 'streets', 'periphery', 'perimeter', 'part', 'corner', 'bank']\n",
      "\n",
      "Complex word: interred\n",
      "top-10 substitutes SG and MA: ['buried', 'cremated', 'placed', 'settled', 'located', 'born', 'raised', 'included', 'living', 'married']\n",
      "\n",
      "Complex word: epigrams\n",
      "top-10 substitutes SG and MA: ['imagery', 'graffiti', 'images', 'work', 'murals', 'paintings', 'drawings', 'works', 'prose', 'artwork']\n",
      "\n",
      "Complex word: homicides\n",
      "top-10 substitutes SG and MA: ['murders', 'deaths', 'killings', 'fatalities', 'crimes', 'incidents', 'cases', 'arrests', 'assaults', 'crashes']\n",
      "\n",
      "Complex word: seized\n",
      "top-10 substitutes SG and MA: ['attacked', 'captured', 'invaded', 'targeted', 'raided', 'liberated', 'occupied', 'overrun', 'recaptured', 'destroyed']\n",
      "\n",
      "Complex word: impugned\n",
      "top-10 substitutes SG and MA: ['affected', 'violated', 'disrupted', 'damaged', 'compromised', 'harmed', 'diminished', 'reduced', 'challenged', 'hurt']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    # print(f\"Sentence: {sentence}\")\n",
    "    #print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, lm_tokenizer.mask_token) # this is different per model (this code line applies to Electra)\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    sentences_concat = f\"{sentence} {lm_tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline (removing elements without token_str key; as this gave errors in the ELECTRA models) .\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "    substitutes = [substitute[\"token_str\"] for substitute in result if \"token_str\" in substitute]\n",
    "    #print(f\"Substitute Generation step: initial substitute list: {substitutes}\\n\")\n",
    "\n",
    "\n",
    "    #2: Morphological Generation and Context Adaptation (Morphological Adaptation):  \n",
    "    ## a) remove noise in the substitutes, by ignoring generated substitutes that are empty or that have unwanted punctuation characters or that start with '##' (this returned errors with the ELECTRA model), and lowercase the substitutes (as some models don't lowercase by default)\n",
    "    ## and lowercase all substitutes. Use try/except statement to prevent other character-related problems to happen\n",
    "    \n",
    "    punctuation_set = set(string.punctuation) - set('-') # retained hyphens in case tokenizers don't split on hyphenated compounds\n",
    "    punctuation_set.update({'',''})   # as these curly quotes appeared in the Electra (SG step) results but were not part of the string set\n",
    "    \n",
    "    try:\n",
    "        substitutes = [substitute[\"token_str\"].lower() for substitute in result if not any(char in punctuation_set for char in substitute[\"token_str\"]) \n",
    "                       and not substitute[\"token_str\"].startswith('##') and substitute[\"token_str\"].strip() != \"\"]\n",
    "        # print(f\"Morphological Adaptation step a): substitute list without unwanted punctuation characters: {substitutes}\\n\")\n",
    "    except TypeError as error:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## b) remove duplicates within the substitute list from the substitute list (duplicates are likely for models that did not lowercase by default)\n",
    "    ## the last mentioned duplicate is removed on purpose, as this may probably be the (previously) uppercased variant of the lowercased substitute (lowercased subs are most likely higher ranked by the model)\n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl:\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    #print(f\"Morphological Adaptation step b): substitute list without duplicates of substitutes: {substitutes_no_dupl}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## c) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    \n",
    "    ## first Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## then, remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step c): substitute list without duplicates of the complex word nor inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "    \n",
    "    \n",
    "    ## d) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step d): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "    \n",
    "        \n",
    "    # limit the substitutes to the 10 highest ranked ones for evaluation\n",
    "    top_10_substitutes = substitutes_no_dupl_complex_word_no_antonym[:10]\n",
    "    #print(f\"top-10 substitutes SG and MA: {top_10_substitutes}\\n\")\n",
    "    \n",
    "    # fill the dataframe with 10 elements even if there are less than 10 in the previous list\n",
    "    required_for_dataframe = 10\n",
    "    # pad the list with None until it has 10 elements\n",
    "    top_10_substitutes += [None] * (required_for_dataframe - len(top_10_substitutes))\n",
    "\n",
    "    # # add the sentence, complex_word, and the substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + top_10_substitutes\n",
    "    \n",
    "    \n",
    "    #print('---------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "# export the dataframe to a tsv file for evaluation\n",
    "substitutes_df.to_csv(\"./predictions/test/ElectraBase_SG_MA.tsv\", sep=\"\\t\", index=False, header=False)\n",
    "print(\"ElectraBase_SG_MA exported to csv in path './predictions/test/ElectraBase_SG_MA.tsv'}\\n\")  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1521ab03-d88c-4212-8a4a-46bc92a3699c",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/ElectraBase_SG_MA.tsv --output_file ./output/test/ElectraBase_SG_MA.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "012771d6-44b1-4e15-8cbd-c7a7d90350ef",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/ElectraBase_SG_MA.tsv\n",
    "OUTPUT file = ./output/test/ElectraBase_SG_MA.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.5469\n",
    "\n",
    "MAP@3 = 0.3683\n",
    "MAP@5 = 0.267\n",
    "MAP@10 = 0.1658\n",
    "\n",
    "Potential@3 = 0.7613\n",
    "Potential@5 = 0.8284\n",
    "Potential@10 = 0.9115\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.2707\n",
    "Accuracy@2@top_gold_1 = 0.3806\n",
    "Accuracy@3@top_gold_1 = 0.4611"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e64340-9f3e-4bfd-9ec8-ee86ddf13d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87194791-fed3-4237-8357-9b05e0b9690e",
   "metadata": {},
   "source": [
    "#### Substitute Generation, Morphological Adaptation, and Contextualized embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68773cb5-3017-4491-a3d3-bae5e3bf282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates similarity between the original sentence and the sentences with candidate substitutes that were retrieved in the SG step \n",
    "# creates a list with sentences with substitute words filled in (commented out for oversight purposes)\n",
    "\n",
    "\n",
    "def calculate_similarity_scores(sentence, sentence_with_substitutes):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"google/electra-base-generator\")\n",
    "    tf_model = TFAutoModel.from_pretrained(\"google/electra-base-generator\")\n",
    "\n",
    "    def embed_text(text):\n",
    "        tokens = tokenizer(text, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "        outputs = tf_model(**tokens)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        embeddings = tf.nn.l2_normalize(embeddings, axis=1)\n",
    "        return embeddings\n",
    "\n",
    "    original_sentence_embedding = embed_text(sentence)\n",
    "    substitute_sentence_embeddings = embed_text(sentence_with_substitutes)\n",
    "\n",
    "    cosine_similarity = np.inner(original_sentence_embedding, substitute_sentence_embeddings)\n",
    "    similarity_scores = cosine_similarity[0]\n",
    "\n",
    "    return similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18125eff-6860-452c-918e-f7ce027e6520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: prototype\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: authoritarian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: collision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: pupates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: discontent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: decomposes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: descent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: sectarian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: sectarian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: offshoot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: decree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: detonating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: deficit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: canopy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: condolences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: benchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: auspicious\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: suspiciously\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: established\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: scrutiny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: regime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: snipers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: precautions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: systemic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: anchored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: accolade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: uprising\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: offender\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: bulging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: encodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: mythological\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: romanized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: residences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: ringleaders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: compound\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: pre-positioned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: exclusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: recognized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: toxins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: nominated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: unprecedented\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: erring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: monsters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: detainees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: harassing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: conflicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: announced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: cementing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: unleashing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: scrutiny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: suspiciously\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: originated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: replica\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: discredits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: vicious\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: strained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: enacted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: primed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: probe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: aviator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: acquiring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: restive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: repression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: vulnerability\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: equipment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: stemming\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: existence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: adequate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: genuinely\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: proportion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: motive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: determination\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: bloodshed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: credibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: exclusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: craven\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: usher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: anonymity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: emerged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: indignation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: re-enacting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: detained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: diplomatic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: troublemakers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: abdomen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: pursuit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: inclusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: acquire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: confidential\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: attentively\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: bombardment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: colonies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: partially\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: segregation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: residence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: sanctions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: threatened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: intimidate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: sought\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: bureau\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: anonymity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: acclaimed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: enquiries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: commissioned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: scrapped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: successive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: degenerate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: offender\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: touted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: anonymity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: purifying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: announced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: residing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: plundering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: clemency\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: enduring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: sanctuary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: demonstrations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: allege\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: unsanctioned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: bloodshed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: adversary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: alleged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: enigmatic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: renderings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: warily\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: evaluated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: nobility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: surpassed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: asserted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: colonies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: erupted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: deployed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: militiamen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: carnage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: stint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: repossessed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: investigating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: atrocities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: underlying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: introduced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: adamantly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: candidacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: disputed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: auctioneers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: bloodshed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: relinquish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: indicating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: organisers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: clearance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: sympathy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: composition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: sanctions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: executed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: flashpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: assumption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: apparent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: appealed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: casualties\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: qualify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: acquisition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: pedestal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: sustained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: prevailing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: imposing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: Initially\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: regime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: dominated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: authorized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: slated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: regrettable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: regime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: demonstrations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: summonsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: sentiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: surveillance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: preliminary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: plethora\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: implemented\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: concentration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: controversial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: acquisition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: outlining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: approximately\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: pinnacle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: uprising\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: overt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: probe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: herald\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: disgraceful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: ominous\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: indication\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: attributed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: impeachment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: infamous\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: annul\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: disassociate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: electoral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: emissions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: eligibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: bombardment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: crippling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: regime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: mandated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: rendition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: morph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: authorized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: internship\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: tragedy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: monitoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: provisioning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: downplayed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: tragedy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: authoritarian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: prohibits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: prevailing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: skittish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: obliged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: ouster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: mainstream\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: appealing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: surveillance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: cooperated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: sought\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: debris\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: sanctions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: acquisition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: pledges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: debris\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: suspicious\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: condolences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: impeach\n",
      "Error occurred: list indices must be integers or slices, not str\n",
      "Complex word: unleashed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: inaugural\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: ongoing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: hostility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: incurred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: quelled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: detained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: insurgents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: distinct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: defected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: critically\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: authorities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: regime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: envisions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: estimate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: significance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: neighbouring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: insurgents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: clemency\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: authorities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: obscene\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: bespoke\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: instrument\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: emerge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: insurgency\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: emerge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: ensued\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: regime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: unearthed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: strategic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: metropolitan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: exhibitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: prospects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: surveillance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: preoccupied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: conservative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: documented\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: awoken\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: inadequate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: challenging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: assassinated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: datum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: eligible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: roamed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: diplomatically\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: conjure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: commemorating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: legislaton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: dissidents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: problematic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: ingested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: definitive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: compiled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: criteria\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: crippling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: unsanctioned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: traumatised\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: bole\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: ignited\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: pertaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: operative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: sole\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: collaborated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: trophies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: backlash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: counteractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: impasse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: defiance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: implied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: marred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: departure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: compound\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: unprecedented\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: enacted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: enactment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: evacuation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: acquisition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: investigate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: slumped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: ambushed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: conclusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: rebound\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: diagnosed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: boycott\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: campaigning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: assassinated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: detonated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: clamoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: credibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: outskirts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: elite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: vulnerable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: reaffirmed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: harassed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: safeguarding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: subsidiaries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: imprecise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: surged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: repealing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: obvious\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: resilience\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: revert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: vicinity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: riposte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: accumulation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: sustained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: vacationing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: allegations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: integral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: monument\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: homicides\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: fatalities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: underscores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: annul\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: deployed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: revered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: evade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: alleged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: indignation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: lingering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: barren\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: falsifications\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: incubated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: flashpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: prejudiced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: conferred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: alighting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: illegitimate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: extend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: subsequently\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: detained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: commenced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: intentions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: disruptive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: outskirts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: interred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: epigrams\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: homicides\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: seized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: impugned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/electra-base-generator were not used when initializing TFElectraModel: ['activation', 'generator_lm_head', 'generator_predictions']\n",
      "- This IS expected if you are initializing TFElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFElectraModel were initialized from the model checkpoint at google/electra-base-generator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    # print(f\"Sentence: {sentence}\")\n",
    "    #print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, lm_tokenizer.mask_token) # this is different per model (this code line applies to Electra)\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    sentences_concat = f\"{sentence} {lm_tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline (removing elements without token_str key; as this gave errors in the ELECTRA models) .\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "    substitutes = [substitute[\"token_str\"] for substitute in result if \"token_str\" in substitute]\n",
    "    #print(f\"Substitute Generation step: initial substitute list: {substitutes}\\n\")\n",
    "\n",
    "\n",
    "    #2: Morphological Generation and Context Adaptation (Morphological Adaptation):  \n",
    "    ## a) remove noise in the substitutes, by ignoring generated substitutes that are empty or that have unwanted punctuation characters or that start with '##' (this returned errors with the ELECTRA model), and lowercase the substitutes (as some models don't lowercase by default)\n",
    "    ## and lowercase all substitutes. Use try/except statement to prevent other character-related problems to happen\n",
    "    \n",
    "    punctuation_set = set(string.punctuation) - set('-') # retained hyphens in case tokenizers don't split on hyphenated compounds\n",
    "    punctuation_set.update({'',''})   # as these curly quotes appeared in the Electra (SG step) results but were not part of the string set\n",
    "    \n",
    "    try:\n",
    "        substitutes = [substitute[\"token_str\"].lower() for substitute in result if not any(char in punctuation_set for char in substitute[\"token_str\"]) \n",
    "                       and not substitute[\"token_str\"].startswith('##') and substitute[\"token_str\"].strip() != \"\"]\n",
    "        # print(f\"Morphological Adaptation step a): substitute list without unwanted punctuation characters: {substitutes}\\n\")\n",
    "    except TypeError as error:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## b) remove duplicates within the substitute list from the substitute list (duplicates are likely for models that did not lowercase by default)\n",
    "    ## the last mentioned duplicate is removed on purpose, as this may probably be the (previously) uppercased variant of the lowercased substitute (lowercased subs are most likely higher ranked by the model)\n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl:\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    #print(f\"Morphological Adaptation step b): substitute list without duplicates of substitutes: {substitutes_no_dupl}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## c) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    \n",
    "    ## first Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## then, remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step c): substitute list without duplicates of the complex word nor inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "    \n",
    "    \n",
    "    ## d) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step d): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "       \n",
    "    \n",
    "    \n",
    "     #3: Substitute Selection (SS) by contextualized embeddings and cosine similarity scores:  \n",
    "          \n",
    "    # create sentence with the complex word replaced by the substitutes\n",
    "    sentence_with_substitutes = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym]\n",
    "    #print(f\"List with sentences where complex word is substituted: {sentence_with_substitutes}\\n\")\n",
    "    \n",
    "    \n",
    "    ##  calculate cosine similarity scores, and rank the substitutes based on their similarity score\n",
    "      \n",
    "    \n",
    "    if len(sentence_with_substitutes) > 0: # to make sure the list with substitutes is always filled\n",
    "        logging.getLogger('transformers').setLevel(logging.ERROR)  # to prevent the same warnings from being printed x times \n",
    "        similarity_scores = calculate_similarity_scores(sentence, sentence_with_substitutes)\n",
    "        logging.getLogger('transformers').setLevel(logging.WARNING) # to reset the logging level back to printing warnings\n",
    "        embeddings_ranked_substitutes_with_scores = sorted(zip(substitutes_no_dupl_complex_word_no_antonym, similarity_scores), key=lambda x: x[1], reverse=True)\n",
    "        embeddings_ranked_substitutes_only = [substitute for substitute, score in embeddings_ranked_substitutes_with_scores]\n",
    "        #print(f\"SS step: Ranked substitutes, based on embedding scores in context: {embeddings_ranked_substitutes_only}\\n\")   \n",
    "        \n",
    "        # limit the substitutes to the 10 first ones for evaluation\n",
    "        #print(f\" SS step: top-10 substitutes based on embedding scores in context: {embeddings_top_10_substitutes}\\n\")\n",
    "        embeddings_top_10_substitutes = embeddings_ranked_substitutes_only[:10]\n",
    "    else:\n",
    "        embeddings_top_10_substitutes = []\n",
    "    \n",
    "        \n",
    "    # fill the dataframe with 10 elements even if there are less than 10 in the previous list\n",
    "    required_for_dataframe = 10\n",
    "    # pad the list with None until it has 10 elements\n",
    "    embeddings_top_10_substitutes += [None] * (required_for_dataframe - len(embeddings_top_10_substitutes))\n",
    "    \n",
    "    # add the sentence, complex_word, and the substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + embeddings_top_10_substitutes\n",
    "    \n",
    "        \n",
    "    #print('---------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "# export the dataframe to a tsv file for evaluation\n",
    "substitutes_df.to_csv(\"./predictions/test/ElectraBase_SG_MA_SS_ce.tsv\", sep=\"\\t\", index=False, header=False) \n",
    "print(\"ElectraBase_SG_MA_SS_ce exported to csv in path './predictions/test/ElectraBase_SG_MA_SS_ce.tsv'}\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145b874a-0f9e-4cb2-b37c-889337fbc778",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/ElectraBase_SG_MA_SS_ce.tsv --output_file ./output/test/ElectraBase_SG_MA_SS_ce.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "037cd769-f7f0-4182-9ca3-6f63efbed39f",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/ElectraBase_SG_MA_SS_ce.tsv\n",
    "OUTPUT file = ./output/test/ElectraBase_SG_MA_SS_ce.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.3914\n",
    "\n",
    "MAP@3 = 0.2417\n",
    "MAP@5 = 0.1821\n",
    "MAP@10 = 0.1154\n",
    "\n",
    "Potential@3 = 0.6407\n",
    "Potential@5 = 0.7184\n",
    "Potential@10 = 0.8498\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1474\n",
    "Accuracy@2@top_gold_1 = 0.2305\n",
    "Accuracy@3@top_gold_1 = 0.2895"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc036c5-6a1e-4e71-a184-b2201ac7baf7",
   "metadata": {},
   "source": [
    "#### Substitute Generation, Morphological Adaptation, and BertScore:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34e0321f-543d-4a12-9607-da7b26365895",
   "metadata": {},
   "source": [
    "##### BErtscore based on ELECTRA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c504ebf4-576b-4370-8345-2492ac65fc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: prototype\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['model', 'clone', 'precursor', 'forerunner', 'dummy', 'specimen', 'design', 'specification', 'product', 'test']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: authoritarian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['corrupt', 'conservative', 'liberal', 'aggressive', 'militant', 'democratic', 'radical', 'paranoid', 'unpopular', 'charismatic']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: collision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['crash', 'accident', 'encounter', 'blast', 'crashes', 'explosion', 'incident', 'disaster', 'tragedy', 'accidents']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: pupates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['collects', 'feeds', 'hides', 'leaves', 'settles', 'nests', 'forms', 'develops', 'dies', 'breeds']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: discontent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['dissatisfaction', 'frustration', 'resentment', 'disappointment', 'anger', 'unrest', 'agitation', 'impatience', 'despair', 'distress']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: decomposes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['contracts', 'bends', 'collapses', 'sinks', 'transforms', 'escapes', 'expands', 'grows', 'yields', 'rises']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: descent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['ascent', 'descend', 'climb', 'hop', 'rise', 'journey', 'takeoff', 'departure', 'transition', 'leap']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sectarian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['sect', 'communal', 'ideological', 'secular', 'tribal', 'ethnic', 'regional', 'racial', 'national', 'demographic']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sectarian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['sect', 'partisan', 'communal', 'secular', 'ideological', 'clerical', 'ethnic', 'religious', 'civil', 'opposition']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: offshoot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['affiliate', 'splinter', 'branch', 'ally', 'antagonist', 'outside', 'extension', 'independent', 'arm', 'agent']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: decree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['edict', 'ordinance', 'motion', 'mandate', 'proclamation', 'decision', 'order', 'recommendation', 'petition', 'letter']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: detonating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['exploding', 'lighting', 'landing', 'smashing', 'shattering', 'hitting', 'damaging', 'downing', 'launching', 'striking']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: deficit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['surplus', 'debt', 'gap', 'inflation', 'loss', 'spending', 'gdp', 'problem', 'expenditure', 'balance']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: canopy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['cover', 'cushion', 'shield', 'dome', 'blanket', 'railing', 'ladder', 'roof', 'deck', 'sash']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: condolences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['apologies', 'gratitude', 'apology', 'congratulations', 'prayers', 'thanks', 'sympathy', 'wishes', 'sentiments', 'relief']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: benchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['backed', 'key', 'standard', 'outstanding', 'comparable', 'traditional', 'troubled', 'cheap', 'approved', 'convertible']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: auspicious\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['unusual', 'magical', 'delicate', 'lavish', 'exotic', 'special', 'rare', 'seasonal', 'regular', 'ceremonial']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: suspiciously\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['warily', 'strangely', 'curiously', 'oddly', 'coldly', 'menacing', 'vaguely', 'quietly', 'aggressively', 'deliberately']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: established\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['existing', 'formed', 'opened', 'official', 'establishment', 'constructed', 'operational', 'initial', 'listed', 'approved']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: scrutiny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['oversight', 'surveillance', 'investigation', 'criticism', 'attention', 'inquiry', 'questioning', 'review', 'consideration', 'enforcement']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: regime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['dictatorship', 'government', 'administration', 'rule', 'army', 'coup', 'overthrow', 'policies', 'presidency', 'leadership']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: snipers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['gunmen', 'drones', 'bombers', 'artillery', 'terrorists', 'missiles', 'bullets', 'insurgents', 'militants', 'attackers']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: precautions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['measures', 'caution', 'warnings', 'steps', 'risks', 'restraint', 'instructions', 'care', 'advise', 'advice']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: systemic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['structural', 'institutional', 'chronic', 'systematic', 'marginal', 'regional', 'generic', 'global', 'liquid', 'centralized']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: anchored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['grounded', 'docked', 'bound', 'sheltered', 'towed', 'held', 'submerged', 'tied', 'sunk', 'launched']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: accolade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['entry', 'endowment', 'endorsement', 'offering', 'achievement', 'evaluation', 'offer', 'item', 'exchange', 'invite']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: uprising\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['revolt', 'insurrection', 'rebellion', 'insurgency', 'revolution', 'mutiny', 'struggle', 'offensive', 'unrest', 'protests']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: offender\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['inmate', 'attacker', 'addict', 'employee', 'accused', 'applicant', 'officer', 'enemy', 'adult', 'individual']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: bulging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['swollen', 'swelling', 'bursting', 'throbbing', 'exploding', 'crawling', 'straining', 'dripping', 'saturated', 'loaded']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: encodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['codes', 'processes', 'expresses', 'forms', 'targets', 'crosses', 'stores', 'extracts', 'constitutes', 'passes']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: mythological\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['mythical', 'mythology', 'folklore', 'supernatural', 'historical', 'fictional', 'biblical', 'epic', 'heroic', 'romantic']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: romanized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['transcribed', 'stains', 'translated', 'refined', 'explains', 'reports', 'identified', 'writes', 'classified', 'reported']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: residences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['dwellings', 'homes', 'mansions', 'houses', 'apartments', 'structures', 'buildings', 'villas', 'properties', 'housing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: ringleaders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['leaders', 'fighters', 'members', 'soldiers', 'officers', 'girls', 'operatives', 'players', 'suspects', 'recruits']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: compound\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['complex', 'facility', 'fortress', 'ranch', 'mansion', 'building', 'premises', 'base', 'villa', 'residence']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: pre-positioned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['positioned', 'poised', 'sited', 'mounted', 'situated', 'placed', 'established', 'installed', 'located', 'stationed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: exclusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['exclude', 'excluded', 'elimination', 'disqualification', 'expulsion', 'removal', 'withdrawal', 'dismissal', 'suspension', 'restriction']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: recognized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['recognised', 'acknowledged', 'accepted', 'hailed', 'identified', 'considered', 'regarded', 'seen', 'honored', 'respected']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: toxins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['chemicals', 'venom', 'poison', 'toxic', 'enzymes', 'bacteria', 'parasites', 'spores', 'acids', 'viruses']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: nominated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['shortlisted', 'selected', 'nominee', 'awarded', 'picked', 'won', 'chosen', 'recognized', 'received', 'voted']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: unprecedented\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['extraordinary', 'unexpected', 'unusual', 'astonishing', 'immense', 'enormous', 'intensified', 'incredible', 'extensive', 'overwhelming']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: erring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['retreating', 'unwanted', 'pursuing', 'chasing', 'interfering', 'anxious', 'advancing', 'dangerous', 'wandering', 'fleeing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: monsters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['beasts', 'zombies', 'creatures', 'robots', 'demons', 'dragons', 'dinosaurs', 'villains', 'vampires', 'ghosts']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: detainees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['prisoners', 'captives', 'inmates', 'people', 'patients', 'hostages', 'students', 'men', 'individuals', 'civilians']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: harassing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['bullying', 'taunting', 'intimidating', 'attacking', 'stalking', 'targeting', 'insulting', 'kidnapping', 'threatening', 'murdering']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: conflicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['contradictory', 'inconsistent', 'mixed', 'weak', 'insufficient', 'negative', 'overwhelming', 'limited', 'lacking', 'compelling']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: announced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['stated', 'declared', 'disclosed', 'confirmed', 'proclaimed', 'reported', 'revealed', 'signaled', 'unveiled', 'acknowledged']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: cementing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['confirming', 'building', 'completing', 'sealing', 'establishing', 'securing', 'creating', 'ensuring', 'concluding', 'announcing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: unleashing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['spreading', 'launching', 'feeding', 'developing', 'possessing', 'pursuing', 'exposing', 'creating', 'supplying', 'providing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: scrutiny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['examination', 'oversight', 'review', 'surveillance', 'inspection', 'criticism', 'evaluation', 'probe', 'critique', 'probing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: suspiciously\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['curiously', 'strangely', 'warily', 'menacing', 'coldly', 'casually', 'vaguely', 'dangerously', 'deliberately', 'suspicious']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: originated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['origins', 'arose', 'developed', 'began', 'existed', 'spawned', 'flourished', 'evolved', 'started', 'occurs']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: replica\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['duplicate', 'reproduction', 'prototype', 'clone', 'imitation', 'copy', 'model', 'version', 'fake', 'mosaic']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: discredits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['assaults', 'insults', 'attacks', 'targets', 'concerns', 'ignores', 'challenges', 'exploits', 'informs', 'feeds']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: vicious\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['ferocious', 'ruthless', 'brutal', 'destructive', 'violent', 'murderous', 'savage', 'cruel', 'nasty', 'bloody']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: strained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['troubled', 'damaged', 'deteriorated', 'crippled', 'weakened', 'hampered', 'complicated', 'torn', 'shaken', 'shattered']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: enacted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['implemented', 'instituted', 'adopted', 'introduced', 'imposed', 'initiated', 'approved', 'executed', 'issued', 'signed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: primed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['targeted', 'treated', 'trained', 'activated', 'captured', 'exposed', 'guided', 'blinded', 'active', 'sensitive']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: probe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['investigation', 'investigate', 'inquiry', 'investigations', 'research', 'study', 'search', 'review', 'dig', 'check']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: aviator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['pilot', 'navigator', 'astronaut', 'observer', 'astronomer', 'officer', 'admiral', 'engineer', 'gunner', 'explorer']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: acquiring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['purchasing', 'buying', 'obtaining', 'earning', 'gaining', 'retaining', 'getting', 'selling', 'withdrawing', 'transferring']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: restive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['occupied', 'volatile', 'troubled', 'impoverished', 'neighbouring', 'breakaway', 'northern', 'western', 'central', 'besieged']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: repression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['persecution', 'oppression', 'suppression', 'torture', 'exploitation', 'harassment', 'detention', 'abuse', 'manipulation', 'intimidation']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: vulnerability\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['vulnerable', 'sensitivity', 'toxicity', 'weakness', 'trauma', 'resistance', 'damage', 'threat', 'weaknesses', 'exposure']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: equipment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['machinery', 'hardware', 'instrumentation', 'instruments', 'facilities', 'apparatus', 'materials', 'gear', 'tools', 'technology']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: stemming\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['arising', 'resulting', 'originating', 'derived', 'spawned', 'ensuing', 'coming', 'leading', 'sparked', 'drawing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: existence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['presence', 'occurrence', 'absence', 'appearance', 'emergence', 'origin', 'disappearance', 'availability', 'activity', 'creation']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: adequate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['adequately', 'sufficient', 'satisfactory', 'proper', 'ample', 'competent', 'appropriate', 'suitable', 'acceptable', 'necessary']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: genuinely\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['truly', 'sincerely', 'really', 'actually', 'clearly', 'naturally', 'obviously', 'specifically', 'definitely', 'deeply']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: proportion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['percentage', 'amount', 'number', 'portion', 'fraction', 'quantity', 'bulk', 'numbers', 'majority', 'volume']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: motive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['motivation', 'cause', 'reason', 'purpose', 'reasons', 'responsibility', 'justification', 'origin', 'basis', 'timing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: determination\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['decision', 'commitment', 'assessment', 'resolve', 'recommendation', 'application', 'willingness', 'effort', 'readiness', 'disposition']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: bloodshed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['violence', 'fighting', 'conflict', 'crisis', 'war', 'pressure', 'struggle', 'fight', 'rhetoric', 'problem']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: credibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['legitimacy', 'reputation', 'prestige', 'sincerity', 'visibility', 'consistency', 'validity', 'popularity', 'reliability', 'competence']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: exclusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['elimination', 'exclude', 'inclusion', 'restriction', 'exemption', 'limitation', 'disqualification', 'dismissal', 'removal', 'exception']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: craven\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['savage', 'reckless', 'cavalier', 'naive', 'cynical', 'destructive', 'dangerous', 'aggressive', 'evil', 'flawed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: usher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['bring', 'foster', 'lead', 'result', 'allow', 'ushered', 'enter', 'assist', 'lock', 'spark']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: anonymity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['comment', 'undisclosed', 'silence', 'clarity', 'condition', 'disbelief', 'anonymous', 'isolation', 'release', 'confidential']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: emerged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['arose', 'stepped', 'surfaced', 'appeared', 'entered', 'reappeared', 'arrived', 'exited', 'burst', 'came']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: indignation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['disgust', 'frustration', 'disappointment', 'outrage', 'alarm', 'anger', 'unease', 'emotion', 'resentment', 'dissatisfaction']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: re-enacting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['staging', 'introducing', 'executing', 'framing', 'repeating', 'resolving', 'airing', 'ending', 'launching', 'concluding']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: detained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['arrested', 'imprisoned', 'jailed', 'incarcerated', 'questioned', 'held', 'kidnapped', 'interned', 'tortured', 'suspended']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: diplomatic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['political', 'trade', 'military', 'bilateral', 'negotiating', 'humanitarian', 'strategic', 'peace', 'legal', 'security']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: troublemakers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['politicians', 'criminals', 'enemies', 'terrorists', 'republicans', 'murderers', 'democrats', 'corrupt', 'heroes', 'idiots']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: abdomen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['torso', 'belly', 'abdominal', 'stomach', 'chest', 'groin', 'body', 'forehead', 'waist', 'thighs']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: pursuit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['exploration', 'quest', 'search', 'assault', 'capture', 'hunt', 'chase', 'chasing', 'hunting', 'racing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: inclusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['incorporation', 'insertion', 'entry', 'placement', 'addition', 'introduction', 'selection', 'exclusion', 'participation', 'integration']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: acquire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['purchase', 'buy', 'develop', 'acquisition', 'obtain', 'sell', 'hire', 'produce', 'receive', 'build']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: confidential\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['secret', 'anonymous', 'legal', 'final', 'secure', 'public', 'binding', 'open', 'valid', 'accurate']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: attentively\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['briefly', 'periodically', 'closely', 'carefully', 'quickly', 'thoroughly', 'immediately', 'generally', 'properly', 'regularly']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: bombardment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['assault', 'siege', 'attack', 'onslaught', 'assaults', 'raids', 'strike', 'offensive', 'attacks', 'occupation']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: colonies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['nests', 'deposits', 'plantations', 'populations', 'groups', 'settlements', 'communities', 'patches', 'collections', 'tribes']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: partially\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['partly', 'slightly', 'momentarily', 'temporarily', 'completely', 'fully', 'substantially', 'totally', 'nearly', 'entirely']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: segregation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['discrimination', 'racism', 'separation', 'censorship', 'exclusion', 'diversity', 'equality', 'isolation', 'segregated', 'integration']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: residence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['dwelling', 'mansion', 'home', 'house', 'villa', 'apartment', 'palace', 'compound', 'estate', 'facility']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sanctions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['penalties', 'restrictions', 'measures', 'blockade', 'resolutions', 'inspections', 'controls', 'rules', 'inspectors', 'pressure']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: threatened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['attacked', 'compromised', 'targeted', 'attempted', 'harassed', 'challenged', 'insulted', 'overwhelmed', 'cursed', 'terrified']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: intimidate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['influence', 'manipulate', 'isolate', 'undermine', 'insult', 'infiltrate', 'provoke', 'deter', 'interrupt', 'attack']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sought\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['requested', 'wanted', 'demanded', 'obtained', 'attempted', 'claimed', 'pursued', 'contested', 'found', 'secured']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: bureau\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['agency', 'department', 'office', 'board', 'commission', 'organization', 'unit', 'panel', 'bureaucracy', 'committee']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: anonymity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['comment', 'clarity', 'silence', 'explanation', 'privacy', 'condition', 'release', 'unknown', 'disbelief', 'anonymous']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: acclaimed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['lauded', 'revered', 'acknowledged', 'respected', 'celebrated', 'honored', 'hailed', 'recognized', 'honoured', 'praised']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: enquiries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['inquiries', 'pleas', 'litigation', 'inquiry', 'investigations', 'examination', 'questioning', 'negotiations', 'proceedings', 'processing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: commissioned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['appointed', 'hired', 'inspired', 'ordained', 'authorized', 'ordered', 'directed', 'summoned', 'assigned', 'compelled']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: scrapped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['discarded', 'abandoned', 'dismantled', 'cancelled', 'discontinued', 'dropped', 'canceled', 'withdrawn', 'reinstated', 'terminated']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: successive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['consecutive', 'subsequent', 'succeeding', 'straight', 'separate', 'prior', 'respective', 'preceding', 'distinct', 'particular']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: degenerate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['evolve', 'transition', 'develop', 'dissolve', 'transform', 'descend', 'convert', 'reverse', 'merge', 'spiral']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: offender\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['attacker', 'accused', 'inmate', 'addict', 'enemy', 'applicant', 'officer', 'adversary', 'adult', 'employee']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: touted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['highlighted', 'lauded', 'cited', 'acknowledged', 'denounced', 'mentioned', 'blasted', 'praised', 'noted', 'repeated']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: anonymity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['clarity', 'comment', 'silence', 'undisclosed', 'anonymous', 'unknown', 'explanation', 'privacy', 'confidential', 'release']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: purifying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['cleansing', 'washing', 'transforming', 'loving', 'refining', 'protecting', 'strengthening', 'preserving', 'filling', 'restoring']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: announced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['disclosed', 'stated', 'declared', 'indicated', 'confirmed', 'revealed', 'notified', 'admitted', 'reported', 'proposed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: residing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['living', 'resident', 'dwelling', 'located', 'operating', 'housing', 'growing', 'active', 'lived', 'settled']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: plundering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['dumping', 'consuming', 'processing', 'looting', 'shipping', 'sealing', 'destroying', 'mining', 'distributing', 'smashing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: clemency\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['suspension', 'immunity', 'privilege', 'probation', 'protection', 'relief', 'exemption', 'power', 'duty', 'amnesty']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: enduring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['lasting', 'ongoing', 'persistent', 'striking', 'compelling', 'sustained', 'active', 'outstanding', 'effective', 'inherent']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sanctuary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['refuge', 'shelter', 'habitat', 'haven', 'stronghold', 'hideout', 'mecca', 'asylum', 'protection', 'space']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: demonstrations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['protests', 'rallies', 'marches', 'gatherings', 'riots', 'celebrations', 'clashes', 'concerts', 'parades', 'events']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: allege\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['assert', 'claim', 'admit', 'advocate', 'urge', 'accuse', 'acknowledge', 'suspect', 'institute', 'demand']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: unsanctioned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['abandoned', 'ongoing', 'isolated', 'unsuccessful', 'impromptu', 'empty', 'unauthorized', 'unofficial', 'unlawful', 'attempted']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: bloodshed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['carnage', 'violence', 'slaughter', 'unrest', 'fighting', 'chaos', 'clashes', 'conflict', 'massacre', 'riots']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: adversary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['opponent', 'enemy', 'foe', 'ally', 'antagonist', 'opposing', 'attacker', 'opposition', 'agent', 'advocate']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: alleged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['suspected', 'allegedly', 'purported', 'attempted', 'reported', 'suspect', 'apparent', 'illegal', 'rampant', 'repeated']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: enigmatic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['enigma', 'cryptic', 'mysterious', 'obscure', 'eccentric', 'elusive', 'ambiguous', 'intriguing', 'exotic', 'eerie']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: renderings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['rendering', 'sketches', 'graphics', 'drawings', 'carvings', 'depictions', 'painting', 'textures', 'constructions', 'mapping']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: warily\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['cautiously', 'eagerly', 'confidently', 'pointedly', 'warmly', 'enthusiastically', 'fiercely', 'vigorously', 'broadly', 'proudly']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: evaluated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['assessed', 'analyzed', 'reviewed', 'examined', 'tested', 'inspected', 'investigated', 'checked', 'judged', 'screened']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: nobility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['aristocracy', 'nobles', 'gentry', 'clergy', 'royalty', 'peasants', 'wealthy', 'dukes', 'royals', 'princes']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: surpassed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['exceeded', 'overshadowed', 'superseded', 'matched', 'topped', 'defeated', 'replaced', 'augmented', 'exceeding', 'preceded']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: asserted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['affirmed', 'claimed', 'stated', 'proclaimed', 'implied', 'invoked', 'expressed', 'demonstrated', 'acknowledged', 'indicated']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: colonies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['clones', 'cells', 'mutants', 'parasites', 'bees', 'ants', 'species', 'plants', 'colonists', 'populations']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: erupted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['flared', 'arose', 'ensued', 'escalated', 'raged', 'ignited', 'occurred', 'emerged', 'unfolded', 'intensified']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: deployed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['stationed', 'mobilized', 'employed', 'dispatched', 'enlisted', 'hired', 'recruited', 'sent', 'volunteered', 'utilized']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: militiamen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['militia', 'militias', 'fighters', 'thugs', 'mercenaries', 'guerrillas', 'soldiers', 'militants', 'insurgents', 'bandits']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: carnage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['mayhem', 'devastation', 'chaos', 'violence', 'slaughter', 'catastrophe', 'brutality', 'tragedy', 'misery', 'disaster']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: stint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['tenure', 'stay', 'period', 'career', 'outing', 'run', 'break', 'time', 'appearance', 'job']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: repossessed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['distressed', 'purchased', 'lost', 'borrowed', 'troubled', 'stolen', 'managed', 'rented', 'leased', 'personal']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: investigating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['probing', 'examining', 'monitoring', 'researching', 'analyzing', 'assessing', 'pursuing', 'exploring', 'confirming', 'discovering']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: atrocities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['horrors', 'crimes', 'abuses', 'murders', 'carnage', 'genocide', 'killings', 'brutality', 'offenses', 'attacks']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: underlying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['inherent', 'intrinsic', 'fundamental', 'implicit', 'core', 'internal', 'basic', 'implied', 'overall', 'ongoing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: introduced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['reintroduced', 'adopted', 'added', 'opened', 'brought', 'promoted', 'presented', 'accepted', 'marketed', 'released']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: adamantly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['strongly', 'firmly', 'fiercely', 'aggressively', 'vigorously', 'actively', 'flatly', 'bitterly', 'overwhelmingly', 'heavily']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: candidacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['nomination', 'candidate', 'campaign', 'bid', 'nominee', 'presidency', 'candidates', 'proposal', 'challenger', 'vote']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: disputed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['contested', 'denied', 'questioned', 'rejected', 'asserted', 'claimed', 'challenged', 'acknowledged', 'sought', 'alleged']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: auctioneers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['dealers', 'producers', 'sellers', 'owners', 'hunters', 'merchants', 'specialists', 'collectors', 'traders', 'buyers']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: bloodshed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['violence', 'carnage', 'suffering', 'fighting', 'chaos', 'clashes', 'unrest', 'slaughter', 'looting', 'riot']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: relinquish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['reserve', 'retain', 'reclaim', 'restore', 'change', 'raise', 'return', 'regain', 'defend', 'use']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: indicating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['confirming', 'implying', 'announcing', 'stating', 'declaring', 'informing', 'showing', 'revealing', 'suggesting', 'explaining']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: organisers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['organizers', 'promoters', 'sponsors', 'participants', 'owners', 'officials', 'holders', 'staff', 'workers', 'group']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: clearance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['authorization', 'certification', 'permission', 'placement', 'protection', 'accreditation', 'recognition', 'endorsement', 'acceptance', 'approval']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sympathy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['empathy', 'compassion', 'affection', 'support', 'solidarity', 'respect', 'pity', 'sadness', 'appreciation', 'concern']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: composition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['recording', 'score', 'piece', 'arrangement', 'melody', 'record', 'instrument', 'artwork', 'material', 'music']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sanctions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['penalties', 'punishments', 'fines', 'controls', 'restrictions', 'regulations', 'resolutions', 'policies', 'incentives', 'measures']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: executed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['hanged', 'beheaded', 'imprisoned', 'assassinated', 'jailed', 'murdered', 'prosecuted', 'convicted', 'arrested', 'tortured']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: flashpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['buffer', 'field', 'target', 'battlefield', 'objective', 'observation', 'tactical', 'remote', 'combat', 'coastal']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: assumption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['perception', 'assertion', 'prediction', 'hypothesis', 'assume', 'observation', 'belief', 'expectation', 'inference', 'impression']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: apparent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['obvious', 'evident', 'visible', 'immediate', 'explicit', 'unmistakable', 'absolute', 'identified', 'extreme', 'unspecified']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: appealed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['petitioned', 'argued', 'begged', 'lobbied', 'pleaded', 'urged', 'applied', 'pressed', 'fought', 'demanded']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: casualties\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['fatalities', 'deaths', 'losses', 'injuries', 'killed', 'killings', 'scores', 'victims', 'incidents', 'injured']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: qualify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['qualified', 'register', 'enter', 'compete', 'apply', 'advance', 'participate', 'tie', 'appear', 'form']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: acquisition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['purchase', 'takeover', 'merger', 'transaction', 'sale', 'development', 'venture', 'investment', 'move', 'project']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: pedestal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['platform', 'pillar', 'shelf', 'mount', 'panel', 'throne', 'bench', 'mound', 'slab', 'plate']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sustained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['prolonged', 'persistent', 'continued', 'severe', 'consistent', 'steady', 'vigorous', 'active', 'sporadic', 'repeated']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: prevailing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['reigning', 'prevalent', 'predominant', 'existing', 'brewing', 'operating', 'dominant', 'changing', 'engaging', 'competing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: imposing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['enforcing', 'asserting', 'implementing', 'placing', 'installing', 'exercising', 'projecting', 'forcing', 'applying', 'issuing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: Initially\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['originally', 'briefly', 'previously', 'subsequently', 'eventually', 'ultimately', 'officially', 'technically', 'formerly', 'earlier']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: regime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['administration', 'government', 'authority', 'leadership', 'army', 'opposition', 'authorities', 'state', 'military', 'republic']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: dominated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['governed', 'controlled', 'powered', 'surrounded', 'ruled', 'run', 'penetrated', 'led', 'backed', 'represented']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: authorized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['authorised', 'mandated', 'permitted', 'allowed', 'empowered', 'sanctioned', 'required', 'ordered', 'licensed', 'approved']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: slated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['scheduled', 'planned', 'expected', 'projected', 'anticipated', 'likely', 'set', 'planning', 'predicted', 'going']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: regrettable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['unfortunate', 'embarrassing', 'painful', 'catastrophic', 'unexpected', 'disastrous', 'tragic', 'serious', 'terrible', 'significant']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: regime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['junta', 'government', 'administration', 'revolutionary', 'occupation', 'opposition', 'loyalist', 'army', 'authorities', 'resistance']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: demonstrations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['protests', 'marches', 'rallies', 'riots', 'protest', 'celebrations', 'demonstrators', 'clashes', 'disturbances', 'movements']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: summonsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['summons', 'summoned', 'called', 'ordered', 'sent', 'appointed', 'brought', 'asked', 'nominated', 'cleared']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sentiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['feeling', 'attitudes', 'anger', 'rhetoric', 'feelings', 'mood', 'resentment', 'outrage', 'frustration', 'discourse']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: surveillance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['monitoring', 'reconnaissance', 'spying', 'spy', 'inspection', 'observation', 'screening', 'interrogation', 'investigative', 'monitor']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: preliminary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['tentative', 'final', 'formal', 'initial', 'provisional', 'summary', 'unofficial', 'partial', 'official', 'actual']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: plethora\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['multitude', 'wealth', 'array', 'myriad', 'breadth', 'variety', 'host', 'spectrum', 'diversity', 'selection']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: implemented\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['enacted', 'adopted', 'formulated', 'accomplished', 'achieved', 'enforced', 'introduced', 'executed', 'drafted', 'developed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: concentration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['composition', 'distribution', 'accumulation', 'density', 'disposition', 'placement', 'intensity', 'selection', 'concentrate', 'storage']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: controversial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['contentious', 'unpopular', 'problematic', 'provocative', 'ambiguous', 'taboo', 'challenging', 'confusing', 'ridiculous', 'uncomfortable']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: acquisition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['purchase', 'takeover', 'transaction', 'merger', 'sale', 'offering', 'development', 'investment', 'expansion', 'deal']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: outlining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['explaining', 'detailing', 'highlighting', 'defining', 'confirming', 'announcing', 'describing', 'listing', 'stating', 'covering']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: approximately\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['roughly', 'about', 'nearly', 'almost', 'around', 'approx', 'exactly', 'some', 'just', 'over']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: pinnacle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['apex', 'zenith', 'peak', 'spire', 'summit', 'colossal', 'top', 'towering', 'maximum', 'grand']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: uprising\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['revolt', 'insurrection', 'rebellion', 'insurgency', 'revolution', 'struggle', 'mutiny', 'unrest', 'protests', 'resistance']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: overt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['excessive', 'over', 'aggressive', 'improper', 'uneven', 'poor', 'low', 'clumsy', 'rough', 'inappropriate']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: probe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['investigation', 'inquiry', 'investigations', 'research', 'study', 'search', 'review', 'dig', 'check', 'digging']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: herald\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['signal', 'represent', 'announce', 'forecast', 'promote', 'mark', 'inspire', 'celebrate', 'spark', 'indicate']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: disgraceful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['humiliating', 'disgusting', 'disgrace', 'embarrassing', 'outrageous', 'foolish', 'rude', 'folly', 'unfair', 'improper']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: ominous\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['sinister', 'disturbing', 'cryptic', 'ambiguous', 'strange', 'scary', 'vague', 'suspicious', 'ironic', 'ugly']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: indication\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['indicator', 'confirmation', 'evidence', 'sign', 'proof', 'assurance', 'indicative', 'indicate', 'endorsement', 'implication']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: attributed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['ascribed', 'credited', 'recounted', 'explained', 'described', 'cited', 'blamed', 'claimed', 'noted', 'acknowledged']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: impeachment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['disqualification', 'bribery', 'expulsion', 'prosecution', 'dismissal', 'resignation', 'reelection', 'ascension', 'murder', 'removal']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: infamous\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['notorious', 'famous', 'memorable', 'controversial', 'outrageous', 'horrific', 'bizarre', 'notable', 'hideous', 'vicious']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: annul\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['cancel', 'terminate', 'honor', 'complete', 'implement', 'alter', 'suspend', 'amend', 'modify', 'announce']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: disassociate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['divorce', 'withdraw', 'remove', 'transform', 'eliminate', 'isolate', 'purge', 'distance', 'separate', 'divert']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: electoral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['election', 'voter', 'political', 'electorate', 'legislative', 'voting', 'democratic', 'constitutional', 'presidential', 'campaign']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: emissions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['concentrations', 'gases', 'impacts', 'footprint', 'output', 'hits', 'spectra', 'filters', 'outputs', 'footprints']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: eligibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['eligible', 'enrollment', 'registration', 'qualification', 'authorization', 'qualifying', 'application', 'membership', 'entry', 'requirement']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: bombardment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['bombing', 'assault', 'siege', 'raid', 'attack', 'raids', 'blast', 'offensive', 'bombings', 'explosion']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: crippling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['crushing', 'devastating', 'damaging', 'hitting', 'passing', 'severe', 'falling', 'massive', 'huge', 'increasing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: regime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['government', 'dictatorship', 'junta', 'administration', 'army', 'rulers', 'authorities', 'country', 'cabinet', 'leadership']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: mandated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['sanctioned', 'authorized', 'required', 'approved', 'instituted', 'ordered', 'allowed', 'recommended', 'demanded', 'imposed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: rendition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['rendering', 'performance', 'staging', 'presentation', 'recording', 'representation', 'version', 'expression', 'imitation', 'installation']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: morph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['spiral', 'fade', 'plunge', 'descend', 'rise', 'slide', 'explode', 'shift', 'sink', 'evolve']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: authorized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['authorised', 'permitted', 'allowed', 'licensed', 'entitled', 'directed', 'empowered', 'available', 'registered', 'eligible']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: internship\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['apprenticeship', 'employment', 'residency', 'intern', 'job', 'assignment', 'occupation', 'application', 'audition', 'orientation']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: tragedy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['catastrophe', 'disaster', 'crisis', 'nightmare', 'death', 'crime', 'miracle', 'loss', 'danger', 'panic']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: monitoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['observing', 'tracking', 'surveying', 'inspecting', 'analyzing', 'measuring', 'reviewing', 'watching', 'overseeing', 'supervising']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: provisioning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['delivery', 'distribution', 'providing', 'filling', 'payment', 'procurement', 'logistics', 'financing', 'contracting', 'supporting']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: downplayed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['challenged', 'exploited', 'ignored', 'beaten', 'repeated', 'pushed', 'rejected', 'upheld', 'embraced', 'defended']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: tragedy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['disaster', 'catastrophe', 'devastation', 'carnage', 'crisis', 'trauma', 'drama', 'tragic', 'scandal', 'incident']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: authoritarian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['corrupt', 'conservative', 'liberal', 'nationalist', 'militant', 'democratic', 'radical', 'aggressive', 'paranoid', 'unpopular']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: prohibits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['forbade', 'permits', 'bars', 'forbid', 'prevents', 'allows', 'outlaws', 'ban', 'mandates', 'regulates']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: prevailing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['reigning', 'prevalent', 'predominant', 'brewing', 'operating', 'changing', 'engaging', 'growing', 'dominant', 'present']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: skittish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['reserved', 'bald', 'fiery', 'shy', 'selfish', 'cocky', 'ignorant', 'quiet', 'arrogant', 'humble']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: obliged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['compelled', 'authorised', 'required', 'instructed', 'empowered', 'permitted', 'persuaded', 'forced', 'authorized', 'ordered']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: ouster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['resignation', 'overthrow', 'removal', 'dismissal', 'ou', 'departure', 'seizure', 'downfall', 'arrest', 'retirement']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: mainstream\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['crossover', 'widespread', 'global', 'western', 'worldwide', 'international', 'critical', 'broad', 'major', 'moderate']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: appealing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['challenging', 'striking', 'promising', 'begging', 'lobbying', 'pressing', 'pushing', 'encouraging', 'wanting', 'campaigning']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: surveillance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['reconnaissance', 'monitoring', 'spying', 'observation', 'spy', 'monitor', 'investigative', 'protection', 'tracking', 'security']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: cooperated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['intervened', 'collaborated', 'assisted', 'engaged', 'participated', 'helped', 'partnered', 'coordinated', 'joined', 'acted']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sought\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['requested', 'wanted', 'demanded', 'craved', 'found', 'obtained', 'offered', 'begged', 'urged', 'attempted']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: debris\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['rubble', 'wreckage', 'dust', 'junk', 'trash', 'dirt', 'rubbish', 'material', 'waste', 'mud']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sanctions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['penalties', 'punishments', 'restrictions', 'fines', 'punishment', 'sentences', 'inspections', 'measures', 'rules', 'resolutions']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: acquisition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['purchase', 'takeover', 'acquiring', 'acquire', 'transaction', 'development', 'merger', 'sale', 'investment', 'expansion']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: pledges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['promises', 'declares', 'guarantees', 'emphasizes', 'supports', 'offers', 'recognizes', 'states', 'establishes', 'ensures']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: debris\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['rubble', 'wreckage', 'dust', 'trash', 'garbage', 'junk', 'waste', 'fragments', 'pile', 'fragment']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: suspicious\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['wary', 'curious', 'suspect', 'skeptical', 'paranoid', 'fearful', 'aware', 'alarmed', 'frightened', 'worried']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: condolences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['apologies', 'prayers', 'sympathy', 'comments', 'warnings', 'petitions', 'statements', 'pleas', 'complaints', 'letters']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: impeach\n",
      "Error occurred: list indices must be integers or slices, not str\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: unleashed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['launched', 'spawned', 'ignited', 'initiated', 'introduced', 'provoked', 'induced', 'triggered', 'sparked', 'generated']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: inaugural\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['first', 'premier', 'annual', '50th', 'final', '25th', '35th', '1st', '100th', 'senior']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: ongoing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['active', 'intense', 'evolving', 'urgent', 'extensive', 'annual', 'existing', 'internal', 'increasing', 'acute']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: hostility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['hatred', 'resentment', 'distrust', 'bitterness', 'anger', 'indifference', 'prejudice', 'hate', 'resistance', 'disagreement']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: incurred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['experienced', 'sustained', 'inflicted', 'borne', 'suffered', 'generated', 'caused', 'raised', 'involved', 'imposed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: quelled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['suppressed', 'provoked', 'ignited', 'sparked', 'subdued', 'escalated', 'intensified', 'dispersed', 'unleashed', 'extinguished']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: detained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['arrested', 'jailed', 'imprisoned', 'incarcerated', 'seized', 'freed', 'expelled', 'deported', 'held', 'captured']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: insurgents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['militants', 'rebels', 'guerrillas', 'gunmen', 'terrorists', 'radicals', 'militias', 'fighters', 'civilians', 'activists']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: distinct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['distinctive', 'unique', 'distinguished', 'diverse', 'characteristic', 'varied', 'subtle', 'simple', 'elaborate', 'particular']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: defected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['emigrated', 'surrendered', 'fled', 'departed', 'vanished', 'moved', 'disappeared', 'escaped', 'retired', 'withdrawn']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: critically\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['seriously', 'gravely', 'severely', 'fatally', 'profoundly', 'terribly', 'deeply', 'badly', 'horribly', 'highly']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: authorities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['officials', 'police', 'investigators', 'officers', 'prosecutors', 'agents', 'agencies', 'lawyers', 'leaders', 'personnel']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: regime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['dictatorship', 'administration', 'government', 'junta', 'rule', 'leadership', 'army', 'opposition', 'authority', 'program']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: envisions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['proposes', 'advocates', 'seeks', 'supports', 'promises', 'sees', 'plans', 'permits', 'targets', 'allows']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: estimate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['estimation', 'prediction', 'forecast', 'calculation', 'assessment', 'guess', 'analysis', 'count', 'projection', 'finding']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: significance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['importance', 'relevance', 'symbolism', 'value', 'seriousness', 'meaning', 'impact', 'implications', 'legitimacy', 'purpose']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: neighbouring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['neighboring', 'nearby', 'adjoining', 'adjacent', 'northern', 'bordering', 'southern', 'western', 'southeastern', 'surrounding']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: insurgents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['militants', 'rebels', 'guerrillas', 'terrorists', 'attackers', 'militias', 'insurgency', 'civilians', 'fighters', 'loyalists']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: clemency\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['pardon', 'amnesty', 'probation', 'exemption', 'bail', 'immunity', 'merit', 'privilege', 'benefits', 'protection']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: authorities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['officials', 'police', 'investigators', 'prosecutors', 'officers', 'detectives', 'doctors', 'lawyers', 'witnesses', 'villagers']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: obscene\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['insulting', 'outrageous', 'disgusting', 'inappropriate', 'vulgar', 'ridiculous', 'vile', 'abusive', 'rude', 'offensive']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: bespoke\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['stimulating', 'special', 'direct', 'prompt', 'valuable', 'exciting', 'innovative', 'intense', 'advance', 'extended']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: instrument\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['instrumentation', 'organ', 'equipment', 'apparatus', 'element', 'object', 'item', 'engine', 'undertaking', 'arm']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: emerge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['appear', 'enter', 'arise', 'arrive', 'appears', 'rise', 'descend', 'disappear', 'spring', 'form']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: insurgency\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['rebellion', 'insurrection', 'uprising', 'conflict', 'insurgents', 'resistance', 'violence', 'militia', 'movement', 'war']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: emerge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['exit', 'arise', 'depart', 'recover', 'arrive', 'descend', 'withdraw', 'retire', 'rise', 'enter']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: ensued\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['proceeded', 'commenced', 'erupted', 'followed', 'unfolded', 'resulted', 'culminated', 'occurred', 'arose', 'prevailed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: regime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['program', 'dictatorship', 'system', 'programme', 'junta', 'administration', 'policy', 'era', 'scheme', 'law']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: unearthed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['excavated', 'uncovered', 'discovered', 'rediscovered', 'retrieved', 'found', 'recovered', 'revealed', 'collected', 'dug']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: strategic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['tactical', 'strategy', 'operational', 'central', 'strategically', 'regional', 'military', 'security', 'diplomatic', 'fiscal']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: metropolitan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['metro', 'metropolis', 'urban', 'municipal', 'regional', 'city', 'central', 'downtown', 'suburban', 'public']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: exhibitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['exhibits', 'shows', 'displays', 'concerts', 'demonstrations', 'collections', 'installations', 'galleries', 'sculptures', 'festivals']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: prospects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['chances', 'hopes', 'potential', 'possibilities', 'possibility', 'opportunities', 'likelihood', 'outlook', 'chance', 'hope']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: surveillance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['reconnaissance', 'monitoring', 'observation', 'spy', 'monitor', 'tracking', 'inspection', 'spying', 'security', 'radar']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: preoccupied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['obsessed', 'distracted', 'bothered', 'consumed', 'bored', 'troubled', 'concerned', 'frustrated', 'fascinated', 'agitated']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: conservative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['liberal', 'radical', 'tory', 'pious', 'moderate', 'leftist', 'secular', 'affluent', 'minority', 'orthodox']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: documented\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['recorded', 'identified', 'reported', 'recognized', 'discovered', 'confirmed', 'uncovered', 'established', 'listed', 'represented']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: awoken\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['awakened', 'woke', 'woken', 'wake', 'waking', 'jolted', 'startled', 'confronted', 'disturbed', 'alerted']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: inadequate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['insufficient', 'poor', 'ineffective', 'incomplete', 'failing', 'unsuitable', 'inaccurate', 'impaired', 'improper', 'weak']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: challenging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['opposing', 'questioning', 'attacking', 'supporting', 'pursuing', 'rejecting', 'condemning', 'defending', 'asserting', 'compelling']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: assassinated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['murdered', 'slain', 'killed', 'executed', 'beheaded', 'kidnapped', 'abducted', 'captured', 'attacked', 'arrested']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: datum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['dat', 'mark', 'sign', 'norm', 'code', 'index', 'point', 'locality', 'signal', 'zone']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: eligible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['eligibility', 'qualified', 'qualify', 'allowed', 'authorized', 'available', 'registered', 'ineligible', 'permitted', 'qualifying']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: roamed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['stalked', 'circled', 'raked', 'buzzed', 'dotted', 'swept', 'covered', 'filled', 'lined', 'pierced']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: diplomatically\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['informally', 'politically', 'directly', 'formally', 'successfully', 'administratively', 'briefly', 'effectively', 'technically', 'peacefully']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: conjure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['draw', 'summon', 'make', 'create', 'bring', 'force', 'shape', 'stir', 'forge', 'build']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: commemorating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['honoring', 'celebrating', 'remembering', 'marking', 'representing', 'documenting', 'recognizing', 'celebrate', 'depicting', 'recalling']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: legislaton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['action', 'relief', 'activism', 'actions', 'movement', 'movements', 'reform', 'discrimination', 'policy', 'rights']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: dissidents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['militants', 'revolutionaries', 'activists', 'rebels', 'opposition', 'individuals', 'minorities', 'prisoners', 'civilians', 'criminals']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: problematic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['unacceptable', 'inappropriate', 'difficult', 'inadequate', 'unnecessary', 'irrelevant', 'problem', 'desirable', 'excessive', 'insufficient']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: ingested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['swallowed', 'absorbed', 'consumed', 'extracted', 'stirred', 'eaten', 'injected', 'squeezed', 'drunk', 'took']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: definitive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['definite', 'concrete', 'final', 'precise', 'comprehensive', 'tentative', 'clear', 'complete', 'formal', 'provisional']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: compiled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['produced', 'gathered', 'collected', 'assembled', 'submitted', 'obtained', 'retrieved', 'conducted', 'prepared', 'developed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: criteria\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['requirements', 'standards', 'parameters', 'guidelines', 'requirement', 'standard', 'specifications', 'conditions', 'objectives', 'qualifications']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: crippling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['crushing', 'devastating', 'damaging', 'hitting', 'massive', 'rising', 'passing', 'falling', 'increasing', 'failing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: unsanctioned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['unsuccessful', 'isolated', 'impromptu', 'unauthorized', 'empty', 'unofficial', 'attempted', 'unarmed', 'organized', 'armed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: traumatised\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['devastated', 'distraught', 'pained', 'troubled', 'horrified', 'overwhelmed', 'distressed', 'disturbed', 'frustrated', 'shaken']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: bole\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['fin', 'shell', 'cone', 'line', 'stem', 'base', 'body', 'ridge', 'groove', 'branch']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: ignited\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['sparked', 'fueled', 'triggered', 'provoked', 'stirred', 'erupted', 'culminated', 'intensified', 'heated', 'deepened']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: pertaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['relating', 'related', 'regarding', 'regards', 'referring', 'corresponding', 'concerning', 'regard', 'unrelated', 'pointing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: operative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['agent', 'officer', 'informant', 'activist', 'employee', 'investigator', 'official', 'aide', 'assassin', 'active']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sole\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['primary', 'ultimate', 'rightful', 'complete', 'permanent', 'true', 'legitimate', 'direct', 'genuine', 'last']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: collaborated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['partnered', 'worked', 'teamed', 'contributed', 'engaged', 'assisted', 'participated', 'coordinated', 'competed', 'helped']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: trophies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['medals', 'titles', 'awards', 'honors', 'prizes', 'victories', 'championships', 'wins', 'records', 'competitions']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: backlash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['bias', 'outrage', 'reaction', 'fallout', 'retaliation', 'resentment', 'retribution', 'hostility', 'anger', 'protests']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: counteractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['advances', 'strikes', 'attacks', 'retaliation', 'operations', 'action', 'intervention', 'threats', 'moves', 'actions']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: impasse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['breakdown', 'compromise', 'disagreement', 'tension', 'dispute', 'disagreements', 'delay', 'conflict', 'crisis', 'failure']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: defiance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['disregard', 'imitation', 'opposition', 'retaliation', 'protest', 'disapproval', 'support', 'spite', 'light', 'favor']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: implied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['indicated', 'hinted', 'asserted', 'stated', 'assumed', 'claimed', 'suggested', 'noted', 'predicted', 'insisted']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: marred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['tainted', 'hampered', 'plagued', 'clouded', 'overshadowed', 'interrupted', 'damaged', 'disrupted', 'complicated', 'haunted']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: departure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['leaving', 'arrival', 'removal', 'release', 'exit', 'leave', 'retirement', 'return', 'dismissal', 'retiring']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: compound\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['facility', 'complex', 'building', 'base', 'mansion', 'warehouse', 'ranch', 'residence', 'hideout', 'field']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: unprecedented\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['extraordinary', 'immense', 'enormous', 'outrageous', 'explosive', 'intensified', 'intense', 'extensive', 'incredible', 'overwhelming']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: enacted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['implemented', 'instituted', 'adopted', 'introduced', 'passed', 'executed', 'approved', 'installed', 'enforced', 'established']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: enactment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['passage', 'incorporation', 'introduction', 'execution', 'passing', 'implementation', 'proclamation', 'signing', 'ratification', 'release']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: evacuation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['evacuate', 'retreat', 'expulsion', 'exodus', 'relocation', 'deportation', 'escape', 'removal', 'withdrawal', 'departure']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['predict', 'predicting', 'forecast', 'assumption', 'suggestion', 'projection', 'assessment', 'calculation', 'estimate', 'warning']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: acquisition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['acquiring', 'purchase', 'takeover', 'buying', 'procurement', 'creation', 'sale', 'launch', 'purchases', 'privatization']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: investigate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['investigation', 'probe', 'examine', 'inspect', 'explore', 'study', 'inquiry', 'research', 'analyze', 'monitor']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: slumped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['tumbled', 'sagged', 'retreated', 'weakened', 'plunged', 'collapsed', 'fallen', 'dropped', 'fell', 'sunk']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: ambushed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['attacked', 'assaulted', 'intercepted', 'captured', 'chased', 'bombed', 'targeted', 'spotted', 'robbed', 'defeated']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: conclusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['realization', 'climax', 'end', 'result', 'outcome', 'ending', 'point', 'beginning', 'start', 'completion']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: rebound\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['bounce', 'comeback', 'recovery', 'gain', 'boost', 'rally', 'surge', 'reversal', 'improvement', 'return']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: diagnosed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['cured', 'detected', 'identified', 'discovered', 'developed', 'treated', 'solved', 'fixed', 'registered', 'resolved']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: boycott\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['disrupt', 'reject', 'block', 'cancel', 'delay', 'skip', 'abandon', 'ignore', 'oppose', 'bypass']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: campaigning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['lobbying', 'fundraising', 'voting', 'polling', 'fighting', 'propaganda', 'politics', 'debate', 'struggle', 'preparations']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: assassinated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['murdered', 'slain', 'killed', 'executed', 'deposed', 'beheaded', 'hanged', 'ousted', 'toppled', 'shot']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: detonated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['exploded', 'ignited', 'planted', 'struck', 'loaded', 'dropped', 'crashed', 'destroyed', 'bombed', 'launched']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: clamoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['yearning', 'hunting', 'longing', 'pressing', 'eager', 'bidding', 'battling', 'desperate', 'lobbying', 'fighting']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: credibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['legitimacy', 'prestige', 'confidence', 'reputation', 'competence', 'reliability', 'integrity', 'loyalty', 'stability', 'authenticity']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: outskirts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['edges', 'edge', 'periphery', 'fringe', 'outside', 'doorstep', 'shores', 'streets', 'perimeter', 'suburbs']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: elite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['aristocracy', 'establishment', 'class', 'minority', 'minorities', 'dynasty', 'classes', 'rulers', 'junta', 'regime']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: vulnerable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['vulnerability', 'susceptible', 'exposed', 'sensitive', 'prone', 'resistant', 'helpless', 'subjected', 'alert', 'subject']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: reaffirmed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['affirmed', 'reiterated', 'confirmed', 'emphasized', 'reinforced', 'renewed', 'repeated', 'clarified', 'acknowledged', 'stressed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: harassed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['assaulted', 'insulted', 'humiliated', 'tortured', 'intimidated', 'teased', 'attacked', 'abused', 'challenged', 'approached']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: safeguarding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['protecting', 'preserving', 'defending', 'ensuring', 'securing', 'guarding', 'maintaining', 'enforcing', 'strengthening', 'promoting']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: subsidiaries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['affiliates', 'partners', 'companies', 'enterprises', 'branches', 'headquarters', 'employees', 'associates', 'assets', 'properties']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: imprecise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['conservative', 'efficient', 'compact', 'crude', 'precise', 'sensitive', 'robust', 'rigid', 'accurate', 'sharp']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: surged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['soared', 'swelled', 'spiked', 'accelerated', 'raced', 'rose', 'escalated', 'raged', 'intensified', 'exploded']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: repealing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['removing', 'reforming', 'eliminating', 'terminating', 'cutting', 'ending', 'adopting', 'stopping', 'replacing', 'implementing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: obvious\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['apparent', 'clear', 'definite', 'explicit', 'visible', 'immediate', 'direct', 'plausible', 'familiar', 'significant']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: resilience\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['strength', 'credibility', 'quality', 'effectiveness', 'readiness', 'persistence', 'morale', 'performance', 'legitimacy', 'continuity']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: revert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['rev', 'shift', 'retreat', 'return', 'turn', 'tilt', 'switch', 'fade', 'default', 'transition']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: vicinity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['proximity', 'neighbourhood', 'area', 'locality', 'neighborhood', 'localities', 'location', 'backyard', 'surroundings', 'region']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: riposte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['blow', 'toast', 'challenge', 'betrayal', 'fabrication', 'concession', 'traitor', 'credit', 'nod', 'disappointment']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: accumulation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['accumulate', 'aggregation', 'precipitation', 'collection', 'melting', 'redistribution', 'absorption', 'diffusion', 'storage', 'production']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sustained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['serious', 'prolonged', 'severe', 'persistent', 'aggravated', 'suffered', 'active', 'sporadic', 'extensive', 'repeated']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: vacationing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['visiting', 'traveling', 'touring', 'staying', 'travelling', 'camping', 'resting', 'lodging', 'relaxing', 'living']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: allegations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['accusations', 'charges', 'accusation', 'claims', 'revelations', 'complaints', 'rumours', 'rumors', 'reports', 'suspicions']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: integral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['essential', 'integrated', 'auxiliary', 'important', 'incorporated', 'effective', 'artificial', 'extra', 'active', 'exclusive']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: monument\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['memorial', 'shrine', 'statue', 'mausoleum', 'sculpture', 'tombstone', 'temple', 'museum', 'plaque', 'tomb']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: homicides\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['murders', 'murder', 'killings', 'crimes', 'deaths', 'fatalities', 'accidents', 'crime', 'incidents', 'cases']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: fatalities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['deaths', 'casualties', 'accidents', 'incidents', 'murders', 'killings', 'injuries', 'corpses', 'arrests', 'cases']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: underscores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['reveals', 'confirms', 'illustrates', 'highlights', 'explains', 'demonstrates', 'addresses', 'introduces', 'outlines', 'reflects']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: annul\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['terminate', 'cancel', 'void', 'honor', 'suspend', 'delay', 'alter', 'modify', 'amend', 'contest']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: deployed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['stationed', 'mobilized', 'dispatched', 'employed', 'sent', 'recruited', 'installed', 'trained', 'assembled', 'posted']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: revered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['respected', 'beloved', 'celebrated', 'renowned', 'sacred', 'prominent', 'prized', 'coveted', 'prestigious', 'famous']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: evade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['escape', 'dodge', 'resist', 'avoid', 'enforce', 'hide', 'conceal', 'block', 'obtain', 'pursue']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: alleged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['suspected', 'purported', 'allegedly', 'attempted', 'suspect', 'reported', 'apparent', 'rampant', 'illegal', 'widespread']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: indignation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['outrage', 'frustration', 'resentment', 'hysteria', 'anger', 'condemnation', 'alarm', 'agitation', 'dissatisfaction', 'reaction']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: lingering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['persistent', 'continuing', 'residual', 'lurking', 'ongoing', 'lasting', 'recurring', 'growing', 'looming', 'fresh']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: barren\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['fertile', 'pristine', 'arid', 'lifeless', 'uninhabited', 'stony', 'vast', 'dry', 'magnificent', 'sandy']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: falsifications\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['errors', 'flaws', 'controversies', 'criticisms', 'scandals', 'complaints', 'mistakes', 'lies', 'accusations', 'allegations']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: incubated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['initiated', 'triggered', 'concentrated', 'contained', 'unleashed', 'placed', 'exposed', 'activated', 'launched', 'centered']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: flashpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['points', 'intersections', 'sites', 'targets', 'ranges', 'locations', 'events', 'posts', 'centres', 'stations']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: prejudiced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['offended', 'biased', 'disadvantaged', 'mistaken', 'disappointed', 'beaten', 'ignorant', 'favoured', 'confused', 'bias']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: conferred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['bestowed', 'granted', 'awarded', 'earned', 'showered', 'offered', 'imposed', 'assigned', 'afforded', 'given']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: alighting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['striking', 'marching', 'flying', 'driving', 'landing', 'proceeding', 'stopping', 'firing', 'riding', 'patrolling']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: illegitimate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['fraudulent', 'legitimate', 'unlawful', 'unwanted', 'illicit', 'illegal', 'unacceptable', 'unconstitutional', 'corrupted', 'monstrous']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: extend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['expand', 'give', 'grant', 'offer', 'release', 'open', 'direct', 'express', 'spread', 'send']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: subsequently\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['afterwards', 'thereafter', 'later', 'ultimately', 'eventually', 'consequently', 'promptly', 'initially', 'then', 'additionally']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: detained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['arrested', 'jailed', 'imprisoned', 'incarcerated', 'captured', 'seized', 'freed', 'released', 'questioned', 'investigated']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: commenced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['began', 'begun', 'resumed', 'completed', 'undertook', 'started', 'concluded', 'finished', 'continued', 'beginning']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: intentions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['intent', 'ambitions', 'plans', 'hopes', 'ideas', 'interests', 'thoughts', 'goals', 'aim', 'plan']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: disruptive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['disrupt', 'destructive', 'disturbing', 'detrimental', 'distracting', 'damaging', 'disruption', 'dangerous', 'interfering', 'harmful']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: outskirts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['periphery', 'edge', 'fringe', 'edges', 'side', 'doorstep', 'corner', 'perimeter', 'suburbs', 'streets']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: interred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['buried', 'cremated', 'burial', 'housed', 'resided', 'seated', 'died', 'interned', 'stored', 'placed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: epigrams\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['patterns', 'images', 'structures', 'narratives', 'texts', 'prints', 'portraits', 'expressions', 'drawings', 'forms']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: homicides\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['murders', 'killings', 'crimes', 'fatalities', 'cases', 'deaths', 'accidents', 'incidents', 'assaults', 'murder']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: seized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['captured', 'recaptured', 'raided', 'conquered', 'liberated', 'invaded', 'attacked', 'destroyed', 'occupied', 'sacked']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: impugned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-base-generator were not used when initializing ElectraModel: ['generator_predictions.dense.weight', 'generator_lm_head.bias', 'generator_lm_head.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 substitutes based on bertscores in context: ['disrupted', 'ruined', 'weakened', 'betrayed', 'disappointed', 'clouded', 'diminished', 'shattered', 'endangered', 'destroyed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    #print(f\"Sentence: {sentence}\")\n",
    "    #print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, lm_tokenizer.mask_token) # this is different per model (this code line applies to Electra)\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    sentences_concat = f\"{sentence} {lm_tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline (removing elements without token_str key; as this gave errors in the ELECTRA models) .\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "    substitutes = [substitute[\"token_str\"] for substitute in result if \"token_str\" in substitute]\n",
    "    #print(f\"Substitute Generation step: initial substitute list: {substitutes}\\n\")\n",
    "\n",
    "\n",
    "    #2: Morphological Generation and Context Adaptation (Morphological Adaptation):  \n",
    "    ## a) remove noise in the substitutes, by ignoring generated substitutes that are empty or that have unwanted punctuation characters or that start with '##' (this returned errors with the ELECTRA model), and lowercase the substitutes (as some models don't lowercase by default)\n",
    "    ## and lowercase all substitutes. Use try/except statement to prevent other character-related problems to happen\n",
    "\n",
    "    punctuation_set = set(string.punctuation) - set('-') # retained hyphens in case tokenizers don't split on hyphenated compounds\n",
    "    punctuation_set.update({'',''})   # as these curly quotes appeared in the Electra (SG step) results but were not part of the string set\n",
    "\n",
    "    try:\n",
    "        substitutes = [substitute[\"token_str\"].lower() for substitute in result if not any(char in punctuation_set for char in substitute[\"token_str\"]) \n",
    "                       and not substitute[\"token_str\"].startswith('##') and substitute[\"token_str\"].strip() != \"\"]\n",
    "        # print(f\"Morphological Adaptation step a): substitute list without unwanted punctuation characters: {substitutes}\\n\")\n",
    "    except TypeError as error:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    ## b) remove duplicates within the substitute list from the substitute list (duplicates are likely for models that did not lowercase by default)\n",
    "    ## the last mentioned duplicate is removed on purpose, as this may probably be the (previously) uppercased variant of the lowercased substitute (lowercased subs are most likely higher ranked by the model)\n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl:\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    #print(f\"Morphological Adaptation step b): substitute list without duplicates of substitutes: {substitutes_no_dupl}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    ## c) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "\n",
    "    ## first Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## then, remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step c): substitute list without duplicates of the complex word nor inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "\n",
    "\n",
    "    ## d) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step d): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #3: Substitute Selection (SS) by calculating Bertscores: \n",
    "    ## create sentence with the complex word replaced by the substitutes\n",
    "    sentence_with_substitutes = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym]\n",
    "    #print(f\"List with sentences where complex word is substituted: {sentence_with_substitutes}\\n\")\n",
    "\n",
    "\n",
    "    ## calculate BERTScores, and rank the substitutes based on these scores\n",
    "    if len(sentence_with_substitutes) > 0: # to make sure the list with substitutes is always filled\n",
    "        logging.getLogger('transformers').setLevel(logging.ERROR)  # to prevent the same warnings from being printed x times \n",
    "        scores = bert_score.score([sentence]*len(sentence_with_substitutes), sentence_with_substitutes, lang=\"en\", model_type='google/electra-base-generator', verbose=False)\n",
    "        logging.getLogger('transformers').setLevel(logging.WARNING) # to reset the logging level back to printing warnings\n",
    "    \n",
    "        # create a list of tuples, each tuple containing a substitute and its score\n",
    "        substitute_score_pairs = list(zip(substitutes_no_dupl_complex_word_no_antonym, scores[0].tolist()))\n",
    "\n",
    "        # sort the list of tuples by the scores (the second element of each tuple), in descending order\n",
    "        sorted_substitute_score_pairs = sorted(substitute_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # print each substitute with its score\n",
    "        # for substitute, score in sorted_substitute_score_pairs:\n",
    "        #     print(f\"Substitute: {substitute}, BertScore: {score}\")\n",
    "\n",
    "        # extract the list of substitutes from the sorted pairs\n",
    "        bertscore_ranked_substitutes_only = [substitute for substitute, _ in sorted_substitute_score_pairs]\n",
    "        #print(f\"substitutes based on bertscores in context: {bertscore_ranked_substitutes_only}\\n\")\n",
    "\n",
    "        # limit the substitutes to the 10 first ones for evaluation\n",
    "        bertscore_top_10_substitutes = bertscore_ranked_substitutes_only[:10]\n",
    "        #print(f\"top-10 substitutes based on bertscores in context: {bertscore_top_10_substitutes}\\n\")\n",
    "\n",
    "    else:\n",
    "        bertscore_top_10_substitutes = []\n",
    "\n",
    "\n",
    "    ## add the results to the dataframe\n",
    "    ## fill the dataframe with 10 elements even if there are less than 10 in the previous list\n",
    "    required_for_dataframe = 10\n",
    "\n",
    "    ## pad the list with None until it has 10 elements\n",
    "    bertscore_top_10_substitutes += [None] * (required_for_dataframe - len(bertscore_top_10_substitutes))\n",
    "   \n",
    "\n",
    "\n",
    "    ## add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + bertscore_top_10_substitutes\n",
    "\n",
    "    #print('---------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "   \n",
    "    \n",
    "    \n",
    "# export the dataframe to a tsv file for evaluation\n",
    "substitutes_df.to_csv(\"./predictions/test/ElectraBase_SG_MA_SS_bsElectra.tsv\", sep=\"\\t\", index=False, header=False)  \n",
    "print(\"ElectraBase_SG_MA_SS_bsElectra exported to csv in path './predictions/test/ElectraBase_SG_MA_SS_bsElectra.tsv'}\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dbfa50-213d-4d26-afce-1df5ce5b539a",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/ElectraBase_SG_MA_SS_bsElectra.tsv --output_file ./output/test/ElectraBase_SG_MA_SS_bsElectra.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43ccf33f-6a06-4f66-9c98-1c5557070111",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/ElectraBase_SG_MA_SS_bs.tsv\n",
    "OUTPUT file = ./output/test/ElectraBase_SG_MA_SS_bs.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.5254\n",
    "\n",
    "MAP@3 = 0.355\n",
    "MAP@5 = 0.2623\n",
    "MAP@10 = 0.1629\n",
    "\n",
    "Potential@3 = 0.7533\n",
    "Potential@5 = 0.8579\n",
    "Potential@10 = 0.9115\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.2091\n",
    "Accuracy@2@top_gold_1 = 0.2949\n",
    "Accuracy@3@top_gold_1 = 0.4021\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d089071-4a94-49ff-be81-11f0c004df91",
   "metadata": {},
   "source": [
    "the best MAP1 and other MAP scores so far!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eb271b-c6c6-4b14-93b8-eb55ce45dbf0",
   "metadata": {},
   "source": [
    "##### BErtscore based on Bert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9f2d19c2-70f8-4f0a-90e7-523b74891dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complex word: prototype\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: pilot, BertScore: 0.9869350790977478\n",
      "Substitute: precursor, BertScore: 0.9847666025161743\n",
      "Substitute: model, BertScore: 0.9846546649932861\n",
      "Substitute: master, BertScore: 0.9843294024467468\n",
      "Substitute: clone, BertScore: 0.9836248755455017\n",
      "Substitute: leader, BertScore: 0.9836096167564392\n",
      "Substitute: forerunner, BertScore: 0.9834112524986267\n",
      "Substitute: core, BertScore: 0.98274165391922\n",
      "Substitute: specimen, BertScore: 0.9827389121055603\n",
      "Substitute: candidate, BertScore: 0.9825534820556641\n",
      "Substitute: original, BertScore: 0.9821335077285767\n",
      "Substitute: test, BertScore: 0.9818716049194336\n",
      "Substitute: specification, BertScore: 0.9815042018890381\n",
      "Substitute: design, BertScore: 0.9813730716705322\n",
      "Substitute: developer, BertScore: 0.9811669588088989\n",
      "Substitute: target, BertScore: 0.9811248779296875\n",
      "Substitute: designer, BertScore: 0.980905294418335\n",
      "Substitute: detector, BertScore: 0.9806215763092041\n",
      "Substitute: dummy, BertScore: 0.979183554649353\n",
      "Substitute: catalyst, BertScore: 0.9786291718482971\n",
      "Substitute: first, BertScore: 0.9784916639328003\n",
      "Substitute: nucleus, BertScore: 0.9779396057128906\n",
      "Substitute: product, BertScore: 0.9772921800613403\n",
      "Substitute: inventor, BertScore: 0.9765879511833191\n",
      "Substitute: host, BertScore: 0.9750721454620361\n",
      "Substitute: second, BertScore: 0.9750439524650574\n",
      "Substitute: third, BertScore: 0.9744561314582825\n",
      "Substitute: proof, BertScore: 0.97026127576828\n",
      "top-10 substitutes based on bertscores in context: ['pilot', 'precursor', 'model', 'master', 'clone', 'leader', 'forerunner', 'core', 'specimen', 'candidate']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: authoritarian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: aggressive, BertScore: 0.9886645674705505\n",
      "Substitute: corrupt, BertScore: 0.9886554479598999\n",
      "Substitute: violent, BertScore: 0.9880530834197998\n",
      "Substitute: radical, BertScore: 0.9875549674034119\n",
      "Substitute: conservative, BertScore: 0.9873263239860535\n",
      "Substitute: militant, BertScore: 0.9868187308311462\n",
      "Substitute: moderate, BertScore: 0.9866560697555542\n",
      "Substitute: liberal, BertScore: 0.985805869102478\n",
      "Substitute: unstable, BertScore: 0.9857958555221558\n",
      "Substitute: political, BertScore: 0.9842546582221985\n",
      "Substitute: unpopular, BertScore: 0.9830994606018066\n",
      "Substitute: erratic, BertScore: 0.9828349351882935\n",
      "Substitute: democratic, BertScore: 0.9827902317047119\n",
      "Substitute: independent, BertScore: 0.9825584888458252\n",
      "Substitute: cautious, BertScore: 0.9818726778030396\n",
      "Substitute: paranoid, BertScore: 0.9816353917121887\n",
      "Substitute: charismatic, BertScore: 0.9815932512283325\n",
      "Substitute: competitive, BertScore: 0.979363203048706\n",
      "Substitute: powerful, BertScore: 0.979338526725769\n",
      "Substitute: efficient, BertScore: 0.978966474533081\n",
      "Substitute: senior, BertScore: 0.9759450554847717\n",
      "Substitute: influential, BertScore: 0.9757419228553772\n",
      "Substitute: ambitious, BertScore: 0.9751704931259155\n",
      "Substitute: effective, BertScore: 0.9746800065040588\n",
      "Substitute: popular, BertScore: 0.9735743999481201\n",
      "Substitute: impatient, BertScore: 0.973383367061615\n",
      "Substitute: active, BertScore: 0.9730246663093567\n",
      "Substitute: power, BertScore: 0.9725348353385925\n",
      "Substitute: confident, BertScore: 0.9715564846992493\n",
      "top-10 substitutes based on bertscores in context: ['aggressive', 'corrupt', 'violent', 'radical', 'conservative', 'militant', 'moderate', 'liberal', 'unstable', 'political']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: collision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: crash, BertScore: 0.9837236404418945\n",
      "Substitute: accident, BertScore: 0.9827234745025635\n",
      "Substitute: explosion, BertScore: 0.9809167385101318\n",
      "Substitute: collided, BertScore: 0.9795665144920349\n",
      "Substitute: impact, BertScore: 0.9769980907440186\n",
      "Substitute: disaster, BertScore: 0.9765609502792358\n",
      "Substitute: incident, BertScore: 0.9759492874145508\n",
      "Substitute: crashes, BertScore: 0.9743978381156921\n",
      "Substitute: blast, BertScore: 0.9711365699768066\n",
      "Substitute: encounter, BertScore: 0.9710476398468018\n",
      "Substitute: tragedy, BertScore: 0.9693416357040405\n",
      "Substitute: accidents, BertScore: 0.9693295955657959\n",
      "Substitute: attack, BertScore: 0.9676911234855652\n",
      "Substitute: problem, BertScore: 0.9582135677337646\n",
      "Substitute: rescue, BertScore: 0.9556356072425842\n",
      "Substitute: launch, BertScore: 0.9549543261528015\n",
      "Substitute: storm, BertScore: 0.952842116355896\n",
      "Substitute: event, BertScore: 0.952329158782959\n",
      "Substitute: landing, BertScore: 0.9497067332267761\n",
      "Substitute: test, BertScore: 0.948430597782135\n",
      "Substitute: flight, BertScore: 0.9472218751907349\n",
      "Substitute: trip, BertScore: 0.9463785886764526\n",
      "Substitute: wreckage, BertScore: 0.9446507692337036\n",
      "Substitute: race, BertScore: 0.9395980834960938\n",
      "Substitute: crossing, BertScore: 0.93946772813797\n",
      "Substitute: discovery, BertScore: 0.939277708530426\n",
      "Substitute: wreck, BertScore: 0.9378163814544678\n",
      "Substitute: scene, BertScore: 0.9354050755500793\n",
      "top-10 substitutes based on bertscores in context: ['crash', 'accident', 'explosion', 'collided', 'impact', 'disaster', 'incident', 'crashes', 'blast', 'encounter']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: pupates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: breeds, BertScore: 0.954571008682251\n",
      "Substitute: develops, BertScore: 0.9543678760528564\n",
      "Substitute: lives, BertScore: 0.9523601531982422\n",
      "Substitute: resides, BertScore: 0.9523058533668518\n",
      "Substitute: emerges, BertScore: 0.952019453048706\n",
      "Substitute: dies, BertScore: 0.9519764184951782\n",
      "Substitute: settles, BertScore: 0.9518728256225586\n",
      "Substitute: feeds, BertScore: 0.949732780456543\n",
      "Substitute: hides, BertScore: 0.9495187401771545\n",
      "Substitute: sleeps, BertScore: 0.9492987394332886\n",
      "Substitute: forms, BertScore: 0.9485462307929993\n",
      "Substitute: sits, BertScore: 0.9480332136154175\n",
      "Substitute: ages, BertScore: 0.9478673338890076\n",
      "Substitute: survives, BertScore: 0.94778972864151\n",
      "Substitute: grows, BertScore: 0.9475570321083069\n",
      "Substitute: collects, BertScore: 0.9469800591468811\n",
      "Substitute: stays, BertScore: 0.9468048214912415\n",
      "Substitute: lays, BertScore: 0.9456010460853577\n",
      "Substitute: remains, BertScore: 0.9444302320480347\n",
      "Substitute: enters, BertScore: 0.9436051249504089\n",
      "Substitute: nests, BertScore: 0.942122757434845\n",
      "Substitute: disappears, BertScore: 0.9402316808700562\n",
      "Substitute: burrows, BertScore: 0.9397714734077454\n",
      "Substitute: seals, BertScore: 0.9394092559814453\n",
      "Substitute: escapes, BertScore: 0.9354164004325867\n",
      "Substitute: leaves, BertScore: 0.9350444674491882\n",
      "Substitute: continues, BertScore: 0.9341493248939514\n",
      "Substitute: breaks, BertScore: 0.9278962016105652\n",
      "Substitute: larvae, BertScore: 0.927280068397522\n",
      "top-10 substitutes based on bertscores in context: ['breeds', 'develops', 'lives', 'resides', 'emerges', 'dies', 'settles', 'feeds', 'hides', 'sleeps']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: discontent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: dissatisfaction, BertScore: 0.9930282831192017\n",
      "Substitute: resentment, BertScore: 0.9890997409820557\n",
      "Substitute: unrest, BertScore: 0.9880886077880859\n",
      "Substitute: agitation, BertScore: 0.988074779510498\n",
      "Substitute: protest, BertScore: 0.9879282116889954\n",
      "Substitute: revolt, BertScore: 0.9873365759849548\n",
      "Substitute: dissent, BertScore: 0.9873073101043701\n",
      "Substitute: frustration, BertScore: 0.9866853356361389\n",
      "Substitute: rebellion, BertScore: 0.9865118265151978\n",
      "Substitute: resistance, BertScore: 0.9853061437606812\n",
      "Substitute: anger, BertScore: 0.9852113723754883\n",
      "Substitute: strife, BertScore: 0.9851835370063782\n",
      "Substitute: turmoil, BertScore: 0.9840506911277771\n",
      "Substitute: disturbances, BertScore: 0.9835731983184814\n",
      "Substitute: instability, BertScore: 0.9834469556808472\n",
      "Substitute: opposition, BertScore: 0.9832375049591064\n",
      "Substitute: confusion, BertScore: 0.9829467535018921\n",
      "Substitute: despair, BertScore: 0.9823205471038818\n",
      "Substitute: disappointment, BertScore: 0.9814459681510925\n",
      "Substitute: chaos, BertScore: 0.9813576936721802\n",
      "Substitute: distress, BertScore: 0.981015145778656\n",
      "Substitute: impatience, BertScore: 0.9808483719825745\n",
      "Substitute: uncertainty, BertScore: 0.9799411296844482\n",
      "Substitute: misery, BertScore: 0.9788656234741211\n",
      "Substitute: problems, BertScore: 0.9767967462539673\n",
      "Substitute: crisis, BertScore: 0.9764423370361328\n",
      "Substitute: unemployment, BertScore: 0.9760527610778809\n",
      "Substitute: change, BertScore: 0.9759986996650696\n",
      "Substitute: corruption, BertScore: 0.9735620617866516\n",
      "top-10 substitutes based on bertscores in context: ['dissatisfaction', 'resentment', 'unrest', 'agitation', 'protest', 'revolt', 'dissent', 'frustration', 'rebellion', 'resistance']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: decomposes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: converts, BertScore: 0.935767412185669\n",
      "Substitute: transforms, BertScore: 0.9353660345077515\n",
      "Substitute: collapses, BertScore: 0.934607982635498\n",
      "Substitute: transitions, BertScore: 0.9334944486618042\n",
      "Substitute: turns, BertScore: 0.9322633743286133\n",
      "Substitute: reduces, BertScore: 0.9317082166671753\n",
      "Substitute: sinks, BertScore: 0.929344117641449\n",
      "Substitute: reacts, BertScore: 0.9280127286911011\n",
      "Substitute: bends, BertScore: 0.92597496509552\n",
      "Substitute: expands, BertScore: 0.9256248474121094\n",
      "Substitute: transfers, BertScore: 0.9223602414131165\n",
      "Substitute: contracts, BertScore: 0.9218739867210388\n",
      "Substitute: changes, BertScore: 0.9218446612358093\n",
      "Substitute: rises, BertScore: 0.9188991785049438\n",
      "Substitute: bonds, BertScore: 0.918881356716156\n",
      "Substitute: passes, BertScore: 0.9169452786445618\n",
      "Substitute: acts, BertScore: 0.9161893129348755\n",
      "Substitute: returns, BertScore: 0.9156715869903564\n",
      "Substitute: increases, BertScore: 0.9152528047561646\n",
      "Substitute: decreases, BertScore: 0.9150073528289795\n",
      "Substitute: responds, BertScore: 0.9146836400032043\n",
      "Substitute: leads, BertScore: 0.9134783744812012\n",
      "Substitute: adds, BertScore: 0.9123787879943848\n",
      "Substitute: yields, BertScore: 0.9107667207717896\n",
      "Substitute: contributes, BertScore: 0.9104251265525818\n",
      "Substitute: escapes, BertScore: 0.9091517925262451\n",
      "Substitute: binds, BertScore: 0.90846848487854\n",
      "Substitute: grows, BertScore: 0.908126175403595\n",
      "Substitute: functions, BertScore: 0.9055730700492859\n",
      "Substitute: corresponds, BertScore: 0.886594295501709\n",
      "top-10 substitutes based on bertscores in context: ['converts', 'transforms', 'collapses', 'transitions', 'turns', 'reduces', 'sinks', 'reacts', 'bends', 'expands']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: descent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: ascent, BertScore: 0.9942246675491333\n",
      "Substitute: climb, BertScore: 0.9940800666809082\n",
      "Substitute: dive, BertScore: 0.9922497868537903\n",
      "Substitute: jump, BertScore: 0.991875946521759\n",
      "Substitute: takeoff, BertScore: 0.9908499121665955\n",
      "Substitute: hop, BertScore: 0.9903311729431152\n",
      "Substitute: departure, BertScore: 0.9897111058235168\n",
      "Substitute: landing, BertScore: 0.989228367805481\n",
      "Substitute: flight, BertScore: 0.9884076118469238\n",
      "Substitute: descend, BertScore: 0.9883177280426025\n",
      "Substitute: turn, BertScore: 0.9868313670158386\n",
      "Substitute: leap, BertScore: 0.9863702058792114\n",
      "Substitute: return, BertScore: 0.986346960067749\n",
      "Substitute: crossing, BertScore: 0.9861182570457458\n",
      "Substitute: journey, BertScore: 0.985312283039093\n",
      "Substitute: trip, BertScore: 0.9852080345153809\n",
      "Substitute: transition, BertScore: 0.985093355178833\n",
      "Substitute: trek, BertScore: 0.9850296378135681\n",
      "Substitute: fall, BertScore: 0.9839850664138794\n",
      "Substitute: crash, BertScore: 0.9836723804473877\n",
      "Substitute: rise, BertScore: 0.9834585785865784\n",
      "Substitute: summit, BertScore: 0.9831223487854004\n",
      "Substitute: path, BertScore: 0.9829620718955994\n",
      "Substitute: race, BertScore: 0.9818464517593384\n",
      "Substitute: route, BertScore: 0.9818146824836731\n",
      "Substitute: descending, BertScore: 0.9804409742355347\n",
      "Substitute: descended, BertScore: 0.9795021414756775\n",
      "Substitute: plane, BertScore: 0.9772821664810181\n",
      "Substitute: downhill, BertScore: 0.9735763072967529\n",
      "top-10 substitutes based on bertscores in context: ['ascent', 'climb', 'dive', 'jump', 'takeoff', 'hop', 'departure', 'landing', 'flight', 'descend']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sectarian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: sect, BertScore: 0.9515995979309082\n",
      "Substitute: ideological, BertScore: 0.9435434341430664\n",
      "Substitute: religious, BertScore: 0.9433034062385559\n",
      "Substitute: tribal, BertScore: 0.9416736364364624\n",
      "Substitute: communal, BertScore: 0.941035270690918\n",
      "Substitute: ethnic, BertScore: 0.9403630495071411\n",
      "Substitute: political, BertScore: 0.9377333521842957\n",
      "Substitute: christian, BertScore: 0.9366855621337891\n",
      "Substitute: secular, BertScore: 0.9361745715141296\n",
      "Substitute: regional, BertScore: 0.933806836605072\n",
      "Substitute: party, BertScore: 0.9327670335769653\n",
      "Substitute: local, BertScore: 0.9319540858268738\n",
      "Substitute: church, BertScore: 0.9318102598190308\n",
      "Substitute: autonomous, BertScore: 0.9311540126800537\n",
      "Substitute: different, BertScore: 0.9294016361236572\n",
      "Substitute: national, BertScore: 0.9288090467453003\n",
      "Substitute: several, BertScore: 0.9277520775794983\n",
      "Substitute: other, BertScore: 0.9276859760284424\n",
      "Substitute: demographic, BertScore: 0.925405740737915\n",
      "Substitute: racial, BertScore: 0.9247418642044067\n",
      "Substitute: those, BertScore: 0.9244720935821533\n",
      "Substitute: two, BertScore: 0.9238207936286926\n",
      "Substitute: these, BertScore: 0.9234007596969604\n",
      "Substitute: three, BertScore: 0.9231346845626831\n",
      "Substitute: rural, BertScore: 0.9221757650375366\n",
      "Substitute: their, BertScore: 0.9197160601615906\n",
      "Substitute: similar, BertScore: 0.918842077255249\n",
      "Substitute: its, BertScore: 0.9179314374923706\n",
      "Substitute: the, BertScore: 0.9125768542289734\n",
      "top-10 substitutes based on bertscores in context: ['sect', 'ideological', 'religious', 'tribal', 'communal', 'ethnic', 'political', 'christian', 'secular', 'regional']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sectarian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: sect, BertScore: 0.979542076587677\n",
      "Substitute: partisan, BertScore: 0.9782788157463074\n",
      "Substitute: ideological, BertScore: 0.9773315191268921\n",
      "Substitute: religious, BertScore: 0.9773286581039429\n",
      "Substitute: communal, BertScore: 0.9770487546920776\n",
      "Substitute: ethnic, BertScore: 0.9759032726287842\n",
      "Substitute: regional, BertScore: 0.9742668271064758\n",
      "Substitute: clerical, BertScore: 0.9736459851264954\n",
      "Substitute: internal, BertScore: 0.9734081029891968\n",
      "Substitute: secular, BertScore: 0.9730751514434814\n",
      "Substitute: theological, BertScore: 0.9728472232818604\n",
      "Substitute: civil, BertScore: 0.9722408056259155\n",
      "Substitute: opposition, BertScore: 0.9718856811523438\n",
      "Substitute: ecclesiastical, BertScore: 0.9718751907348633\n",
      "Substitute: personal, BertScore: 0.9715173244476318\n",
      "Substitute: social, BertScore: 0.9710198640823364\n",
      "Substitute: spiritual, BertScore: 0.970788836479187\n",
      "Substitute: military, BertScore: 0.9706635475158691\n",
      "Substitute: territorial, BertScore: 0.9706607460975647\n",
      "Substitute: administrative, BertScore: 0.9706411361694336\n",
      "Substitute: democratic, BertScore: 0.9705490469932556\n",
      "Substitute: domestic, BertScore: 0.970340371131897\n",
      "Substitute: security, BertScore: 0.9701994061470032\n",
      "Substitute: material, BertScore: 0.9701952338218689\n",
      "Substitute: cultural, BertScore: 0.9701291918754578\n",
      "Substitute: economic, BertScore: 0.9697232842445374\n",
      "Substitute: strategic, BertScore: 0.9695069789886475\n",
      "Substitute: political, BertScore: 0.9690133929252625\n",
      "Substitute: diplomatic, BertScore: 0.9689299464225769\n",
      "Substitute: historical, BertScore: 0.9688506722450256\n",
      "top-10 substitutes based on bertscores in context: ['sect', 'partisan', 'ideological', 'religious', 'communal', 'ethnic', 'regional', 'clerical', 'internal', 'secular']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: offshoot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: affiliate, BertScore: 0.9804146885871887\n",
      "Substitute: branch, BertScore: 0.980023980140686\n",
      "Substitute: splinter, BertScore: 0.9794329404830933\n",
      "Substitute: arm, BertScore: 0.9772950410842896\n",
      "Substitute: extension, BertScore: 0.9771524667739868\n",
      "Substitute: element, BertScore: 0.9728899002075195\n",
      "Substitute: associate, BertScore: 0.9726551175117493\n",
      "Substitute: outpost, BertScore: 0.9706907272338867\n",
      "Substitute: organization, BertScore: 0.9697920083999634\n",
      "Substitute: ally, BertScore: 0.9694305062294006\n",
      "Substitute: amalgamation, BertScore: 0.9693008065223694\n",
      "Substitute: antagonist, BertScore: 0.9683325886726379\n",
      "Substitute: axis, BertScore: 0.967276394367218\n",
      "Substitute: organisation, BertScore: 0.9671979546546936\n",
      "Substitute: independent, BertScore: 0.9671927690505981\n",
      "Substitute: adversary, BertScore: 0.9665703773498535\n",
      "Substitute: umbrella, BertScore: 0.9658297300338745\n",
      "Substitute: association, BertScore: 0.9651264548301697\n",
      "Substitute: alliance, BertScore: 0.9643459320068359\n",
      "Substitute: agent, BertScore: 0.9636475443840027\n",
      "Substitute: enemy, BertScore: 0.9607017636299133\n",
      "Substitute: opponent, BertScore: 0.9605324268341064\n",
      "Substitute: ideology, BertScore: 0.960425615310669\n",
      "Substitute: outside, BertScore: 0.9595068097114563\n",
      "Substitute: area, BertScore: 0.9570155143737793\n",
      "Substitute: out, BertScore: 0.9563887715339661\n",
      "Substitute: icon, BertScore: 0.9555120468139648\n",
      "Substitute: ancestor, BertScore: 0.9540318250656128\n",
      "Substitute: act, BertScore: 0.9532248377799988\n",
      "Substitute: example, BertScore: 0.9518335461616516\n",
      "top-10 substitutes based on bertscores in context: ['affiliate', 'branch', 'splinter', 'arm', 'extension', 'element', 'associate', 'outpost', 'organization', 'ally']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: decree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: ordinance, BertScore: 0.9890459775924683\n",
      "Substitute: decision, BertScore: 0.9864133596420288\n",
      "Substitute: act, BertScore: 0.9853634834289551\n",
      "Substitute: proclamation, BertScore: 0.9837354421615601\n",
      "Substitute: edict, BertScore: 0.9829226136207581\n",
      "Substitute: motion, BertScore: 0.9826515913009644\n",
      "Substitute: law, BertScore: 0.9826329946517944\n",
      "Substitute: declaration, BertScore: 0.9804323315620422\n",
      "Substitute: recommendation, BertScore: 0.9798017740249634\n",
      "Substitute: initiative, BertScore: 0.979583203792572\n",
      "Substitute: mandate, BertScore: 0.9795316457748413\n",
      "Substitute: fiat, BertScore: 0.9787418842315674\n",
      "Substitute: approval, BertScore: 0.9776920676231384\n",
      "Substitute: petition, BertScore: 0.9770088791847229\n",
      "Substitute: consent, BertScore: 0.9769797325134277\n",
      "Substitute: request, BertScore: 0.9763484001159668\n",
      "Substitute: letter, BertScore: 0.9758800268173218\n",
      "Substitute: order, BertScore: 0.9753973484039307\n",
      "Substitute: orders, BertScore: 0.9748818874359131\n",
      "Substitute: deed, BertScore: 0.9728306531906128\n",
      "Substitute: treaty, BertScore: 0.9720742106437683\n",
      "Substitute: vote, BertScore: 0.9714495539665222\n",
      "Substitute: design, BertScore: 0.9697296023368835\n",
      "Substitute: demand, BertScore: 0.9697111248970032\n",
      "Substitute: command, BertScore: 0.968315064907074\n",
      "Substitute: council, BertScore: 0.9620137810707092\n",
      "Substitute: virtue, BertScore: 0.9526429176330566\n",
      "Substitute: favour, BertScore: 0.9489233493804932\n",
      "top-10 substitutes based on bertscores in context: ['ordinance', 'decision', 'act', 'proclamation', 'edict', 'motion', 'law', 'declaration', 'recommendation', 'initiative']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: detonating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: exploding, BertScore: 0.9755610227584839\n",
      "Substitute: launching, BertScore: 0.9741053581237793\n",
      "Substitute: dropping, BertScore: 0.972787082195282\n",
      "Substitute: triggering, BertScore: 0.972522497177124\n",
      "Substitute: firing, BertScore: 0.9719369411468506\n",
      "Substitute: releasing, BertScore: 0.9714152216911316\n",
      "Substitute: lighting, BertScore: 0.9708776473999023\n",
      "Substitute: planting, BertScore: 0.9707977175712585\n",
      "Substitute: producing, BertScore: 0.9705802798271179\n",
      "Substitute: throwing, BertScore: 0.9693088531494141\n",
      "Substitute: delivering, BertScore: 0.9677720665931702\n",
      "Substitute: striking, BertScore: 0.9677227735519409\n",
      "Substitute: hurling, BertScore: 0.9676889777183533\n",
      "Substitute: destroying, BertScore: 0.9674500226974487\n",
      "Substitute: hitting, BertScore: 0.9672350287437439\n",
      "Substitute: setting, BertScore: 0.9668302536010742\n",
      "Substitute: downing, BertScore: 0.966296911239624\n",
      "Substitute: landing, BertScore: 0.9659860134124756\n",
      "Substitute: generating, BertScore: 0.9655877351760864\n",
      "Substitute: shooting, BertScore: 0.9643635153770447\n",
      "Substitute: smashing, BertScore: 0.9641545414924622\n",
      "Substitute: creating, BertScore: 0.9635623693466187\n",
      "Substitute: damaging, BertScore: 0.962985634803772\n",
      "Substitute: shattering, BertScore: 0.962593138217926\n",
      "Substitute: sustaining, BertScore: 0.959955096244812\n",
      "Substitute: causing, BertScore: 0.9592751264572144\n",
      "Substitute: forming, BertScore: 0.957578718662262\n",
      "Substitute: killing, BertScore: 0.9565509557723999\n",
      "Substitute: using, BertScore: 0.9557183384895325\n",
      "Substitute: including, BertScore: 0.9468842148780823\n",
      "top-10 substitutes based on bertscores in context: ['exploding', 'launching', 'dropping', 'triggering', 'firing', 'releasing', 'lighting', 'planting', 'producing', 'throwing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: deficit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: surplus, BertScore: 0.9814126491546631\n",
      "Substitute: debt, BertScore: 0.9796677827835083\n",
      "Substitute: spending, BertScore: 0.9754190444946289\n",
      "Substitute: balance, BertScore: 0.9735943675041199\n",
      "Substitute: budget, BertScore: 0.972564160823822\n",
      "Substitute: expenditure, BertScore: 0.9721914529800415\n",
      "Substitute: gap, BertScore: 0.9718083739280701\n",
      "Substitute: ceiling, BertScore: 0.9697560667991638\n",
      "Substitute: cap, BertScore: 0.9689796566963196\n",
      "Substitute: gdp, BertScore: 0.9684919118881226\n",
      "Substitute: cut, BertScore: 0.9682274460792542\n",
      "Substitute: inflation, BertScore: 0.9678170084953308\n",
      "Substitute: loss, BertScore: 0.967803955078125\n",
      "Substitute: contribution, BertScore: 0.9675523638725281\n",
      "Substitute: cost, BertScore: 0.9656940698623657\n",
      "Substitute: margin, BertScore: 0.9637810587882996\n",
      "Substitute: problem, BertScore: 0.9633716940879822\n",
      "Substitute: rate, BertScore: 0.9631927013397217\n",
      "Substitute: growth, BertScore: 0.9625832438468933\n",
      "Substitute: increase, BertScore: 0.9615574479103088\n",
      "Substitute: reduction, BertScore: 0.9611963033676147\n",
      "Substitute: total, BertScore: 0.9597537517547607\n",
      "Substitute: amount, BertScore: 0.958221971988678\n",
      "Substitute: bill, BertScore: 0.9570029973983765\n",
      "Substitute: figure, BertScore: 0.9558050632476807\n",
      "Substitute: ratio, BertScore: 0.9539592862129211\n",
      "Substitute: limit, BertScore: 0.9529320001602173\n",
      "Substitute: euro, BertScore: 0.9526645541191101\n",
      "Substitute: target, BertScore: 0.952203094959259\n",
      "top-10 substitutes based on bertscores in context: ['surplus', 'debt', 'spending', 'balance', 'budget', 'expenditure', 'gap', 'ceiling', 'cap', 'gdp']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: canopy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: roof, BertScore: 0.9763792753219604\n",
      "Substitute: dome, BertScore: 0.9741117358207703\n",
      "Substitute: hood, BertScore: 0.9740942716598511\n",
      "Substitute: curtain, BertScore: 0.9682258367538452\n",
      "Substitute: cover, BertScore: 0.96674644947052\n",
      "Substitute: wing, BertScore: 0.9663236737251282\n",
      "Substitute: flap, BertScore: 0.9662825465202332\n",
      "Substitute: sash, BertScore: 0.9649456739425659\n",
      "Substitute: parachute, BertScore: 0.9628774523735046\n",
      "Substitute: window, BertScore: 0.9627023339271545\n",
      "Substitute: screen, BertScore: 0.9621618986129761\n",
      "Substitute: lid, BertScore: 0.9617011547088623\n",
      "Substitute: cushion, BertScore: 0.9609447121620178\n",
      "Substitute: shield, BertScore: 0.9598598480224609\n",
      "Substitute: deck, BertScore: 0.959678590297699\n",
      "Substitute: mirror, BertScore: 0.9578466415405273\n",
      "Substitute: harness, BertScore: 0.9577828645706177\n",
      "Substitute: ladder, BertScore: 0.9574847221374512\n",
      "Substitute: bridge, BertScore: 0.9571511149406433\n",
      "Substitute: belt, BertScore: 0.9571048617362976\n",
      "Substitute: railing, BertScore: 0.9554096460342407\n",
      "Substitute: ramp, BertScore: 0.9536420106887817\n",
      "Substitute: door, BertScore: 0.9517699480056763\n",
      "Substitute: rope, BertScore: 0.9506728649139404\n",
      "Substitute: blanket, BertScore: 0.9500114917755127\n",
      "Substitute: seat, BertScore: 0.9486061930656433\n",
      "Substitute: switch, BertScore: 0.9456808567047119\n",
      "Substitute: tree, BertScore: 0.9376630783081055\n",
      "Substitute: cloud, BertScore: 0.9303057193756104\n",
      "top-10 substitutes based on bertscores in context: ['roof', 'dome', 'hood', 'curtain', 'cover', 'wing', 'flap', 'sash', 'parachute', 'window']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: condolences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: congratulations, BertScore: 0.9645681977272034\n",
      "Substitute: apologies, BertScore: 0.9638298153877258\n",
      "Substitute: gratitude, BertScore: 0.962785542011261\n",
      "Substitute: thanks, BertScore: 0.9618377685546875\n",
      "Substitute: apology, BertScore: 0.960413932800293\n",
      "Substitute: sympathy, BertScore: 0.9561514854431152\n",
      "Substitute: regrets, BertScore: 0.9559859037399292\n",
      "Substitute: appreciation, BertScore: 0.9557079076766968\n",
      "Substitute: hospitality, BertScore: 0.9544464349746704\n",
      "Substitute: solidarity, BertScore: 0.953774094581604\n",
      "Substitute: support, BertScore: 0.9537029266357422\n",
      "Substitute: prayers, BertScore: 0.9529309868812561\n",
      "Substitute: compassion, BertScore: 0.9521567225456238\n",
      "Substitute: respect, BertScore: 0.9516164064407349\n",
      "Substitute: relief, BertScore: 0.9505083560943604\n",
      "Substitute: concern, BertScore: 0.9490060806274414\n",
      "Substitute: love, BertScore: 0.9483439922332764\n",
      "Substitute: assistance, BertScore: 0.9481452107429504\n",
      "Substitute: sentiments, BertScore: 0.9472654461860657\n",
      "Substitute: feelings, BertScore: 0.9438192844390869\n",
      "Substitute: devotion, BertScore: 0.9435012936592102\n",
      "Substitute: loyalty, BertScore: 0.9434800744056702\n",
      "Substitute: concerns, BertScore: 0.9430258274078369\n",
      "Substitute: pleas, BertScore: 0.9415420889854431\n",
      "Substitute: wishes, BertScore: 0.9413081407546997\n",
      "Substitute: representations, BertScore: 0.9385912418365479\n",
      "Substitute: appeals, BertScore: 0.9375447630882263\n",
      "Substitute: views, BertScore: 0.9353513717651367\n",
      "top-10 substitutes based on bertscores in context: ['congratulations', 'apologies', 'gratitude', 'thanks', 'apology', 'sympathy', 'regrets', 'appreciation', 'hospitality', 'solidarity']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: benchmark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: standard, BertScore: 0.977049708366394\n",
      "Substitute: approved, BertScore: 0.9752163290977478\n",
      "Substitute: preferred, BertScore: 0.9745914936065674\n",
      "Substitute: common, BertScore: 0.9744389057159424\n",
      "Substitute: key, BertScore: 0.9738166928291321\n",
      "Substitute: outstanding, BertScore: 0.9737101197242737\n",
      "Substitute: traditional, BertScore: 0.9737026691436768\n",
      "Substitute: major, BertScore: 0.9726213216781616\n",
      "Substitute: existing, BertScore: 0.9717037677764893\n",
      "Substitute: cheap, BertScore: 0.97137051820755\n",
      "Substitute: troubled, BertScore: 0.9710327982902527\n",
      "Substitute: convertible, BertScore: 0.9709960222244263\n",
      "Substitute: backed, BertScore: 0.9708179235458374\n",
      "Substitute: cheaper, BertScore: 0.9701118469238281\n",
      "Substitute: comparable, BertScore: 0.9693703651428223\n",
      "Substitute: expired, BertScore: 0.9692949056625366\n",
      "Substitute: average, BertScore: 0.9690858721733093\n",
      "Substitute: current, BertScore: 0.9688986539840698\n",
      "Substitute: new, BertScore: 0.9687570333480835\n",
      "Substitute: bad, BertScore: 0.9685013294219971\n",
      "Substitute: certain, BertScore: 0.9681529998779297\n",
      "Substitute: some, BertScore: 0.9656124114990234\n",
      "Substitute: those, BertScore: 0.9651505947113037\n",
      "Substitute: most, BertScore: 0.9650201201438904\n",
      "Substitute: the, BertScore: 0.964726984500885\n",
      "Substitute: all, BertScore: 0.9645056128501892\n",
      "Substitute: these, BertScore: 0.9641808271408081\n",
      "Substitute: other, BertScore: 0.9635158181190491\n",
      "Substitute: its, BertScore: 0.9615042209625244\n",
      "top-10 substitutes based on bertscores in context: ['standard', 'approved', 'preferred', 'common', 'key', 'outstanding', 'traditional', 'major', 'existing', 'cheap']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: auspicious\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: unusual, BertScore: 0.9462262392044067\n",
      "Substitute: lavish, BertScore: 0.9460675120353699\n",
      "Substitute: busy, BertScore: 0.9447227716445923\n",
      "Substitute: delicate, BertScore: 0.9439563751220703\n",
      "Substitute: special, BertScore: 0.9439071416854858\n",
      "Substitute: romantic, BertScore: 0.942962110042572\n",
      "Substitute: ceremonial, BertScore: 0.9385216236114502\n",
      "Substitute: exotic, BertScore: 0.9370770454406738\n",
      "Substitute: warm, BertScore: 0.9370660781860352\n",
      "Substitute: rare, BertScore: 0.9367856979370117\n",
      "Substitute: seasonal, BertScore: 0.9359171986579895\n",
      "Substitute: social, BertScore: 0.9352809190750122\n",
      "Substitute: magical, BertScore: 0.9350458383560181\n",
      "Substitute: religious, BertScore: 0.9345031380653381\n",
      "Substitute: specific, BertScore: 0.9340171813964844\n",
      "Substitute: public, BertScore: 0.9339885711669922\n",
      "Substitute: regular, BertScore: 0.9326348900794983\n",
      "Substitute: wedding, BertScore: 0.9324855804443359\n",
      "Substitute: certain, BertScore: 0.9305282831192017\n",
      "Substitute: various, BertScore: 0.9303590655326843\n",
      "Substitute: many, BertScore: 0.9300544857978821\n",
      "Substitute: numerous, BertScore: 0.9293413758277893\n",
      "Substitute: different, BertScore: 0.9277071952819824\n",
      "Substitute: other, BertScore: 0.9270671606063843\n",
      "Substitute: several, BertScore: 0.9268646240234375\n",
      "Substitute: multiple, BertScore: 0.9268361330032349\n",
      "Substitute: all, BertScore: 0.9259046912193298\n",
      "Substitute: such, BertScore: 0.9247734546661377\n",
      "Substitute: those, BertScore: 0.9223647117614746\n",
      "Substitute: these, BertScore: 0.9188856482505798\n",
      "top-10 substitutes based on bertscores in context: ['unusual', 'lavish', 'busy', 'delicate', 'special', 'romantic', 'ceremonial', 'exotic', 'warm', 'rare']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: suspiciously\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: curiously, BertScore: 0.9861161708831787\n",
      "Substitute: strangely, BertScore: 0.9857251644134521\n",
      "Substitute: dangerously, BertScore: 0.9851016402244568\n",
      "Substitute: suspicious, BertScore: 0.9850572347640991\n",
      "Substitute: menacing, BertScore: 0.9833675622940063\n",
      "Substitute: oddly, BertScore: 0.983280599117279\n",
      "Substitute: strange, BertScore: 0.9829795360565186\n",
      "Substitute: warily, BertScore: 0.9803026914596558\n",
      "Substitute: aggressively, BertScore: 0.9795500636100769\n",
      "Substitute: coldly, BertScore: 0.9795233011245728\n",
      "Substitute: deliberately, BertScore: 0.97933030128479\n",
      "Substitute: casually, BertScore: 0.9786880016326904\n",
      "Substitute: cautiously, BertScore: 0.9784418344497681\n",
      "Substitute: quietly, BertScore: 0.976820707321167\n",
      "Substitute: vaguely, BertScore: 0.9759438037872314\n",
      "Substitute: badly, BertScore: 0.9752577543258667\n",
      "Substitute: poorly, BertScore: 0.9743807315826416\n",
      "Substitute: closely, BertScore: 0.9732213616371155\n",
      "Substitute: reasonably, BertScore: 0.9728937149047852\n",
      "Substitute: fairly, BertScore: 0.9728540182113647\n",
      "Substitute: seriously, BertScore: 0.9725663661956787\n",
      "Substitute: similarly, BertScore: 0.9708618521690369\n",
      "Substitute: carefully, BertScore: 0.9702441096305847\n",
      "Substitute: actively, BertScore: 0.9700317978858948\n",
      "Substitute: appropriately, BertScore: 0.9690962433815002\n",
      "Substitute: kindly, BertScore: 0.9676815271377563\n",
      "Substitute: just, BertScore: 0.9651911854743958\n",
      "Substitute: really, BertScore: 0.9646474123001099\n",
      "Substitute: well, BertScore: 0.9622209668159485\n",
      "top-10 substitutes based on bertscores in context: ['curiously', 'strangely', 'dangerously', 'suspicious', 'menacing', 'oddly', 'strange', 'warily', 'aggressively', 'coldly']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: established\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: existing, BertScore: 0.9854486584663391\n",
      "Substitute: formed, BertScore: 0.9845744371414185\n",
      "Substitute: constructed, BertScore: 0.9836602210998535\n",
      "Substitute: opened, BertScore: 0.9832563400268555\n",
      "Substitute: approved, BertScore: 0.9820757508277893\n",
      "Substitute: operational, BertScore: 0.9818475246429443\n",
      "Substitute: initial, BertScore: 0.9799238443374634\n",
      "Substitute: main, BertScore: 0.9796814918518066\n",
      "Substitute: old, BertScore: 0.9785459041595459\n",
      "Substitute: official, BertScore: 0.9785051941871643\n",
      "Substitute: planned, BertScore: 0.977703869342804\n",
      "Substitute: open, BertScore: 0.9775716066360474\n",
      "Substitute: original, BertScore: 0.9774594306945801\n",
      "Substitute: new, BertScore: 0.9765849709510803\n",
      "Substitute: institutional, BertScore: 0.9762346744537354\n",
      "Substitute: elevated, BertScore: 0.9762016534805298\n",
      "Substitute: high, BertScore: 0.9752716422080994\n",
      "Substitute: local, BertScore: 0.9731185436248779\n",
      "Substitute: proposed, BertScore: 0.9730896353721619\n",
      "Substitute: establishment, BertScore: 0.9717053771018982\n",
      "Substitute: listed, BertScore: 0.9712770581245422\n",
      "Substitute: current, BertScore: 0.9709432125091553\n",
      "Substitute: set, BertScore: 0.9705137610435486\n",
      "Substitute: national, BertScore: 0.9688968658447266\n",
      "Substitute: actual, BertScore: 0.9688539505004883\n",
      "Substitute: davenport, BertScore: 0.9683861136436462\n",
      "Substitute: same, BertScore: 0.9622295498847961\n",
      "top-10 substitutes based on bertscores in context: ['existing', 'formed', 'constructed', 'opened', 'approved', 'operational', 'initial', 'main', 'old', 'official']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: scrutiny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: oversight, BertScore: 0.9943565726280212\n",
      "Substitute: review, BertScore: 0.9941983222961426\n",
      "Substitute: investigation, BertScore: 0.9934437870979309\n",
      "Substitute: monitoring, BertScore: 0.9932786226272583\n",
      "Substitute: surveillance, BertScore: 0.9932477474212646\n",
      "Substitute: enforcement, BertScore: 0.9929884672164917\n",
      "Substitute: questioning, BertScore: 0.9929574131965637\n",
      "Substitute: supervision, BertScore: 0.9929312467575073\n",
      "Substitute: reviewing, BertScore: 0.9929172992706299\n",
      "Substitute: attention, BertScore: 0.9926900863647461\n",
      "Substitute: manipulation, BertScore: 0.992342472076416\n",
      "Substitute: inquiry, BertScore: 0.9922213554382324\n",
      "Substitute: consideration, BertScore: 0.9922078251838684\n",
      "Substitute: regulation, BertScore: 0.9920940399169922\n",
      "Substitute: investigations, BertScore: 0.9918919205665588\n",
      "Substitute: evaluation, BertScore: 0.9917558431625366\n",
      "Substitute: interrogation, BertScore: 0.9916704893112183\n",
      "Substitute: examination, BertScore: 0.9916390776634216\n",
      "Substitute: protection, BertScore: 0.9914160370826721\n",
      "Substitute: inspection, BertScore: 0.9913251996040344\n",
      "Substitute: pressure, BertScore: 0.9911371469497681\n",
      "Substitute: analysis, BertScore: 0.9908422827720642\n",
      "Substitute: audit, BertScore: 0.9908202886581421\n",
      "Substitute: competition, BertScore: 0.9903035163879395\n",
      "Substitute: exposure, BertScore: 0.9901520013809204\n",
      "Substitute: testing, BertScore: 0.9899992942810059\n",
      "Substitute: criticism, BertScore: 0.9899078607559204\n",
      "Substitute: approval, BertScore: 0.9897570013999939\n",
      "Substitute: screening, BertScore: 0.9891180992126465\n",
      "top-10 substitutes based on bertscores in context: ['oversight', 'review', 'investigation', 'monitoring', 'surveillance', 'enforcement', 'questioning', 'supervision', 'reviewing', 'attention']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: regime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: government, BertScore: 0.9893220067024231\n",
      "Substitute: administration, BertScore: 0.9880676865577698\n",
      "Substitute: dictatorship, BertScore: 0.9873532056808472\n",
      "Substitute: rule, BertScore: 0.9847932457923889\n",
      "Substitute: presidency, BertScore: 0.9767225384712219\n",
      "Substitute: coup, BertScore: 0.9751697778701782\n",
      "Substitute: policies, BertScore: 0.974372386932373\n",
      "Substitute: reforms, BertScore: 0.9709758758544922\n",
      "Substitute: overthrow, BertScore: 0.9708552360534668\n",
      "Substitute: leadership, BertScore: 0.9708123207092285\n",
      "Substitute: policy, BertScore: 0.9689203500747681\n",
      "Substitute: army, BertScore: 0.9687926173210144\n",
      "Substitute: forces, BertScore: 0.9685478806495667\n",
      "Substitute: movement, BertScore: 0.9660283923149109\n",
      "Substitute: power, BertScore: 0.9654011726379395\n",
      "Substitute: plan, BertScore: 0.965067446231842\n",
      "Substitute: actions, BertScore: 0.9637197852134705\n",
      "Substitute: plans, BertScore: 0.963347852230072\n",
      "Substitute: position, BertScore: 0.9607604146003723\n",
      "Substitute: assassination, BertScore: 0.9592651128768921\n",
      "Substitute: decision, BertScore: 0.9581766128540039\n",
      "Substitute: activities, BertScore: 0.9574911594390869\n",
      "Substitute: rise, BertScore: 0.9566245079040527\n",
      "Substitute: removal, BertScore: 0.9560319185256958\n",
      "Substitute: downfall, BertScore: 0.9532458782196045\n",
      "Substitute: death, BertScore: 0.9516978859901428\n",
      "Substitute: move, BertScore: 0.9515810608863831\n",
      "Substitute: arrest, BertScore: 0.9514387249946594\n",
      "Substitute: detention, BertScore: 0.9466639757156372\n",
      "top-10 substitutes based on bertscores in context: ['government', 'administration', 'dictatorship', 'rule', 'presidency', 'coup', 'policies', 'reforms', 'overthrow', 'leadership']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: snipers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: gunmen, BertScore: 0.976091742515564\n",
      "Substitute: rifles, BertScore: 0.9725436568260193\n",
      "Substitute: rockets, BertScore: 0.9702413082122803\n",
      "Substitute: bombers, BertScore: 0.9698677659034729\n",
      "Substitute: drones, BertScore: 0.969136655330658\n",
      "Substitute: tanks, BertScore: 0.9685287475585938\n",
      "Substitute: guards, BertScore: 0.9683274626731873\n",
      "Substitute: policemen, BertScore: 0.9682762622833252\n",
      "Substitute: helicopters, BertScore: 0.9679774045944214\n",
      "Substitute: guns, BertScore: 0.9679700136184692\n",
      "Substitute: soldiers, BertScore: 0.9677217602729797\n",
      "Substitute: attackers, BertScore: 0.9672600030899048\n",
      "Substitute: police, BertScore: 0.9672260284423828\n",
      "Substitute: artillery, BertScore: 0.9671877026557922\n",
      "Substitute: militants, BertScore: 0.966681957244873\n",
      "Substitute: dogs, BertScore: 0.9665309190750122\n",
      "Substitute: marines, BertScore: 0.9665237665176392\n",
      "Substitute: bullets, BertScore: 0.9663583040237427\n",
      "Substitute: terrorists, BertScore: 0.9660026431083679\n",
      "Substitute: troops, BertScore: 0.9655948877334595\n",
      "Substitute: missiles, BertScore: 0.9653653502464294\n",
      "Substitute: insurgents, BertScore: 0.9650545716285706\n",
      "Substitute: bombs, BertScore: 0.9649421572685242\n",
      "Substitute: grenades, BertScore: 0.9614424705505371\n",
      "Substitute: civilians, BertScore: 0.9607439637184143\n",
      "Substitute: men, BertScore: 0.9596138596534729\n",
      "Substitute: mines, BertScore: 0.9593788385391235\n",
      "Substitute: rebels, BertScore: 0.958836555480957\n",
      "Substitute: palestinians, BertScore: 0.9572455883026123\n",
      "top-10 substitutes based on bertscores in context: ['gunmen', 'rifles', 'rockets', 'bombers', 'drones', 'tanks', 'guards', 'policemen', 'helicopters', 'guns']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: precautions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: measures, BertScore: 0.977657675743103\n",
      "Substitute: caution, BertScore: 0.9723502397537231\n",
      "Substitute: risks, BertScore: 0.9665356874465942\n",
      "Substitute: warnings, BertScore: 0.962749719619751\n",
      "Substitute: steps, BertScore: 0.961851954460144\n",
      "Substitute: instructions, BertScore: 0.9601051807403564\n",
      "Substitute: restraint, BertScore: 0.9597411751747131\n",
      "Substitute: action, BertScore: 0.9595596790313721\n",
      "Substitute: risk, BertScore: 0.9588810801506042\n",
      "Substitute: measurements, BertScore: 0.9567403793334961\n",
      "Substitute: care, BertScore: 0.9565517902374268\n",
      "Substitute: advise, BertScore: 0.9562230110168457\n",
      "Substitute: orders, BertScore: 0.9558343291282654\n",
      "Substitute: shelter, BertScore: 0.9542799592018127\n",
      "Substitute: advice, BertScore: 0.9518545269966125\n",
      "Substitute: exceptions, BertScore: 0.9513112306594849\n",
      "Substitute: notes, BertScore: 0.9495773315429688\n",
      "Substitute: responsibility, BertScore: 0.9460277557373047\n",
      "Substitute: pictures, BertScore: 0.9416151642799377\n",
      "Substitute: notice, BertScore: 0.9411222338676453\n",
      "Substitute: photographs, BertScore: 0.9409177899360657\n",
      "Substitute: control, BertScore: 0.9400601983070374\n",
      "Substitute: pride, BertScore: 0.9400298595428467\n",
      "Substitute: time, BertScore: 0.9331264495849609\n",
      "Substitute: nothing, BertScore: 0.9317853450775146\n",
      "Substitute: exception, BertScore: 0.931445837020874\n",
      "Substitute: everything, BertScore: 0.9297582507133484\n",
      "Substitute: it, BertScore: 0.9228395223617554\n",
      "Substitute: them, BertScore: 0.9200795888900757\n",
      "top-10 substitutes based on bertscores in context: ['measures', 'caution', 'risks', 'warnings', 'steps', 'instructions', 'restraint', 'action', 'risk', 'measurements']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: systemic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: systematic, BertScore: 0.994471549987793\n",
      "Substitute: structural, BertScore: 0.9942014217376709\n",
      "Substitute: institutional, BertScore: 0.9932634234428406\n",
      "Substitute: generic, BertScore: 0.9931098222732544\n",
      "Substitute: centralized, BertScore: 0.9927934408187866\n",
      "Substitute: chronic, BertScore: 0.9923335313796997\n",
      "Substitute: liquid, BertScore: 0.9919456839561462\n",
      "Substitute: marginal, BertScore: 0.9918521046638489\n",
      "Substitute: central, BertScore: 0.9915256500244141\n",
      "Substitute: global, BertScore: 0.9913976788520813\n",
      "Substitute: managed, BertScore: 0.9912488460540771\n",
      "Substitute: wholesale, BertScore: 0.9911132454872131\n",
      "Substitute: retail, BertScore: 0.9905235171318054\n",
      "Substitute: regional, BertScore: 0.9904402494430542\n",
      "Substitute: major, BertScore: 0.9904102683067322\n",
      "Substitute: chain, BertScore: 0.9900839328765869\n",
      "Substitute: international, BertScore: 0.9898954033851624\n",
      "Substitute: federal, BertScore: 0.9894216656684875\n",
      "Substitute: financial, BertScore: 0.9893671274185181\n",
      "Substitute: municipal, BertScore: 0.9892273545265198\n",
      "Substitute: local, BertScore: 0.9888429641723633\n",
      "Substitute: pharmaceutical, BertScore: 0.988431453704834\n",
      "Substitute: bank, BertScore: 0.9879504442214966\n",
      "Substitute: struggling, BertScore: 0.9879474639892578\n",
      "Substitute: drug, BertScore: 0.9874715209007263\n",
      "Substitute: the, BertScore: 0.9874142408370972\n",
      "Substitute: mortgage, BertScore: 0.9870525598526001\n",
      "Substitute: at, BertScore: 0.9780980944633484\n",
      "top-10 substitutes based on bertscores in context: ['systematic', 'structural', 'institutional', 'generic', 'centralized', 'chronic', 'liquid', 'marginal', 'central', 'global']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: anchored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: docked, BertScore: 0.9962247610092163\n",
      "Substitute: floating, BertScore: 0.9926636219024658\n",
      "Substitute: located, BertScore: 0.99245685338974\n",
      "Substitute: submerged, BertScore: 0.991568922996521\n",
      "Substitute: grounded, BertScore: 0.9907159805297852\n",
      "Substitute: engaged, BertScore: 0.9905595779418945\n",
      "Substitute: tied, BertScore: 0.9902533292770386\n",
      "Substitute: sheltered, BertScore: 0.990212082862854\n",
      "Substitute: stranded, BertScore: 0.9902063012123108\n",
      "Substitute: bound, BertScore: 0.9898092746734619\n",
      "Substitute: stopped, BertScore: 0.9883607029914856\n",
      "Substitute: held, BertScore: 0.9882196187973022\n",
      "Substitute: towed, BertScore: 0.9880388379096985\n",
      "Substitute: launched, BertScore: 0.9869422316551208\n",
      "Substitute: sunk, BertScore: 0.9861857295036316\n",
      "Substitute: placed, BertScore: 0.9860103130340576\n",
      "Substitute: sighted, BertScore: 0.9857430458068848\n",
      "Substitute: captured, BertScore: 0.9851106405258179\n",
      "Substitute: kept, BertScore: 0.9850142002105713\n",
      "Substitute: found, BertScore: 0.9848408102989197\n",
      "Substitute: caught, BertScore: 0.9848304986953735\n",
      "Substitute: carried, BertScore: 0.9841971397399902\n",
      "Substitute: spotted, BertScore: 0.9840540885925293\n",
      "Substitute: reported, BertScore: 0.9839016199111938\n",
      "Substitute: intercepted, BertScore: 0.9838811755180359\n",
      "Substitute: put, BertScore: 0.9838288426399231\n",
      "Substitute: suspended, BertScore: 0.9822412729263306\n",
      "Substitute: rescued, BertScore: 0.9816179275512695\n",
      "top-10 substitutes based on bertscores in context: ['docked', 'floating', 'located', 'submerged', 'grounded', 'engaged', 'tied', 'sheltered', 'stranded', 'bound']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: accolade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: award, BertScore: 0.9687458276748657\n",
      "Substitute: honor, BertScore: 0.9685600996017456\n",
      "Substitute: honour, BertScore: 0.9666151404380798\n",
      "Substitute: awards, BertScore: 0.9647934436798096\n",
      "Substitute: achievement, BertScore: 0.9647020101547241\n",
      "Substitute: occasion, BertScore: 0.9644292593002319\n",
      "Substitute: offering, BertScore: 0.9642345905303955\n",
      "Substitute: oscar, BertScore: 0.9641196131706238\n",
      "Substitute: annual, BertScore: 0.9638634324073792\n",
      "Substitute: item, BertScore: 0.963822603225708\n",
      "Substitute: image, BertScore: 0.9635213613510132\n",
      "Substitute: entry, BertScore: 0.9632766246795654\n",
      "Substitute: invitation, BertScore: 0.9632747769355774\n",
      "Substitute: academy, BertScore: 0.9631968140602112\n",
      "Substitute: event, BertScore: 0.9631353616714478\n",
      "Substitute: institution, BertScore: 0.9630913138389587\n",
      "Substitute: expression, BertScore: 0.9624852538108826\n",
      "Substitute: incentive, BertScore: 0.9624207019805908\n",
      "Substitute: endorsement, BertScore: 0.9624152183532715\n",
      "Substitute: evaluation, BertScore: 0.9623225927352905\n",
      "Substitute: opportunity, BertScore: 0.962200939655304\n",
      "Substitute: offer, BertScore: 0.9619271755218506\n",
      "Substitute: invite, BertScore: 0.9618059396743774\n",
      "Substitute: organization, BertScore: 0.9616032838821411\n",
      "Substitute: initiative, BertScore: 0.9613401889801025\n",
      "Substitute: order, BertScore: 0.9612411260604858\n",
      "Substitute: endowment, BertScore: 0.9603888988494873\n",
      "Substitute: allowance, BertScore: 0.9587074518203735\n",
      "Substitute: exchange, BertScore: 0.9582972526550293\n",
      "top-10 substitutes based on bertscores in context: ['award', 'honor', 'honour', 'awards', 'achievement', 'occasion', 'offering', 'oscar', 'annual', 'item']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: uprising\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: rebellion, BertScore: 0.9971906542778015\n",
      "Substitute: insurrection, BertScore: 0.9965924024581909\n",
      "Substitute: revolt, BertScore: 0.9959190487861633\n",
      "Substitute: revolution, BertScore: 0.9933481216430664\n",
      "Substitute: unrest, BertScore: 0.9924458265304565\n",
      "Substitute: insurgency, BertScore: 0.9923373460769653\n",
      "Substitute: struggle, BertScore: 0.9908003211021423\n",
      "Substitute: protests, BertScore: 0.9902279376983643\n",
      "Substitute: riots, BertScore: 0.9900459051132202\n",
      "Substitute: coup, BertScore: 0.9897133708000183\n",
      "Substitute: mutiny, BertScore: 0.9889187812805176\n",
      "Substitute: resistance, BertScore: 0.9888993501663208\n",
      "Substitute: conflict, BertScore: 0.9888320565223694\n",
      "Substitute: invasion, BertScore: 0.9887940287590027\n",
      "Substitute: war, BertScore: 0.988757312297821\n",
      "Substitute: movement, BertScore: 0.9885328412055969\n",
      "Substitute: offensive, BertScore: 0.9880898594856262\n",
      "Substitute: crisis, BertScore: 0.988065779209137\n",
      "Substitute: violence, BertScore: 0.9875116944313049\n",
      "Substitute: fighting, BertScore: 0.9866029024124146\n",
      "Substitute: occupation, BertScore: 0.9864658117294312\n",
      "Substitute: aggression, BertScore: 0.9849141240119934\n",
      "Substitute: genocide, BertScore: 0.9839678406715393\n",
      "Substitute: assault, BertScore: 0.9836698770523071\n",
      "Substitute: attack, BertScore: 0.9828357696533203\n",
      "Substitute: siege, BertScore: 0.9821290373802185\n",
      "Substitute: famine, BertScore: 0.9813591241836548\n",
      "Substitute: army, BertScore: 0.9785400629043579\n",
      "Substitute: government, BertScore: 0.9772776365280151\n",
      "top-10 substitutes based on bertscores in context: ['rebellion', 'insurrection', 'revolt', 'revolution', 'unrest', 'insurgency', 'struggle', 'protests', 'riots', 'coup']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: offender\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: accused, BertScore: 0.9706009030342102\n",
      "Substitute: inmate, BertScore: 0.9663641452789307\n",
      "Substitute: individual, BertScore: 0.9661670923233032\n",
      "Substitute: applicant, BertScore: 0.9642888903617859\n",
      "Substitute: addict, BertScore: 0.9610205888748169\n",
      "Substitute: attacker, BertScore: 0.9603834748268127\n",
      "Substitute: adult, BertScore: 0.9593415260314941\n",
      "Substitute: intruder, BertScore: 0.9575773477554321\n",
      "Substitute: immigrant, BertScore: 0.95705246925354\n",
      "Substitute: officer, BertScore: 0.9570157527923584\n",
      "Substitute: offence, BertScore: 0.9549516439437866\n",
      "Substitute: offense, BertScore: 0.9548860788345337\n",
      "Substitute: employee, BertScore: 0.9526981115341187\n",
      "Substitute: associate, BertScore: 0.9505130648612976\n",
      "Substitute: artist, BertScore: 0.9500795602798462\n",
      "Substitute: employer, BertScore: 0.9467806220054626\n",
      "Substitute: investigator, BertScore: 0.9466792345046997\n",
      "Substitute: incident, BertScore: 0.9460950493812561\n",
      "Substitute: act, BertScore: 0.9458154439926147\n",
      "Substitute: assault, BertScore: 0.944587767124176\n",
      "Substitute: agent, BertScore: 0.9435139298439026\n",
      "Substitute: enemy, BertScore: 0.9433817863464355\n",
      "Substitute: injustice, BertScore: 0.9420516490936279\n",
      "Substitute: abuse, BertScore: 0.9417562484741211\n",
      "Substitute: attack, BertScore: 0.9413857460021973\n",
      "Substitute: arrest, BertScore: 0.9413643479347229\n",
      "Substitute: agency, BertScore: 0.9387388825416565\n",
      "Substitute: enforcement, BertScore: 0.9262067079544067\n",
      "top-10 substitutes based on bertscores in context: ['accused', 'inmate', 'individual', 'applicant', 'addict', 'attacker', 'adult', 'intruder', 'immigrant', 'officer']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: bulging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: throbbing, BertScore: 0.992293119430542\n",
      "Substitute: crawling, BertScore: 0.9913110136985779\n",
      "Substitute: saturated, BertScore: 0.9909124374389648\n",
      "Substitute: stuffed, BertScore: 0.9908956289291382\n",
      "Substitute: swollen, BertScore: 0.9903882741928101\n",
      "Substitute: dripping, BertScore: 0.9902347922325134\n",
      "Substitute: swelling, BertScore: 0.9899946451187134\n",
      "Substitute: bursting, BertScore: 0.989820122718811\n",
      "Substitute: laden, BertScore: 0.9896053671836853\n",
      "Substitute: loaded, BertScore: 0.9887462854385376\n",
      "Substitute: packed, BertScore: 0.9885261654853821\n",
      "Substitute: filled, BertScore: 0.9884898066520691\n",
      "Substitute: reeling, BertScore: 0.9883899688720703\n",
      "Substitute: full, BertScore: 0.987077534198761\n",
      "Substitute: straining, BertScore: 0.986007571220398\n",
      "Substitute: rising, BertScore: 0.9856412410736084\n",
      "Substitute: roaring, BertScore: 0.9854162931442261\n",
      "Substitute: rolling, BertScore: 0.9849756360054016\n",
      "Substitute: filling, BertScore: 0.9849676489830017\n",
      "Substitute: struggling, BertScore: 0.9834463596343994\n",
      "Substitute: narrowing, BertScore: 0.9819963574409485\n",
      "Substitute: exploding, BertScore: 0.9818137884140015\n",
      "Substitute: flush, BertScore: 0.9815394282341003\n",
      "Substitute: widening, BertScore: 0.9804377555847168\n",
      "Substitute: closing, BertScore: 0.9769915342330933\n",
      "Substitute: complete, BertScore: 0.9743425846099854\n",
      "Substitute: dealing, BertScore: 0.9727935791015625\n",
      "Substitute: flooding, BertScore: 0.9670423865318298\n",
      "Substitute: along, BertScore: 0.9640994071960449\n",
      "top-10 substitutes based on bertscores in context: ['throbbing', 'crawling', 'saturated', 'stuffed', 'swollen', 'dripping', 'swelling', 'bursting', 'laden', 'loaded']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: encodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: codes, BertScore: 0.9596217274665833\n",
      "Substitute: expresses, BertScore: 0.9530118107795715\n",
      "Substitute: stores, BertScore: 0.9439281225204468\n",
      "Substitute: contains, BertScore: 0.9432995319366455\n",
      "Substitute: produces, BertScore: 0.9428836703300476\n",
      "Substitute: reads, BertScore: 0.9426487684249878\n",
      "Substitute: generates, BertScore: 0.9425294995307922\n",
      "Substitute: processes, BertScore: 0.9423398375511169\n",
      "Substitute: targets, BertScore: 0.9423275589942932\n",
      "Substitute: recognizes, BertScore: 0.9422627687454224\n",
      "Substitute: represents, BertScore: 0.9399213790893555\n",
      "Substitute: binds, BertScore: 0.9386026859283447\n",
      "Substitute: controls, BertScore: 0.9381123185157776\n",
      "Substitute: serves, BertScore: 0.9368926286697388\n",
      "Substitute: carries, BertScore: 0.936493992805481\n",
      "Substitute: identifies, BertScore: 0.9364233613014221\n",
      "Substitute: forms, BertScore: 0.9346861839294434\n",
      "Substitute: comprises, BertScore: 0.9344086050987244\n",
      "Substitute: includes, BertScore: 0.9336071014404297\n",
      "Substitute: preserves, BertScore: 0.9335310459136963\n",
      "Substitute: constitutes, BertScore: 0.9331797957420349\n",
      "Substitute: extracts, BertScore: 0.9318398237228394\n",
      "Substitute: has, BertScore: 0.9315499663352966\n",
      "Substitute: passes, BertScore: 0.930261492729187\n",
      "Substitute: involves, BertScore: 0.927639901638031\n",
      "Substitute: crosses, BertScore: 0.9249587655067444\n",
      "Substitute: is, BertScore: 0.9159732460975647\n",
      "top-10 substitutes based on bertscores in context: ['codes', 'expresses', 'stores', 'contains', 'produces', 'reads', 'generates', 'processes', 'targets', 'recognizes']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: mythological\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: mythical, BertScore: 0.9922738075256348\n",
      "Substitute: mythology, BertScore: 0.9875782132148743\n",
      "Substitute: epic, BertScore: 0.9856674075126648\n",
      "Substitute: biblical, BertScore: 0.9793806076049805\n",
      "Substitute: folklore, BertScore: 0.9783345460891724\n",
      "Substitute: hero, BertScore: 0.9768943190574646\n",
      "Substitute: heroic, BertScore: 0.9768022298812866\n",
      "Substitute: supernatural, BertScore: 0.9767553806304932\n",
      "Substitute: historical, BertScore: 0.976177453994751\n",
      "Substitute: narrative, BertScore: 0.9726681709289551\n",
      "Substitute: medieval, BertScore: 0.9725751876831055\n",
      "Substitute: romantic, BertScore: 0.9721882343292236\n",
      "Substitute: religious, BertScore: 0.9713422060012817\n",
      "Substitute: greek, BertScore: 0.969277024269104\n",
      "Substitute: political, BertScore: 0.9691590666770935\n",
      "Substitute: musical, BertScore: 0.9690608978271484\n",
      "Substitute: human, BertScore: 0.9686446189880371\n",
      "Substitute: military, BertScore: 0.9678661227226257\n",
      "Substitute: fictional, BertScore: 0.9672179818153381\n",
      "Substitute: model, BertScore: 0.9672039747238159\n",
      "Substitute: family, BertScore: 0.9668630361557007\n",
      "Substitute: character, BertScore: 0.9668121933937073\n",
      "Substitute: cartoon, BertScore: 0.9662148356437683\n",
      "Substitute: male, BertScore: 0.9652866721153259\n",
      "Substitute: female, BertScore: 0.9649645686149597\n",
      "Substitute: titular, BertScore: 0.9648584127426147\n",
      "Substitute: title, BertScore: 0.9643624424934387\n",
      "Substitute: central, BertScore: 0.9596186876296997\n",
      "Substitute: recurring, BertScore: 0.957682728767395\n",
      "top-10 substitutes based on bertscores in context: ['mythical', 'mythology', 'epic', 'biblical', 'folklore', 'hero', 'heroic', 'supernatural', 'historical', 'narrative']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: romanized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: transcribed, BertScore: 0.9860296249389648\n",
      "Substitute: translated, BertScore: 0.9855399131774902\n",
      "Substitute: refined, BertScore: 0.9833341836929321\n",
      "Substitute: named, BertScore: 0.9784055352210999\n",
      "Substitute: classified, BertScore: 0.9780825972557068\n",
      "Substitute: mixes, BertScore: 0.9776272773742676\n",
      "Substitute: translates, BertScore: 0.9773668050765991\n",
      "Substitute: converts, BertScore: 0.9760808944702148\n",
      "Substitute: identified, BertScore: 0.975862443447113\n",
      "Substitute: used, BertScore: 0.9736135601997375\n",
      "Substitute: reads, BertScore: 0.9719813466072083\n",
      "Substitute: takes, BertScore: 0.9715345501899719\n",
      "Substitute: related, BertScore: 0.9715337753295898\n",
      "Substitute: ranks, BertScore: 0.970177412033081\n",
      "Substitute: names, BertScore: 0.9700442552566528\n",
      "Substitute: preserves, BertScore: 0.9697989821434021\n",
      "Substitute: stains, BertScore: 0.9695550203323364\n",
      "Substitute: describes, BertScore: 0.9685038924217224\n",
      "Substitute: uses, BertScore: 0.9681918621063232\n",
      "Substitute: identifies, BertScore: 0.9676096439361572\n",
      "Substitute: cites, BertScore: 0.9675992727279663\n",
      "Substitute: traces, BertScore: 0.9675268530845642\n",
      "Substitute: writes, BertScore: 0.9651059508323669\n",
      "Substitute: notes, BertScore: 0.9644935131072998\n",
      "Substitute: reports, BertScore: 0.964301586151123\n",
      "Substitute: compares, BertScore: 0.9638798236846924\n",
      "Substitute: reported, BertScore: 0.9630618691444397\n",
      "Substitute: explains, BertScore: 0.9604648947715759\n",
      "Substitute: knows, BertScore: 0.9599384069442749\n",
      "top-10 substitutes based on bertscores in context: ['transcribed', 'translated', 'refined', 'named', 'classified', 'mixes', 'translates', 'converts', 'identified', 'used']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: residences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: homes, BertScore: 0.9962160587310791\n",
      "Substitute: dwellings, BertScore: 0.9959682822227478\n",
      "Substitute: houses, BertScore: 0.9942017793655396\n",
      "Substitute: properties, BertScore: 0.9940981864929199\n",
      "Substitute: apartments, BertScore: 0.9929555654525757\n",
      "Substitute: structures, BertScore: 0.9929544925689697\n",
      "Substitute: buildings, BertScore: 0.9926648736000061\n",
      "Substitute: households, BertScore: 0.9919548630714417\n",
      "Substitute: housing, BertScore: 0.9915677309036255\n",
      "Substitute: units, BertScore: 0.9914976954460144\n",
      "Substitute: mansions, BertScore: 0.9910933375358582\n",
      "Substitute: establishments, BertScore: 0.9905956387519836\n",
      "Substitute: subdivisions, BertScore: 0.9900689125061035\n",
      "Substitute: estates, BertScore: 0.989495038986206\n",
      "Substitute: villas, BertScore: 0.9890542030334473\n",
      "Substitute: businesses, BertScore: 0.988662600517273\n",
      "Substitute: areas, BertScore: 0.9885894656181335\n",
      "Substitute: dwelling, BertScore: 0.987449049949646\n",
      "Substitute: property, BertScore: 0.9868358373641968\n",
      "Substitute: communities, BertScore: 0.9863938093185425\n",
      "Substitute: residential, BertScore: 0.985835611820221\n",
      "Substitute: families, BertScore: 0.9855554699897766\n",
      "Substitute: offices, BertScore: 0.985184371471405\n",
      "Substitute: neighborhoods, BertScore: 0.9851277470588684\n",
      "Substitute: residents, BertScore: 0.985065221786499\n",
      "Substitute: living, BertScore: 0.9832087755203247\n",
      "Substitute: home, BertScore: 0.9806589484214783\n",
      "Substitute: gatherings, BertScore: 0.9784165620803833\n",
      "top-10 substitutes based on bertscores in context: ['homes', 'dwellings', 'houses', 'properties', 'apartments', 'structures', 'buildings', 'households', 'housing', 'units']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: ringleaders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: leaders, BertScore: 0.9295705556869507\n",
      "Substitute: members, BertScore: 0.9093875288963318\n",
      "Substitute: soldiers, BertScore: 0.8965553045272827\n",
      "Substitute: suspects, BertScore: 0.8960235118865967\n",
      "Substitute: operatives, BertScore: 0.8958427906036377\n",
      "Substitute: men, BertScore: 0.8954983949661255\n",
      "Substitute: recruits, BertScore: 0.8941435813903809\n",
      "Substitute: officers, BertScore: 0.8920174837112427\n",
      "Substitute: boys, BertScore: 0.8890299797058105\n",
      "Substitute: players, BertScore: 0.8883510231971741\n",
      "Substitute: girls, BertScore: 0.8866938948631287\n",
      "Substitute: victims, BertScore: 0.8861459493637085\n",
      "Substitute: fighters, BertScore: 0.8859246969223022\n",
      "Substitute: prisoners, BertScore: 0.885431170463562\n",
      "Substitute: women, BertScore: 0.8851332664489746\n",
      "Substitute: staff, BertScore: 0.8850777745246887\n",
      "Substitute: hostages, BertScore: 0.8844059705734253\n",
      "Substitute: personnel, BertScore: 0.8808149099349976\n",
      "Substitute: survivors, BertScore: 0.8776997327804565\n",
      "Substitute: captives, BertScore: 0.8775403499603271\n",
      "Substitute: crew, BertScore: 0.8770732879638672\n",
      "Substitute: others, BertScore: 0.8718177676200867\n",
      "Substitute: four, BertScore: 0.8676208853721619\n",
      "Substitute: eight, BertScore: 0.8675915002822876\n",
      "Substitute: five, BertScore: 0.8675819039344788\n",
      "Substitute: nine, BertScore: 0.8670943379402161\n",
      "Substitute: seven, BertScore: 0.8667508363723755\n",
      "Substitute: six, BertScore: 0.8666895627975464\n",
      "Substitute: three, BertScore: 0.8658353686332703\n",
      "Substitute: rest, BertScore: 0.8630726337432861\n",
      "top-10 substitutes based on bertscores in context: ['leaders', 'members', 'soldiers', 'suspects', 'operatives', 'men', 'recruits', 'officers', 'boys', 'players']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: compound\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: complex, BertScore: 0.994930624961853\n",
      "Substitute: premises, BertScore: 0.9937692880630493\n",
      "Substitute: facility, BertScore: 0.9936556816101074\n",
      "Substitute: residence, BertScore: 0.9934067726135254\n",
      "Substitute: mansion, BertScore: 0.9932417869567871\n",
      "Substitute: villa, BertScore: 0.9931854009628296\n",
      "Substitute: building, BertScore: 0.9926720261573792\n",
      "Substitute: house, BertScore: 0.9924033284187317\n",
      "Substitute: palace, BertScore: 0.9923941493034363\n",
      "Substitute: base, BertScore: 0.9920404553413391\n",
      "Substitute: property, BertScore: 0.9918876886367798\n",
      "Substitute: headquarters, BertScore: 0.9918302297592163\n",
      "Substitute: home, BertScore: 0.9915711283683777\n",
      "Substitute: hideout, BertScore: 0.9913658499717712\n",
      "Substitute: fortress, BertScore: 0.9912335276603699\n",
      "Substitute: office, BertScore: 0.9905833005905151\n",
      "Substitute: hotel, BertScore: 0.9905149936676025\n",
      "Substitute: site, BertScore: 0.9904851317405701\n",
      "Substitute: ranch, BertScore: 0.9894000291824341\n",
      "Substitute: hospital, BertScore: 0.9893203973770142\n",
      "Substitute: station, BertScore: 0.9888158440589905\n",
      "Substitute: restaurant, BertScore: 0.9881827235221863\n",
      "Substitute: stadium, BertScore: 0.9879472851753235\n",
      "Substitute: neighborhood, BertScore: 0.987484335899353\n",
      "Substitute: gate, BertScore: 0.984469473361969\n",
      "Substitute: operation, BertScore: 0.983593225479126\n",
      "Substitute: capital, BertScore: 0.9828104376792908\n",
      "Substitute: city, BertScore: 0.981968879699707\n",
      "top-10 substitutes based on bertscores in context: ['complex', 'premises', 'facility', 'residence', 'mansion', 'villa', 'building', 'house', 'palace', 'base']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: pre-positioned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: positioned, BertScore: 0.9592460989952087\n",
      "Substitute: sited, BertScore: 0.9538625478744507\n",
      "Substitute: poised, BertScore: 0.9535764455795288\n",
      "Substitute: stationed, BertScore: 0.9527407884597778\n",
      "Substitute: placed, BertScore: 0.9521416425704956\n",
      "Substitute: deployed, BertScore: 0.9518453478813171\n",
      "Substitute: secured, BertScore: 0.951108455657959\n",
      "Substitute: mounted, BertScore: 0.9510141015052795\n",
      "Substitute: arranged, BertScore: 0.9509091377258301\n",
      "Substitute: located, BertScore: 0.950821042060852\n",
      "Substitute: installed, BertScore: 0.9500266909599304\n",
      "Substitute: ready, BertScore: 0.9493839740753174\n",
      "Substitute: situated, BertScore: 0.9493768215179443\n",
      "Substitute: established, BertScore: 0.9489061832427979\n",
      "Substitute: concealed, BertScore: 0.9486027359962463\n",
      "Substitute: trained, BertScore: 0.9478577375411987\n",
      "Substitute: embedded, BertScore: 0.9478400945663452\n",
      "Substitute: parked, BertScore: 0.94742751121521\n",
      "Substitute: prepared, BertScore: 0.9474108219146729\n",
      "Substitute: fitted, BertScore: 0.9469352960586548\n",
      "Substitute: planted, BertScore: 0.9469193816184998\n",
      "Substitute: stored, BertScore: 0.9444865584373474\n",
      "Substitute: constructed, BertScore: 0.9444852471351624\n",
      "Substitute: hidden, BertScore: 0.9444078207015991\n",
      "Substitute: place, BertScore: 0.9418939352035522\n",
      "Substitute: planned, BertScore: 0.9410046339035034\n",
      "Substitute: identified, BertScore: 0.9393981695175171\n",
      "Substitute: available, BertScore: 0.9358342885971069\n",
      "Substitute: used, BertScore: 0.9349747896194458\n",
      "Substitute: somewhere, BertScore: 0.9241062998771667\n",
      "top-10 substitutes based on bertscores in context: ['positioned', 'sited', 'poised', 'stationed', 'placed', 'deployed', 'secured', 'mounted', 'arranged', 'located']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: exclusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: removal, BertScore: 0.9920428395271301\n",
      "Substitute: elimination, BertScore: 0.9919171333312988\n",
      "Substitute: withdrawal, BertScore: 0.9908834099769592\n",
      "Substitute: exclude, BertScore: 0.9902948141098022\n",
      "Substitute: excluded, BertScore: 0.9900301694869995\n",
      "Substitute: disqualification, BertScore: 0.9898306131362915\n",
      "Substitute: banning, BertScore: 0.9898122549057007\n",
      "Substitute: rejection, BertScore: 0.9891869425773621\n",
      "Substitute: ban, BertScore: 0.9879977703094482\n",
      "Substitute: absence, BertScore: 0.9879729747772217\n",
      "Substitute: expulsion, BertScore: 0.9878553748130798\n",
      "Substitute: exit, BertScore: 0.9874247908592224\n",
      "Substitute: departure, BertScore: 0.9872815012931824\n",
      "Substitute: dismissal, BertScore: 0.9865400195121765\n",
      "Substitute: deviation, BertScore: 0.985335111618042\n",
      "Substitute: termination, BertScore: 0.9850389361381531\n",
      "Substitute: exemption, BertScore: 0.9842770099639893\n",
      "Substitute: inclusion, BertScore: 0.9842451214790344\n",
      "Substitute: suspension, BertScore: 0.9838484525680542\n",
      "Substitute: restriction, BertScore: 0.9832067489624023\n",
      "Substitute: resignation, BertScore: 0.9805607199668884\n",
      "Substitute: release, BertScore: 0.9780222177505493\n",
      "Substitute: freedom, BertScore: 0.9768419861793518\n",
      "Substitute: interference, BertScore: 0.9765685200691223\n",
      "Substitute: protection, BertScore: 0.9760035276412964\n",
      "Substitute: opposition, BertScore: 0.9749454259872437\n",
      "Substitute: selection, BertScore: 0.9742252230644226\n",
      "Substitute: entry, BertScore: 0.9719129204750061\n",
      "Substitute: performance, BertScore: 0.9688884019851685\n",
      "top-10 substitutes based on bertscores in context: ['removal', 'elimination', 'withdrawal', 'exclude', 'excluded', 'disqualification', 'banning', 'rejection', 'ban', 'absence']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: recognized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: acknowledged, BertScore: 0.9979056119918823\n",
      "Substitute: accepted, BertScore: 0.9951192140579224\n",
      "Substitute: identified, BertScore: 0.9945114850997925\n",
      "Substitute: considered, BertScore: 0.9944712519645691\n",
      "Substitute: regarded, BertScore: 0.994369387626648\n",
      "Substitute: hailed, BertScore: 0.9942734241485596\n",
      "Substitute: labeled, BertScore: 0.9941875338554382\n",
      "Substitute: recognised, BertScore: 0.9938658475875854\n",
      "Substitute: designated, BertScore: 0.9938643574714661\n",
      "Substitute: respected, BertScore: 0.9934148788452148\n",
      "Substitute: established, BertScore: 0.9930856823921204\n",
      "Substitute: counted, BertScore: 0.993057370185852\n",
      "Substitute: perceived, BertScore: 0.9929845929145813\n",
      "Substitute: certified, BertScore: 0.992858350276947\n",
      "Substitute: seen, BertScore: 0.9925563335418701\n",
      "Substitute: honored, BertScore: 0.9922930002212524\n",
      "Substitute: celebrated, BertScore: 0.9919781684875488\n",
      "Substitute: treated, BertScore: 0.9916769862174988\n",
      "Substitute: qualified, BertScore: 0.9916582703590393\n",
      "Substitute: embraced, BertScore: 0.9915911555290222\n",
      "Substitute: categorized, BertScore: 0.9914898872375488\n",
      "Substitute: welcomed, BertScore: 0.9913389086723328\n",
      "Substitute: represented, BertScore: 0.991159200668335\n",
      "Substitute: listed, BertScore: 0.9907196760177612\n",
      "Substitute: known, BertScore: 0.9905937314033508\n",
      "Substitute: classified, BertScore: 0.990477979183197\n",
      "Substitute: described, BertScore: 0.9889348745346069\n",
      "Substitute: registered, BertScore: 0.9889054298400879\n",
      "Substitute: honoured, BertScore: 0.9888538718223572\n",
      "top-10 substitutes based on bertscores in context: ['acknowledged', 'accepted', 'identified', 'considered', 'regarded', 'hailed', 'labeled', 'recognised', 'designated', 'respected']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: toxins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: chemicals, BertScore: 0.9634941816329956\n",
      "Substitute: poison, BertScore: 0.958462119102478\n",
      "Substitute: enzymes, BertScore: 0.9584108591079712\n",
      "Substitute: bacteria, BertScore: 0.9568547010421753\n",
      "Substitute: spores, BertScore: 0.956556499004364\n",
      "Substitute: substances, BertScore: 0.9564504623413086\n",
      "Substitute: infections, BertScore: 0.9564371109008789\n",
      "Substitute: viruses, BertScore: 0.9557732939720154\n",
      "Substitute: diseases, BertScore: 0.9552788138389587\n",
      "Substitute: acids, BertScore: 0.9548405408859253\n",
      "Substitute: venom, BertScore: 0.9544358253479004\n",
      "Substitute: residues, BertScore: 0.9528291821479797\n",
      "Substitute: hormones, BertScore: 0.9524874091148376\n",
      "Substitute: fungi, BertScore: 0.9522378444671631\n",
      "Substitute: antibiotics, BertScore: 0.9516813158988953\n",
      "Substitute: pollution, BertScore: 0.9510827660560608\n",
      "Substitute: radiation, BertScore: 0.950823187828064\n",
      "Substitute: mold, BertScore: 0.9503215551376343\n",
      "Substitute: heat, BertScore: 0.9500049352645874\n",
      "Substitute: bugs, BertScore: 0.9495962858200073\n",
      "Substitute: insects, BertScore: 0.9485364556312561\n",
      "Substitute: drugs, BertScore: 0.9477308392524719\n",
      "Substitute: dust, BertScore: 0.9466230869293213\n",
      "Substitute: acid, BertScore: 0.9465627074241638\n",
      "Substitute: radicals, BertScore: 0.9451091885566711\n",
      "Substitute: parasites, BertScore: 0.9444524645805359\n",
      "Substitute: plants, BertScore: 0.9418845176696777\n",
      "Substitute: toxic, BertScore: 0.9385161995887756\n",
      "top-10 substitutes based on bertscores in context: ['chemicals', 'poison', 'enzymes', 'bacteria', 'spores', 'substances', 'infections', 'viruses', 'diseases', 'acids']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: nominated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: nominee, BertScore: 0.9859370589256287\n",
      "Substitute: shortlisted, BertScore: 0.9853674173355103\n",
      "Substitute: finalist, BertScore: 0.9815261363983154\n",
      "Substitute: won, BertScore: 0.9742608070373535\n",
      "Substitute: awarded, BertScore: 0.973284900188446\n",
      "Substitute: honored, BertScore: 0.971712052822113\n",
      "Substitute: selected, BertScore: 0.9716478586196899\n",
      "Substitute: recognized, BertScore: 0.9710174202919006\n",
      "Substitute: voted, BertScore: 0.9708070755004883\n",
      "Substitute: chosen, BertScore: 0.9703341126441956\n",
      "Substitute: honoured, BertScore: 0.9688013195991516\n",
      "Substitute: presented, BertScore: 0.9685122966766357\n",
      "Substitute: picked, BertScore: 0.967973530292511\n",
      "Substitute: named, BertScore: 0.9673745632171631\n",
      "Substitute: received, BertScore: 0.9657434225082397\n",
      "Substitute: accepted, BertScore: 0.9656257629394531\n",
      "Substitute: eligible, BertScore: 0.9652751684188843\n",
      "Substitute: decorated, BertScore: 0.9628897905349731\n",
      "Substitute: elected, BertScore: 0.9622121453285217\n",
      "Substitute: entered, BertScore: 0.9614073038101196\n",
      "Substitute: listed, BertScore: 0.9582582712173462\n",
      "Substitute: placed, BertScore: 0.9559816718101501\n",
      "Substitute: given, BertScore: 0.9543827176094055\n",
      "Substitute: announced, BertScore: 0.9528359174728394\n",
      "Substitute: crowned, BertScore: 0.9489088654518127\n",
      "Substitute: tapped, BertScore: 0.9470655918121338\n",
      "Substitute: asked, BertScore: 0.9456596374511719\n",
      "Substitute: defeated, BertScore: 0.9400676488876343\n",
      "Substitute: competing, BertScore: 0.9320774674415588\n",
      "top-10 substitutes based on bertscores in context: ['nominee', 'shortlisted', 'finalist', 'won', 'awarded', 'honored', 'selected', 'recognized', 'voted', 'chosen']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: unprecedented\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: extraordinary, BertScore: 0.9920191764831543\n",
      "Substitute: unexpected, BertScore: 0.9912330508232117\n",
      "Substitute: unusual, BertScore: 0.9899943470954895\n",
      "Substitute: astonishing, BertScore: 0.988845944404602\n",
      "Substitute: incredible, BertScore: 0.9885123372077942\n",
      "Substitute: enormous, BertScore: 0.9879623651504517\n",
      "Substitute: immense, BertScore: 0.9878833293914795\n",
      "Substitute: overwhelming, BertScore: 0.9877920150756836\n",
      "Substitute: extreme, BertScore: 0.9872537851333618\n",
      "Substitute: aggressive, BertScore: 0.98662269115448\n",
      "Substitute: unacceptable, BertScore: 0.9860215187072754\n",
      "Substitute: intense, BertScore: 0.985901951789856\n",
      "Substitute: extensive, BertScore: 0.985777735710144\n",
      "Substitute: outrageous, BertScore: 0.985763430595398\n",
      "Substitute: intensified, BertScore: 0.9852270483970642\n",
      "Substitute: immediate, BertScore: 0.9849517345428467\n",
      "Substitute: explosive, BertScore: 0.9846078157424927\n",
      "Substitute: embarrassing, BertScore: 0.9845139980316162\n",
      "Substitute: excessive, BertScore: 0.9833961129188538\n",
      "Substitute: extended, BertScore: 0.9824860692024231\n",
      "Substitute: effective, BertScore: 0.9822167754173279\n",
      "Substitute: imminent, BertScore: 0.9812099933624268\n",
      "Substitute: absolute, BertScore: 0.9806915521621704\n",
      "Substitute: ongoing, BertScore: 0.9803874492645264\n",
      "Substitute: illegal, BertScore: 0.9803869724273682\n",
      "Substitute: official, BertScore: 0.9796082973480225\n",
      "Substitute: unconstitutional, BertScore: 0.978722333908081\n",
      "Substitute: increasing, BertScore: 0.9785668253898621\n",
      "Substitute: international, BertScore: 0.9778133630752563\n",
      "top-10 substitutes based on bertscores in context: ['extraordinary', 'unexpected', 'unusual', 'astonishing', 'incredible', 'enormous', 'immense', 'overwhelming', 'extreme', 'aggressive']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: erring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: dangerous, BertScore: 0.9860622882843018\n",
      "Substitute: anxious, BertScore: 0.9856849312782288\n",
      "Substitute: interfering, BertScore: 0.9855445623397827\n",
      "Substitute: wandering, BertScore: 0.9852235317230225\n",
      "Substitute: hungry, BertScore: 0.9844514727592468\n",
      "Substitute: unwanted, BertScore: 0.9841306805610657\n",
      "Substitute: frightened, BertScore: 0.9830557703971863\n",
      "Substitute: illegal, BertScore: 0.9826250076293945\n",
      "Substitute: chasing, BertScore: 0.9825329780578613\n",
      "Substitute: traveling, BertScore: 0.9824001789093018\n",
      "Substitute: attacking, BertScore: 0.9816098809242249\n",
      "Substitute: returning, BertScore: 0.9815418720245361\n",
      "Substitute: fleeing, BertScore: 0.98117595911026\n",
      "Substitute: falling, BertScore: 0.9810948967933655\n",
      "Substitute: departing, BertScore: 0.98101806640625\n",
      "Substitute: fugitive, BertScore: 0.9805048704147339\n",
      "Substitute: incoming, BertScore: 0.9803839921951294\n",
      "Substitute: pursuing, BertScore: 0.9803332090377808\n",
      "Substitute: coming, BertScore: 0.979491114616394\n",
      "Substitute: arriving, BertScore: 0.9794871211051941\n",
      "Substitute: approaching, BertScore: 0.9789571762084961\n",
      "Substitute: flying, BertScore: 0.9786059260368347\n",
      "Substitute: advancing, BertScore: 0.9785230159759521\n",
      "Substitute: invading, BertScore: 0.9781314730644226\n",
      "Substitute: retreating, BertScore: 0.9778606295585632\n",
      "Substitute: missing, BertScore: 0.9772823452949524\n",
      "Substitute: remaining, BertScore: 0.9772765636444092\n",
      "Substitute: many, BertScore: 0.9770485758781433\n",
      "Substitute: more, BertScore: 0.976851224899292\n",
      "Substitute: other, BertScore: 0.9755719900131226\n",
      "top-10 substitutes based on bertscores in context: ['dangerous', 'anxious', 'interfering', 'wandering', 'hungry', 'unwanted', 'frightened', 'illegal', 'chasing', 'traveling']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: monsters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: beasts, BertScore: 0.9936831593513489\n",
      "Substitute: creatures, BertScore: 0.9928030967712402\n",
      "Substitute: demons, BertScore: 0.992624044418335\n",
      "Substitute: zombies, BertScore: 0.9925268888473511\n",
      "Substitute: villains, BertScore: 0.9920465350151062\n",
      "Substitute: evil, BertScore: 0.9911782741546631\n",
      "Substitute: ghosts, BertScore: 0.9909915924072266\n",
      "Substitute: animals, BertScore: 0.9909793138504028\n",
      "Substitute: robots, BertScore: 0.9905397891998291\n",
      "Substitute: mutants, BertScore: 0.9901466965675354\n",
      "Substitute: trolls, BertScore: 0.989831805229187\n",
      "Substitute: giants, BertScore: 0.9898245334625244\n",
      "Substitute: scary, BertScore: 0.9897880554199219\n",
      "Substitute: heroes, BertScore: 0.9893103241920471\n",
      "Substitute: wolves, BertScore: 0.9892731308937073\n",
      "Substitute: witches, BertScore: 0.9889901876449585\n",
      "Substitute: dragons, BertScore: 0.9888561964035034\n",
      "Substitute: aliens, BertScore: 0.9887216687202454\n",
      "Substitute: dinosaurs, BertScore: 0.9881879687309265\n",
      "Substitute: undead, BertScore: 0.9877820611000061\n",
      "Substitute: humans, BertScore: 0.9873120188713074\n",
      "Substitute: enemies, BertScore: 0.9869744777679443\n",
      "Substitute: people, BertScore: 0.9865509271621704\n",
      "Substitute: nazis, BertScore: 0.9850703477859497\n",
      "Substitute: dogs, BertScore: 0.9850211143493652\n",
      "Substitute: vampires, BertScore: 0.9848081469535828\n",
      "Substitute: adults, BertScore: 0.9795593619346619\n",
      "Substitute: children, BertScore: 0.9788596034049988\n",
      "top-10 substitutes based on bertscores in context: ['beasts', 'creatures', 'demons', 'zombies', 'villains', 'evil', 'ghosts', 'animals', 'robots', 'mutants']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: detainees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: captives, BertScore: 0.9972032904624939\n",
      "Substitute: prisoners, BertScore: 0.9971234202384949\n",
      "Substitute: inmates, BertScore: 0.9961557388305664\n",
      "Substitute: suspects, BertScore: 0.9953736662864685\n",
      "Substitute: defendants, BertScore: 0.9952148199081421\n",
      "Substitute: hostages, BertScore: 0.9951474666595459\n",
      "Substitute: civilians, BertScore: 0.9950318932533264\n",
      "Substitute: individuals, BertScore: 0.9950284957885742\n",
      "Substitute: patients, BertScore: 0.9949595332145691\n",
      "Substitute: combatants, BertScore: 0.9948195219039917\n",
      "Substitute: students, BertScore: 0.9947937726974487\n",
      "Substitute: soldiers, BertScore: 0.9947819113731384\n",
      "Substitute: members, BertScore: 0.9947644472122192\n",
      "Substitute: personnel, BertScore: 0.994696319103241\n",
      "Substitute: officers, BertScore: 0.9946709275245667\n",
      "Substitute: people, BertScore: 0.9946608543395996\n",
      "Substitute: men, BertScore: 0.9945732355117798\n",
      "Substitute: fighters, BertScore: 0.994505763053894\n",
      "Substitute: persons, BertScore: 0.9944425225257874\n",
      "Substitute: comrades, BertScore: 0.9943990707397461\n",
      "Substitute: marines, BertScore: 0.9940244555473328\n",
      "Substitute: those, BertScore: 0.99383944272995\n",
      "Substitute: americans, BertScore: 0.9936276078224182\n",
      "Substitute: others, BertScore: 0.9935125708580017\n",
      "Substitute: prisoner, BertScore: 0.9927630424499512\n",
      "Substitute: detention, BertScore: 0.9915086030960083\n",
      "Substitute: information, BertScore: 0.9911513924598694\n",
      "Substitute: them, BertScore: 0.9910471439361572\n",
      "Substitute: being, BertScore: 0.989613950252533\n",
      "top-10 substitutes based on bertscores in context: ['captives', 'prisoners', 'inmates', 'suspects', 'defendants', 'hostages', 'civilians', 'individuals', 'patients', 'combatants']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: harassing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: attacking, BertScore: 0.9785138368606567\n",
      "Substitute: stalking, BertScore: 0.976844310760498\n",
      "Substitute: threatening, BertScore: 0.9733508229255676\n",
      "Substitute: targeting, BertScore: 0.9718371629714966\n",
      "Substitute: pursuing, BertScore: 0.9705159664154053\n",
      "Substitute: intimidating, BertScore: 0.9704045057296753\n",
      "Substitute: bullying, BertScore: 0.9698376655578613\n",
      "Substitute: taunting, BertScore: 0.9681639075279236\n",
      "Substitute: insulting, BertScore: 0.9664409160614014\n",
      "Substitute: beating, BertScore: 0.9657183885574341\n",
      "Substitute: hurting, BertScore: 0.9652642011642456\n",
      "Substitute: aiding, BertScore: 0.9636151194572449\n",
      "Substitute: hunting, BertScore: 0.9629161357879639\n",
      "Substitute: murdering, BertScore: 0.9628031849861145\n",
      "Substitute: assisting, BertScore: 0.9625805616378784\n",
      "Substitute: following, BertScore: 0.962441086769104\n",
      "Substitute: killing, BertScore: 0.9617085456848145\n",
      "Substitute: protecting, BertScore: 0.9616167545318604\n",
      "Substitute: kidnapping, BertScore: 0.9609313607215881\n",
      "Substitute: misleading, BertScore: 0.9593560099601746\n",
      "Substitute: ignoring, BertScore: 0.9588786959648132\n",
      "Substitute: blocking, BertScore: 0.9584192037582397\n",
      "Substitute: executing, BertScore: 0.9581458568572998\n",
      "Substitute: arresting, BertScore: 0.9581080079078674\n",
      "Substitute: shooting, BertScore: 0.9578962922096252\n",
      "Substitute: firing, BertScore: 0.9572327733039856\n",
      "Substitute: supporting, BertScore: 0.9565986394882202\n",
      "Substitute: helping, BertScore: 0.9552510976791382\n",
      "Substitute: poisoning, BertScore: 0.9514741897583008\n",
      "Substitute: recruiting, BertScore: 0.9498366713523865\n",
      "top-10 substitutes based on bertscores in context: ['attacking', 'stalking', 'threatening', 'targeting', 'pursuing', 'intimidating', 'bullying', 'taunting', 'insulting', 'beating']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: conflicting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: contradictory, BertScore: 0.9918423891067505\n",
      "Substitute: inconsistent, BertScore: 0.986173152923584\n",
      "Substitute: mixed, BertScore: 0.9764732718467712\n",
      "Substitute: weak, BertScore: 0.965099036693573\n",
      "Substitute: limited, BertScore: 0.9641883969306946\n",
      "Substitute: negative, BertScore: 0.9640110731124878\n",
      "Substitute: insufficient, BertScore: 0.9633834958076477\n",
      "Substitute: lacking, BertScore: 0.9629127979278564\n",
      "Substitute: compelling, BertScore: 0.9570114016532898\n",
      "Substitute: overwhelming, BertScore: 0.9563761949539185\n",
      "Substitute: mounting, BertScore: 0.9548326730728149\n",
      "Substitute: strong, BertScore: 0.9545250535011292\n",
      "Substitute: abundant, BertScore: 0.9533563852310181\n",
      "Substitute: little, BertScore: 0.9517898559570312\n",
      "Substitute: other, BertScore: 0.9517718553543091\n",
      "Substitute: widespread, BertScore: 0.9509440064430237\n",
      "Substitute: solid, BertScore: 0.9495833516120911\n",
      "Substitute: not, BertScore: 0.9492846727371216\n",
      "Substitute: increasing, BertScore: 0.9471355080604553\n",
      "Substitute: no, BertScore: 0.9470162391662598\n",
      "Substitute: some, BertScore: 0.9468664526939392\n",
      "Substitute: good, BertScore: 0.9463593363761902\n",
      "Substitute: more, BertScore: 0.9443186521530151\n",
      "Substitute: less, BertScore: 0.9425303339958191\n",
      "Substitute: still, BertScore: 0.9422724843025208\n",
      "Substitute: only, BertScore: 0.9406716823577881\n",
      "Substitute: growing, BertScore: 0.9367097020149231\n",
      "Substitute: also, BertScore: 0.9338161945343018\n",
      "Substitute: even, BertScore: 0.9282535910606384\n",
      "top-10 substitutes based on bertscores in context: ['contradictory', 'inconsistent', 'mixed', 'weak', 'limited', 'negative', 'insufficient', 'lacking', 'compelling', 'overwhelming']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: announced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: confirmed, BertScore: 0.9907575249671936\n",
      "Substitute: reported, BertScore: 0.9880616664886475\n",
      "Substitute: acknowledged, BertScore: 0.987022876739502\n",
      "Substitute: revealed, BertScore: 0.9862675666809082\n",
      "Substitute: signaled, BertScore: 0.9850869178771973\n",
      "Substitute: disclosed, BertScore: 0.9850179553031921\n",
      "Substitute: proclaimed, BertScore: 0.9849994778633118\n",
      "Substitute: stated, BertScore: 0.9847401976585388\n",
      "Substitute: declared, BertScore: 0.9831593036651611\n",
      "Substitute: recognized, BertScore: 0.9830693006515503\n",
      "Substitute: unveiled, BertScore: 0.9826735854148865\n",
      "Substitute: notified, BertScore: 0.982135534286499\n",
      "Substitute: approved, BertScore: 0.9818181991577148\n",
      "Substitute: accepted, BertScore: 0.9815945625305176\n",
      "Substitute: informed, BertScore: 0.9799768924713135\n",
      "Substitute: pronounced, BertScore: 0.9796786308288574\n",
      "Substitute: claimed, BertScore: 0.9791510105133057\n",
      "Substitute: finalized, BertScore: 0.9775300621986389\n",
      "Substitute: mentioned, BertScore: 0.9773094654083252\n",
      "Substitute: declare, BertScore: 0.9761497974395752\n",
      "Substitute: said, BertScore: 0.9761375784873962\n",
      "Substitute: predicted, BertScore: 0.9756265878677368\n",
      "Substitute: celebrated, BertScore: 0.9756152629852295\n",
      "Substitute: discussed, BertScore: 0.9754251837730408\n",
      "Substitute: documented, BertScore: 0.9743710160255432\n",
      "Substitute: described, BertScore: 0.9737656116485596\n",
      "top-10 substitutes based on bertscores in context: ['confirmed', 'reported', 'acknowledged', 'revealed', 'signaled', 'disclosed', 'proclaimed', 'stated', 'declared', 'recognized']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: cementing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: concluding, BertScore: 0.9876803159713745\n",
      "Substitute: confirming, BertScore: 0.9866971969604492\n",
      "Substitute: completing, BertScore: 0.9845297336578369\n",
      "Substitute: ensuring, BertScore: 0.9840303659439087\n",
      "Substitute: establishing, BertScore: 0.9838300943374634\n",
      "Substitute: ending, BertScore: 0.9835330247879028\n",
      "Substitute: overseeing, BertScore: 0.9829961061477661\n",
      "Substitute: building, BertScore: 0.982768714427948\n",
      "Substitute: sealing, BertScore: 0.9826834797859192\n",
      "Substitute: securing, BertScore: 0.9825692176818848\n",
      "Substitute: expanding, BertScore: 0.9819731712341309\n",
      "Substitute: announcing, BertScore: 0.9818474054336548\n",
      "Substitute: creating, BertScore: 0.9813706874847412\n",
      "Substitute: restoring, BertScore: 0.9813686609268188\n",
      "Substitute: extending, BertScore: 0.9813632369041443\n",
      "Substitute: signing, BertScore: 0.9812102913856506\n",
      "Substitute: adding, BertScore: 0.981148898601532\n",
      "Substitute: declaring, BertScore: 0.9802768230438232\n",
      "Substitute: negotiating, BertScore: 0.980017900466919\n",
      "Substitute: agreeing, BertScore: 0.9789379239082336\n",
      "Substitute: making, BertScore: 0.9786243438720703\n",
      "Substitute: claiming, BertScore: 0.9767515063285828\n",
      "Substitute: allowing, BertScore: 0.9765756130218506\n",
      "Substitute: promising, BertScore: 0.9755184650421143\n",
      "Substitute: providing, BertScore: 0.9748674631118774\n",
      "Substitute: granting, BertScore: 0.9748214483261108\n",
      "Substitute: cutting, BertScore: 0.9747159481048584\n",
      "Substitute: offering, BertScore: 0.9737096428871155\n",
      "Substitute: including, BertScore: 0.9713835120201111\n",
      "Substitute: demanding, BertScore: 0.970760703086853\n",
      "top-10 substitutes based on bertscores in context: ['concluding', 'confirming', 'completing', 'ensuring', 'establishing', 'ending', 'overseeing', 'building', 'sealing', 'securing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: unleashing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: pursuing, BertScore: 0.9593582153320312\n",
      "Substitute: launching, BertScore: 0.9581713676452637\n",
      "Substitute: executing, BertScore: 0.9575166702270508\n",
      "Substitute: firing, BertScore: 0.9571756720542908\n",
      "Substitute: possessing, BertScore: 0.9569603800773621\n",
      "Substitute: planting, BertScore: 0.956774115562439\n",
      "Substitute: attacking, BertScore: 0.9564059376716614\n",
      "Substitute: killing, BertScore: 0.9561337232589722\n",
      "Substitute: targeting, BertScore: 0.9560337066650391\n",
      "Substitute: releasing, BertScore: 0.9556692242622375\n",
      "Substitute: utilizing, BertScore: 0.9555261135101318\n",
      "Substitute: recruiting, BertScore: 0.9549732804298401\n",
      "Substitute: employing, BertScore: 0.9549586772918701\n",
      "Substitute: using, BertScore: 0.9547765254974365\n",
      "Substitute: hiring, BertScore: 0.9537600874900818\n",
      "Substitute: feeding, BertScore: 0.9536581039428711\n",
      "Substitute: spreading, BertScore: 0.9528214335441589\n",
      "Substitute: acquiring, BertScore: 0.9527605772018433\n",
      "Substitute: sending, BertScore: 0.9524074196815491\n",
      "Substitute: developing, BertScore: 0.9523961544036865\n",
      "Substitute: shooting, BertScore: 0.9521178007125854\n",
      "Substitute: creating, BertScore: 0.9513431787490845\n",
      "Substitute: supplying, BertScore: 0.951000988483429\n",
      "Substitute: providing, BertScore: 0.9501695036888123\n",
      "Substitute: introducing, BertScore: 0.9501564502716064\n",
      "Substitute: exposing, BertScore: 0.949556827545166\n",
      "Substitute: selling, BertScore: 0.9487142562866211\n",
      "Substitute: revealing, BertScore: 0.9480100870132446\n",
      "Substitute: offering, BertScore: 0.9451393485069275\n",
      "Substitute: having, BertScore: 0.9444276094436646\n",
      "top-10 substitutes based on bertscores in context: ['pursuing', 'launching', 'executing', 'firing', 'possessing', 'planting', 'attacking', 'killing', 'targeting', 'releasing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: scrutiny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: review, BertScore: 0.9969478249549866\n",
      "Substitute: examination, BertScore: 0.9965950846672058\n",
      "Substitute: questioning, BertScore: 0.9960756301879883\n",
      "Substitute: inspection, BertScore: 0.9960582852363586\n",
      "Substitute: investigation, BertScore: 0.9957594275474548\n",
      "Substitute: analysis, BertScore: 0.9957354068756104\n",
      "Substitute: oversight, BertScore: 0.9954855442047119\n",
      "Substitute: probe, BertScore: 0.9954243898391724\n",
      "Substitute: evaluation, BertScore: 0.9952989220619202\n",
      "Substitute: inquiry, BertScore: 0.9951891303062439\n",
      "Substitute: consideration, BertScore: 0.9951328635215759\n",
      "Substitute: interrogation, BertScore: 0.99501633644104\n",
      "Substitute: probing, BertScore: 0.994928777217865\n",
      "Substitute: criticism, BertScore: 0.9947348237037659\n",
      "Substitute: critique, BertScore: 0.9946903586387634\n",
      "Substitute: testing, BertScore: 0.9944733381271362\n",
      "Substitute: reflection, BertScore: 0.9942394495010376\n",
      "Substitute: judging, BertScore: 0.9941685199737549\n",
      "Substitute: reading, BertScore: 0.9940980672836304\n",
      "Substitute: check, BertScore: 0.9932302832603455\n",
      "Substitute: protection, BertScore: 0.9928802847862244\n",
      "Substitute: glare, BertScore: 0.9928202629089355\n",
      "Substitute: attention, BertScore: 0.9928056001663208\n",
      "Substitute: judgment, BertScore: 0.9927877187728882\n",
      "Substitute: transparency, BertScore: 0.9927728772163391\n",
      "Substitute: surveillance, BertScore: 0.9919804930686951\n",
      "Substitute: respect, BertScore: 0.9917972087860107\n",
      "Substitute: regard, BertScore: 0.9914895296096802\n",
      "top-10 substitutes based on bertscores in context: ['review', 'examination', 'questioning', 'inspection', 'investigation', 'analysis', 'oversight', 'probe', 'evaluation', 'inquiry']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: suspiciously\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: strangely, BertScore: 0.9931821227073669\n",
      "Substitute: suspicious, BertScore: 0.9929183721542358\n",
      "Substitute: menacing, BertScore: 0.9923900961875916\n",
      "Substitute: strange, BertScore: 0.9921310544013977\n",
      "Substitute: dangerous, BertScore: 0.991519570350647\n",
      "Substitute: curiously, BertScore: 0.9912368655204773\n",
      "Substitute: violent, BertScore: 0.9907548427581787\n",
      "Substitute: dangerously, BertScore: 0.9905063509941101\n",
      "Substitute: aggressive, BertScore: 0.9893680810928345\n",
      "Substitute: aggressively, BertScore: 0.989013671875\n",
      "Substitute: casually, BertScore: 0.9881616830825806\n",
      "Substitute: coldly, BertScore: 0.9878398180007935\n",
      "Substitute: warily, BertScore: 0.9874792098999023\n",
      "Substitute: cautiously, BertScore: 0.9873760938644409\n",
      "Substitute: deliberately, BertScore: 0.9872381091117859\n",
      "Substitute: remotely, BertScore: 0.9868327975273132\n",
      "Substitute: badly, BertScore: 0.986537754535675\n",
      "Substitute: quietly, BertScore: 0.986397385597229\n",
      "Substitute: vaguely, BertScore: 0.9857949018478394\n",
      "Substitute: poorly, BertScore: 0.9852764010429382\n",
      "Substitute: reasonably, BertScore: 0.9848432540893555\n",
      "Substitute: actively, BertScore: 0.9841148257255554\n",
      "Substitute: seriously, BertScore: 0.9840734601020813\n",
      "Substitute: fairly, BertScore: 0.9840344190597534\n",
      "Substitute: similarly, BertScore: 0.9835377335548401\n",
      "Substitute: closely, BertScore: 0.9834380149841309\n",
      "Substitute: kindly, BertScore: 0.982003927230835\n",
      "Substitute: heavily, BertScore: 0.9819844365119934\n",
      "Substitute: well, BertScore: 0.9790290594100952\n",
      "top-10 substitutes based on bertscores in context: ['strangely', 'suspicious', 'menacing', 'strange', 'dangerous', 'curiously', 'violent', 'dangerously', 'aggressive', 'aggressively']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: originated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: arose, BertScore: 0.9913840889930725\n",
      "Substitute: emerged, BertScore: 0.9888932704925537\n",
      "Substitute: origins, BertScore: 0.9887136220932007\n",
      "Substitute: developed, BertScore: 0.9877154231071472\n",
      "Substitute: spawned, BertScore: 0.9873316287994385\n",
      "Substitute: debuted, BertScore: 0.9861267805099487\n",
      "Substitute: existed, BertScore: 0.9855940937995911\n",
      "Substitute: evolved, BertScore: 0.9848727583885193\n",
      "Substitute: appeared, BertScore: 0.9842642545700073\n",
      "Substitute: began, BertScore: 0.9837803840637207\n",
      "Substitute: flourished, BertScore: 0.9834067225456238\n",
      "Substitute: introduced, BertScore: 0.9822646379470825\n",
      "Substitute: roots, BertScore: 0.9822420477867126\n",
      "Substitute: occurred, BertScore: 0.9811739325523376\n",
      "Substitute: started, BertScore: 0.9806338548660278\n",
      "Substitute: occurs, BertScore: 0.979056715965271\n",
      "Substitute: grew, BertScore: 0.9777835011482239\n",
      "Substitute: arrived, BertScore: 0.9774175882339478\n",
      "Substitute: begins, BertScore: 0.9764719605445862\n",
      "Substitute: was, BertScore: 0.9757726788520813\n",
      "Substitute: starts, BertScore: 0.9718050956726074\n",
      "Substitute: ended, BertScore: 0.9701593518257141\n",
      "Substitute: comes, BertScore: 0.9692569971084595\n",
      "Substitute: branched, BertScore: 0.9681931734085083\n",
      "Substitute: came, BertScore: 0.9667865037918091\n",
      "Substitute: stopped, BertScore: 0.958076536655426\n",
      "top-10 substitutes based on bertscores in context: ['arose', 'emerged', 'origins', 'developed', 'spawned', 'debuted', 'existed', 'evolved', 'appeared', 'began']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: replica\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: reproduction, BertScore: 0.9899806380271912\n",
      "Substitute: duplicate, BertScore: 0.987718939781189\n",
      "Substitute: copy, BertScore: 0.9842225313186646\n",
      "Substitute: imitation, BertScore: 0.984130859375\n",
      "Substitute: clone, BertScore: 0.9818824529647827\n",
      "Substitute: version, BertScore: 0.9801521897315979\n",
      "Substitute: model, BertScore: 0.9800825715065002\n",
      "Substitute: substitute, BertScore: 0.9772988557815552\n",
      "Substitute: prototype, BertScore: 0.9771971702575684\n",
      "Substitute: reconstruction, BertScore: 0.9759059548377991\n",
      "Substitute: fake, BertScore: 0.9754182696342468\n",
      "Substitute: replacement, BertScore: 0.9751363396644592\n",
      "Substitute: bronze, BertScore: 0.9750752449035645\n",
      "Substitute: statue, BertScore: 0.9699766039848328\n",
      "Substitute: pair, BertScore: 0.9697999954223633\n",
      "Substitute: portrait, BertScore: 0.9692872762680054\n",
      "Substitute: sculpture, BertScore: 0.9687267541885376\n",
      "Substitute: mosaic, BertScore: 0.9665695428848267\n",
      "Substitute: legend, BertScore: 0.9649535417556763\n",
      "Substitute: plaster, BertScore: 0.9646828174591064\n",
      "Substitute: rebuild, BertScore: 0.9645166993141174\n",
      "Substitute: restoration, BertScore: 0.9622721076011658\n",
      "Substitute: museum, BertScore: 0.9621524810791016\n",
      "Substitute: collection, BertScore: 0.9592129588127136\n",
      "Substitute: design, BertScore: 0.9591778516769409\n",
      "Substitute: redesign, BertScore: 0.9589824676513672\n",
      "Substitute: collector, BertScore: 0.9563153982162476\n",
      "Substitute: sculptor, BertScore: 0.9549402594566345\n",
      "Substitute: designer, BertScore: 0.9548382759094238\n",
      "top-10 substitutes based on bertscores in context: ['reproduction', 'duplicate', 'copy', 'imitation', 'clone', 'version', 'model', 'substitute', 'prototype', 'reconstruction']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: discredits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: insults, BertScore: 0.9417674541473389\n",
      "Substitute: fools, BertScore: 0.9388166069984436\n",
      "Substitute: attacks, BertScore: 0.9384201169013977\n",
      "Substitute: challenges, BertScore: 0.9369120001792908\n",
      "Substitute: assaults, BertScore: 0.9366902709007263\n",
      "Substitute: abuses, BertScore: 0.9365893006324768\n",
      "Substitute: shocks, BertScore: 0.9355222582817078\n",
      "Substitute: defeats, BertScore: 0.9355124235153198\n",
      "Substitute: hurts, BertScore: 0.9351755380630493\n",
      "Substitute: destroys, BertScore: 0.9350661039352417\n",
      "Substitute: exploits, BertScore: 0.934623122215271\n",
      "Substitute: damages, BertScore: 0.9337643384933472\n",
      "Substitute: tests, BertScore: 0.9322994351387024\n",
      "Substitute: blinds, BertScore: 0.9311804175376892\n",
      "Substitute: threatens, BertScore: 0.9309118986129761\n",
      "Substitute: tricks, BertScore: 0.9287553429603577\n",
      "Substitute: scares, BertScore: 0.9282252788543701\n",
      "Substitute: targets, BertScore: 0.9278956055641174\n",
      "Substitute: ignores, BertScore: 0.927606463432312\n",
      "Substitute: kills, BertScore: 0.9275674223899841\n",
      "Substitute: affects, BertScore: 0.9273236989974976\n",
      "Substitute: impacts, BertScore: 0.9271560311317444\n",
      "Substitute: concerns, BertScore: 0.9270782470703125\n",
      "Substitute: feeds, BertScore: 0.9265124797821045\n",
      "Substitute: benefits, BertScore: 0.9244821071624756\n",
      "Substitute: influences, BertScore: 0.9235008955001831\n",
      "Substitute: informs, BertScore: 0.922692596912384\n",
      "Substitute: misleading, BertScore: 0.9116106629371643\n",
      "top-10 substitutes based on bertscores in context: ['insults', 'fools', 'attacks', 'challenges', 'assaults', 'abuses', 'shocks', 'defeats', 'hurts', 'destroys']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: vicious\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: ferocious, BertScore: 0.9976217746734619\n",
      "Substitute: brutal, BertScore: 0.9972206354141235\n",
      "Substitute: deadly, BertScore: 0.9967864751815796\n",
      "Substitute: ruthless, BertScore: 0.9965543150901794\n",
      "Substitute: violent, BertScore: 0.9958610534667969\n",
      "Substitute: destructive, BertScore: 0.995850682258606\n",
      "Substitute: devastating, BertScore: 0.995632529258728\n",
      "Substitute: savage, BertScore: 0.9955357313156128\n",
      "Substitute: bitter, BertScore: 0.9950424432754517\n",
      "Substitute: murderous, BertScore: 0.9950185418128967\n",
      "Substitute: relentless, BertScore: 0.9950032830238342\n",
      "Substitute: horrific, BertScore: 0.9949755072593689\n",
      "Substitute: terrible, BertScore: 0.9949228763580322\n",
      "Substitute: bloody, BertScore: 0.9948599338531494\n",
      "Substitute: nasty, BertScore: 0.9943696856498718\n",
      "Substitute: cruel, BertScore: 0.9942734241485596\n",
      "Substitute: dangerous, BertScore: 0.9942705035209656\n",
      "Substitute: raging, BertScore: 0.9940670132637024\n",
      "Substitute: massive, BertScore: 0.993726372718811\n",
      "Substitute: disastrous, BertScore: 0.9933701753616333\n",
      "Substitute: chaotic, BertScore: 0.9930681586265564\n",
      "Substitute: systematic, BertScore: 0.9920374155044556\n",
      "Substitute: criminal, BertScore: 0.9917442202568054\n",
      "Substitute: wild, BertScore: 0.9914565086364746\n",
      "Substitute: prolonged, BertScore: 0.9907751083374023\n",
      "Substitute: great, BertScore: 0.9898321032524109\n",
      "Substitute: total, BertScore: 0.9889436364173889\n",
      "Substitute: complete, BertScore: 0.9887502193450928\n",
      "Substitute: new, BertScore: 0.9875553250312805\n",
      "top-10 substitutes based on bertscores in context: ['ferocious', 'brutal', 'deadly', 'ruthless', 'violent', 'destructive', 'devastating', 'savage', 'bitter', 'murderous']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: strained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: weakened, BertScore: 0.9942680597305298\n",
      "Substitute: hampered, BertScore: 0.9937279224395752\n",
      "Substitute: complicated, BertScore: 0.9934462904930115\n",
      "Substitute: disturbed, BertScore: 0.9931424260139465\n",
      "Substitute: disrupted, BertScore: 0.9930408596992493\n",
      "Substitute: troubled, BertScore: 0.9929760098457336\n",
      "Substitute: deteriorated, BertScore: 0.9928833842277527\n",
      "Substitute: worsened, BertScore: 0.9926305413246155\n",
      "Substitute: shaken, BertScore: 0.9925225377082825\n",
      "Substitute: clouded, BertScore: 0.9923052191734314\n",
      "Substitute: crippled, BertScore: 0.992213249206543\n",
      "Substitute: damaged, BertScore: 0.9920299053192139\n",
      "Substitute: aggravated, BertScore: 0.991831362247467\n",
      "Substitute: affected, BertScore: 0.991260826587677\n",
      "Substitute: threatened, BertScore: 0.9911413192749023\n",
      "Substitute: hurt, BertScore: 0.9911200404167175\n",
      "Substitute: marred, BertScore: 0.990929365158081\n",
      "Substitute: shattered, BertScore: 0.9909246563911438\n",
      "Substitute: frustrated, BertScore: 0.9906874299049377\n",
      "Substitute: eroded, BertScore: 0.9902924299240112\n",
      "Substitute: deteriorating, BertScore: 0.9899994730949402\n",
      "Substitute: torn, BertScore: 0.9899277687072754\n",
      "Substitute: broken, BertScore: 0.9899119138717651\n",
      "Substitute: limited, BertScore: 0.989712655544281\n",
      "Substitute: strengthened, BertScore: 0.9886928200721741\n",
      "Substitute: deepened, BertScore: 0.9883779883384705\n",
      "Substitute: interrupted, BertScore: 0.9876463413238525\n",
      "Substitute: marked, BertScore: 0.9862263798713684\n",
      "top-10 substitutes based on bertscores in context: ['weakened', 'hampered', 'complicated', 'disturbed', 'disrupted', 'troubled', 'deteriorated', 'worsened', 'shaken', 'clouded']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: enacted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: implemented, BertScore: 0.9963714480400085\n",
      "Substitute: instituted, BertScore: 0.9948847889900208\n",
      "Substitute: introduced, BertScore: 0.9936205148696899\n",
      "Substitute: adopted, BertScore: 0.9936172962188721\n",
      "Substitute: executed, BertScore: 0.9933967590332031\n",
      "Substitute: initiated, BertScore: 0.9931280612945557\n",
      "Substitute: imposed, BertScore: 0.9922724366188049\n",
      "Substitute: completed, BertScore: 0.9916663765907288\n",
      "Substitute: launched, BertScore: 0.9915221333503723\n",
      "Substitute: undertaken, BertScore: 0.9907436370849609\n",
      "Substitute: signed, BertScore: 0.9902624487876892\n",
      "Substitute: accomplished, BertScore: 0.9902284145355225\n",
      "Substitute: conducted, BertScore: 0.9902008771896362\n",
      "Substitute: approved, BertScore: 0.9900217652320862\n",
      "Substitute: issued, BertScore: 0.9899431467056274\n",
      "Substitute: attempted, BertScore: 0.9898567795753479\n",
      "Substitute: staged, BertScore: 0.9895169734954834\n",
      "Substitute: announced, BertScore: 0.9894419312477112\n",
      "Substitute: made, BertScore: 0.9893395900726318\n",
      "Substitute: built, BertScore: 0.9893189072608948\n",
      "Substitute: committed, BertScore: 0.9891160130500793\n",
      "Substitute: achieved, BertScore: 0.989020824432373\n",
      "Substitute: released, BertScore: 0.98897385597229\n",
      "Substitute: done, BertScore: 0.9877635836601257\n",
      "Substitute: proposed, BertScore: 0.9877583980560303\n",
      "Substitute: performed, BertScore: 0.9877068400382996\n",
      "Substitute: begun, BertScore: 0.9875040650367737\n",
      "Substitute: overseen, BertScore: 0.9863057732582092\n",
      "Substitute: passed, BertScore: 0.9851934909820557\n",
      "top-10 substitutes based on bertscores in context: ['implemented', 'instituted', 'introduced', 'adopted', 'executed', 'initiated', 'imposed', 'completed', 'launched', 'undertaken']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: primed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: trained, BertScore: 0.9808021783828735\n",
      "Substitute: active, BertScore: 0.9800255298614502\n",
      "Substitute: sensitive, BertScore: 0.9797271490097046\n",
      "Substitute: guided, BertScore: 0.9794700145721436\n",
      "Substitute: activated, BertScore: 0.9788749814033508\n",
      "Substitute: conditioned, BertScore: 0.9780744314193726\n",
      "Substitute: injected, BertScore: 0.9780433177947998\n",
      "Substitute: hot, BertScore: 0.9778323173522949\n",
      "Substitute: blinded, BertScore: 0.9773078560829163\n",
      "Substitute: captured, BertScore: 0.9771854877471924\n",
      "Substitute: roasted, BertScore: 0.9768059849739075\n",
      "Substitute: mature, BertScore: 0.9767398834228516\n",
      "Substitute: skinned, BertScore: 0.9766948223114014\n",
      "Substitute: small, BertScore: 0.9766464233398438\n",
      "Substitute: green, BertScore: 0.9765051603317261\n",
      "Substitute: frozen, BertScore: 0.9764696359634399\n",
      "Substitute: hungry, BertScore: 0.9764520525932312\n",
      "Substitute: trapped, BertScore: 0.9762352108955383\n",
      "Substitute: wild, BertScore: 0.9760807156562805\n",
      "Substitute: exposed, BertScore: 0.9759986400604248\n",
      "Substitute: damaged, BertScore: 0.9759631752967834\n",
      "Substitute: treated, BertScore: 0.9758971929550171\n",
      "Substitute: naked, BertScore: 0.975873589515686\n",
      "Substitute: infected, BertScore: 0.9755418300628662\n",
      "Substitute: young, BertScore: 0.9755129814147949\n",
      "Substitute: wounded, BertScore: 0.9753653407096863\n",
      "Substitute: targeted, BertScore: 0.9751462340354919\n",
      "Substitute: injured, BertScore: 0.9749950170516968\n",
      "Substitute: target, BertScore: 0.974977970123291\n",
      "top-10 substitutes based on bertscores in context: ['trained', 'active', 'sensitive', 'guided', 'activated', 'conditioned', 'injected', 'hot', 'blinded', 'captured']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: probe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: investigation, BertScore: 0.9939918518066406\n",
      "Substitute: inquiry, BertScore: 0.9933946132659912\n",
      "Substitute: investigations, BertScore: 0.9928361773490906\n",
      "Substitute: investigate, BertScore: 0.9922323822975159\n",
      "Substitute: review, BertScore: 0.9863284826278687\n",
      "Substitute: report, BertScore: 0.9859819412231445\n",
      "Substitute: check, BertScore: 0.9858070015907288\n",
      "Substitute: hunt, BertScore: 0.9853116869926453\n",
      "Substitute: search, BertScore: 0.9850417971611023\n",
      "Substitute: hearing, BertScore: 0.9847736358642578\n",
      "Substitute: look, BertScore: 0.9839419722557068\n",
      "Substitute: dig, BertScore: 0.9839046001434326\n",
      "Substitute: sweep, BertScore: 0.9838240742683411\n",
      "Substitute: research, BertScore: 0.9834012985229492\n",
      "Substitute: study, BertScore: 0.982395350933075\n",
      "Substitute: watch, BertScore: 0.9823671579360962\n",
      "Substitute: crack, BertScore: 0.9816878437995911\n",
      "Substitute: trial, BertScore: 0.9808651208877563\n",
      "Substitute: peek, BertScore: 0.9801647067070007\n",
      "Substitute: looking, BertScore: 0.9801113605499268\n",
      "Substitute: digging, BertScore: 0.9796667098999023\n",
      "Substitute: insight, BertScore: 0.9754778742790222\n",
      "Substitute: view, BertScore: 0.9729065299034119\n",
      "Substitute: glimpse, BertScore: 0.9726117849349976\n",
      "Substitute: deeper, BertScore: 0.9722813367843628\n",
      "Substitute: widening, BertScore: 0.9637653827667236\n",
      "Substitute: turn, BertScore: 0.9628941416740417\n",
      "Substitute: way, BertScore: 0.9614697098731995\n",
      "top-10 substitutes based on bertscores in context: ['investigation', 'inquiry', 'investigations', 'investigate', 'review', 'report', 'check', 'hunt', 'search', 'hearing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: aviator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: pilot, BertScore: 0.986382007598877\n",
      "Substitute: navigator, BertScore: 0.9819555282592773\n",
      "Substitute: observer, BertScore: 0.9772707223892212\n",
      "Substitute: officer, BertScore: 0.9741191267967224\n",
      "Substitute: engineer, BertScore: 0.9737262725830078\n",
      "Substitute: gunner, BertScore: 0.9734199047088623\n",
      "Substitute: investigator, BertScore: 0.9730052947998047\n",
      "Substitute: astronaut, BertScore: 0.9725021123886108\n",
      "Substitute: explorer, BertScore: 0.9718579053878784\n",
      "Substitute: architect, BertScore: 0.9707890152931213\n",
      "Substitute: aviation, BertScore: 0.9706570506095886\n",
      "Substitute: lieutenant, BertScore: 0.9701662063598633\n",
      "Substitute: astronomer, BertScore: 0.9700957536697388\n",
      "Substitute: ensign, BertScore: 0.9686259031295776\n",
      "Substitute: instructor, BertScore: 0.9684498906135559\n",
      "Substitute: official, BertScore: 0.9674092531204224\n",
      "Substitute: examiner, BertScore: 0.9664963483810425\n",
      "Substitute: administrator, BertScore: 0.9662702083587646\n",
      "Substitute: agent, BertScore: 0.966205894947052\n",
      "Substitute: inspector, BertScore: 0.9647723436355591\n",
      "Substitute: admiral, BertScore: 0.9641969203948975\n",
      "Substitute: eagle, BertScore: 0.9626076817512512\n",
      "Substitute: assistant, BertScore: 0.9614163041114807\n",
      "Substitute: american, BertScore: 0.96030592918396\n",
      "Substitute: undergraduate, BertScore: 0.9588930606842041\n",
      "Substitute: enlisted, BertScore: 0.9572357535362244\n",
      "Substitute: attache, BertScore: 0.9566071033477783\n",
      "Substitute: intern, BertScore: 0.9565960168838501\n",
      "Substitute: expert, BertScore: 0.9540008902549744\n",
      "top-10 substitutes based on bertscores in context: ['pilot', 'navigator', 'observer', 'officer', 'engineer', 'gunner', 'investigator', 'astronaut', 'explorer', 'architect']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: acquiring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: purchasing, BertScore: 0.9976139664649963\n",
      "Substitute: obtaining, BertScore: 0.9975531101226807\n",
      "Substitute: gaining, BertScore: 0.9970386028289795\n",
      "Substitute: buying, BertScore: 0.9966225028038025\n",
      "Substitute: receiving, BertScore: 0.9957842230796814\n",
      "Substitute: getting, BertScore: 0.9955846071243286\n",
      "Substitute: earning, BertScore: 0.9955185055732727\n",
      "Substitute: seeking, BertScore: 0.9935250282287598\n",
      "Substitute: selling, BertScore: 0.9924929738044739\n",
      "Substitute: retaining, BertScore: 0.9921651482582092\n",
      "Substitute: transferring, BertScore: 0.991533100605011\n",
      "Substitute: purchase, BertScore: 0.9913049340248108\n",
      "Substitute: having, BertScore: 0.9912992715835571\n",
      "Substitute: winning, BertScore: 0.990324079990387\n",
      "Substitute: increasing, BertScore: 0.9902957677841187\n",
      "Substitute: eliminating, BertScore: 0.9896256923675537\n",
      "Substitute: acquisition, BertScore: 0.9896069765090942\n",
      "Substitute: growing, BertScore: 0.9888007044792175\n",
      "Substitute: losing, BertScore: 0.9883728623390198\n",
      "Substitute: withdrawing, BertScore: 0.9882671236991882\n",
      "Substitute: renewed, BertScore: 0.9879642128944397\n",
      "Substitute: additional, BertScore: 0.9873961806297302\n",
      "Substitute: declining, BertScore: 0.9863267540931702\n",
      "Substitute: new, BertScore: 0.9861160516738892\n",
      "Substitute: initial, BertScore: 0.9849575161933899\n",
      "Substitute: the, BertScore: 0.9840120673179626\n",
      "Substitute: more, BertScore: 0.9838998317718506\n",
      "top-10 substitutes based on bertscores in context: ['purchasing', 'obtaining', 'gaining', 'buying', 'receiving', 'getting', 'earning', 'seeking', 'selling', 'retaining']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: restive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: troubled, BertScore: 0.9530846476554871\n",
      "Substitute: impoverished, BertScore: 0.950085461139679\n",
      "Substitute: occupied, BertScore: 0.9484586119651794\n",
      "Substitute: breakaway, BertScore: 0.9483745098114014\n",
      "Substitute: besieged, BertScore: 0.9473649859428406\n",
      "Substitute: neighbouring, BertScore: 0.945972204208374\n",
      "Substitute: nearby, BertScore: 0.9450045228004456\n",
      "Substitute: central, BertScore: 0.9449570775032043\n",
      "Substitute: remote, BertScore: 0.9447271227836609\n",
      "Substitute: neighboring, BertScore: 0.9434918165206909\n",
      "Substitute: northern, BertScore: 0.9433424472808838\n",
      "Substitute: autonomous, BertScore: 0.9433252811431885\n",
      "Substitute: east, BertScore: 0.9433095455169678\n",
      "Substitute: eastern, BertScore: 0.9431676864624023\n",
      "Substitute: mountainous, BertScore: 0.9431067705154419\n",
      "Substitute: southern, BertScore: 0.9430466294288635\n",
      "Substitute: volatile, BertScore: 0.9426054358482361\n",
      "Substitute: western, BertScore: 0.9425394535064697\n",
      "Substitute: south, BertScore: 0.9424008131027222\n",
      "Substitute: north, BertScore: 0.9421070218086243\n",
      "Substitute: west, BertScore: 0.9416258931159973\n",
      "Substitute: southeastern, BertScore: 0.941360592842102\n",
      "Substitute: southwestern, BertScore: 0.9413569569587708\n",
      "Substitute: northeast, BertScore: 0.9410330653190613\n",
      "Substitute: southwest, BertScore: 0.9407375454902649\n",
      "Substitute: northwestern, BertScore: 0.9406151175498962\n",
      "Substitute: northwest, BertScore: 0.9397953152656555\n",
      "Substitute: former, BertScore: 0.9397150874137878\n",
      "Substitute: northeastern, BertScore: 0.9396016597747803\n",
      "Substitute: capital, BertScore: 0.9319688081741333\n",
      "top-10 substitutes based on bertscores in context: ['troubled', 'impoverished', 'occupied', 'breakaway', 'besieged', 'neighbouring', 'nearby', 'central', 'remote', 'neighboring']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: repression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: suppression, BertScore: 0.9954575896263123\n",
      "Substitute: persecution, BertScore: 0.9952393174171448\n",
      "Substitute: oppression, BertScore: 0.9943421483039856\n",
      "Substitute: harassment, BertScore: 0.9938877820968628\n",
      "Substitute: intimidation, BertScore: 0.9927319884300232\n",
      "Substitute: prosecution, BertScore: 0.9916609525680542\n",
      "Substitute: surveillance, BertScore: 0.9910481572151184\n",
      "Substitute: massacre, BertScore: 0.9908491373062134\n",
      "Substitute: killings, BertScore: 0.9907679557800293\n",
      "Substitute: deportation, BertScore: 0.9905874729156494\n",
      "Substitute: exploitation, BertScore: 0.9904643893241882\n",
      "Substitute: torture, BertScore: 0.9903621077537537\n",
      "Substitute: displacement, BertScore: 0.9902885556221008\n",
      "Substitute: abuse, BertScore: 0.9901867508888245\n",
      "Substitute: imprisonment, BertScore: 0.9900965094566345\n",
      "Substitute: manipulation, BertScore: 0.9899799227714539\n",
      "Substitute: detention, BertScore: 0.9897324442863464\n",
      "Substitute: killing, BertScore: 0.9895042181015015\n",
      "Substitute: genocide, BertScore: 0.9891141653060913\n",
      "Substitute: executions, BertScore: 0.9890779852867126\n",
      "Substitute: arrest, BertScore: 0.9890775084495544\n",
      "Substitute: interrogation, BertScore: 0.988944947719574\n",
      "Substitute: abuses, BertScore: 0.9889150261878967\n",
      "Substitute: occupation, BertScore: 0.9885129332542419\n",
      "Substitute: attacks, BertScore: 0.9883954524993896\n",
      "Substitute: treatment, BertScore: 0.9883289933204651\n",
      "Substitute: capture, BertScore: 0.9882379770278931\n",
      "Substitute: brutality, BertScore: 0.9874193668365479\n",
      "Substitute: resistance, BertScore: 0.9832953810691833\n",
      "top-10 substitutes based on bertscores in context: ['suppression', 'persecution', 'oppression', 'harassment', 'intimidation', 'prosecution', 'surveillance', 'massacre', 'killings', 'deportation']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: vulnerability\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: sensitivity, BertScore: 0.9933882355690002\n",
      "Substitute: weakness, BertScore: 0.9918569922447205\n",
      "Substitute: toxicity, BertScore: 0.9916411638259888\n",
      "Substitute: risks, BertScore: 0.9906560778617859\n",
      "Substitute: danger, BertScore: 0.9906271696090698\n",
      "Substitute: risk, BertScore: 0.9905785322189331\n",
      "Substitute: vulnerable, BertScore: 0.990533709526062\n",
      "Substitute: resistance, BertScore: 0.9898418188095093\n",
      "Substitute: exposure, BertScore: 0.9897828102111816\n",
      "Substitute: immunity, BertScore: 0.9897174835205078\n",
      "Substitute: potential, BertScore: 0.9895203113555908\n",
      "Substitute: severity, BertScore: 0.9894782304763794\n",
      "Substitute: threat, BertScore: 0.9894062876701355\n",
      "Substitute: weaknesses, BertScore: 0.9890093803405762\n",
      "Substitute: damage, BertScore: 0.9887638092041016\n",
      "Substitute: isolation, BertScore: 0.988427460193634\n",
      "Substitute: complexity, BertScore: 0.9882633090019226\n",
      "Substitute: strength, BertScore: 0.9880918264389038\n",
      "Substitute: trauma, BertScore: 0.9879905581474304\n",
      "Substitute: impact, BertScore: 0.9876242280006409\n",
      "Substitute: violence, BertScore: 0.9870057106018066\n",
      "Substitute: security, BertScore: 0.9866912961006165\n",
      "Substitute: effectiveness, BertScore: 0.9860922694206238\n",
      "Substitute: ability, BertScore: 0.9858790040016174\n",
      "Substitute: resources, BertScore: 0.9857775568962097\n",
      "Substitute: capacity, BertScore: 0.9846429228782654\n",
      "Substitute: size, BertScore: 0.9841749668121338\n",
      "Substitute: number, BertScore: 0.9829015731811523\n",
      "Substitute: trafficking, BertScore: 0.9770811796188354\n",
      "top-10 substitutes based on bertscores in context: ['sensitivity', 'weakness', 'toxicity', 'risks', 'danger', 'risk', 'vulnerable', 'resistance', 'exposure', 'immunity']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: equipment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: gear, BertScore: 0.9865936636924744\n",
      "Substitute: machinery, BertScore: 0.9845826625823975\n",
      "Substitute: devices, BertScore: 0.9831045269966125\n",
      "Substitute: tools, BertScore: 0.9805517196655273\n",
      "Substitute: instruments, BertScore: 0.979953944683075\n",
      "Substitute: instrumentation, BertScore: 0.9797238707542419\n",
      "Substitute: facilities, BertScore: 0.9795019626617432\n",
      "Substitute: technology, BertScore: 0.9791009426116943\n",
      "Substitute: apparatus, BertScore: 0.9780805110931396\n",
      "Substitute: hardware, BertScore: 0.9777396321296692\n",
      "Substitute: machines, BertScore: 0.9775741100311279\n",
      "Substitute: material, BertScore: 0.9764830470085144\n",
      "Substitute: implements, BertScore: 0.9763395190238953\n",
      "Substitute: accessories, BertScore: 0.9762005805969238\n",
      "Substitute: supplies, BertScore: 0.9757228493690491\n",
      "Substitute: weaponry, BertScore: 0.9755308628082275\n",
      "Substitute: materials, BertScore: 0.9748492240905762\n",
      "Substitute: personnel, BertScore: 0.9730532765388489\n",
      "Substitute: procedures, BertScore: 0.9727137684822083\n",
      "Substitute: systems, BertScore: 0.9724169969558716\n",
      "Substitute: technologies, BertScore: 0.9723665714263916\n",
      "Substitute: products, BertScore: 0.9704772233963013\n",
      "Substitute: information, BertScore: 0.9697778224945068\n",
      "Substitute: weapons, BertScore: 0.9692201018333435\n",
      "Substitute: items, BertScore: 0.9691950678825378\n",
      "Substitute: components, BertScore: 0.9684664607048035\n",
      "Substitute: techniques, BertScore: 0.965131402015686\n",
      "Substitute: weights, BertScore: 0.9591283798217773\n",
      "Substitute: methods, BertScore: 0.9489398002624512\n",
      "top-10 substitutes based on bertscores in context: ['gear', 'machinery', 'devices', 'tools', 'instruments', 'instrumentation', 'facilities', 'technology', 'apparatus', 'hardware']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: stemming\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: arising, BertScore: 0.997132420539856\n",
      "Substitute: originating, BertScore: 0.9964814186096191\n",
      "Substitute: resulting, BertScore: 0.9957760572433472\n",
      "Substitute: derived, BertScore: 0.994192898273468\n",
      "Substitute: coming, BertScore: 0.9922302961349487\n",
      "Substitute: leading, BertScore: 0.9917826056480408\n",
      "Substitute: spawned, BertScore: 0.990985631942749\n",
      "Substitute: triggered, BertScore: 0.9904629588127136\n",
      "Substitute: ensuing, BertScore: 0.9903823733329773\n",
      "Substitute: generated, BertScore: 0.9902757406234741\n",
      "Substitute: associated, BertScore: 0.9901420474052429\n",
      "Substitute: emerging, BertScore: 0.989837110042572\n",
      "Substitute: drawing, BertScore: 0.9897987842559814\n",
      "Substitute: flowing, BertScore: 0.9896637201309204\n",
      "Substitute: dating, BertScore: 0.9894881844520569\n",
      "Substitute: related, BertScore: 0.9893804788589478\n",
      "Substitute: starting, BertScore: 0.9885907769203186\n",
      "Substitute: rising, BertScore: 0.988099992275238\n",
      "Substitute: continuing, BertScore: 0.9879398941993713\n",
      "Substitute: sparked, BertScore: 0.9877684116363525\n",
      "Substitute: raised, BertScore: 0.98719722032547\n",
      "Substitute: drawn, BertScore: 0.9869610071182251\n",
      "Substitute: extending, BertScore: 0.9869006872177124\n",
      "Substitute: growing, BertScore: 0.9862889647483826\n",
      "Substitute: resulted, BertScore: 0.9862368106842041\n",
      "Substitute: running, BertScore: 0.9853789806365967\n",
      "Substitute: erupted, BertScore: 0.9796978235244751\n",
      "Substitute: suspended, BertScore: 0.9744356870651245\n",
      "top-10 substitutes based on bertscores in context: ['arising', 'originating', 'resulting', 'derived', 'coming', 'leading', 'spawned', 'triggered', 'ensuing', 'generated']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: existence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: presence, BertScore: 0.9920200109481812\n",
      "Substitute: occurrence, BertScore: 0.9882972240447998\n",
      "Substitute: appearance, BertScore: 0.9860771894454956\n",
      "Substitute: establishment, BertScore: 0.9855830669403076\n",
      "Substitute: emergence, BertScore: 0.9852607846260071\n",
      "Substitute: possibility, BertScore: 0.9842303991317749\n",
      "Substitute: availability, BertScore: 0.9842163920402527\n",
      "Substitute: creation, BertScore: 0.983891487121582\n",
      "Substitute: formation, BertScore: 0.9825884103775024\n",
      "Substitute: development, BertScore: 0.9820541143417358\n",
      "Substitute: origins, BertScore: 0.9814202785491943\n",
      "Substitute: nature, BertScore: 0.9814200401306152\n",
      "Substitute: evolution, BertScore: 0.9812250137329102\n",
      "Substitute: origin, BertScore: 0.9812058210372925\n",
      "Substitute: discovery, BertScore: 0.980567216873169\n",
      "Substitute: disappearance, BertScore: 0.9795832633972168\n",
      "Substitute: absence, BertScore: 0.9795485138893127\n",
      "Substitute: location, BertScore: 0.9788662195205688\n",
      "Substitute: addition, BertScore: 0.9779800176620483\n",
      "Substitute: phenomenon, BertScore: 0.9777668118476868\n",
      "Substitute: occurrences, BertScore: 0.9776492118835449\n",
      "Substitute: function, BertScore: 0.9775870442390442\n",
      "Substitute: use, BertScore: 0.977567732334137\n",
      "Substitute: form, BertScore: 0.9761425256729126\n",
      "Substitute: reality, BertScore: 0.9759993553161621\n",
      "Substitute: activity, BertScore: 0.9756712913513184\n",
      "Substitute: history, BertScore: 0.9755397439002991\n",
      "Substitute: life, BertScore: 0.9724113345146179\n",
      "Substitute: number, BertScore: 0.9690006971359253\n",
      "top-10 substitutes based on bertscores in context: ['presence', 'occurrence', 'appearance', 'establishment', 'emergence', 'possibility', 'availability', 'creation', 'formation', 'development']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: adequate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: proper, BertScore: 0.9920018315315247\n",
      "Substitute: appropriate, BertScore: 0.9912020564079285\n",
      "Substitute: satisfactory, BertScore: 0.9909492135047913\n",
      "Substitute: suitable, BertScore: 0.990557849407196\n",
      "Substitute: credible, BertScore: 0.9903062582015991\n",
      "Substitute: adequately, BertScore: 0.9895879030227661\n",
      "Substitute: competent, BertScore: 0.9892498254776001\n",
      "Substitute: sufficient, BertScore: 0.9891717433929443\n",
      "Substitute: reasonable, BertScore: 0.989152729511261\n",
      "Substitute: effective, BertScore: 0.9889066815376282\n",
      "Substitute: acceptable, BertScore: 0.9884825944900513\n",
      "Substitute: ample, BertScore: 0.9872531890869141\n",
      "Substitute: timely, BertScore: 0.98625648021698\n",
      "Substitute: comprehensive, BertScore: 0.9860353469848633\n",
      "Substitute: accurate, BertScore: 0.9851834177970886\n",
      "Substitute: substantial, BertScore: 0.9850579500198364\n",
      "Substitute: meaningful, BertScore: 0.9846751093864441\n",
      "Substitute: good, BertScore: 0.9837319254875183\n",
      "Substitute: objective, BertScore: 0.982961118221283\n",
      "Substitute: necessary, BertScore: 0.9823092818260193\n",
      "Substitute: significant, BertScore: 0.9808087348937988\n",
      "Substitute: enough, BertScore: 0.9800031185150146\n",
      "Substitute: inadequate, BertScore: 0.9767104983329773\n",
      "Substitute: actual, BertScore: 0.9765299558639526\n",
      "Substitute: insufficient, BertScore: 0.9750583171844482\n",
      "Substitute: any, BertScore: 0.9704537391662598\n",
      "Substitute: emergency, BertScore: 0.9663648009300232\n",
      "Substitute: the, BertScore: 0.9653233289718628\n",
      "Substitute: such, BertScore: 0.9632217288017273\n",
      "top-10 substitutes based on bertscores in context: ['proper', 'appropriate', 'satisfactory', 'suitable', 'credible', 'adequately', 'competent', 'sufficient', 'reasonable', 'effective']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: genuinely\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: truly, BertScore: 0.995503306388855\n",
      "Substitute: sincerely, BertScore: 0.9952924251556396\n",
      "Substitute: deeply, BertScore: 0.9948623776435852\n",
      "Substitute: really, BertScore: 0.9941369891166687\n",
      "Substitute: absolutely, BertScore: 0.9939388632774353\n",
      "Substitute: completely, BertScore: 0.9937663078308105\n",
      "Substitute: fully, BertScore: 0.9936441779136658\n",
      "Substitute: actually, BertScore: 0.993255078792572\n",
      "Substitute: strongly, BertScore: 0.9930334091186523\n",
      "Substitute: definitely, BertScore: 0.9928276538848877\n",
      "Substitute: desperately, BertScore: 0.9926539659500122\n",
      "Substitute: naturally, BertScore: 0.992558479309082\n",
      "Substitute: secretly, BertScore: 0.9923012852668762\n",
      "Substitute: positively, BertScore: 0.9922633767127991\n",
      "Substitute: obviously, BertScore: 0.9917433857917786\n",
      "Substitute: clearly, BertScore: 0.9913859367370605\n",
      "Substitute: specifically, BertScore: 0.9908710718154907\n",
      "Substitute: directly, BertScore: 0.9905586838722229\n",
      "Substitute: certainly, BertScore: 0.9902337193489075\n",
      "Substitute: immediately, BertScore: 0.989956259727478\n",
      "Substitute: simply, BertScore: 0.9897802472114563\n",
      "Substitute: also, BertScore: 0.9892202019691467\n",
      "Substitute: indeed, BertScore: 0.989153265953064\n",
      "Substitute: already, BertScore: 0.9880557656288147\n",
      "Substitute: still, BertScore: 0.9873226284980774\n",
      "Substitute: even, BertScore: 0.9868637323379517\n",
      "Substitute: just, BertScore: 0.9868570566177368\n",
      "Substitute: only, BertScore: 0.9854574203491211\n",
      "Substitute: genuine, BertScore: 0.9840570092201233\n",
      "top-10 substitutes based on bertscores in context: ['truly', 'sincerely', 'deeply', 'really', 'absolutely', 'completely', 'fully', 'actually', 'strongly', 'definitely']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: proportion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: percentage, BertScore: 0.9978784322738647\n",
      "Substitute: number, BertScore: 0.9944256544113159\n",
      "Substitute: fraction, BertScore: 0.9940000772476196\n",
      "Substitute: amount, BertScore: 0.993643045425415\n",
      "Substitute: concentration, BertScore: 0.9932208061218262\n",
      "Substitute: portion, BertScore: 0.9929742813110352\n",
      "Substitute: numbers, BertScore: 0.9928997755050659\n",
      "Substitute: quantity, BertScore: 0.9928853511810303\n",
      "Substitute: share, BertScore: 0.9923070669174194\n",
      "Substitute: percent, BertScore: 0.991909384727478\n",
      "Substitute: bulk, BertScore: 0.9918677806854248\n",
      "Substitute: majority, BertScore: 0.9908208847045898\n",
      "Substitute: volume, BertScore: 0.9906543493270874\n",
      "Substitute: rate, BertScore: 0.9905146956443787\n",
      "Substitute: population, BertScore: 0.9890187978744507\n",
      "Substitute: ratio, BertScore: 0.9888954162597656\n",
      "Substitute: minority, BertScore: 0.988750159740448\n",
      "Substitute: total, BertScore: 0.9882037043571472\n",
      "Substitute: incidence, BertScore: 0.988175630569458\n",
      "Substitute: group, BertScore: 0.9877262115478516\n",
      "Substitute: level, BertScore: 0.9871639609336853\n",
      "Substitute: pool, BertScore: 0.9860692620277405\n",
      "Substitute: elevation, BertScore: 0.9858986139297485\n",
      "Substitute: variety, BertScore: 0.9858022332191467\n",
      "Substitute: intake, BertScore: 0.9854981899261475\n",
      "Substitute: size, BertScore: 0.9853296875953674\n",
      "Substitute: degree, BertScore: 0.9849601984024048\n",
      "Substitute: unit, BertScore: 0.9816240072250366\n",
      "top-10 substitutes based on bertscores in context: ['percentage', 'number', 'fraction', 'amount', 'concentration', 'portion', 'numbers', 'quantity', 'share', 'percent']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: motive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: motivation, BertScore: 0.9775851964950562\n",
      "Substitute: justification, BertScore: 0.95243239402771\n",
      "Substitute: purpose, BertScore: 0.9511337876319885\n",
      "Substitute: reason, BertScore: 0.9510298371315002\n",
      "Substitute: cause, BertScore: 0.9501927495002747\n",
      "Substitute: reasons, BertScore: 0.9434650540351868\n",
      "Substitute: basis, BertScore: 0.9409334063529968\n",
      "Substitute: source, BertScore: 0.9378675222396851\n",
      "Substitute: origin, BertScore: 0.9319988489151001\n",
      "Substitute: plot, BertScore: 0.9276143908500671\n",
      "Substitute: timing, BertScore: 0.9237887263298035\n",
      "Substitute: responsibility, BertScore: 0.9227182269096375\n",
      "Substitute: charge, BertScore: 0.9225872755050659\n",
      "Substitute: background, BertScore: 0.9208245277404785\n",
      "Substitute: circumstances, BertScore: 0.9169076681137085\n",
      "Substitute: trigger, BertScore: 0.9125811457633972\n",
      "Substitute: blame, BertScore: 0.9116071462631226\n",
      "Substitute: location, BertScore: 0.9111857414245605\n",
      "Substitute: price, BertScore: 0.9099629521369934\n",
      "Substitute: figure, BertScore: 0.9080164432525635\n",
      "Substitute: scope, BertScore: 0.9065468907356262\n",
      "Substitute: date, BertScore: 0.903727650642395\n",
      "Substitute: timeline, BertScore: 0.8962740898132324\n",
      "Substitute: dates, BertScore: 0.8959438800811768\n",
      "Substitute: evidence, BertScore: 0.8946777582168579\n",
      "Substitute: number, BertScore: 0.8913518786430359\n",
      "Substitute: time, BertScore: 0.8872889280319214\n",
      "Substitute: period, BertScore: 0.8850522637367249\n",
      "top-10 substitutes based on bertscores in context: ['motivation', 'justification', 'purpose', 'reason', 'cause', 'reasons', 'basis', 'source', 'origin', 'plot']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: determination\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: assessment, BertScore: 0.9877358078956604\n",
      "Substitute: decision, BertScore: 0.9874907732009888\n",
      "Substitute: disposition, BertScore: 0.9866981506347656\n",
      "Substitute: resolve, BertScore: 0.9862558245658875\n",
      "Substitute: selection, BertScore: 0.9859670400619507\n",
      "Substitute: choice, BertScore: 0.9847548604011536\n",
      "Substitute: order, BertScore: 0.9845463633537292\n",
      "Substitute: application, BertScore: 0.9843406677246094\n",
      "Substitute: position, BertScore: 0.9842130541801453\n",
      "Substitute: readiness, BertScore: 0.9833483695983887\n",
      "Substitute: commitment, BertScore: 0.9828310012817383\n",
      "Substitute: progress, BertScore: 0.9815269708633423\n",
      "Substitute: mandate, BertScore: 0.9812006950378418\n",
      "Substitute: effort, BertScore: 0.9809454679489136\n",
      "Substitute: decisions, BertScore: 0.9801485538482666\n",
      "Substitute: intention, BertScore: 0.9800744652748108\n",
      "Substitute: willingness, BertScore: 0.9796943068504333\n",
      "Substitute: ability, BertScore: 0.9794009923934937\n",
      "Substitute: efforts, BertScore: 0.9793509244918823\n",
      "Substitute: competence, BertScore: 0.9784495830535889\n",
      "Substitute: capacity, BertScore: 0.9784135222434998\n",
      "Substitute: right, BertScore: 0.9783379435539246\n",
      "Substitute: recommendation, BertScore: 0.9783161878585815\n",
      "Substitute: will, BertScore: 0.9781315922737122\n",
      "Substitute: desire, BertScore: 0.9775405526161194\n",
      "Substitute: capability, BertScore: 0.9775392413139343\n",
      "Substitute: refusal, BertScore: 0.9753504395484924\n",
      "Substitute: failure, BertScore: 0.9742099046707153\n",
      "Substitute: inability, BertScore: 0.9723663330078125\n",
      "top-10 substitutes based on bertscores in context: ['assessment', 'decision', 'disposition', 'resolve', 'selection', 'choice', 'order', 'application', 'position', 'readiness']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: bloodshed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: violence, BertScore: 0.984218180179596\n",
      "Substitute: fighting, BertScore: 0.9839290380477905\n",
      "Substitute: conflict, BertScore: 0.978460967540741\n",
      "Substitute: fight, BertScore: 0.9766412973403931\n",
      "Substitute: war, BertScore: 0.9754546880722046\n",
      "Substitute: struggle, BertScore: 0.9750761389732361\n",
      "Substitute: dialogue, BertScore: 0.9716224074363708\n",
      "Substitute: pressure, BertScore: 0.9702025651931763\n",
      "Substitute: situation, BertScore: 0.9694265127182007\n",
      "Substitute: rhetoric, BertScore: 0.9693183302879333\n",
      "Substitute: bombing, BertScore: 0.9692414999008179\n",
      "Substitute: peace, BertScore: 0.9689992666244507\n",
      "Substitute: negotiations, BertScore: 0.9689714312553406\n",
      "Substitute: diplomacy, BertScore: 0.9689128994941711\n",
      "Substitute: crisis, BertScore: 0.9686528444290161\n",
      "Substitute: talks, BertScore: 0.9682276248931885\n",
      "Substitute: campaign, BertScore: 0.967940092086792\n",
      "Substitute: problem, BertScore: 0.9668177962303162\n",
      "Substitute: talk, BertScore: 0.9665473699569702\n",
      "Substitute: action, BertScore: 0.9662224054336548\n",
      "Substitute: debate, BertScore: 0.9661684632301331\n",
      "Substitute: effort, BertScore: 0.9641225934028625\n",
      "Substitute: initiative, BertScore: 0.9637314677238464\n",
      "Substitute: deal, BertScore: 0.9629839658737183\n",
      "Substitute: process, BertScore: 0.9629820585250854\n",
      "Substitute: meeting, BertScore: 0.9629366397857666\n",
      "Substitute: issue, BertScore: 0.9623969793319702\n",
      "Substitute: mission, BertScore: 0.9617407917976379\n",
      "Substitute: work, BertScore: 0.9616623520851135\n",
      "Substitute: plan, BertScore: 0.9601383805274963\n",
      "top-10 substitutes based on bertscores in context: ['violence', 'fighting', 'conflict', 'fight', 'war', 'struggle', 'dialogue', 'pressure', 'situation', 'rhetoric']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: credibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: legitimacy, BertScore: 0.9957327246665955\n",
      "Substitute: visibility, BertScore: 0.9950099587440491\n",
      "Substitute: prestige, BertScore: 0.994726836681366\n",
      "Substitute: reputation, BertScore: 0.9941318035125732\n",
      "Substitute: integrity, BertScore: 0.9940283298492432\n",
      "Substitute: sincerity, BertScore: 0.9939915537834167\n",
      "Substitute: consistency, BertScore: 0.9936010837554932\n",
      "Substitute: popularity, BertScore: 0.9929844737052917\n",
      "Substitute: loyalty, BertScore: 0.9929146766662598\n",
      "Substitute: effectiveness, BertScore: 0.9926528334617615\n",
      "Substitute: reliability, BertScore: 0.9925758242607117\n",
      "Substitute: strength, BertScore: 0.9925752282142639\n",
      "Substitute: authenticity, BertScore: 0.9922687411308289\n",
      "Substitute: trust, BertScore: 0.9922186732292175\n",
      "Substitute: momentum, BertScore: 0.9921132326126099\n",
      "Substitute: validity, BertScore: 0.991986870765686\n",
      "Substitute: leadership, BertScore: 0.9918639659881592\n",
      "Substitute: courage, BertScore: 0.9918227195739746\n",
      "Substitute: stability, BertScore: 0.9918075799942017\n",
      "Substitute: capacity, BertScore: 0.9916995167732239\n",
      "Substitute: transparency, BertScore: 0.991136908531189\n",
      "Substitute: competence, BertScore: 0.9908705949783325\n",
      "Substitute: faith, BertScore: 0.9904193878173828\n",
      "Substitute: support, BertScore: 0.9903416633605957\n",
      "Substitute: experience, BertScore: 0.9902005195617676\n",
      "Substitute: success, BertScore: 0.9898053407669067\n",
      "Substitute: confidence, BertScore: 0.9896460771560669\n",
      "Substitute: security, BertScore: 0.9884684085845947\n",
      "Substitute: credible, BertScore: 0.9874175190925598\n",
      "top-10 substitutes based on bertscores in context: ['legitimacy', 'visibility', 'prestige', 'reputation', 'integrity', 'sincerity', 'consistency', 'popularity', 'loyalty', 'effectiveness']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: exclusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: elimination, BertScore: 0.9951340556144714\n",
      "Substitute: inclusion, BertScore: 0.9943212866783142\n",
      "Substitute: removal, BertScore: 0.9940500259399414\n",
      "Substitute: restriction, BertScore: 0.9939785599708557\n",
      "Substitute: disqualification, BertScore: 0.9935243725776672\n",
      "Substitute: exemption, BertScore: 0.9933590888977051\n",
      "Substitute: limitation, BertScore: 0.9933542013168335\n",
      "Substitute: ban, BertScore: 0.9933011531829834\n",
      "Substitute: expulsion, BertScore: 0.9929415583610535\n",
      "Substitute: dismissal, BertScore: 0.992489218711853\n",
      "Substitute: departure, BertScore: 0.9924576282501221\n",
      "Substitute: exception, BertScore: 0.9920945167541504\n",
      "Substitute: absence, BertScore: 0.9918889403343201\n",
      "Substitute: admission, BertScore: 0.9915468096733093\n",
      "Substitute: exclude, BertScore: 0.9910304546356201\n",
      "Substitute: infringement, BertScore: 0.9909632802009583\n",
      "Substitute: acceptance, BertScore: 0.990937352180481\n",
      "Substitute: deportation, BertScore: 0.9896796941757202\n",
      "Substitute: application, BertScore: 0.9894253015518188\n",
      "Substitute: release, BertScore: 0.9893921613693237\n",
      "Substitute: contribution, BertScore: 0.9892966151237488\n",
      "Substitute: eligibility, BertScore: 0.9888907074928284\n",
      "Substitute: rule, BertScore: 0.9887546300888062\n",
      "Substitute: entry, BertScore: 0.9881824254989624\n",
      "Substitute: statement, BertScore: 0.9879744648933411\n",
      "Substitute: identity, BertScore: 0.9876255989074707\n",
      "Substitute: claim, BertScore: 0.9873390197753906\n",
      "Substitute: suit, BertScore: 0.9856585264205933\n",
      "Substitute: employer, BertScore: 0.9804946780204773\n",
      "top-10 substitutes based on bertscores in context: ['elimination', 'inclusion', 'removal', 'restriction', 'disqualification', 'exemption', 'limitation', 'ban', 'expulsion', 'dismissal']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: craven\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: reckless, BertScore: 0.9848200082778931\n",
      "Substitute: savage, BertScore: 0.9830049276351929\n",
      "Substitute: cynical, BertScore: 0.9805193543434143\n",
      "Substitute: cavalier, BertScore: 0.9799339771270752\n",
      "Substitute: destructive, BertScore: 0.9791377782821655\n",
      "Substitute: excessive, BertScore: 0.978939414024353\n",
      "Substitute: naive, BertScore: 0.9786162972450256\n",
      "Substitute: dangerous, BertScore: 0.9783564805984497\n",
      "Substitute: evil, BertScore: 0.9780745506286621\n",
      "Substitute: terrible, BertScore: 0.9778206944465637\n",
      "Substitute: corrupt, BertScore: 0.9768880009651184\n",
      "Substitute: aggressive, BertScore: 0.9761045575141907\n",
      "Substitute: flawed, BertScore: 0.9744493365287781\n",
      "Substitute: bad, BertScore: 0.9737097024917603\n",
      "Substitute: disappointing, BertScore: 0.973429799079895\n",
      "Substitute: partisan, BertScore: 0.972844123840332\n",
      "Substitute: boring, BertScore: 0.9717905521392822\n",
      "Substitute: annoying, BertScore: 0.9712812900543213\n",
      "Substitute: serious, BertScore: 0.9697755575180054\n",
      "Substitute: worrying, BertScore: 0.9682670831680298\n",
      "Substitute: failing, BertScore: 0.9658027291297913\n",
      "Substitute: misleading, BertScore: 0.9652363657951355\n",
      "Substitute: insulting, BertScore: 0.9651657342910767\n",
      "Substitute: irritating, BertScore: 0.9650145769119263\n",
      "Substitute: disturbing, BertScore: 0.9647336602210999\n",
      "Substitute: damaging, BertScore: 0.9635317921638489\n",
      "Substitute: distracting, BertScore: 0.9632496237754822\n",
      "Substitute: interfering, BertScore: 0.9630478620529175\n",
      "Substitute: engaging, BertScore: 0.9569975137710571\n",
      "top-10 substitutes based on bertscores in context: ['reckless', 'savage', 'cynical', 'cavalier', 'destructive', 'excessive', 'naive', 'dangerous', 'evil', 'terrible']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: usher\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: bring, BertScore: 0.9919873476028442\n",
      "Substitute: enter, BertScore: 0.9895890355110168\n",
      "Substitute: result, BertScore: 0.9895002245903015\n",
      "Substitute: spark, BertScore: 0.9893372654914856\n",
      "Substitute: foster, BertScore: 0.9891955256462097\n",
      "Substitute: ushered, BertScore: 0.9887018799781799\n",
      "Substitute: lead, BertScore: 0.987512469291687\n",
      "Substitute: allow, BertScore: 0.9866565465927124\n",
      "Substitute: arrive, BertScore: 0.9864614605903625\n",
      "Substitute: bringing, BertScore: 0.9863059520721436\n",
      "Substitute: introduce, BertScore: 0.9862452149391174\n",
      "Substitute: engage, BertScore: 0.9860595464706421\n",
      "Substitute: put, BertScore: 0.9857737421989441\n",
      "Substitute: invest, BertScore: 0.9854837656021118\n",
      "Substitute: throw, BertScore: 0.9853331446647644\n",
      "Substitute: lock, BertScore: 0.9851437211036682\n",
      "Substitute: stage, BertScore: 0.9851218461990356\n",
      "Substitute: step, BertScore: 0.9848287105560303\n",
      "Substitute: create, BertScore: 0.9847033619880676\n",
      "Substitute: deliver, BertScore: 0.9840652942657471\n",
      "Substitute: move, BertScore: 0.983920693397522\n",
      "Substitute: participate, BertScore: 0.9837340712547302\n",
      "Substitute: assist, BertScore: 0.9834024310112\n",
      "Substitute: add, BertScore: 0.9830365180969238\n",
      "Substitute: anchor, BertScore: 0.982852041721344\n",
      "Substitute: shine, BertScore: 0.9825356602668762\n",
      "Substitute: act, BertScore: 0.9820038676261902\n",
      "Substitute: provide, BertScore: 0.9820036888122559\n",
      "Substitute: call, BertScore: 0.9818738698959351\n",
      "top-10 substitutes based on bertscores in context: ['bring', 'enter', 'result', 'spark', 'foster', 'ushered', 'lead', 'allow', 'arrive', 'bringing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: anonymity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: secrecy, BertScore: 0.9393587112426758\n",
      "Substitute: isolation, BertScore: 0.9337366819381714\n",
      "Substitute: silence, BertScore: 0.9327664375305176\n",
      "Substitute: privacy, BertScore: 0.9309325218200684\n",
      "Substitute: clarity, BertScore: 0.9189521074295044\n",
      "Substitute: security, BertScore: 0.9153470396995544\n",
      "Substitute: calm, BertScore: 0.9151287078857422\n",
      "Substitute: confidence, BertScore: 0.9140048623085022\n",
      "Substitute: disbelief, BertScore: 0.9117293953895569\n",
      "Substitute: anonymous, BertScore: 0.9117053747177124\n",
      "Substitute: safety, BertScore: 0.9113727807998657\n",
      "Substitute: confidential, BertScore: 0.910489022731781\n",
      "Substitute: comment, BertScore: 0.9100691080093384\n",
      "Substitute: release, BertScore: 0.9036075472831726\n",
      "Substitute: writing, BertScore: 0.9026997089385986\n",
      "Substitute: undisclosed, BertScore: 0.9023264050483704\n",
      "Substitute: speaking, BertScore: 0.9009096026420593\n",
      "Substitute: location, BertScore: 0.8995028734207153\n",
      "Substitute: death, BertScore: 0.8973313570022583\n",
      "Substitute: office, BertScore: 0.8931106328964233\n",
      "Substitute: court, BertScore: 0.8879659175872803\n",
      "Substitute: unknown, BertScore: 0.8875926733016968\n",
      "Substitute: attorney, BertScore: 0.8860066533088684\n",
      "Substitute: bond, BertScore: 0.8859305381774902\n",
      "Substitute: hospital, BertScore: 0.8826537132263184\n",
      "Substitute: such, BertScore: 0.8814987540245056\n",
      "Substitute: condition, BertScore: 0.874305009841919\n",
      "Substitute: state, BertScore: 0.8639976382255554\n",
      "top-10 substitutes based on bertscores in context: ['secrecy', 'isolation', 'silence', 'privacy', 'clarity', 'security', 'calm', 'confidence', 'disbelief', 'anonymous']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: emerged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: surfaced, BertScore: 0.9911069273948669\n",
      "Substitute: appeared, BertScore: 0.9883474111557007\n",
      "Substitute: arose, BertScore: 0.9876477122306824\n",
      "Substitute: reappeared, BertScore: 0.9872736930847168\n",
      "Substitute: exited, BertScore: 0.9869530200958252\n",
      "Substitute: stepped, BertScore: 0.9856349229812622\n",
      "Substitute: entered, BertScore: 0.9855640530586243\n",
      "Substitute: returned, BertScore: 0.9835449457168579\n",
      "Substitute: arrived, BertScore: 0.9816840291023254\n",
      "Substitute: walked, BertScore: 0.9807272553443909\n",
      "Substitute: came, BertScore: 0.9805325865745544\n",
      "Substitute: descended, BertScore: 0.9804973006248474\n",
      "Substitute: awakened, BertScore: 0.980119526386261\n",
      "Substitute: rose, BertScore: 0.979709267616272\n",
      "Substitute: burst, BertScore: 0.978368878364563\n",
      "Substitute: slipped, BertScore: 0.9782202243804932\n",
      "Substitute: awoke, BertScore: 0.9775620102882385\n",
      "Substitute: woke, BertScore: 0.9766276478767395\n",
      "Substitute: jumped, BertScore: 0.973802387714386\n",
      "Substitute: withdrew, BertScore: 0.9712218046188354\n",
      "Substitute: disappeared, BertScore: 0.9699889421463013\n",
      "Substitute: bolted, BertScore: 0.9693678617477417\n",
      "Substitute: ran, BertScore: 0.9687399864196777\n",
      "Substitute: escaped, BertScore: 0.9686903953552246\n",
      "Substitute: vanished, BertScore: 0.9665043354034424\n",
      "Substitute: called, BertScore: 0.9649849534034729\n",
      "Substitute: heard, BertScore: 0.9551031589508057\n",
      "top-10 substitutes based on bertscores in context: ['surfaced', 'appeared', 'arose', 'reappeared', 'exited', 'stepped', 'entered', 'returned', 'arrived', 'walked']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: indignation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: anger, BertScore: 0.9377899765968323\n",
      "Substitute: disgust, BertScore: 0.9375976920127869\n",
      "Substitute: outrage, BertScore: 0.9371219277381897\n",
      "Substitute: frustration, BertScore: 0.9340133666992188\n",
      "Substitute: dissatisfaction, BertScore: 0.9310445189476013\n",
      "Substitute: resentment, BertScore: 0.9309644103050232\n",
      "Substitute: discontent, BertScore: 0.9261626601219177\n",
      "Substitute: disappointment, BertScore: 0.9247133731842041\n",
      "Substitute: defiance, BertScore: 0.9211012125015259\n",
      "Substitute: alarm, BertScore: 0.9201536774635315\n",
      "Substitute: emotion, BertScore: 0.9186568856239319\n",
      "Substitute: unease, BertScore: 0.9180331230163574\n",
      "Substitute: contempt, BertScore: 0.9172296524047852\n",
      "Substitute: fear, BertScore: 0.9151710867881775\n",
      "Substitute: desperation, BertScore: 0.9146493077278137\n",
      "Substitute: protest, BertScore: 0.9145047664642334\n",
      "Substitute: concern, BertScore: 0.9127861857414246\n",
      "Substitute: solidarity, BertScore: 0.9083519577980042\n",
      "Substitute: sympathy, BertScore: 0.9077167510986328\n",
      "Substitute: resistance, BertScore: 0.906463623046875\n",
      "Substitute: violence, BertScore: 0.905110239982605\n",
      "Substitute: enthusiasm, BertScore: 0.9037812948226929\n",
      "Substitute: optimism, BertScore: 0.9036281108856201\n",
      "Substitute: opposition, BertScore: 0.9028081893920898\n",
      "Substitute: hope, BertScore: 0.901190459728241\n",
      "Substitute: action, BertScore: 0.8982974886894226\n",
      "Substitute: support, BertScore: 0.896454930305481\n",
      "Substitute: relief, BertScore: 0.8954596519470215\n",
      "Substitute: unity, BertScore: 0.8941524624824524\n",
      "Substitute: strength, BertScore: 0.8934327960014343\n",
      "top-10 substitutes based on bertscores in context: ['anger', 'disgust', 'outrage', 'frustration', 'dissatisfaction', 'resentment', 'discontent', 'disappointment', 'defiance', 'alarm']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: re-enacting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: repeating, BertScore: 0.9163379073143005\n",
      "Substitute: continuing, BertScore: 0.9146130681037903\n",
      "Substitute: resolving, BertScore: 0.9132425785064697\n",
      "Substitute: staging, BertScore: 0.9121937155723572\n",
      "Substitute: framing, BertScore: 0.9111216068267822\n",
      "Substitute: conducting, BertScore: 0.9110890626907349\n",
      "Substitute: concluding, BertScore: 0.9092831611633301\n",
      "Substitute: launching, BertScore: 0.9092009663581848\n",
      "Substitute: presenting, BertScore: 0.908820629119873\n",
      "Substitute: finishing, BertScore: 0.9084088206291199\n",
      "Substitute: ending, BertScore: 0.9077027440071106\n",
      "Substitute: performing, BertScore: 0.9069784283638\n",
      "Substitute: airing, BertScore: 0.9061771631240845\n",
      "Substitute: introducing, BertScore: 0.9058567881584167\n",
      "Substitute: announcing, BertScore: 0.9053801894187927\n",
      "Substitute: doing, BertScore: 0.9046211242675781\n",
      "Substitute: recording, BertScore: 0.9043128490447998\n",
      "Substitute: committing, BertScore: 0.9037915468215942\n",
      "Substitute: reporting, BertScore: 0.9037371873855591\n",
      "Substitute: executing, BertScore: 0.9037143588066101\n",
      "Substitute: documenting, BertScore: 0.9037086963653564\n",
      "Substitute: depicting, BertScore: 0.903636634349823\n",
      "Substitute: publishing, BertScore: 0.9017198085784912\n",
      "Substitute: witnessing, BertScore: 0.9001672863960266\n",
      "Substitute: addressing, BertScore: 0.8996734023094177\n",
      "Substitute: describing, BertScore: 0.8980613350868225\n",
      "Substitute: writing, BertScore: 0.8976017236709595\n",
      "Substitute: showing, BertScore: 0.8964145183563232\n",
      "Substitute: filming, BertScore: 0.8939343690872192\n",
      "Substitute: discussing, BertScore: 0.8919152021408081\n",
      "top-10 substitutes based on bertscores in context: ['repeating', 'continuing', 'resolving', 'staging', 'framing', 'conducting', 'concluding', 'launching', 'presenting', 'finishing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: detained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: imprisoned, BertScore: 0.9940503835678101\n",
      "Substitute: jailed, BertScore: 0.9931623935699463\n",
      "Substitute: arrested, BertScore: 0.9927505254745483\n",
      "Substitute: interned, BertScore: 0.990879237651825\n",
      "Substitute: incarcerated, BertScore: 0.9901975989341736\n",
      "Substitute: trapped, BertScore: 0.9896888136863708\n",
      "Substitute: held, BertScore: 0.9893364906311035\n",
      "Substitute: confined, BertScore: 0.9879504442214966\n",
      "Substitute: kidnapped, BertScore: 0.9863020181655884\n",
      "Substitute: stranded, BertScore: 0.9862676858901978\n",
      "Substitute: tortured, BertScore: 0.9854905605316162\n",
      "Substitute: questioned, BertScore: 0.9828485250473022\n",
      "Substitute: kept, BertScore: 0.9827401638031006\n",
      "Substitute: locked, BertScore: 0.9820073843002319\n",
      "Substitute: wanted, BertScore: 0.9818222522735596\n",
      "Substitute: banned, BertScore: 0.9817246198654175\n",
      "Substitute: hiding, BertScore: 0.9816833734512329\n",
      "Substitute: hidden, BertScore: 0.9814161658287048\n",
      "Substitute: stuck, BertScore: 0.9811102747917175\n",
      "Substitute: suspended, BertScore: 0.9805108308792114\n",
      "Substitute: missing, BertScore: 0.9796090722084045\n",
      "Substitute: living, BertScore: 0.9776108264923096\n",
      "Substitute: staying, BertScore: 0.9762454032897949\n",
      "Substitute: residing, BertScore: 0.9761419892311096\n",
      "Substitute: serving, BertScore: 0.9738830924034119\n",
      "Substitute: working, BertScore: 0.9723678827285767\n",
      "Substitute: traveling, BertScore: 0.9718955159187317\n",
      "Substitute: holding, BertScore: 0.9717602133750916\n",
      "Substitute: waiting, BertScore: 0.9711853861808777\n",
      "top-10 substitutes based on bertscores in context: ['imprisoned', 'jailed', 'arrested', 'interned', 'incarcerated', 'trapped', 'held', 'confined', 'kidnapped', 'stranded']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: diplomatic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: bilateral, BertScore: 0.9848029017448425\n",
      "Substitute: political, BertScore: 0.9833940267562866\n",
      "Substitute: trade, BertScore: 0.9833383560180664\n",
      "Substitute: peace, BertScore: 0.9808211326599121\n",
      "Substitute: negotiating, BertScore: 0.9805675745010376\n",
      "Substitute: business, BertScore: 0.9799669981002808\n",
      "Substitute: negotiated, BertScore: 0.9794565439224243\n",
      "Substitute: financial, BertScore: 0.9793649911880493\n",
      "Substitute: formal, BertScore: 0.9791659116744995\n",
      "Substitute: legal, BertScore: 0.9791610240936279\n",
      "Substitute: working, BertScore: 0.9787327647209167\n",
      "Substitute: security, BertScore: 0.9785325527191162\n",
      "Substitute: strategic, BertScore: 0.9780174493789673\n",
      "Substitute: permanent, BertScore: 0.9778558611869812\n",
      "Substitute: peaceful, BertScore: 0.9778062105178833\n",
      "Substitute: final, BertScore: 0.9778009653091431\n",
      "Substitute: humanitarian, BertScore: 0.9777735471725464\n",
      "Substitute: secret, BertScore: 0.9774661064147949\n",
      "Substitute: military, BertScore: 0.9771681427955627\n",
      "Substitute: temporary, BertScore: 0.9767112731933594\n",
      "Substitute: partial, BertScore: 0.9763741493225098\n",
      "Substitute: direct, BertScore: 0.9762812852859497\n",
      "Substitute: crisis, BertScore: 0.9756760597229004\n",
      "Substitute: proposed, BertScore: 0.9750920534133911\n",
      "Substitute: potential, BertScore: 0.9750481843948364\n",
      "Substitute: possible, BertScore: 0.9748612642288208\n",
      "Substitute: satisfactory, BertScore: 0.9748494625091553\n",
      "Substitute: better, BertScore: 0.972511887550354\n",
      "Substitute: similar, BertScore: 0.9665548801422119\n",
      "top-10 substitutes based on bertscores in context: ['bilateral', 'political', 'trade', 'peace', 'negotiating', 'business', 'negotiated', 'financial', 'formal', 'legal']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: troublemakers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: criminals, BertScore: 0.9130345582962036\n",
      "Substitute: terrorists, BertScore: 0.9047567248344421\n",
      "Substitute: murderers, BertScore: 0.904287576675415\n",
      "Substitute: idiots, BertScore: 0.8952860832214355\n",
      "Substitute: heroes, BertScore: 0.889416515827179\n",
      "Substitute: politicians, BertScore: 0.8853247761726379\n",
      "Substitute: dangerous, BertScore: 0.8826018571853638\n",
      "Substitute: corrupt, BertScore: 0.8819959163665771\n",
      "Substitute: victims, BertScore: 0.8816304802894592\n",
      "Substitute: people, BertScore: 0.8784302473068237\n",
      "Substitute: enemies, BertScore: 0.8748986124992371\n",
      "Substitute: democrats, BertScore: 0.8710560202598572\n",
      "Substitute: farmers, BertScore: 0.8707787990570068\n",
      "Substitute: republicans, BertScore: 0.8675309419631958\n",
      "Substitute: poor, BertScore: 0.8671278953552246\n",
      "Substitute: bad, BertScore: 0.8620880842208862\n",
      "Substitute: parents, BertScore: 0.8615010380744934\n",
      "Substitute: stupid, BertScore: 0.8587213754653931\n",
      "Substitute: rich, BertScore: 0.8585647940635681\n",
      "Substitute: wealthy, BertScore: 0.8562985062599182\n",
      "Substitute: innocent, BertScore: 0.8560023307800293\n",
      "Substitute: women, BertScore: 0.8555698394775391\n",
      "Substitute: angry, BertScore: 0.851161539554596\n",
      "Substitute: afraid, BertScore: 0.8497181534767151\n",
      "Substitute: good, BertScore: 0.8467540740966797\n",
      "Substitute: children, BertScore: 0.8446507453918457\n",
      "Substitute: friends, BertScore: 0.8397543430328369\n",
      "Substitute: honest, BertScore: 0.8157089352607727\n",
      "Substitute: wrong, BertScore: 0.8124915361404419\n",
      "Substitute: not, BertScore: 0.8118044137954712\n",
      "top-10 substitutes based on bertscores in context: ['criminals', 'terrorists', 'murderers', 'idiots', 'heroes', 'politicians', 'dangerous', 'corrupt', 'victims', 'people']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: abdomen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: belly, BertScore: 0.9898878931999207\n",
      "Substitute: stomach, BertScore: 0.9878537654876709\n",
      "Substitute: abdominal, BertScore: 0.9838871359825134\n",
      "Substitute: tail, BertScore: 0.9836757183074951\n",
      "Substitute: body, BertScore: 0.9824586510658264\n",
      "Substitute: chest, BertScore: 0.981795072555542\n",
      "Substitute: forehead, BertScore: 0.980194628238678\n",
      "Substitute: neck, BertScore: 0.9798674583435059\n",
      "Substitute: thighs, BertScore: 0.9794812798500061\n",
      "Substitute: legs, BertScore: 0.9793025255203247\n",
      "Substitute: wings, BertScore: 0.9782856702804565\n",
      "Substitute: head, BertScore: 0.9780626893043518\n",
      "Substitute: anatomy, BertScore: 0.9771289229393005\n",
      "Substitute: groin, BertScore: 0.9769723415374756\n",
      "Substitute: penis, BertScore: 0.9766954183578491\n",
      "Substitute: torso, BertScore: 0.9761748909950256\n",
      "Substitute: hips, BertScore: 0.9758228659629822\n",
      "Substitute: arms, BertScore: 0.9736903309822083\n",
      "Substitute: waist, BertScore: 0.9735521674156189\n",
      "Substitute: nostrils, BertScore: 0.9734479188919067\n",
      "Substitute: flesh, BertScore: 0.9733068943023682\n",
      "Substitute: heart, BertScore: 0.9724252223968506\n",
      "Substitute: breasts, BertScore: 0.9722862243652344\n",
      "Substitute: shoulders, BertScore: 0.9717004299163818\n",
      "Substitute: ribs, BertScore: 0.9716000556945801\n",
      "Substitute: face, BertScore: 0.97076416015625\n",
      "Substitute: back, BertScore: 0.9688010215759277\n",
      "Substitute: eyes, BertScore: 0.9684656858444214\n",
      "Substitute: exterior, BertScore: 0.9648417830467224\n",
      "top-10 substitutes based on bertscores in context: ['belly', 'stomach', 'abdominal', 'tail', 'body', 'chest', 'forehead', 'neck', 'thighs', 'legs']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: pursuit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: search, BertScore: 0.9915434718132019\n",
      "Substitute: chasing, BertScore: 0.9915192723274231\n",
      "Substitute: tracking, BertScore: 0.9914306998252869\n",
      "Substitute: pursuing, BertScore: 0.9905238151550293\n",
      "Substitute: exploration, BertScore: 0.9902031421661377\n",
      "Substitute: quest, BertScore: 0.9896190166473389\n",
      "Substitute: capture, BertScore: 0.9889013767242432\n",
      "Substitute: seeking, BertScore: 0.9886715412139893\n",
      "Substitute: hunting, BertScore: 0.9884312748908997\n",
      "Substitute: hunt, BertScore: 0.9873535633087158\n",
      "Substitute: chase, BertScore: 0.9873525500297546\n",
      "Substitute: driving, BertScore: 0.9869656562805176\n",
      "Substitute: attack, BertScore: 0.9868576526641846\n",
      "Substitute: seeker, BertScore: 0.9858059287071228\n",
      "Substitute: targeting, BertScore: 0.9857158660888672\n",
      "Substitute: assault, BertScore: 0.9855804443359375\n",
      "Substitute: foraging, BertScore: 0.9851900935173035\n",
      "Substitute: racing, BertScore: 0.9851810336112976\n",
      "Substitute: action, BertScore: 0.9841088652610779\n",
      "Substitute: track, BertScore: 0.9840145111083984\n",
      "Substitute: pursue, BertScore: 0.9840046763420105\n",
      "Substitute: activity, BertScore: 0.9831082820892334\n",
      "Substitute: walking, BertScore: 0.9819398522377014\n",
      "Substitute: exercise, BertScore: 0.9790069460868835\n",
      "Substitute: behavior, BertScore: 0.9787460565567017\n",
      "Substitute: seek, BertScore: 0.9785946011543274\n",
      "Substitute: prey, BertScore: 0.9751712679862976\n",
      "Substitute: stalking, BertScore: 0.972403883934021\n",
      "top-10 substitutes based on bertscores in context: ['search', 'chasing', 'tracking', 'pursuing', 'exploration', 'quest', 'capture', 'seeking', 'hunting', 'hunt']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: inclusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: insertion, BertScore: 0.99568110704422\n",
      "Substitute: addition, BertScore: 0.9954346418380737\n",
      "Substitute: entry, BertScore: 0.9948756098747253\n",
      "Substitute: admission, BertScore: 0.994850754737854\n",
      "Substitute: presence, BertScore: 0.9946515560150146\n",
      "Substitute: incorporation, BertScore: 0.9945212602615356\n",
      "Substitute: placement, BertScore: 0.994500458240509\n",
      "Substitute: acceptance, BertScore: 0.9940292835235596\n",
      "Substitute: introduction, BertScore: 0.9937635064125061\n",
      "Substitute: involvement, BertScore: 0.9934905171394348\n",
      "Substitute: participation, BertScore: 0.9934250712394714\n",
      "Substitute: appearance, BertScore: 0.9933821558952332\n",
      "Substitute: absence, BertScore: 0.9927222728729248\n",
      "Substitute: exclusion, BertScore: 0.9926605224609375\n",
      "Substitute: availability, BertScore: 0.9926580190658569\n",
      "Substitute: integration, BertScore: 0.9924056529998779\n",
      "Substitute: identification, BertScore: 0.9923380017280579\n",
      "Substitute: selection, BertScore: 0.9922100305557251\n",
      "Substitute: elimination, BertScore: 0.9919158220291138\n",
      "Substitute: use, BertScore: 0.9914783239364624\n",
      "Substitute: existence, BertScore: 0.9913699626922607\n",
      "Substitute: eligibility, BertScore: 0.9912065267562866\n",
      "Substitute: consideration, BertScore: 0.9908137917518616\n",
      "Substitute: passage, BertScore: 0.9905774593353271\n",
      "Substitute: attendance, BertScore: 0.9905688762664795\n",
      "Substitute: included, BertScore: 0.9893283843994141\n",
      "Substitute: visibility, BertScore: 0.9886557459831238\n",
      "Substitute: identity, BertScore: 0.9884189367294312\n",
      "Substitute: membership, BertScore: 0.9870721101760864\n",
      "top-10 substitutes based on bertscores in context: ['insertion', 'addition', 'entry', 'admission', 'presence', 'incorporation', 'placement', 'acceptance', 'introduction', 'involvement']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: acquire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: purchase, BertScore: 0.9954737424850464\n",
      "Substitute: buy, BertScore: 0.994188129901886\n",
      "Substitute: obtain, BertScore: 0.9904088377952576\n",
      "Substitute: sell, BertScore: 0.990127682685852\n",
      "Substitute: acquisition, BertScore: 0.9880331158638\n",
      "Substitute: buying, BertScore: 0.9853124618530273\n",
      "Substitute: lease, BertScore: 0.9844498634338379\n",
      "Substitute: develop, BertScore: 0.9837812185287476\n",
      "Substitute: produce, BertScore: 0.9834050536155701\n",
      "Substitute: operate, BertScore: 0.9833819270133972\n",
      "Substitute: receive, BertScore: 0.9832996129989624\n",
      "Substitute: get, BertScore: 0.9825350046157837\n",
      "Substitute: pursue, BertScore: 0.9824905395507812\n",
      "Substitute: hire, BertScore: 0.9823664426803589\n",
      "Substitute: move, BertScore: 0.9818456768989563\n",
      "Substitute: build, BertScore: 0.9817697405815125\n",
      "Substitute: take, BertScore: 0.9817672967910767\n",
      "Substitute: combine, BertScore: 0.9811908006668091\n",
      "Substitute: own, BertScore: 0.9806761741638184\n",
      "Substitute: offer, BertScore: 0.9787108898162842\n",
      "Substitute: use, BertScore: 0.978218674659729\n",
      "Substitute: raise, BertScore: 0.9780725836753845\n",
      "Substitute: bid, BertScore: 0.9777915477752686\n",
      "Substitute: have, BertScore: 0.9774923920631409\n",
      "Substitute: accept, BertScore: 0.9763151407241821\n",
      "Substitute: leave, BertScore: 0.9748492240905762\n",
      "Substitute: do, BertScore: 0.9738502502441406\n",
      "top-10 substitutes based on bertscores in context: ['purchase', 'buy', 'obtain', 'sell', 'acquisition', 'buying', 'lease', 'develop', 'produce', 'operate']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: confidential\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: secret, BertScore: 0.991614580154419\n",
      "Substitute: classified, BertScore: 0.9905797243118286\n",
      "Substitute: anonymous, BertScore: 0.9895208477973938\n",
      "Substitute: sealed, BertScore: 0.9830946922302246\n",
      "Substitute: disclosed, BertScore: 0.9825206995010376\n",
      "Substitute: public, BertScore: 0.9823266863822937\n",
      "Substitute: leaked, BertScore: 0.9815194606781006\n",
      "Substitute: open, BertScore: 0.9812324643135071\n",
      "Substitute: legal, BertScore: 0.9812133312225342\n",
      "Substitute: valid, BertScore: 0.9800323247909546\n",
      "Substitute: secure, BertScore: 0.9797435402870178\n",
      "Substitute: protected, BertScore: 0.9794266223907471\n",
      "Substitute: closed, BertScore: 0.9793225526809692\n",
      "Substitute: binding, BertScore: 0.9788267612457275\n",
      "Substitute: accurate, BertScore: 0.9787737131118774\n",
      "Substitute: released, BertScore: 0.9780389070510864\n",
      "Substitute: final, BertScore: 0.9779493808746338\n",
      "Substitute: available, BertScore: 0.9777188301086426\n",
      "Substitute: complete, BertScore: 0.9766829609870911\n",
      "Substitute: respected, BertScore: 0.9765655994415283\n",
      "Substitute: published, BertScore: 0.9765583276748657\n",
      "Substitute: suspended, BertScore: 0.9765052795410156\n",
      "Substitute: reviewed, BertScore: 0.9756783246994019\n",
      "Substitute: accepted, BertScore: 0.9751873016357422\n",
      "Substitute: completed, BertScore: 0.974467933177948\n",
      "Substitute: finalized, BertScore: 0.9744493365287781\n",
      "Substitute: written, BertScore: 0.9740797877311707\n",
      "Substitute: forthcoming, BertScore: 0.973703920841217\n",
      "Substitute: held, BertScore: 0.970553994178772\n",
      "top-10 substitutes based on bertscores in context: ['secret', 'classified', 'anonymous', 'sealed', 'disclosed', 'public', 'leaked', 'open', 'legal', 'valid']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: attentively\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: closely, BertScore: 0.9321447610855103\n",
      "Substitute: carefully, BertScore: 0.9320552349090576\n",
      "Substitute: regularly, BertScore: 0.9290608763694763\n",
      "Substitute: properly, BertScore: 0.9288520216941833\n",
      "Substitute: clearly, BertScore: 0.9285557866096497\n",
      "Substitute: constantly, BertScore: 0.9276590347290039\n",
      "Substitute: specifically, BertScore: 0.9271478652954102\n",
      "Substitute: periodically, BertScore: 0.9258112907409668\n",
      "Substitute: thoroughly, BertScore: 0.9244221448898315\n",
      "Substitute: correctly, BertScore: 0.9235917329788208\n",
      "Substitute: fully, BertScore: 0.9234753847122192\n",
      "Substitute: immediately, BertScore: 0.9232643842697144\n",
      "Substitute: quickly, BertScore: 0.9216989874839783\n",
      "Substitute: briefly, BertScore: 0.919625997543335\n",
      "Substitute: also, BertScore: 0.9153207540512085\n",
      "Substitute: actually, BertScore: 0.9130064845085144\n",
      "Substitute: simply, BertScore: 0.9126437306404114\n",
      "Substitute: generally, BertScore: 0.912389874458313\n",
      "Substitute: first, BertScore: 0.9116597175598145\n",
      "Substitute: always, BertScore: 0.9110275506973267\n",
      "Substitute: definitely, BertScore: 0.9100680947303772\n",
      "Substitute: merely, BertScore: 0.9093945622444153\n",
      "Substitute: already, BertScore: 0.9071722030639648\n",
      "Substitute: certainly, BertScore: 0.9067769646644592\n",
      "Substitute: then, BertScore: 0.9055535197257996\n",
      "Substitute: only, BertScore: 0.9053483009338379\n",
      "Substitute: just, BertScore: 0.9025672674179077\n",
      "Substitute: not, BertScore: 0.8994460105895996\n",
      "Substitute: probably, BertScore: 0.8990087509155273\n",
      "Substitute: have, BertScore: 0.8887519240379333\n",
      "top-10 substitutes based on bertscores in context: ['closely', 'carefully', 'regularly', 'properly', 'clearly', 'constantly', 'specifically', 'periodically', 'thoroughly', 'correctly']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: bombardment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: attack, BertScore: 0.9767712354660034\n",
      "Substitute: assault, BertScore: 0.9762495756149292\n",
      "Substitute: harassment, BertScore: 0.97299724817276\n",
      "Substitute: onslaught, BertScore: 0.9720548391342163\n",
      "Substitute: raids, BertScore: 0.9715954661369324\n",
      "Substitute: siege, BertScore: 0.9708127379417419\n",
      "Substitute: assaults, BertScore: 0.9697914719581604\n",
      "Substitute: attacks, BertScore: 0.9683884382247925\n",
      "Substitute: fire, BertScore: 0.9673936367034912\n",
      "Substitute: engagement, BertScore: 0.9642693400382996\n",
      "Substitute: strikes, BertScore: 0.962742269039154\n",
      "Substitute: retaliation, BertScore: 0.9626278877258301\n",
      "Substitute: offensive, BertScore: 0.9623501300811768\n",
      "Substitute: strike, BertScore: 0.9622593522071838\n",
      "Substitute: occupation, BertScore: 0.9622067809104919\n",
      "Substitute: patrols, BertScore: 0.9608246088027954\n",
      "Substitute: action, BertScore: 0.9588939547538757\n",
      "Substitute: violence, BertScore: 0.9576600790023804\n",
      "Substitute: fighting, BertScore: 0.9562560319900513\n",
      "Substitute: operation, BertScore: 0.9554633498191833\n",
      "Substitute: operations, BertScore: 0.9532699584960938\n",
      "Substitute: movement, BertScore: 0.9522843360900879\n",
      "Substitute: resistance, BertScore: 0.9522112011909485\n",
      "Substitute: actions, BertScore: 0.9507076144218445\n",
      "Substitute: clashes, BertScore: 0.9502761960029602\n",
      "Substitute: response, BertScore: 0.9479184150695801\n",
      "Substitute: efforts, BertScore: 0.9444679021835327\n",
      "Substitute: activities, BertScore: 0.9434211254119873\n",
      "Substitute: use, BertScore: 0.9289079308509827\n",
      "top-10 substitutes based on bertscores in context: ['attack', 'assault', 'harassment', 'onslaught', 'raids', 'siege', 'assaults', 'attacks', 'fire', 'engagement']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: colonies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: populations, BertScore: 0.9879361987113953\n",
      "Substitute: communities, BertScore: 0.98677659034729\n",
      "Substitute: groups, BertScore: 0.9859298467636108\n",
      "Substitute: patches, BertScore: 0.9834014773368835\n",
      "Substitute: collections, BertScore: 0.983237624168396\n",
      "Substitute: nests, BertScore: 0.9818423390388489\n",
      "Substitute: clones, BertScore: 0.981809675693512\n",
      "Substitute: forms, BertScore: 0.9814006686210632\n",
      "Substitute: settlements, BertScore: 0.9812788367271423\n",
      "Substitute: plantations, BertScore: 0.9803323745727539\n",
      "Substitute: varieties, BertScore: 0.9802960753440857\n",
      "Substitute: specimens, BertScore: 0.9794034361839294\n",
      "Substitute: deposits, BertScore: 0.9793673753738403\n",
      "Substitute: remnants, BertScore: 0.9778628945350647\n",
      "Substitute: parts, BertScore: 0.9770153164863586\n",
      "Substitute: regions, BertScore: 0.9762467741966248\n",
      "Substitute: tribes, BertScore: 0.9755395650863647\n",
      "Substitute: traces, BertScore: 0.9752036333084106\n",
      "Substitute: species, BertScore: 0.973300039768219\n",
      "Substitute: forests, BertScore: 0.9715522527694702\n",
      "Substitute: prints, BertScore: 0.9696794748306274\n",
      "Substitute: plants, BertScore: 0.9691066741943359\n",
      "Substitute: islands, BertScore: 0.9684409499168396\n",
      "Substitute: finds, BertScore: 0.9679446816444397\n",
      "Substitute: colonists, BertScore: 0.9677112102508545\n",
      "Substitute: trees, BertScore: 0.9672582149505615\n",
      "Substitute: natives, BertScore: 0.9635661244392395\n",
      "top-10 substitutes based on bertscores in context: ['populations', 'communities', 'groups', 'patches', 'collections', 'nests', 'clones', 'forms', 'settlements', 'plantations']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: partially\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: partly, BertScore: 0.9961024522781372\n",
      "Substitute: half, BertScore: 0.9917625188827515\n",
      "Substitute: slightly, BertScore: 0.990301787853241\n",
      "Substitute: completely, BertScore: 0.9901935458183289\n",
      "Substitute: fully, BertScore: 0.9898806810379028\n",
      "Substitute: entirely, BertScore: 0.9881670475006104\n",
      "Substitute: totally, BertScore: 0.9877684116363525\n",
      "Substitute: substantially, BertScore: 0.9873123168945312\n",
      "Substitute: badly, BertScore: 0.9862592220306396\n",
      "Substitute: nearly, BertScore: 0.9860724210739136\n",
      "Substitute: temporarily, BertScore: 0.9856284856796265\n",
      "Substitute: severely, BertScore: 0.9850898385047913\n",
      "Substitute: momentarily, BertScore: 0.9842146635055542\n",
      "Substitute: mostly, BertScore: 0.9832848310470581\n",
      "Substitute: initially, BertScore: 0.9805209040641785\n",
      "Substitute: both, BertScore: 0.9801706075668335\n",
      "Substitute: all, BertScore: 0.9800827503204346\n",
      "Substitute: eventually, BertScore: 0.9800314903259277\n",
      "Substitute: further, BertScore: 0.9793217778205872\n",
      "Substitute: subsequently, BertScore: 0.9793134927749634\n",
      "Substitute: later, BertScore: 0.9789078235626221\n",
      "Substitute: immediately, BertScore: 0.9785866141319275\n",
      "Substitute: again, BertScore: 0.9779665470123291\n",
      "Substitute: simultaneously, BertScore: 0.9776648283004761\n",
      "Substitute: also, BertScore: 0.9775037169456482\n",
      "Substitute: apparently, BertScore: 0.9764461517333984\n",
      "Substitute: not, BertScore: 0.9757710695266724\n",
      "Substitute: then, BertScore: 0.9753791689872742\n",
      "Substitute: similarly, BertScore: 0.9744238257408142\n",
      "top-10 substitutes based on bertscores in context: ['partly', 'half', 'slightly', 'completely', 'fully', 'entirely', 'totally', 'substantially', 'badly', 'nearly']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: segregation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: segregated, BertScore: 0.9816331267356873\n",
      "Substitute: isolation, BertScore: 0.9759500622749329\n",
      "Substitute: integration, BertScore: 0.9745835065841675\n",
      "Substitute: separation, BertScore: 0.9734771251678467\n",
      "Substitute: minority, BertScore: 0.9730062484741211\n",
      "Substitute: exclusion, BertScore: 0.9709835052490234\n",
      "Substitute: discrimination, BertScore: 0.9708864092826843\n",
      "Substitute: equality, BertScore: 0.970360279083252\n",
      "Substitute: classification, BertScore: 0.9703280925750732\n",
      "Substitute: diversity, BertScore: 0.9703161716461182\n",
      "Substitute: confinement, BertScore: 0.9695178866386414\n",
      "Substitute: detention, BertScore: 0.9694386124610901\n",
      "Substitute: racism, BertScore: 0.9670738577842712\n",
      "Substitute: control, BertScore: 0.9669686555862427\n",
      "Substitute: division, BertScore: 0.9665763974189758\n",
      "Substitute: union, BertScore: 0.965827226638794\n",
      "Substitute: custody, BertScore: 0.965202271938324\n",
      "Substitute: privilege, BertScore: 0.9647635817527771\n",
      "Substitute: safety, BertScore: 0.9644805788993835\n",
      "Substitute: seating, BertScore: 0.9635208249092102\n",
      "Substitute: censorship, BertScore: 0.9633120894432068\n",
      "Substitute: oversight, BertScore: 0.9632701277732849\n",
      "Substitute: boundary, BertScore: 0.9631189107894897\n",
      "Substitute: teaching, BertScore: 0.962356448173523\n",
      "Substitute: education, BertScore: 0.9611505270004272\n",
      "Substitute: justice, BertScore: 0.9606719017028809\n",
      "Substitute: district, BertScore: 0.960468590259552\n",
      "Substitute: liaison, BertScore: 0.9590529799461365\n",
      "Substitute: hearing, BertScore: 0.9571697115898132\n",
      "top-10 substitutes based on bertscores in context: ['segregated', 'isolation', 'integration', 'separation', 'minority', 'exclusion', 'discrimination', 'equality', 'classification', 'diversity']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: residence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: mansion, BertScore: 0.9901303052902222\n",
      "Substitute: dwelling, BertScore: 0.989425778388977\n",
      "Substitute: villa, BertScore: 0.9881962537765503\n",
      "Substitute: house, BertScore: 0.9880474805831909\n",
      "Substitute: home, BertScore: 0.9872028231620789\n",
      "Substitute: estate, BertScore: 0.9864384531974792\n",
      "Substitute: farmhouse, BertScore: 0.9854231476783752\n",
      "Substitute: apartment, BertScore: 0.9849683046340942\n",
      "Substitute: property, BertScore: 0.9839098453521729\n",
      "Substitute: building, BertScore: 0.9838768839836121\n",
      "Substitute: apartments, BertScore: 0.9834657311439514\n",
      "Substitute: household, BertScore: 0.9829631447792053\n",
      "Substitute: compound, BertScore: 0.9809063673019409\n",
      "Substitute: premises, BertScore: 0.9808270335197449\n",
      "Substitute: housing, BertScore: 0.9793617725372314\n",
      "Substitute: place, BertScore: 0.9793246984481812\n",
      "Substitute: facility, BertScore: 0.9776484966278076\n",
      "Substitute: office, BertScore: 0.9774249792098999\n",
      "Substitute: room, BertScore: 0.9749090671539307\n",
      "Substitute: palace, BertScore: 0.9742575883865356\n",
      "Substitute: bedroom, BertScore: 0.9739581942558289\n",
      "Substitute: street, BertScore: 0.9733286499977112\n",
      "Substitute: kitchen, BertScore: 0.9732115864753723\n",
      "Substitute: vehicle, BertScore: 0.9719082117080688\n",
      "Substitute: car, BertScore: 0.9710991978645325\n",
      "Substitute: family, BertScore: 0.9679083824157715\n",
      "Substitute: driveway, BertScore: 0.9676599502563477\n",
      "Substitute: present, BertScore: 0.9670257568359375\n",
      "top-10 substitutes based on bertscores in context: ['mansion', 'dwelling', 'villa', 'house', 'home', 'estate', 'farmhouse', 'apartment', 'property', 'building']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sanctions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: restrictions, BertScore: 0.9887394905090332\n",
      "Substitute: inspections, BertScore: 0.9846311807632446\n",
      "Substitute: penalties, BertScore: 0.9845831394195557\n",
      "Substitute: blockade, BertScore: 0.984015166759491\n",
      "Substitute: measures, BertScore: 0.982669472694397\n",
      "Substitute: pressure, BertScore: 0.9811897277832031\n",
      "Substitute: condemnation, BertScore: 0.979743242263794\n",
      "Substitute: veto, BertScore: 0.9777352809906006\n",
      "Substitute: controls, BertScore: 0.9777320623397827\n",
      "Substitute: rules, BertScore: 0.9773367047309875\n",
      "Substitute: authorities, BertScore: 0.9765753746032715\n",
      "Substitute: monitors, BertScore: 0.9753555655479431\n",
      "Substitute: critics, BertScore: 0.9748468399047852\n",
      "Substitute: allies, BertScore: 0.9703043699264526\n",
      "Substitute: countries, BertScore: 0.970081627368927\n",
      "Substitute: officials, BertScore: 0.9662070870399475\n",
      "Substitute: resolutions, BertScore: 0.9648693799972534\n",
      "Substitute: rejects, BertScore: 0.9641383290290833\n",
      "Substitute: leaders, BertScore: 0.9622348546981812\n",
      "Substitute: -, BertScore: 0.9609944820404053\n",
      "Substitute: resolution, BertScore: 0.9583712816238403\n",
      "Substitute: inspectors, BertScore: 0.9582551121711731\n",
      "Substitute: charges, BertScore: 0.9566419124603271\n",
      "Substitute: in, BertScore: 0.9565629363059998\n",
      "Substitute: and, BertScore: 0.9497306942939758\n",
      "Substitute: insists, BertScore: 0.9471921324729919\n",
      "Substitute: says, BertScore: 0.9468855857849121\n",
      "Substitute: said, BertScore: 0.9425117373466492\n",
      "top-10 substitutes based on bertscores in context: ['restrictions', 'inspections', 'penalties', 'blockade', 'measures', 'pressure', 'condemnation', 'veto', 'controls', 'rules']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: threatened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: harassed, BertScore: 0.990696370601654\n",
      "Substitute: insulted, BertScore: 0.9895541071891785\n",
      "Substitute: attacked, BertScore: 0.9894564747810364\n",
      "Substitute: assaulted, BertScore: 0.9892767667770386\n",
      "Substitute: challenged, BertScore: 0.9887257814407349\n",
      "Substitute: abused, BertScore: 0.9879544973373413\n",
      "Substitute: struck, BertScore: 0.9876978397369385\n",
      "Substitute: targeted, BertScore: 0.9876136183738708\n",
      "Substitute: violated, BertScore: 0.9875366687774658\n",
      "Substitute: humiliated, BertScore: 0.9868742823600769\n",
      "Substitute: stalked, BertScore: 0.9866467714309692\n",
      "Substitute: attempted, BertScore: 0.986543595790863\n",
      "Substitute: charged, BertScore: 0.9854164123535156\n",
      "Substitute: tortured, BertScore: 0.9851410984992981\n",
      "Substitute: raped, BertScore: 0.9851256608963013\n",
      "Substitute: breached, BertScore: 0.984636664390564\n",
      "Substitute: compromised, BertScore: 0.9845278859138489\n",
      "Substitute: protected, BertScore: 0.9837051630020142\n",
      "Substitute: flooded, BertScore: 0.9825302362442017\n",
      "Substitute: cursed, BertScore: 0.9823348522186279\n",
      "Substitute: overwhelmed, BertScore: 0.9822949171066284\n",
      "Substitute: besieged, BertScore: 0.9818626642227173\n",
      "Substitute: terrified, BertScore: 0.9804120659828186\n",
      "Substitute: threat, BertScore: 0.9797443747520447\n",
      "Substitute: battered, BertScore: 0.979291558265686\n",
      "Substitute: beaten, BertScore: 0.9791051149368286\n",
      "Substitute: vulnerable, BertScore: 0.9764257669448853\n",
      "top-10 substitutes based on bertscores in context: ['harassed', 'insulted', 'attacked', 'assaulted', 'challenged', 'abused', 'struck', 'targeted', 'violated', 'humiliated']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: intimidate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: provoke, BertScore: 0.9748013019561768\n",
      "Substitute: insult, BertScore: 0.9728143215179443\n",
      "Substitute: threaten, BertScore: 0.9724821448326111\n",
      "Substitute: manipulate, BertScore: 0.9721524715423584\n",
      "Substitute: disrupt, BertScore: 0.9717105627059937\n",
      "Substitute: influence, BertScore: 0.97166907787323\n",
      "Substitute: harm, BertScore: 0.9716301560401917\n",
      "Substitute: attack, BertScore: 0.9715912342071533\n",
      "Substitute: infiltrate, BertScore: 0.9705851674079895\n",
      "Substitute: interrupt, BertScore: 0.9703555107116699\n",
      "Substitute: deter, BertScore: 0.9702870845794678\n",
      "Substitute: undermine, BertScore: 0.9699029326438904\n",
      "Substitute: suppress, BertScore: 0.9690117835998535\n",
      "Substitute: poison, BertScore: 0.9686327576637268\n",
      "Substitute: sabotage, BertScore: 0.9682960510253906\n",
      "Substitute: punish, BertScore: 0.9682732820510864\n",
      "Substitute: weaken, BertScore: 0.967907726764679\n",
      "Substitute: kill, BertScore: 0.967208981513977\n",
      "Substitute: destroy, BertScore: 0.967140793800354\n",
      "Substitute: beat, BertScore: 0.9670015573501587\n",
      "Substitute: control, BertScore: 0.966945469379425\n",
      "Substitute: confuse, BertScore: 0.9669378399848938\n",
      "Substitute: break, BertScore: 0.9665876030921936\n",
      "Substitute: organize, BertScore: 0.9662383198738098\n",
      "Substitute: inform, BertScore: 0.9660853147506714\n",
      "Substitute: silence, BertScore: 0.9658384919166565\n",
      "Substitute: corrupt, BertScore: 0.9657987356185913\n",
      "Substitute: isolate, BertScore: 0.9655139446258545\n",
      "Substitute: evade, BertScore: 0.9651322960853577\n",
      "top-10 substitutes based on bertscores in context: ['provoke', 'insult', 'threaten', 'manipulate', 'disrupt', 'influence', 'harm', 'attack', 'infiltrate', 'interrupt']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sought\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: pursued, BertScore: 0.9946779608726501\n",
      "Substitute: contested, BertScore: 0.9936015009880066\n",
      "Substitute: obtained, BertScore: 0.993145227432251\n",
      "Substitute: received, BertScore: 0.9929800629615784\n",
      "Substitute: gained, BertScore: 0.9926459193229675\n",
      "Substitute: secured, BertScore: 0.9926400780677795\n",
      "Substitute: took, BertScore: 0.9924435019493103\n",
      "Substitute: won, BertScore: 0.9923499226570129\n",
      "Substitute: attempted, BertScore: 0.9922762513160706\n",
      "Substitute: accepted, BertScore: 0.9921891093254089\n",
      "Substitute: garnered, BertScore: 0.9919377565383911\n",
      "Substitute: claimed, BertScore: 0.9918649196624756\n",
      "Substitute: held, BertScore: 0.9917510151863098\n",
      "Substitute: earned, BertScore: 0.9911524057388306\n",
      "Substitute: got, BertScore: 0.9909379482269287\n",
      "Substitute: requested, BertScore: 0.9907404184341431\n",
      "Substitute: demanded, BertScore: 0.9906743764877319\n",
      "Substitute: challenged, BertScore: 0.99061119556427\n",
      "Substitute: wanted, BertScore: 0.9904293417930603\n",
      "Substitute: drew, BertScore: 0.9902551174163818\n",
      "Substitute: needed, BertScore: 0.9896425008773804\n",
      "Substitute: declined, BertScore: 0.9891168475151062\n",
      "Substitute: offered, BertScore: 0.986199676990509\n",
      "Substitute: found, BertScore: 0.9850234985351562\n",
      "Substitute: for, BertScore: 0.9839450716972351\n",
      "Substitute: asked, BertScore: 0.9831526875495911\n",
      "Substitute: denied, BertScore: 0.9816588759422302\n",
      "top-10 substitutes based on bertscores in context: ['pursued', 'contested', 'obtained', 'received', 'gained', 'secured', 'took', 'won', 'attempted', 'accepted']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: bureau\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: office, BertScore: 0.9958875179290771\n",
      "Substitute: department, BertScore: 0.9944792985916138\n",
      "Substitute: agency, BertScore: 0.994050145149231\n",
      "Substitute: committee, BertScore: 0.9939223527908325\n",
      "Substitute: unit, BertScore: 0.993732213973999\n",
      "Substitute: division, BertScore: 0.9936294555664062\n",
      "Substitute: board, BertScore: 0.9933114051818848\n",
      "Substitute: authority, BertScore: 0.9932695627212524\n",
      "Substitute: commission, BertScore: 0.9931033849716187\n",
      "Substitute: panel, BertScore: 0.9920544624328613\n",
      "Substitute: organization, BertScore: 0.9920083284378052\n",
      "Substitute: administration, BertScore: 0.9916618466377258\n",
      "Substitute: apparatus, BertScore: 0.9907411336898804\n",
      "Substitute: group, BertScore: 0.9905179738998413\n",
      "Substitute: team, BertScore: 0.9904632568359375\n",
      "Substitute: authorities, BertScore: 0.9899750351905823\n",
      "Substitute: party, BertScore: 0.9891930818557739\n",
      "Substitute: entity, BertScore: 0.9889582991600037\n",
      "Substitute: government, BertScore: 0.9889200329780579\n",
      "Substitute: police, BertScore: 0.9889189004898071\n",
      "Substitute: cabinet, BertScore: 0.9885225892066956\n",
      "Substitute: system, BertScore: 0.9874023199081421\n",
      "Substitute: bureaucracy, BertScore: 0.987375020980835\n",
      "Substitute: operation, BertScore: 0.9873466491699219\n",
      "Substitute: program, BertScore: 0.9870027303695679\n",
      "Substitute: law, BertScore: 0.9818713665008545\n",
      "Substitute: agenda, BertScore: 0.9816524386405945\n",
      "Substitute: regulation, BertScore: 0.9816514849662781\n",
      "Substitute: issue, BertScore: 0.9787465929985046\n",
      "top-10 substitutes based on bertscores in context: ['office', 'department', 'agency', 'committee', 'unit', 'division', 'board', 'authority', 'commission', 'panel']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: anonymity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: secrecy, BertScore: 0.9315558671951294\n",
      "Substitute: privacy, BertScore: 0.9260928630828857\n",
      "Substitute: silence, BertScore: 0.9215782880783081\n",
      "Substitute: safety, BertScore: 0.9131160974502563\n",
      "Substitute: security, BertScore: 0.9103507995605469\n",
      "Substitute: explanation, BertScore: 0.9073779582977295\n",
      "Substitute: clarity, BertScore: 0.9063689708709717\n",
      "Substitute: calm, BertScore: 0.9059435129165649\n",
      "Substitute: identity, BertScore: 0.9053495526313782\n",
      "Substitute: comment, BertScore: 0.9022917747497559\n",
      "Substitute: anonymous, BertScore: 0.9008560180664062\n",
      "Substitute: disbelief, BertScore: 0.8996375799179077\n",
      "Substitute: credit, BertScore: 0.8985313773155212\n",
      "Substitute: confidential, BertScore: 0.8983504772186279\n",
      "Substitute: release, BertScore: 0.898032546043396\n",
      "Substitute: advance, BertScore: 0.8953522443771362\n",
      "Substitute: writing, BertScore: 0.8952980041503906\n",
      "Substitute: speaking, BertScore: 0.8952719569206238\n",
      "Substitute: convenience, BertScore: 0.891941487789154\n",
      "Substitute: information, BertScore: 0.8886576890945435\n",
      "Substitute: location, BertScore: 0.8871467113494873\n",
      "Substitute: office, BertScore: 0.883927583694458\n",
      "Substitute: condition, BertScore: 0.8810936808586121\n",
      "Substitute: court, BertScore: 0.8781245946884155\n",
      "Substitute: attorney, BertScore: 0.8768032193183899\n",
      "Substitute: unknown, BertScore: 0.8755940198898315\n",
      "Substitute: state, BertScore: 0.868323564529419\n",
      "Substitute: such, BertScore: 0.8666351437568665\n",
      "top-10 substitutes based on bertscores in context: ['secrecy', 'privacy', 'silence', 'safety', 'security', 'explanation', 'clarity', 'calm', 'identity', 'comment']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: acclaimed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: proclaimed, BertScore: 0.994833767414093\n",
      "Substitute: elected, BertScore: 0.9948158264160156\n",
      "Substitute: crowned, BertScore: 0.9935530424118042\n",
      "Substitute: declared, BertScore: 0.9933022856712341\n",
      "Substitute: nominated, BertScore: 0.9932766556739807\n",
      "Substitute: hailed, BertScore: 0.9931830763816833\n",
      "Substitute: recognized, BertScore: 0.991986095905304\n",
      "Substitute: lauded, BertScore: 0.9912445545196533\n",
      "Substitute: elevated, BertScore: 0.9908807277679443\n",
      "Substitute: acknowledged, BertScore: 0.9907203912734985\n",
      "Substitute: appointed, BertScore: 0.9906517267227173\n",
      "Substitute: confirmed, BertScore: 0.9904223680496216\n",
      "Substitute: affirmed, BertScore: 0.9903076887130737\n",
      "Substitute: accepted, BertScore: 0.9891993999481201\n",
      "Substitute: recognised, BertScore: 0.9890741109848022\n",
      "Substitute: judged, BertScore: 0.9881539940834045\n",
      "Substitute: praised, BertScore: 0.9880005121231079\n",
      "Substitute: promoted, BertScore: 0.9869054555892944\n",
      "Substitute: commended, BertScore: 0.9843125343322754\n",
      "Substitute: recommended, BertScore: 0.9841809272766113\n",
      "Substitute: considered, BertScore: 0.9840694069862366\n",
      "Substitute: honored, BertScore: 0.9834415912628174\n",
      "Substitute: celebrated, BertScore: 0.9825835824012756\n",
      "Substitute: honoured, BertScore: 0.9821860790252686\n",
      "Substitute: upheld, BertScore: 0.9813961386680603\n",
      "Substitute: regarded, BertScore: 0.9811611175537109\n",
      "Substitute: revered, BertScore: 0.9798842668533325\n",
      "Substitute: respected, BertScore: 0.9788029789924622\n",
      "Substitute: beloved, BertScore: 0.9688097834587097\n",
      "top-10 substitutes based on bertscores in context: ['proclaimed', 'elected', 'crowned', 'declared', 'nominated', 'hailed', 'recognized', 'lauded', 'elevated', 'acknowledged']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: enquiries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: inquiries, BertScore: 0.9684719443321228\n",
      "Substitute: inquiry, BertScore: 0.9660657644271851\n",
      "Substitute: investigations, BertScore: 0.9629980325698853\n",
      "Substitute: investigation, BertScore: 0.9603947401046753\n",
      "Substitute: examination, BertScore: 0.9552090167999268\n",
      "Substitute: hearings, BertScore: 0.9540044069290161\n",
      "Substitute: proceedings, BertScore: 0.9538131952285767\n",
      "Substitute: review, BertScore: 0.9531519412994385\n",
      "Substitute: appeals, BertScore: 0.9522793292999268\n",
      "Substitute: questioning, BertScore: 0.9513446688652039\n",
      "Substitute: discovery, BertScore: 0.9493364095687866\n",
      "Substitute: consideration, BertScore: 0.9489619135856628\n",
      "Substitute: action, BertScore: 0.9488734006881714\n",
      "Substitute: negotiations, BertScore: 0.9488219022750854\n",
      "Substitute: appeal, BertScore: 0.9486349821090698\n",
      "Substitute: pleas, BertScore: 0.9483898282051086\n",
      "Substitute: hearing, BertScore: 0.9480597376823425\n",
      "Substitute: trials, BertScore: 0.9473079442977905\n",
      "Substitute: evidence, BertScore: 0.9465703368186951\n",
      "Substitute: arrests, BertScore: 0.9449103474617004\n",
      "Substitute: litigation, BertScore: 0.944685161113739\n",
      "Substitute: settlement, BertScore: 0.9446730613708496\n",
      "Substitute: prosecution, BertScore: 0.9445943236351013\n",
      "Substitute: processing, BertScore: 0.9445227384567261\n",
      "Substitute: charges, BertScore: 0.9416943192481995\n",
      "Substitute: trial, BertScore: 0.9406009912490845\n",
      "Substitute: convictions, BertScore: 0.9370658993721008\n",
      "Substitute: arrest, BertScore: 0.9360626935958862\n",
      "Substitute: cooperation, BertScore: 0.9345372915267944\n",
      "Substitute: detention, BertScore: 0.9344311952590942\n",
      "top-10 substitutes based on bertscores in context: ['inquiries', 'inquiry', 'investigations', 'investigation', 'examination', 'hearings', 'proceedings', 'review', 'appeals', 'questioning']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: commissioned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: appointed, BertScore: 0.9878193140029907\n",
      "Substitute: hired, BertScore: 0.9853078126907349\n",
      "Substitute: authorized, BertScore: 0.9815032482147217\n",
      "Substitute: ordered, BertScore: 0.9813110828399658\n",
      "Substitute: assigned, BertScore: 0.980908215045929\n",
      "Substitute: requested, BertScore: 0.9805130958557129\n",
      "Substitute: directed, BertScore: 0.9799398183822632\n",
      "Substitute: summoned, BertScore: 0.9799041152000427\n",
      "Substitute: commanded, BertScore: 0.9797595143318176\n",
      "Substitute: sent, BertScore: 0.979136049747467\n",
      "Substitute: asked, BertScore: 0.9790788888931274\n",
      "Substitute: required, BertScore: 0.9788415431976318\n",
      "Substitute: ordained, BertScore: 0.9781785011291504\n",
      "Substitute: compelled, BertScore: 0.9779269099235535\n",
      "Substitute: instructed, BertScore: 0.9770428538322449\n",
      "Substitute: prompted, BertScore: 0.9768360257148743\n",
      "Substitute: created, BertScore: 0.9764345288276672\n",
      "Substitute: empowered, BertScore: 0.9764063954353333\n",
      "Substitute: led, BertScore: 0.9739744663238525\n",
      "Substitute: wanted, BertScore: 0.9733140468597412\n",
      "Substitute: called, BertScore: 0.9729193449020386\n",
      "Substitute: orders, BertScore: 0.9722991585731506\n",
      "Substitute: inspired, BertScore: 0.9718703031539917\n",
      "Substitute: allowed, BertScore: 0.9717128276824951\n",
      "Substitute: trained, BertScore: 0.9706896543502808\n",
      "Substitute: encouraged, BertScore: 0.9704855680465698\n",
      "Substitute: caused, BertScore: 0.9703601002693176\n",
      "Substitute: told, BertScore: 0.9692788124084473\n",
      "Substitute: taught, BertScore: 0.9646872282028198\n",
      "top-10 substitutes based on bertscores in context: ['appointed', 'hired', 'authorized', 'ordered', 'assigned', 'requested', 'directed', 'summoned', 'commanded', 'sent']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: scrapped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: discarded, BertScore: 0.9944051504135132\n",
      "Substitute: abandoned, BertScore: 0.9925068616867065\n",
      "Substitute: cancelled, BertScore: 0.9924358129501343\n",
      "Substitute: withdrawn, BertScore: 0.9917427897453308\n",
      "Substitute: dropped, BertScore: 0.9914844036102295\n",
      "Substitute: canceled, BertScore: 0.9914134740829468\n",
      "Substitute: dismantled, BertScore: 0.9903321266174316\n",
      "Substitute: discontinued, BertScore: 0.9902329444885254\n",
      "Substitute: eliminated, BertScore: 0.9889183640480042\n",
      "Substitute: terminated, BertScore: 0.9882702827453613\n",
      "Substitute: dismissed, BertScore: 0.9882503747940063\n",
      "Substitute: removed, BertScore: 0.9878979921340942\n",
      "Substitute: rejected, BertScore: 0.986770510673523\n",
      "Substitute: abolished, BertScore: 0.9863071441650391\n",
      "Substitute: suspended, BertScore: 0.9861254692077637\n",
      "Substitute: postponed, BertScore: 0.9837458729743958\n",
      "Substitute: blocked, BertScore: 0.9834168553352356\n",
      "Substitute: demolished, BertScore: 0.98338782787323\n",
      "Substitute: banned, BertScore: 0.9818738698959351\n",
      "Substitute: delayed, BertScore: 0.980213463306427\n",
      "Substitute: modified, BertScore: 0.9796316623687744\n",
      "Substitute: reinstated, BertScore: 0.9773209095001221\n",
      "Substitute: completed, BertScore: 0.9753212332725525\n",
      "Substitute: revived, BertScore: 0.9745398163795471\n",
      "Substitute: implemented, BertScore: 0.9738997220993042\n",
      "Substitute: accepted, BertScore: 0.9736449718475342\n",
      "Substitute: approved, BertScore: 0.9724815487861633\n",
      "Substitute: replaced, BertScore: 0.9659094214439392\n",
      "Substitute: done, BertScore: 0.9654513001441956\n",
      "top-10 substitutes based on bertscores in context: ['discarded', 'abandoned', 'cancelled', 'withdrawn', 'dropped', 'canceled', 'dismantled', 'discontinued', 'eliminated', 'terminated']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: successive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: consecutive, BertScore: 0.9840589761734009\n",
      "Substitute: succeeding, BertScore: 0.9825506806373596\n",
      "Substitute: separate, BertScore: 0.9817680716514587\n",
      "Substitute: subsequent, BertScore: 0.9807612895965576\n",
      "Substitute: straight, BertScore: 0.9749834537506104\n",
      "Substitute: different, BertScore: 0.9744046926498413\n",
      "Substitute: distinct, BertScore: 0.9739922881126404\n",
      "Substitute: respective, BertScore: 0.9726325869560242\n",
      "Substitute: further, BertScore: 0.9701089859008789\n",
      "Substitute: preceding, BertScore: 0.9694684147834778\n",
      "Substitute: additional, BertScore: 0.968061089515686\n",
      "Substitute: particular, BertScore: 0.9635863304138184\n",
      "Substitute: previous, BertScore: 0.9619333744049072\n",
      "Substitute: other, BertScore: 0.9611073732376099\n",
      "Substitute: calendar, BertScore: 0.9602133631706238\n",
      "Substitute: official, BertScore: 0.9593021869659424\n",
      "Substitute: more, BertScore: 0.9590074419975281\n",
      "Substitute: earlier, BertScore: 0.9585734605789185\n",
      "Substitute: prior, BertScore: 0.9585587978363037\n",
      "Substitute: later, BertScore: 0.9584900736808777\n",
      "Substitute: appointed, BertScore: 0.9575620293617249\n",
      "Substitute: longer, BertScore: 0.9574812054634094\n",
      "Substitute: extra, BertScore: 0.956549882888794\n",
      "Substitute: full, BertScore: 0.9565377235412598\n",
      "Substitute: recent, BertScore: 0.9563843011856079\n",
      "Substitute: such, BertScore: 0.9544124603271484\n",
      "Substitute: final, BertScore: 0.9511032700538635\n",
      "Substitute: special, BertScore: 0.9481614232063293\n",
      "Substitute: new, BertScore: 0.9463751912117004\n",
      "top-10 substitutes based on bertscores in context: ['consecutive', 'succeeding', 'separate', 'subsequent', 'straight', 'different', 'distinct', 'respective', 'further', 'preceding']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: degenerate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: transform, BertScore: 0.9716741442680359\n",
      "Substitute: convert, BertScore: 0.9713069796562195\n",
      "Substitute: evolve, BertScore: 0.9704177379608154\n",
      "Substitute: develop, BertScore: 0.9701550602912903\n",
      "Substitute: transition, BertScore: 0.9693191051483154\n",
      "Substitute: turn, BertScore: 0.9687770009040833\n",
      "Substitute: mature, BertScore: 0.9685308933258057\n",
      "Substitute: blossom, BertScore: 0.9684563875198364\n",
      "Substitute: dissolve, BertScore: 0.9680228233337402\n",
      "Substitute: grow, BertScore: 0.9676938056945801\n",
      "Substitute: shift, BertScore: 0.9668450355529785\n",
      "Substitute: spiral, BertScore: 0.9666857719421387\n",
      "Substitute: reverse, BertScore: 0.9661324620246887\n",
      "Substitute: collapse, BertScore: 0.966116189956665\n",
      "Substitute: change, BertScore: 0.9658998250961304\n",
      "Substitute: explode, BertScore: 0.9656429290771484\n",
      "Substitute: descend, BertScore: 0.9653481245040894\n",
      "Substitute: fade, BertScore: 0.9632678031921387\n",
      "Substitute: become, BertScore: 0.9625300765037537\n",
      "Substitute: translate, BertScore: 0.9623702764511108\n",
      "Substitute: lead, BertScore: 0.9619395732879639\n",
      "Substitute: merge, BertScore: 0.9614390730857849\n",
      "Substitute: converge, BertScore: 0.9608265161514282\n",
      "Substitute: run, BertScore: 0.9603071212768555\n",
      "Substitute: rise, BertScore: 0.960206151008606\n",
      "Substitute: crash, BertScore: 0.9590532779693604\n",
      "Substitute: emerge, BertScore: 0.9588144421577454\n",
      "Substitute: slip, BertScore: 0.9587748646736145\n",
      "Substitute: fall, BertScore: 0.9561805725097656\n",
      "Substitute: go, BertScore: 0.9559846520423889\n",
      "top-10 substitutes based on bertscores in context: ['transform', 'convert', 'evolve', 'develop', 'transition', 'turn', 'mature', 'blossom', 'dissolve', 'grow']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: offender\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: accused, BertScore: 0.9893368482589722\n",
      "Substitute: inmate, BertScore: 0.9886273741722107\n",
      "Substitute: individual, BertScore: 0.9885914325714111\n",
      "Substitute: applicant, BertScore: 0.9885729551315308\n",
      "Substitute: attacker, BertScore: 0.9883338212966919\n",
      "Substitute: addict, BertScore: 0.9877261519432068\n",
      "Substitute: officer, BertScore: 0.9873965978622437\n",
      "Substitute: intruder, BertScore: 0.9873709678649902\n",
      "Substitute: adult, BertScore: 0.9873316287994385\n",
      "Substitute: associate, BertScore: 0.9854466915130615\n",
      "Substitute: adversary, BertScore: 0.9851955771446228\n",
      "Substitute: opponent, BertScore: 0.9851899743080139\n",
      "Substitute: offense, BertScore: 0.9851707220077515\n",
      "Substitute: innocent, BertScore: 0.9850077629089355\n",
      "Substitute: employee, BertScore: 0.9848147034645081\n",
      "Substitute: agent, BertScore: 0.9847729802131653\n",
      "Substitute: immigrant, BertScore: 0.9846060872077942\n",
      "Substitute: artist, BertScore: 0.9846044182777405\n",
      "Substitute: employer, BertScore: 0.9845607876777649\n",
      "Substitute: informant, BertScore: 0.9844881296157837\n",
      "Substitute: enemy, BertScore: 0.9838558435440063\n",
      "Substitute: offence, BertScore: 0.9834563732147217\n",
      "Substitute: assault, BertScore: 0.9827823042869568\n",
      "Substitute: attack, BertScore: 0.9824331998825073\n",
      "Substitute: act, BertScore: 0.9824057817459106\n",
      "Substitute: incident, BertScore: 0.9814916849136353\n",
      "Substitute: arrest, BertScore: 0.9811967611312866\n",
      "Substitute: accident, BertScore: 0.9800123572349548\n",
      "top-10 substitutes based on bertscores in context: ['accused', 'inmate', 'individual', 'applicant', 'attacker', 'addict', 'officer', 'intruder', 'adult', 'associate']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: touted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: highlighted, BertScore: 0.9741873741149902\n",
      "Substitute: mentioned, BertScore: 0.9734690189361572\n",
      "Substitute: blasted, BertScore: 0.9720950126647949\n",
      "Substitute: mocked, BertScore: 0.971081554889679\n",
      "Substitute: lauded, BertScore: 0.969576358795166\n",
      "Substitute: acknowledged, BertScore: 0.9695690870285034\n",
      "Substitute: described, BertScore: 0.9695302844047546\n",
      "Substitute: reiterated, BertScore: 0.9692507982254028\n",
      "Substitute: praised, BertScore: 0.9692176580429077\n",
      "Substitute: defended, BertScore: 0.9679464101791382\n",
      "Substitute: endorsed, BertScore: 0.9679136276245117\n",
      "Substitute: referenced, BertScore: 0.9674258232116699\n",
      "Substitute: denounced, BertScore: 0.9671369791030884\n",
      "Substitute: announced, BertScore: 0.9666486978530884\n",
      "Substitute: noted, BertScore: 0.9660643339157104\n",
      "Substitute: cited, BertScore: 0.9656740427017212\n",
      "Substitute: attacked, BertScore: 0.964356005191803\n",
      "Substitute: slammed, BertScore: 0.9641261100769043\n",
      "Substitute: criticized, BertScore: 0.9634650945663452\n",
      "Substitute: challenged, BertScore: 0.9630165100097656\n",
      "Substitute: questioned, BertScore: 0.9621231555938721\n",
      "Substitute: disputed, BertScore: 0.9609135985374451\n",
      "Substitute: condemned, BertScore: 0.9604334831237793\n",
      "Substitute: repeated, BertScore: 0.96031254529953\n",
      "Substitute: criticised, BertScore: 0.9596450328826904\n",
      "Substitute: echoed, BertScore: 0.9571704864501953\n",
      "Substitute: denied, BertScore: 0.954853892326355\n",
      "Substitute: rejected, BertScore: 0.9530302286148071\n",
      "Substitute: ignored, BertScore: 0.9462113380432129\n",
      "top-10 substitutes based on bertscores in context: ['highlighted', 'mentioned', 'blasted', 'mocked', 'lauded', 'acknowledged', 'described', 'reiterated', 'praised', 'defended']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: anonymity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: secrecy, BertScore: 0.9593497514724731\n",
      "Substitute: privacy, BertScore: 0.9579011797904968\n",
      "Substitute: silence, BertScore: 0.9544077515602112\n",
      "Substitute: safety, BertScore: 0.952099084854126\n",
      "Substitute: security, BertScore: 0.9513437747955322\n",
      "Substitute: clarity, BertScore: 0.9502853751182556\n",
      "Substitute: identity, BertScore: 0.9488942623138428\n",
      "Substitute: calm, BertScore: 0.9481605887413025\n",
      "Substitute: explanation, BertScore: 0.9464803338050842\n",
      "Substitute: comment, BertScore: 0.945838451385498\n",
      "Substitute: absence, BertScore: 0.9456806778907776\n",
      "Substitute: anonymous, BertScore: 0.9453901052474976\n",
      "Substitute: disbelief, BertScore: 0.9438304901123047\n",
      "Substitute: confidential, BertScore: 0.9427135586738586\n",
      "Substitute: information, BertScore: 0.9422277808189392\n",
      "Substitute: release, BertScore: 0.9402867555618286\n",
      "Substitute: speaking, BertScore: 0.9401728510856628\n",
      "Substitute: background, BertScore: 0.9379509687423706\n",
      "Substitute: location, BertScore: 0.9376441836357117\n",
      "Substitute: no, BertScore: 0.9363527894020081\n",
      "Substitute: death, BertScore: 0.935279130935669\n",
      "Substitute: condition, BertScore: 0.9352681040763855\n",
      "Substitute: undisclosed, BertScore: 0.9341804385185242\n",
      "Substitute: court, BertScore: 0.9332641363143921\n",
      "Substitute: state, BertScore: 0.9311063885688782\n",
      "Substitute: unknown, BertScore: 0.9310532808303833\n",
      "Substitute: amnesia, BertScore: 0.930031955242157\n",
      "Substitute: such, BertScore: 0.9282878041267395\n",
      "top-10 substitutes based on bertscores in context: ['secrecy', 'privacy', 'silence', 'safety', 'security', 'clarity', 'identity', 'calm', 'explanation', 'comment']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: purifying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: cleansing, BertScore: 0.9560036659240723\n",
      "Substitute: transforming, BertScore: 0.9559087753295898\n",
      "Substitute: strengthening, BertScore: 0.9548169374465942\n",
      "Substitute: washing, BertScore: 0.9532832503318787\n",
      "Substitute: refining, BertScore: 0.9532414674758911\n",
      "Substitute: preserving, BertScore: 0.9522157907485962\n",
      "Substitute: filling, BertScore: 0.9521291851997375\n",
      "Substitute: restoring, BertScore: 0.9521064758300781\n",
      "Substitute: healing, BertScore: 0.9515520930290222\n",
      "Substitute: improving, BertScore: 0.9506877660751343\n",
      "Substitute: loving, BertScore: 0.9506123065948486\n",
      "Substitute: controlling, BertScore: 0.9501517415046692\n",
      "Substitute: exercising, BertScore: 0.9497159719467163\n",
      "Substitute: altering, BertScore: 0.9496109485626221\n",
      "Substitute: maintaining, BertScore: 0.9495439529418945\n",
      "Substitute: burning, BertScore: 0.9494797587394714\n",
      "Substitute: destroying, BertScore: 0.9493154287338257\n",
      "Substitute: creating, BertScore: 0.9492521286010742\n",
      "Substitute: influencing, BertScore: 0.9492190480232239\n",
      "Substitute: protecting, BertScore: 0.9486722946166992\n",
      "Substitute: raising, BertScore: 0.9485536813735962\n",
      "Substitute: examining, BertScore: 0.9482453465461731\n",
      "Substitute: revealing, BertScore: 0.9480983018875122\n",
      "Substitute: studying, BertScore: 0.9479472041130066\n",
      "Substitute: fulfilling, BertScore: 0.9478070735931396\n",
      "Substitute: killing, BertScore: 0.9471070170402527\n",
      "Substitute: replacing, BertScore: 0.9466648101806641\n",
      "Substitute: changing, BertScore: 0.9461207985877991\n",
      "Substitute: invading, BertScore: 0.944686233997345\n",
      "top-10 substitutes based on bertscores in context: ['cleansing', 'transforming', 'strengthening', 'washing', 'refining', 'preserving', 'filling', 'restoring', 'healing', 'improving']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: announced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: confirmed, BertScore: 0.9941933751106262\n",
      "Substitute: disclosed, BertScore: 0.9918324947357178\n",
      "Substitute: revealed, BertScore: 0.9916989803314209\n",
      "Substitute: reported, BertScore: 0.9894888997077942\n",
      "Substitute: unveiled, BertScore: 0.988858699798584\n",
      "Substitute: claimed, BertScore: 0.9886865615844727\n",
      "Substitute: indicated, BertScore: 0.9885175228118896\n",
      "Substitute: declared, BertScore: 0.9884204864501953\n",
      "Substitute: stated, BertScore: 0.9881027936935425\n",
      "Substitute: admitted, BertScore: 0.9877413511276245\n",
      "Substitute: acknowledged, BertScore: 0.9856781959533691\n",
      "Substitute: approved, BertScore: 0.9853959083557129\n",
      "Substitute: insisted, BertScore: 0.9841986894607544\n",
      "Substitute: proposed, BertScore: 0.9840149879455566\n",
      "Substitute: demanded, BertScore: 0.9824470281600952\n",
      "Substitute: finalized, BertScore: 0.9818214178085327\n",
      "Substitute: suggested, BertScore: 0.981765866279602\n",
      "Substitute: assured, BertScore: 0.9811152815818787\n",
      "Substitute: added, BertScore: 0.9802185893058777\n",
      "Substitute: mentioned, BertScore: 0.9795961380004883\n",
      "Substitute: said, BertScore: 0.9789920449256897\n",
      "Substitute: notified, BertScore: 0.9783922433853149\n",
      "Substitute: seen, BertScore: 0.9761654734611511\n",
      "Substitute: informed, BertScore: 0.9753111600875854\n",
      "Substitute: advised, BertScore: 0.9747934937477112\n",
      "Substitute: denied, BertScore: 0.9742097854614258\n",
      "Substitute: told, BertScore: 0.9723100066184998\n",
      "top-10 substitutes based on bertscores in context: ['confirmed', 'disclosed', 'revealed', 'reported', 'unveiled', 'claimed', 'indicated', 'declared', 'stated', 'admitted']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: residing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: living, BertScore: 0.9894770383834839\n",
      "Substitute: lived, BertScore: 0.9845208525657654\n",
      "Substitute: located, BertScore: 0.9838672280311584\n",
      "Substitute: resident, BertScore: 0.9821999669075012\n",
      "Substitute: housing, BertScore: 0.9793900847434998\n",
      "Substitute: operating, BertScore: 0.972825288772583\n",
      "Substitute: spread, BertScore: 0.9719254970550537\n",
      "Substitute: settled, BertScore: 0.9715320467948914\n",
      "Substitute: alone, BertScore: 0.9714173078536987\n",
      "Substitute: present, BertScore: 0.9711909294128418\n",
      "Substitute: out, BertScore: 0.968014121055603\n",
      "Substitute: units, BertScore: 0.9667328000068665\n",
      "Substitute: incorporated, BertScore: 0.9665597677230835\n",
      "Substitute: dwelling, BertScore: 0.9664745926856995\n",
      "Substitute: growing, BertScore: 0.9661988019943237\n",
      "Substitute: available, BertScore: 0.9659264087677002\n",
      "Substitute: together, BertScore: 0.96434485912323\n",
      "Substitute: organized, BertScore: 0.9640711545944214\n",
      "Substitute: married, BertScore: 0.9623151421546936\n",
      "Substitute: staying, BertScore: 0.9614865779876709\n",
      "Substitute: still, BertScore: 0.9606876373291016\n",
      "Substitute: active, BertScore: 0.9592677354812622\n",
      "Substitute: employed, BertScore: 0.9584906697273254\n",
      "Substitute: engaged, BertScore: 0.9570441246032715\n",
      "Substitute: working, BertScore: 0.9566638469696045\n",
      "Substitute: elsewhere, BertScore: 0.952863335609436\n",
      "Substitute: permanently, BertScore: 0.9522038102149963\n",
      "top-10 substitutes based on bertscores in context: ['living', 'lived', 'located', 'resident', 'housing', 'operating', 'spread', 'settled', 'alone', 'present']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: plundering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: looting, BertScore: 0.9710039496421814\n",
      "Substitute: occupying, BertScore: 0.9689565896987915\n",
      "Substitute: stealing, BertScore: 0.9685088396072388\n",
      "Substitute: seizing, BertScore: 0.9684816598892212\n",
      "Substitute: consuming, BertScore: 0.9684678912162781\n",
      "Substitute: capturing, BertScore: 0.96821528673172\n",
      "Substitute: burning, BertScore: 0.9670963287353516\n",
      "Substitute: destroying, BertScore: 0.9670118689537048\n",
      "Substitute: smashing, BertScore: 0.9662514328956604\n",
      "Substitute: mining, BertScore: 0.965796709060669\n",
      "Substitute: stripping, BertScore: 0.964820384979248\n",
      "Substitute: damaging, BertScore: 0.9646152257919312\n",
      "Substitute: distributing, BertScore: 0.9645868539810181\n",
      "Substitute: killing, BertScore: 0.9644163250923157\n",
      "Substitute: breaking, BertScore: 0.9643538594245911\n",
      "Substitute: processing, BertScore: 0.9636548757553101\n",
      "Substitute: collecting, BertScore: 0.9632977247238159\n",
      "Substitute: releasing, BertScore: 0.9632329344749451\n",
      "Substitute: removing, BertScore: 0.9631688594818115\n",
      "Substitute: burying, BertScore: 0.9630193710327148\n",
      "Substitute: sealing, BertScore: 0.9626995325088501\n",
      "Substitute: painting, BertScore: 0.9625424146652222\n",
      "Substitute: selling, BertScore: 0.9624164700508118\n",
      "Substitute: storing, BertScore: 0.9623223543167114\n",
      "Substitute: dumping, BertScore: 0.9620703458786011\n",
      "Substitute: restoring, BertScore: 0.9611878991127014\n",
      "Substitute: shipping, BertScore: 0.9604348540306091\n",
      "Substitute: transporting, BertScore: 0.9604300260543823\n",
      "Substitute: manufacturing, BertScore: 0.9601457118988037\n",
      "Substitute: preserving, BertScore: 0.9587169289588928\n",
      "top-10 substitutes based on bertscores in context: ['looting', 'occupying', 'stealing', 'seizing', 'consuming', 'capturing', 'burning', 'destroying', 'smashing', 'mining']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: clemency\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: probation, BertScore: 0.9635616540908813\n",
      "Substitute: immunity, BertScore: 0.9635477066040039\n",
      "Substitute: relief, BertScore: 0.963442325592041\n",
      "Substitute: pardon, BertScore: 0.9633581638336182\n",
      "Substitute: amnesty, BertScore: 0.9629219770431519\n",
      "Substitute: parole, BertScore: 0.9626196622848511\n",
      "Substitute: protection, BertScore: 0.9623784422874451\n",
      "Substitute: suspension, BertScore: 0.9623578190803528\n",
      "Substitute: imprisonment, BertScore: 0.9623234272003174\n",
      "Substitute: bail, BertScore: 0.9622223377227783\n",
      "Substitute: conviction, BertScore: 0.9614387154579163\n",
      "Substitute: exemption, BertScore: 0.9613866806030273\n",
      "Substitute: asylum, BertScore: 0.9602648019790649\n",
      "Substitute: justice, BertScore: 0.9597055315971375\n",
      "Substitute: residency, BertScore: 0.9594376087188721\n",
      "Substitute: detention, BertScore: 0.9592716693878174\n",
      "Substitute: custody, BertScore: 0.9588978886604309\n",
      "Substitute: privilege, BertScore: 0.9586613774299622\n",
      "Substitute: power, BertScore: 0.9585870504379272\n",
      "Substitute: consent, BertScore: 0.9582313895225525\n",
      "Substitute: membership, BertScore: 0.9580500721931458\n",
      "Substitute: permission, BertScore: 0.9580070376396179\n",
      "Substitute: duty, BertScore: 0.9577585458755493\n",
      "Substitute: id, BertScore: 0.9572415947914124\n",
      "Substitute: citizenship, BertScore: 0.957085907459259\n",
      "Substitute: this, BertScore: 0.9552209973335266\n",
      "Substitute: it, BertScore: 0.9537226557731628\n",
      "Substitute: that, BertScore: 0.949009895324707\n",
      "top-10 substitutes based on bertscores in context: ['probation', 'immunity', 'relief', 'pardon', 'amnesty', 'parole', 'protection', 'suspension', 'imprisonment', 'bail']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: enduring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: lasting, BertScore: 0.9963476061820984\n",
      "Substitute: persistent, BertScore: 0.9935299158096313\n",
      "Substitute: compelling, BertScore: 0.9926354885101318\n",
      "Substitute: ongoing, BertScore: 0.9923925399780273\n",
      "Substitute: substantial, BertScore: 0.9916062951087952\n",
      "Substitute: significant, BertScore: 0.991496205329895\n",
      "Substitute: sustained, BertScore: 0.9910022616386414\n",
      "Substitute: effective, BertScore: 0.990782618522644\n",
      "Substitute: active, BertScore: 0.990403413772583\n",
      "Substitute: intrinsic, BertScore: 0.9903181195259094\n",
      "Substitute: outstanding, BertScore: 0.9901846051216125\n",
      "Substitute: valuable, BertScore: 0.990031361579895\n",
      "Substitute: continued, BertScore: 0.9898461103439331\n",
      "Substitute: inherent, BertScore: 0.9897896647453308\n",
      "Substitute: absolute, BertScore: 0.9896630644798279\n",
      "Substitute: timeless, BertScore: 0.9894878268241882\n",
      "Substitute: striking, BertScore: 0.9894580841064453\n",
      "Substitute: true, BertScore: 0.9888020753860474\n",
      "Substitute: tremendous, BertScore: 0.9885196685791016\n",
      "Substitute: lifetime, BertScore: 0.9884978532791138\n",
      "Substitute: residual, BertScore: 0.9883050918579102\n",
      "Substitute: some, BertScore: 0.9875882863998413\n",
      "Substitute: a, BertScore: 0.9867274761199951\n",
      "Substitute: accumulated, BertScore: 0.9865991473197937\n",
      "Substitute: life, BertScore: 0.9846397042274475\n",
      "Substitute: accepted, BertScore: 0.9813539385795593\n",
      "Substitute: the, BertScore: 0.9795311093330383\n",
      "Substitute: their, BertScore: 0.9791772961616516\n",
      "top-10 substitutes based on bertscores in context: ['lasting', 'persistent', 'compelling', 'ongoing', 'substantial', 'significant', 'sustained', 'effective', 'active', 'intrinsic']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sanctuary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: refuge, BertScore: 0.9957072138786316\n",
      "Substitute: shelter, BertScore: 0.9942764639854431\n",
      "Substitute: habitat, BertScore: 0.9918912649154663\n",
      "Substitute: home, BertScore: 0.9910989999771118\n",
      "Substitute: haven, BertScore: 0.9910498857498169\n",
      "Substitute: hideout, BertScore: 0.9906494617462158\n",
      "Substitute: stronghold, BertScore: 0.9900919198989868\n",
      "Substitute: base, BertScore: 0.989995002746582\n",
      "Substitute: protection, BertScore: 0.9892801642417908\n",
      "Substitute: homeland, BertScore: 0.9888113737106323\n",
      "Substitute: asylum, BertScore: 0.9886758923530579\n",
      "Substitute: mecca, BertScore: 0.9881402254104614\n",
      "Substitute: destination, BertScore: 0.9873136281967163\n",
      "Substitute: prison, BertScore: 0.9871793389320374\n",
      "Substitute: place, BertScore: 0.9860836863517761\n",
      "Substitute: paradise, BertScore: 0.9859878420829773\n",
      "Substitute: space, BertScore: 0.9855017066001892\n",
      "Substitute: retreat, BertScore: 0.9853680729866028\n",
      "Substitute: center, BertScore: 0.9852285385131836\n",
      "Substitute: house, BertScore: 0.9850897789001465\n",
      "Substitute: hospital, BertScore: 0.9847539663314819\n",
      "Substitute: wilderness, BertScore: 0.9841082096099854\n",
      "Substitute: realm, BertScore: 0.9834520816802979\n",
      "Substitute: land, BertScore: 0.982416033744812\n",
      "Substitute: city, BertScore: 0.981486439704895\n",
      "Substitute: jail, BertScore: 0.9814838767051697\n",
      "Substitute: world, BertScore: 0.9758731126785278\n",
      "Substitute: life, BertScore: 0.9758361577987671\n",
      "Substitute: nightmare, BertScore: 0.9757294654846191\n",
      "top-10 substitutes based on bertscores in context: ['refuge', 'shelter', 'habitat', 'home', 'haven', 'hideout', 'stronghold', 'base', 'protection', 'homeland']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: demonstrations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: protests, BertScore: 0.9981940388679504\n",
      "Substitute: marches, BertScore: 0.9943076372146606\n",
      "Substitute: protest, BertScore: 0.9942877888679504\n",
      "Substitute: riots, BertScore: 0.9938213229179382\n",
      "Substitute: parades, BertScore: 0.9937410354614258\n",
      "Substitute: rallies, BertScore: 0.9935884475708008\n",
      "Substitute: events, BertScore: 0.9932788014411926\n",
      "Substitute: meetings, BertScore: 0.9926234483718872\n",
      "Substitute: celebrations, BertScore: 0.9924555420875549\n",
      "Substitute: clashes, BertScore: 0.9923722147941589\n",
      "Substitute: struggles, BertScore: 0.9923141002655029\n",
      "Substitute: incidents, BertScore: 0.9920817017555237\n",
      "Substitute: gatherings, BertScore: 0.9917769432067871\n",
      "Substitute: actions, BertScore: 0.9910621643066406\n",
      "Substitute: activities, BertScore: 0.9910542368888855\n",
      "Substitute: elections, BertScore: 0.9908192157745361\n",
      "Substitute: campaigns, BertScore: 0.9905980825424194\n",
      "Substitute: speeches, BertScore: 0.9900417327880859\n",
      "Substitute: concerts, BertScore: 0.9899929761886597\n",
      "Substitute: action, BertScore: 0.9892961382865906\n",
      "Substitute: activism, BertScore: 0.9892427921295166\n",
      "Substitute: rally, BertScore: 0.9886252284049988\n",
      "Substitute: movements, BertScore: 0.9885463118553162\n",
      "Substitute: shows, BertScore: 0.9874740839004517\n",
      "Substitute: groups, BertScore: 0.9857779741287231\n",
      "Substitute: parties, BertScore: 0.985196053981781\n",
      "Substitute: movement, BertScore: 0.9851059913635254\n",
      "top-10 substitutes based on bertscores in context: ['protests', 'marches', 'protest', 'riots', 'parades', 'rallies', 'events', 'meetings', 'celebrations', 'clashes']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: allege\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: accuse, BertScore: 0.9773784875869751\n",
      "Substitute: assert, BertScore: 0.9766199588775635\n",
      "Substitute: charge, BertScore: 0.9750349521636963\n",
      "Substitute: claim, BertScore: 0.9748436212539673\n",
      "Substitute: report, BertScore: 0.9714422225952148\n",
      "Substitute: acknowledge, BertScore: 0.9709221124649048\n",
      "Substitute: expose, BertScore: 0.9708958864212036\n",
      "Substitute: advocate, BertScore: 0.9704754948616028\n",
      "Substitute: admit, BertScore: 0.9686977863311768\n",
      "Substitute: recognize, BertScore: 0.967112123966217\n",
      "Substitute: condemn, BertScore: 0.9668684601783752\n",
      "Substitute: suspect, BertScore: 0.9666839838027954\n",
      "Substitute: oppose, BertScore: 0.9658365249633789\n",
      "Substitute: urge, BertScore: 0.9657481908798218\n",
      "Substitute: admitted, BertScore: 0.964199423789978\n",
      "Substitute: pursue, BertScore: 0.9641069173812866\n",
      "Substitute: demand, BertScore: 0.9633762240409851\n",
      "Substitute: denies, BertScore: 0.9621804356575012\n",
      "Substitute: investigate, BertScore: 0.9618751406669617\n",
      "Substitute: deny, BertScore: 0.9613499641418457\n",
      "Substitute: commit, BertScore: 0.9606678485870361\n",
      "Substitute: promote, BertScore: 0.9605960845947266\n",
      "Substitute: institute, BertScore: 0.959822416305542\n",
      "Substitute: tolerate, BertScore: 0.9585694074630737\n",
      "Substitute: encourage, BertScore: 0.9563466906547546\n",
      "Substitute: commits, BertScore: 0.9550839066505432\n",
      "Substitute: committed, BertScore: 0.9491291046142578\n",
      "top-10 substitutes based on bertscores in context: ['accuse', 'assert', 'charge', 'claim', 'report', 'acknowledge', 'expose', 'advocate', 'admit', 'recognize']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: unsanctioned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: unauthorized, BertScore: 0.9390909671783447\n",
      "Substitute: abandoned, BertScore: 0.9378135800361633\n",
      "Substitute: open, BertScore: 0.9372560977935791\n",
      "Substitute: unofficial, BertScore: 0.9372143149375916\n",
      "Substitute: isolated, BertScore: 0.9366395473480225\n",
      "Substitute: empty, BertScore: 0.9363113045692444\n",
      "Substitute: unarmed, BertScore: 0.9362463355064392\n",
      "Substitute: impromptu, BertScore: 0.9361605048179626\n",
      "Substitute: organized, BertScore: 0.9360294938087463\n",
      "Substitute: unsuccessful, BertScore: 0.935385525226593\n",
      "Substitute: outside, BertScore: 0.9352654814720154\n",
      "Substitute: armed, BertScore: 0.9351436495780945\n",
      "Substitute: independent, BertScore: 0.9347383975982666\n",
      "Substitute: official, BertScore: 0.9344956278800964\n",
      "Substitute: illegal, BertScore: 0.9343781471252441\n",
      "Substitute: emergency, BertScore: 0.9341803193092346\n",
      "Substitute: unlawful, BertScore: 0.9341399669647217\n",
      "Substitute: angry, BertScore: 0.9338273406028748\n",
      "Substitute: evening, BertScore: 0.9337784051895142\n",
      "Substitute: underground, BertScore: 0.9337381720542908\n",
      "Substitute: overnight, BertScore: 0.9334996938705444\n",
      "Substitute: ongoing, BertScore: 0.9334229826927185\n",
      "Substitute: outdoor, BertScore: 0.9329157471656799\n",
      "Substitute: attempted, BertScore: 0.9327840209007263\n",
      "Substitute: alleged, BertScore: 0.9323594570159912\n",
      "Substitute: international, BertScore: 0.9308522939682007\n",
      "Substitute: annual, BertScore: 0.9302948117256165\n",
      "Substitute: opposition, BertScore: 0.9291160702705383\n",
      "Substitute: anarchist, BertScore: 0.9290893077850342\n",
      "Substitute: army, BertScore: 0.927979588508606\n",
      "top-10 substitutes based on bertscores in context: ['unauthorized', 'abandoned', 'open', 'unofficial', 'isolated', 'empty', 'unarmed', 'impromptu', 'organized', 'unsuccessful']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: bloodshed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: carnage, BertScore: 0.9763914346694946\n",
      "Substitute: fighting, BertScore: 0.9755374789237976\n",
      "Substitute: chaos, BertScore: 0.9720184206962585\n",
      "Substitute: violence, BertScore: 0.9711627960205078\n",
      "Substitute: devastation, BertScore: 0.9708517789840698\n",
      "Substitute: slaughter, BertScore: 0.9688384532928467\n",
      "Substitute: casualties, BertScore: 0.9685337543487549\n",
      "Substitute: conflict, BertScore: 0.967488706111908\n",
      "Substitute: unrest, BertScore: 0.9654785394668579\n",
      "Substitute: clashes, BertScore: 0.9644233584403992\n",
      "Substitute: destruction, BertScore: 0.9640892148017883\n",
      "Substitute: looting, BertScore: 0.9636496901512146\n",
      "Substitute: atrocities, BertScore: 0.9608098864555359\n",
      "Substitute: tragedy, BertScore: 0.9606143236160278\n",
      "Substitute: crisis, BertScore: 0.9605842232704163\n",
      "Substitute: disaster, BertScore: 0.9596890211105347\n",
      "Substitute: events, BertScore: 0.9594160318374634\n",
      "Substitute: massacre, BertScore: 0.9588483572006226\n",
      "Substitute: situation, BertScore: 0.958409309387207\n",
      "Substitute: riots, BertScore: 0.9581445455551147\n",
      "Substitute: killings, BertScore: 0.9576413035392761\n",
      "Substitute: genocide, BertScore: 0.9570668935775757\n",
      "Substitute: deaths, BertScore: 0.9566566944122314\n",
      "Substitute: killing, BertScore: 0.954588770866394\n",
      "Substitute: attacks, BertScore: 0.9539216756820679\n",
      "Substitute: famine, BertScore: 0.9535809755325317\n",
      "Substitute: incident, BertScore: 0.9535307288169861\n",
      "Substitute: war, BertScore: 0.9525632262229919\n",
      "Substitute: attack, BertScore: 0.9505414962768555\n",
      "Substitute: assault, BertScore: 0.9414699077606201\n",
      "top-10 substitutes based on bertscores in context: ['carnage', 'fighting', 'chaos', 'violence', 'devastation', 'slaughter', 'casualties', 'conflict', 'unrest', 'clashes']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: adversary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: foe, BertScore: 0.9975177049636841\n",
      "Substitute: enemy, BertScore: 0.9971325397491455\n",
      "Substitute: opponent, BertScore: 0.9961673021316528\n",
      "Substitute: antagonist, BertScore: 0.9957808256149292\n",
      "Substitute: ally, BertScore: 0.9954604506492615\n",
      "Substitute: attacker, BertScore: 0.9934530258178711\n",
      "Substitute: intruder, BertScore: 0.9922550320625305\n",
      "Substitute: asset, BertScore: 0.991927981376648\n",
      "Substitute: authority, BertScore: 0.9916085600852966\n",
      "Substitute: outsider, BertScore: 0.9914935827255249\n",
      "Substitute: obstacle, BertScore: 0.9911906719207764\n",
      "Substitute: agent, BertScore: 0.99104243516922\n",
      "Substitute: assassin, BertScore: 0.9908720254898071\n",
      "Substitute: alien, BertScore: 0.990561842918396\n",
      "Substitute: object, BertScore: 0.9905041456222534\n",
      "Substitute: advisor, BertScore: 0.9903430938720703\n",
      "Substitute: opposing, BertScore: 0.9901509881019592\n",
      "Substitute: employer, BertScore: 0.9900912046432495\n",
      "Substitute: individual, BertScore: 0.9900889992713928\n",
      "Substitute: incumbent, BertScore: 0.9897872805595398\n",
      "Substitute: organization, BertScore: 0.9897754192352295\n",
      "Substitute: adviser, BertScore: 0.9897569417953491\n",
      "Substitute: alternative, BertScore: 0.9896677732467651\n",
      "Substitute: opposition, BertScore: 0.9896023273468018\n",
      "Substitute: expert, BertScore: 0.9894304275512695\n",
      "Substitute: advocate, BertScore: 0.98935866355896\n",
      "Substitute: army, BertScore: 0.9889254570007324\n",
      "Substitute: observer, BertScore: 0.9877457022666931\n",
      "Substitute: attack, BertScore: 0.9838489294052124\n",
      "top-10 substitutes based on bertscores in context: ['foe', 'enemy', 'opponent', 'antagonist', 'ally', 'attacker', 'intruder', 'asset', 'authority', 'outsider']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: alleged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: suspected, BertScore: 0.9968423843383789\n",
      "Substitute: purported, BertScore: 0.9968223571777344\n",
      "Substitute: allegedly, BertScore: 0.99587082862854\n",
      "Substitute: apparent, BertScore: 0.9949913024902344\n",
      "Substitute: reported, BertScore: 0.9935641884803772\n",
      "Substitute: attempted, BertScore: 0.9931111931800842\n",
      "Substitute: possible, BertScore: 0.9914558529853821\n",
      "Substitute: suspect, BertScore: 0.9912194013595581\n",
      "Substitute: unlawful, BertScore: 0.9902703762054443\n",
      "Substitute: illegal, BertScore: 0.9901959896087646\n",
      "Substitute: potential, BertScore: 0.9901956915855408\n",
      "Substitute: ongoing, BertScore: 0.9899724721908569\n",
      "Substitute: repeated, BertScore: 0.9896035194396973\n",
      "Substitute: disputed, BertScore: 0.9894354939460754\n",
      "Substitute: widespread, BertScore: 0.988893449306488\n",
      "Substitute: fraudulent, BertScore: 0.9881009459495544\n",
      "Substitute: rampant, BertScore: 0.9880989193916321\n",
      "Substitute: false, BertScore: 0.9875524044036865\n",
      "Substitute: fake, BertScore: 0.9873520731925964\n",
      "Substitute: massive, BertScore: 0.9872972369194031\n",
      "Substitute: recent, BertScore: 0.9872069358825684\n",
      "Substitute: the, BertScore: 0.9867942333221436\n",
      "Substitute: actual, BertScore: 0.9865636825561523\n",
      "Substitute: official, BertScore: 0.9862093329429626\n",
      "Substitute: rigged, BertScore: 0.9850395917892456\n",
      "Substitute: new, BertScore: 0.9850361347198486\n",
      "Substitute: an, BertScore: 0.9836384654045105\n",
      "Substitute: such, BertScore: 0.9819921255111694\n",
      "top-10 substitutes based on bertscores in context: ['suspected', 'purported', 'allegedly', 'apparent', 'reported', 'attempted', 'possible', 'suspect', 'unlawful', 'illegal']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: enigmatic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: mysterious, BertScore: 0.9791011810302734\n",
      "Substitute: enigma, BertScore: 0.9780534505844116\n",
      "Substitute: cryptic, BertScore: 0.9759857654571533\n",
      "Substitute: ambiguous, BertScore: 0.9739159345626831\n",
      "Substitute: obscure, BertScore: 0.972809910774231\n",
      "Substitute: static, BertScore: 0.9716506004333496\n",
      "Substitute: intriguing, BertScore: 0.9709317088127136\n",
      "Substitute: exotic, BertScore: 0.9708039164543152\n",
      "Substitute: elusive, BertScore: 0.9703949689865112\n",
      "Substitute: unusual, BertScore: 0.9678609371185303\n",
      "Substitute: eclectic, BertScore: 0.9671134948730469\n",
      "Substitute: eerie, BertScore: 0.9667955636978149\n",
      "Substitute: primitive, BertScore: 0.966511607170105\n",
      "Substitute: eccentric, BertScore: 0.9662063121795654\n",
      "Substitute: complex, BertScore: 0.9661032557487488\n",
      "Substitute: uncanny, BertScore: 0.9656499624252319\n",
      "Substitute: unknown, BertScore: 0.9656412601470947\n",
      "Substitute: incomplete, BertScore: 0.9637436270713806\n",
      "Substitute: rare, BertScore: 0.9634676575660706\n",
      "Substitute: simple, BertScore: 0.9630126357078552\n",
      "Substitute: elegant, BertScore: 0.9629429578781128\n",
      "Substitute: unmarked, BertScore: 0.9625630974769592\n",
      "Substitute: intuitive, BertScore: 0.9617140293121338\n",
      "Substitute: opaque, BertScore: 0.9616946578025818\n",
      "Substitute: oblique, BertScore: 0.9615620374679565\n",
      "Substitute: distant, BertScore: 0.9611008167266846\n",
      "Substitute: solitary, BertScore: 0.960231363773346\n",
      "Substitute: straightforward, BertScore: 0.9589703679084778\n",
      "Substitute: distinguished, BertScore: 0.9566985368728638\n",
      "Substitute: spectral, BertScore: 0.9473108649253845\n",
      "top-10 substitutes based on bertscores in context: ['mysterious', 'enigma', 'cryptic', 'ambiguous', 'obscure', 'static', 'intriguing', 'exotic', 'elusive', 'unusual']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: renderings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: sketches, BertScore: 0.9809216856956482\n",
      "Substitute: depictions, BertScore: 0.980750560760498\n",
      "Substitute: drawings, BertScore: 0.9789935946464539\n",
      "Substitute: rendering, BertScore: 0.9769191741943359\n",
      "Substitute: images, BertScore: 0.9762281775474548\n",
      "Substitute: views, BertScore: 0.9748358726501465\n",
      "Substitute: graphics, BertScore: 0.9722034931182861\n",
      "Substitute: simulations, BertScore: 0.9710595607757568\n",
      "Substitute: painting, BertScore: 0.9703662991523743\n",
      "Substitute: reconstruction, BertScore: 0.9700669050216675\n",
      "Substitute: modeling, BertScore: 0.9693526029586792\n",
      "Substitute: sculptures, BertScore: 0.9691054821014404\n",
      "Substitute: constructions, BertScore: 0.9676234722137451\n",
      "Substitute: models, BertScore: 0.9676098823547363\n",
      "Substitute: carvings, BertScore: 0.9674069881439209\n",
      "Substitute: textures, BertScore: 0.9671424627304077\n",
      "Substitute: features, BertScore: 0.9660226106643677\n",
      "Substitute: render, BertScore: 0.9654945135116577\n",
      "Substitute: versions, BertScore: 0.9645747542381287\n",
      "Substitute: mapping, BertScore: 0.9626815319061279\n",
      "Substitute: 3d, BertScore: 0.9624084830284119\n",
      "Substitute: modifications, BertScore: 0.9616366028785706\n",
      "Substitute: an, BertScore: 0.9552077054977417\n",
      "Substitute: a, BertScore: 0.9541075229644775\n",
      "Substitute: that, BertScore: 0.9522398710250854\n",
      "Substitute: the, BertScore: 0.9508522152900696\n",
      "Substitute: rendered, BertScore: 0.9500783681869507\n",
      "Substitute: and, BertScore: 0.9491584300994873\n",
      "Substitute: making, BertScore: 0.9481893181800842\n",
      "top-10 substitutes based on bertscores in context: ['sketches', 'depictions', 'drawings', 'rendering', 'images', 'views', 'graphics', 'simulations', 'painting', 'reconstruction']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: warily\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: cautiously, BertScore: 0.9913180470466614\n",
      "Substitute: eagerly, BertScore: 0.9850234985351562\n",
      "Substitute: privately, BertScore: 0.9842008948326111\n",
      "Substitute: vaguely, BertScore: 0.9838164448738098\n",
      "Substitute: confidently, BertScore: 0.9833150506019592\n",
      "Substitute: vigorously, BertScore: 0.9832574129104614\n",
      "Substitute: fiercely, BertScore: 0.9831504821777344\n",
      "Substitute: pointedly, BertScore: 0.9821906089782715\n",
      "Substitute: broadly, BertScore: 0.9814759492874146\n",
      "Substitute: generally, BertScore: 0.9810580015182495\n",
      "Substitute: openly, BertScore: 0.9806761145591736\n",
      "Substitute: strongly, BertScore: 0.9805760383605957\n",
      "Substitute: enthusiastically, BertScore: 0.9802500605583191\n",
      "Substitute: largely, BertScore: 0.9801428318023682\n",
      "Substitute: quickly, BertScore: 0.9793131947517395\n",
      "Substitute: warmly, BertScore: 0.9792529344558716\n",
      "Substitute: clearly, BertScore: 0.9777262210845947\n",
      "Substitute: briefly, BertScore: 0.9773574471473694\n",
      "Substitute: proudly, BertScore: 0.9769911170005798\n",
      "Substitute: explicitly, BertScore: 0.9766787886619568\n",
      "Substitute: mostly, BertScore: 0.9758615493774414\n",
      "Substitute: overwhelmingly, BertScore: 0.9755120873451233\n",
      "Substitute: initially, BertScore: 0.9754781723022461\n",
      "Substitute: specifically, BertScore: 0.9731746315956116\n",
      "Substitute: still, BertScore: 0.9716192483901978\n",
      "Substitute: certainly, BertScore: 0.9702402949333191\n",
      "Substitute: likewise, BertScore: 0.9696937799453735\n",
      "Substitute: similarly, BertScore: 0.96927809715271\n",
      "Substitute: also, BertScore: 0.9654088616371155\n",
      "top-10 substitutes based on bertscores in context: ['cautiously', 'eagerly', 'privately', 'vaguely', 'confidently', 'vigorously', 'fiercely', 'pointedly', 'broadly', 'generally']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: evaluated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: examined, BertScore: 0.9922946691513062\n",
      "Substitute: analyzed, BertScore: 0.9920200705528259\n",
      "Substitute: assessed, BertScore: 0.9911696910858154\n",
      "Substitute: tested, BertScore: 0.9909918904304504\n",
      "Substitute: reviewed, BertScore: 0.9908626079559326\n",
      "Substitute: inspected, BertScore: 0.9896944761276245\n",
      "Substitute: checked, BertScore: 0.9886491298675537\n",
      "Substitute: investigated, BertScore: 0.9884915351867676\n",
      "Substitute: screened, BertScore: 0.9875187277793884\n",
      "Substitute: monitored, BertScore: 0.9861677885055542\n",
      "Substitute: tried, BertScore: 0.984058141708374\n",
      "Substitute: treated, BertScore: 0.9825891256332397\n",
      "Substitute: referred, BertScore: 0.9820430874824524\n",
      "Substitute: questioned, BertScore: 0.9816169738769531\n",
      "Substitute: considered, BertScore: 0.9806045889854431\n",
      "Substitute: judged, BertScore: 0.979679524898529\n",
      "Substitute: certified, BertScore: 0.9772273302078247\n",
      "Substitute: listed, BertScore: 0.9769225120544434\n",
      "Substitute: diagnosed, BertScore: 0.9766222834587097\n",
      "Substitute: rated, BertScore: 0.9750120043754578\n",
      "Substitute: looked, BertScore: 0.974428117275238\n",
      "Substitute: classified, BertScore: 0.9744150042533875\n",
      "Substitute: hospitalized, BertScore: 0.9739968180656433\n",
      "Substitute: approved, BertScore: 0.9718814492225647\n",
      "Substitute: positive, BertScore: 0.9680736064910889\n",
      "Substitute: arrested, BertScore: 0.9669486284255981\n",
      "Substitute: discharged, BertScore: 0.9667295217514038\n",
      "Substitute: released, BertScore: 0.9602783918380737\n",
      "Substitute: dismissed, BertScore: 0.9567174315452576\n",
      "top-10 substitutes based on bertscores in context: ['examined', 'analyzed', 'assessed', 'tested', 'reviewed', 'inspected', 'checked', 'investigated', 'screened', 'monitored']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: nobility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: aristocracy, BertScore: 0.9950802326202393\n",
      "Substitute: nobles, BertScore: 0.9920011162757874\n",
      "Substitute: gentry, BertScore: 0.9911552667617798\n",
      "Substitute: royalty, BertScore: 0.9858269691467285\n",
      "Substitute: elite, BertScore: 0.9852861762046814\n",
      "Substitute: clergy, BertScore: 0.984798014163971\n",
      "Substitute: royals, BertScore: 0.9828787446022034\n",
      "Substitute: wealthy, BertScore: 0.980972409248352\n",
      "Substitute: lords, BertScore: 0.9790189862251282\n",
      "Substitute: rich, BertScore: 0.9781204462051392\n",
      "Substitute: princes, BertScore: 0.9773950576782227\n",
      "Substitute: peasants, BertScore: 0.9765030145645142\n",
      "Substitute: dukes, BertScore: 0.9763189554214478\n",
      "Substitute: landowners, BertScore: 0.976003885269165\n",
      "Substitute: knights, BertScore: 0.9751518964767456\n",
      "Substitute: merchants, BertScore: 0.9731312990188599\n",
      "Substitute: populace, BertScore: 0.9728721380233765\n",
      "Substitute: citizens, BertScore: 0.9724770188331604\n",
      "Substitute: people, BertScore: 0.9709580540657043\n",
      "Substitute: public, BertScore: 0.9699984788894653\n",
      "Substitute: king, BertScore: 0.9684532880783081\n",
      "Substitute: population, BertScore: 0.9682337641716003\n",
      "Substitute: ladies, BertScore: 0.9668349027633667\n",
      "Substitute: villagers, BertScore: 0.9652333855628967\n",
      "Substitute: inhabitants, BertScore: 0.9634780883789062\n",
      "Substitute: poor, BertScore: 0.9633885622024536\n",
      "Substitute: residents, BertScore: 0.9632573127746582\n",
      "Substitute: women, BertScore: 0.9593726992607117\n",
      "Substitute: guests, BertScore: 0.9592126607894897\n",
      "top-10 substitutes based on bertscores in context: ['aristocracy', 'nobles', 'gentry', 'royalty', 'elite', 'clergy', 'royals', 'wealthy', 'lords', 'rich']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: surpassed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: exceeded, BertScore: 0.9959917664527893\n",
      "Substitute: overshadowed, BertScore: 0.9919039607048035\n",
      "Substitute: preceded, BertScore: 0.9910670518875122\n",
      "Substitute: topped, BertScore: 0.9903283715248108\n",
      "Substitute: superseded, BertScore: 0.9902965426445007\n",
      "Substitute: matched, BertScore: 0.9882075786590576\n",
      "Substitute: exceeding, BertScore: 0.9874281287193298\n",
      "Substitute: broken, BertScore: 0.9852885603904724\n",
      "Substitute: followed, BertScore: 0.9843728542327881\n",
      "Substitute: augmented, BertScore: 0.9822992086410522\n",
      "Substitute: distinguished, BertScore: 0.9816780090332031\n",
      "Substitute: tempered, BertScore: 0.9814692139625549\n",
      "Substitute: shared, BertScore: 0.9804779887199402\n",
      "Substitute: separated, BertScore: 0.9801242351531982\n",
      "Substitute: overcome, BertScore: 0.9801009297370911\n",
      "Substitute: defeated, BertScore: 0.9785854816436768\n",
      "Substitute: replaced, BertScore: 0.9777365326881409\n",
      "Substitute: reached, BertScore: 0.9769474267959595\n",
      "Substitute: confirmed, BertScore: 0.9733033180236816\n",
      "Substitute: met, BertScore: 0.9732052683830261\n",
      "Substitute: achieved, BertScore: 0.9731946587562561\n",
      "Substitute: conquered, BertScore: 0.9726725816726685\n",
      "Substitute: recognized, BertScore: 0.9706738591194153\n",
      "Substitute: combined, BertScore: 0.970334529876709\n",
      "Substitute: known, BertScore: 0.9660853743553162\n",
      "Substitute: and, BertScore: 0.9607897996902466\n",
      "Substitute: but, BertScore: 0.9566576480865479\n",
      "Substitute: not, BertScore: 0.9519662261009216\n",
      "top-10 substitutes based on bertscores in context: ['exceeded', 'overshadowed', 'preceded', 'topped', 'superseded', 'matched', 'exceeding', 'broken', 'followed', 'augmented']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: asserted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: claimed, BertScore: 0.9934654831886292\n",
      "Substitute: proclaimed, BertScore: 0.9928528666496277\n",
      "Substitute: assumed, BertScore: 0.9915285706520081\n",
      "Substitute: affirmed, BertScore: 0.9914367198944092\n",
      "Substitute: established, BertScore: 0.9914110898971558\n",
      "Substitute: declared, BertScore: 0.9903026223182678\n",
      "Substitute: acknowledged, BertScore: 0.9902126789093018\n",
      "Substitute: exercised, BertScore: 0.9900885224342346\n",
      "Substitute: maintained, BertScore: 0.9897463917732239\n",
      "Substitute: expressed, BertScore: 0.9893139004707336\n",
      "Substitute: invoked, BertScore: 0.9887266159057617\n",
      "Substitute: demonstrated, BertScore: 0.9885724186897278\n",
      "Substitute: reiterated, BertScore: 0.9884018898010254\n",
      "Substitute: stated, BertScore: 0.9883362650871277\n",
      "Substitute: pledged, BertScore: 0.9875917434692383\n",
      "Substitute: defended, BertScore: 0.9875103235244751\n",
      "Substitute: implied, BertScore: 0.9874556660652161\n",
      "Substitute: indicated, BertScore: 0.9844940900802612\n",
      "Substitute: emphasized, BertScore: 0.9841715693473816\n",
      "Substitute: demanded, BertScore: 0.9841601848602295\n",
      "Substitute: challenged, BertScore: 0.9835038185119629\n",
      "Substitute: alleged, BertScore: 0.9825723171234131\n",
      "Substitute: argued, BertScore: 0.9800684452056885\n",
      "Substitute: denied, BertScore: 0.980065643787384\n",
      "Substitute: disputed, BertScore: 0.9799633026123047\n",
      "Substitute: protested, BertScore: 0.9791095852851868\n",
      "Substitute: questioned, BertScore: 0.9749733209609985\n",
      "top-10 substitutes based on bertscores in context: ['claimed', 'proclaimed', 'assumed', 'affirmed', 'established', 'declared', 'acknowledged', 'exercised', 'maintained', 'expressed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: colonies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: colonists, BertScore: 0.9790732264518738\n",
      "Substitute: clones, BertScore: 0.9765549302101135\n",
      "Substitute: mutants, BertScore: 0.9699207544326782\n",
      "Substitute: humans, BertScore: 0.9627115726470947\n",
      "Substitute: populations, BertScore: 0.9622766375541687\n",
      "Substitute: species, BertScore: 0.9616873264312744\n",
      "Substitute: bees, BertScore: 0.9597177505493164\n",
      "Substitute: babies, BertScore: 0.958652913570404\n",
      "Substitute: ants, BertScore: 0.95848149061203\n",
      "Substitute: cultures, BertScore: 0.9568720459938049\n",
      "Substitute: plants, BertScore: 0.9560027718544006\n",
      "Substitute: cells, BertScore: 0.9517375230789185\n",
      "Substitute: states, BertScore: 0.9514596462249756\n",
      "Substitute: them, BertScore: 0.9509283304214478\n",
      "Substitute: people, BertScore: 0.9498578906059265\n",
      "Substitute: patients, BertScore: 0.9498031139373779\n",
      "Substitute: parasites, BertScore: 0.9477697014808655\n",
      "Substitute: individuals, BertScore: 0.9467107057571411\n",
      "Substitute: us, BertScore: 0.9438389539718628\n",
      "Substitute: ones, BertScore: 0.9435133337974548\n",
      "Substitute: those, BertScore: 0.9430527091026306\n",
      "Substitute: eggs, BertScore: 0.9414381980895996\n",
      "Substitute: these, BertScore: 0.9413983821868896\n",
      "Substitute: it, BertScore: 0.9411423802375793\n",
      "Substitute: one, BertScore: 0.9404296875\n",
      "Substitute: her, BertScore: 0.935603678226471\n",
      "Substitute: this, BertScore: 0.9347997307777405\n",
      "Substitute: ourselves, BertScore: 0.934592068195343\n",
      "top-10 substitutes based on bertscores in context: ['colonists', 'clones', 'mutants', 'humans', 'populations', 'species', 'bees', 'babies', 'ants', 'cultures']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: erupted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: flared, BertScore: 0.9972437620162964\n",
      "Substitute: occurred, BertScore: 0.9969388842582703\n",
      "Substitute: unfolded, BertScore: 0.9968693256378174\n",
      "Substitute: escalated, BertScore: 0.9966187477111816\n",
      "Substitute: ensued, BertScore: 0.9962353706359863\n",
      "Substitute: commenced, BertScore: 0.9960952997207642\n",
      "Substitute: broke, BertScore: 0.9958613514900208\n",
      "Substitute: raged, BertScore: 0.9956989884376526\n",
      "Substitute: began, BertScore: 0.9956102967262268\n",
      "Substitute: happened, BertScore: 0.9953948855400085\n",
      "Substitute: started, BertScore: 0.9952625632286072\n",
      "Substitute: intensified, BertScore: 0.9951725602149963\n",
      "Substitute: emerged, BertScore: 0.995170533657074\n",
      "Substitute: ignited, BertScore: 0.9949620366096497\n",
      "Substitute: arose, BertScore: 0.9949568510055542\n",
      "Substitute: rose, BertScore: 0.9946628212928772\n",
      "Substitute: appeared, BertScore: 0.9946161508560181\n",
      "Substitute: opened, BertScore: 0.9938749074935913\n",
      "Substitute: sparked, BertScore: 0.993705689907074\n",
      "Substitute: continued, BertScore: 0.993670642375946\n",
      "Substitute: developed, BertScore: 0.993421733379364\n",
      "Substitute: resumed, BertScore: 0.9934057593345642\n",
      "Substitute: came, BertScore: 0.9931105971336365\n",
      "Substitute: ended, BertScore: 0.9927753806114197\n",
      "Substitute: formed, BertScore: 0.9925121068954468\n",
      "Substitute: mounted, BertScore: 0.9923543930053711\n",
      "Substitute: increased, BertScore: 0.9913866519927979\n",
      "Substitute: drew, BertScore: 0.9900892972946167\n",
      "Substitute: fought, BertScore: 0.9869013428688049\n",
      "top-10 substitutes based on bertscores in context: ['flared', 'occurred', 'unfolded', 'escalated', 'ensued', 'commenced', 'broke', 'raged', 'began', 'happened']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: deployed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: dispatched, BertScore: 0.9892462491989136\n",
      "Substitute: stationed, BertScore: 0.9851896166801453\n",
      "Substitute: sent, BertScore: 0.9849514961242676\n",
      "Substitute: mobilized, BertScore: 0.9824696779251099\n",
      "Substitute: assigned, BertScore: 0.9794074892997742\n",
      "Substitute: recruited, BertScore: 0.9780370593070984\n",
      "Substitute: employed, BertScore: 0.9776458740234375\n",
      "Substitute: gathered, BertScore: 0.9764806032180786\n",
      "Substitute: appointed, BertScore: 0.976214587688446\n",
      "Substitute: commissioned, BertScore: 0.9753026366233826\n",
      "Substitute: hired, BertScore: 0.975267767906189\n",
      "Substitute: installed, BertScore: 0.9742861986160278\n",
      "Substitute: transferred, BertScore: 0.9741319417953491\n",
      "Substitute: provided, BertScore: 0.9739750623703003\n",
      "Substitute: enlisted, BertScore: 0.9739547967910767\n",
      "Substitute: released, BertScore: 0.973889172077179\n",
      "Substitute: supplied, BertScore: 0.9737261533737183\n",
      "Substitute: established, BertScore: 0.9736942052841187\n",
      "Substitute: allocated, BertScore: 0.9736868143081665\n",
      "Substitute: assembled, BertScore: 0.9734761714935303\n",
      "Substitute: brought, BertScore: 0.9720944762229919\n",
      "Substitute: utilized, BertScore: 0.9714071154594421\n",
      "Substitute: used, BertScore: 0.9712449312210083\n",
      "Substitute: dedicated, BertScore: 0.9708389043807983\n",
      "Substitute: trained, BertScore: 0.9705029726028442\n",
      "Substitute: added, BertScore: 0.9694010019302368\n",
      "Substitute: volunteered, BertScore: 0.9690269231796265\n",
      "Substitute: created, BertScore: 0.9685752391815186\n",
      "Substitute: selected, BertScore: 0.9602082371711731\n",
      "top-10 substitutes based on bertscores in context: ['dispatched', 'stationed', 'sent', 'mobilized', 'assigned', 'recruited', 'employed', 'gathered', 'appointed', 'commissioned']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: militiamen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: militia, BertScore: 0.9896657466888428\n",
      "Substitute: soldiers, BertScore: 0.9860302209854126\n",
      "Substitute: militias, BertScore: 0.9858583807945251\n",
      "Substitute: rebels, BertScore: 0.9857438802719116\n",
      "Substitute: insurgents, BertScore: 0.9856499433517456\n",
      "Substitute: militants, BertScore: 0.9850412607192993\n",
      "Substitute: policemen, BertScore: 0.984429121017456\n",
      "Substitute: guerrillas, BertScore: 0.9844210147857666\n",
      "Substitute: troops, BertScore: 0.9843093752861023\n",
      "Substitute: fighters, BertScore: 0.9840741157531738\n",
      "Substitute: mercenaries, BertScore: 0.9839758276939392\n",
      "Substitute: guards, BertScore: 0.9832843542098999\n",
      "Substitute: officers, BertScore: 0.9832299947738647\n",
      "Substitute: forces, BertScore: 0.9828515648841858\n",
      "Substitute: thugs, BertScore: 0.9825063943862915\n",
      "Substitute: civilians, BertScore: 0.9823895692825317\n",
      "Substitute: bandits, BertScore: 0.982366681098938\n",
      "Substitute: gunmen, BertScore: 0.9819514155387878\n",
      "Substitute: men, BertScore: 0.9817720055580139\n",
      "Substitute: villagers, BertScore: 0.9815917611122131\n",
      "Substitute: terrorists, BertScore: 0.9806079864501953\n",
      "Substitute: attackers, BertScore: 0.9805520176887512\n",
      "Substitute: agents, BertScore: 0.9799058437347412\n",
      "Substitute: police, BertScore: 0.9796953797340393\n",
      "Substitute: youths, BertScore: 0.9784529805183411\n",
      "Substitute: people, BertScore: 0.9777699708938599\n",
      "Substitute: foreigners, BertScore: 0.9755200147628784\n",
      "Substitute: someone, BertScore: 0.9733920693397522\n",
      "Substitute: others, BertScore: 0.9730127453804016\n",
      "Substitute: women, BertScore: 0.9712274074554443\n",
      "top-10 substitutes based on bertscores in context: ['militia', 'soldiers', 'militias', 'rebels', 'insurgents', 'militants', 'policemen', 'guerrillas', 'troops', 'fighters']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: carnage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: devastation, BertScore: 0.9954262971878052\n",
      "Substitute: mayhem, BertScore: 0.9939568638801575\n",
      "Substitute: violence, BertScore: 0.992585301399231\n",
      "Substitute: destruction, BertScore: 0.9923661947250366\n",
      "Substitute: chaos, BertScore: 0.9915887117385864\n",
      "Substitute: fighting, BertScore: 0.9913638830184937\n",
      "Substitute: disaster, BertScore: 0.9911640882492065\n",
      "Substitute: slaughter, BertScore: 0.9909041523933411\n",
      "Substitute: terror, BertScore: 0.9908585548400879\n",
      "Substitute: catastrophe, BertScore: 0.9906871914863586\n",
      "Substitute: onslaught, BertScore: 0.9905686378479004\n",
      "Substitute: brutality, BertScore: 0.9903351664543152\n",
      "Substitute: tragedy, BertScore: 0.9902523159980774\n",
      "Substitute: horrors, BertScore: 0.9900434017181396\n",
      "Substitute: anarchy, BertScore: 0.9894852042198181\n",
      "Substitute: suffering, BertScore: 0.9892883896827698\n",
      "Substitute: looting, BertScore: 0.9882146716117859\n",
      "Substitute: misery, BertScore: 0.9880540370941162\n",
      "Substitute: conflict, BertScore: 0.9875909686088562\n",
      "Substitute: unrest, BertScore: 0.9874268770217896\n",
      "Substitute: war, BertScore: 0.986608624458313\n",
      "Substitute: genocide, BertScore: 0.9865402579307556\n",
      "Substitute: crisis, BertScore: 0.9864755272865295\n",
      "Substitute: outrage, BertScore: 0.9863165616989136\n",
      "Substitute: threat, BertScore: 0.985606849193573\n",
      "Substitute: fury, BertScore: 0.9853920936584473\n",
      "Substitute: horror, BertScore: 0.9851760864257812\n",
      "Substitute: tension, BertScore: 0.9839690327644348\n",
      "Substitute: drama, BertScore: 0.9836186170578003\n",
      "top-10 substitutes based on bertscores in context: ['devastation', 'mayhem', 'violence', 'destruction', 'chaos', 'fighting', 'disaster', 'slaughter', 'terror', 'catastrophe']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: stint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: tenure, BertScore: 0.9918732643127441\n",
      "Substitute: period, BertScore: 0.9908579587936401\n",
      "Substitute: stay, BertScore: 0.9901968240737915\n",
      "Substitute: time, BertScore: 0.9899121522903442\n",
      "Substitute: run, BertScore: 0.9892744421958923\n",
      "Substitute: outing, BertScore: 0.9884775876998901\n",
      "Substitute: year, BertScore: 0.9877040386199951\n",
      "Substitute: month, BertScore: 0.9869594573974609\n",
      "Substitute: job, BertScore: 0.9867312908172607\n",
      "Substitute: week, BertScore: 0.9864690899848938\n",
      "Substitute: involvement, BertScore: 0.9864529371261597\n",
      "Substitute: break, BertScore: 0.9853610396385193\n",
      "Substitute: appearance, BertScore: 0.9848683476448059\n",
      "Substitute: stop, BertScore: 0.9845113158226013\n",
      "Substitute: career, BertScore: 0.9843868017196655\n",
      "Substitute: experience, BertScore: 0.9843441247940063\n",
      "Substitute: visit, BertScore: 0.984022319316864\n",
      "Substitute: work, BertScore: 0.9831308126449585\n",
      "Substitute: years, BertScore: 0.9819486141204834\n",
      "Substitute: days, BertScore: 0.9817554950714111\n",
      "Substitute: attempt, BertScore: 0.981657087802887\n",
      "Substitute: encounter, BertScore: 0.9814078211784363\n",
      "Substitute: incident, BertScore: 0.9812042117118835\n",
      "Substitute: day, BertScore: 0.980186402797699\n",
      "Substitute: night, BertScore: 0.9796568155288696\n",
      "Substitute: escape, BertScore: 0.9796000719070435\n",
      "Substitute: trial, BertScore: 0.9788225889205933\n",
      "Substitute: performance, BertScore: 0.977891743183136\n",
      "Substitute: arrest, BertScore: 0.9769116640090942\n",
      "top-10 substitutes based on bertscores in context: ['tenure', 'period', 'stay', 'time', 'run', 'outing', 'year', 'month', 'job', 'week']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: repossessed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: lost, BertScore: 0.9644978642463684\n",
      "Substitute: purchased, BertScore: 0.9622122049331665\n",
      "Substitute: borrowed, BertScore: 0.9595293998718262\n",
      "Substitute: leased, BertScore: 0.9591634273529053\n",
      "Substitute: troubled, BertScore: 0.9590353965759277\n",
      "Substitute: stolen, BertScore: 0.9571842551231384\n",
      "Substitute: rented, BertScore: 0.956893265247345\n",
      "Substitute: distressed, BertScore: 0.9554576873779297\n",
      "Substitute: managed, BertScore: 0.9545298218727112\n",
      "Substitute: existing, BertScore: 0.954462468624115\n",
      "Substitute: new, BertScore: 0.9540194272994995\n",
      "Substitute: rental, BertScore: 0.9535524249076843\n",
      "Substitute: common, BertScore: 0.9530434012413025\n",
      "Substitute: government, BertScore: 0.9530289173126221\n",
      "Substitute: private, BertScore: 0.9529565572738647\n",
      "Substitute: public, BertScore: 0.9527437686920166\n",
      "Substitute: commercial, BertScore: 0.9526143074035645\n",
      "Substitute: property, BertScore: 0.952275276184082\n",
      "Substitute: investment, BertScore: 0.9516646265983582\n",
      "Substitute: personal, BertScore: 0.9513764381408691\n",
      "Substitute: residential, BertScore: 0.9511704444885254\n",
      "Substitute: mortgage, BertScore: 0.9510800242424011\n",
      "Substitute: real, BertScore: 0.9502899050712585\n",
      "Substitute: such, BertScore: 0.9485770463943481\n",
      "Substitute: these, BertScore: 0.9466210007667542\n",
      "Substitute: their, BertScore: 0.9457380175590515\n",
      "Substitute: its, BertScore: 0.9443026781082153\n",
      "Substitute: that, BertScore: 0.942379355430603\n",
      "Substitute: the, BertScore: 0.9422684907913208\n",
      "Substitute: this, BertScore: 0.9398775696754456\n",
      "top-10 substitutes based on bertscores in context: ['lost', 'purchased', 'borrowed', 'leased', 'troubled', 'stolen', 'rented', 'distressed', 'managed', 'existing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: investigating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: monitoring, BertScore: 0.9801623821258545\n",
      "Substitute: researching, BertScore: 0.9795055389404297\n",
      "Substitute: examining, BertScore: 0.9769046306610107\n",
      "Substitute: assessing, BertScore: 0.9768001437187195\n",
      "Substitute: probing, BertScore: 0.9747442603111267\n",
      "Substitute: exploring, BertScore: 0.9725685715675354\n",
      "Substitute: studying, BertScore: 0.9724858999252319\n",
      "Substitute: regarding, BertScore: 0.9717760682106018\n",
      "Substitute: analyzing, BertScore: 0.970880389213562\n",
      "Substitute: pursuing, BertScore: 0.9695871472358704\n",
      "Substitute: discovering, BertScore: 0.9656241536140442\n",
      "Substitute: discussing, BertScore: 0.9633228778839111\n",
      "Substitute: confirming, BertScore: 0.9622988700866699\n",
      "Substitute: considering, BertScore: 0.9621556401252747\n",
      "Substitute: watching, BertScore: 0.9608839750289917\n",
      "Substitute: following, BertScore: 0.9608187079429626\n",
      "Substitute: witnessing, BertScore: 0.9604364633560181\n",
      "Substitute: seeing, BertScore: 0.9570351243019104\n",
      "Substitute: about, BertScore: 0.9562670588493347\n",
      "Substitute: on, BertScore: 0.953544020652771\n",
      "Substitute: in, BertScore: 0.9460527896881104\n",
      "Substitute: after, BertScore: 0.9448711276054382\n",
      "Substitute: with, BertScore: 0.9415554404258728\n",
      "Substitute: suspected, BertScore: 0.9406739473342896\n",
      "Substitute: suspects, BertScore: 0.9346153140068054\n",
      "Substitute: investigations, BertScore: 0.9305903911590576\n",
      "Substitute: and, BertScore: 0.926877498626709\n",
      "top-10 substitutes based on bertscores in context: ['monitoring', 'researching', 'examining', 'assessing', 'probing', 'exploring', 'studying', 'regarding', 'analyzing', 'pursuing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: atrocities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: abuses, BertScore: 0.9946761727333069\n",
      "Substitute: crimes, BertScore: 0.9944617748260498\n",
      "Substitute: horrors, BertScore: 0.9938092231750488\n",
      "Substitute: killings, BertScore: 0.9934349060058594\n",
      "Substitute: murders, BertScore: 0.9929002523422241\n",
      "Substitute: genocide, BertScore: 0.9926318526268005\n",
      "Substitute: violations, BertScore: 0.9922723174095154\n",
      "Substitute: actions, BertScore: 0.9919594526290894\n",
      "Substitute: attacks, BertScore: 0.9919145107269287\n",
      "Substitute: offenses, BertScore: 0.9918979406356812\n",
      "Substitute: aggression, BertScore: 0.9918638467788696\n",
      "Substitute: acts, BertScore: 0.9918507933616638\n",
      "Substitute: violence, BertScore: 0.991747260093689\n",
      "Substitute: massacre, BertScore: 0.9912025928497314\n",
      "Substitute: brutality, BertScore: 0.9909669160842896\n",
      "Substitute: carnage, BertScore: 0.9909449219703674\n",
      "Substitute: incidents, BertScore: 0.9908189177513123\n",
      "Substitute: activities, BertScore: 0.9907481670379639\n",
      "Substitute: conflicts, BertScore: 0.9904025793075562\n",
      "Substitute: crime, BertScore: 0.9899667501449585\n",
      "Substitute: wars, BertScore: 0.9892072081565857\n",
      "Substitute: holocaust, BertScore: 0.9891551733016968\n",
      "Substitute: events, BertScore: 0.9890936613082886\n",
      "Substitute: torture, BertScore: 0.9887948036193848\n",
      "Substitute: policies, BertScore: 0.988028347492218\n",
      "Substitute: war, BertScore: 0.9864779114723206\n",
      "Substitute: weapons, BertScore: 0.9860565662384033\n",
      "Substitute: stories, BertScore: 0.9848135709762573\n",
      "Substitute: things, BertScore: 0.9847989082336426\n",
      "top-10 substitutes based on bertscores in context: ['abuses', 'crimes', 'horrors', 'killings', 'murders', 'genocide', 'violations', 'actions', 'attacks', 'offenses']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: underlying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: base, BertScore: 0.9878305196762085\n",
      "Substitute: prevailing, BertScore: 0.9874309301376343\n",
      "Substitute: intrinsic, BertScore: 0.9873923659324646\n",
      "Substitute: core, BertScore: 0.9872708916664124\n",
      "Substitute: implied, BertScore: 0.986723005771637\n",
      "Substitute: internal, BertScore: 0.9866323471069336\n",
      "Substitute: fundamental, BertScore: 0.9864707589149475\n",
      "Substitute: overall, BertScore: 0.9853688478469849\n",
      "Substitute: inherent, BertScore: 0.9852117300033569\n",
      "Substitute: corresponding, BertScore: 0.9850804209709167\n",
      "Substitute: real, BertScore: 0.9849379062652588\n",
      "Substitute: implicit, BertScore: 0.9848251938819885\n",
      "Substitute: basic, BertScore: 0.9846497178077698\n",
      "Substitute: initial, BertScore: 0.984295129776001\n",
      "Substitute: absolute, BertScore: 0.9837561249732971\n",
      "Substitute: nominal, BertScore: 0.9834635257720947\n",
      "Substitute: actual, BertScore: 0.9834015369415283\n",
      "Substitute: rational, BertScore: 0.9832447171211243\n",
      "Substitute: original, BertScore: 0.9831576943397522\n",
      "Substitute: existing, BertScore: 0.9828663468360901\n",
      "Substitute: stated, BertScore: 0.9828283786773682\n",
      "Substitute: ongoing, BertScore: 0.9821971654891968\n",
      "Substitute: natural, BertScore: 0.982175350189209\n",
      "Substitute: current, BertScore: 0.9816019535064697\n",
      "Substitute: annual, BertScore: 0.9814387559890747\n",
      "Substitute: present, BertScore: 0.980920135974884\n",
      "Substitute: expected, BertScore: 0.9809057712554932\n",
      "Substitute: anticipated, BertScore: 0.9802519679069519\n",
      "Substitute: predicted, BertScore: 0.9796338081359863\n",
      "top-10 substitutes based on bertscores in context: ['base', 'prevailing', 'intrinsic', 'core', 'implied', 'internal', 'fundamental', 'overall', 'inherent', 'corresponding']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: introduced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: brought, BertScore: 0.9840404987335205\n",
      "Substitute: imported, BertScore: 0.9795599579811096\n",
      "Substitute: reintroduced, BertScore: 0.9782606363296509\n",
      "Substitute: distributed, BertScore: 0.9769574403762817\n",
      "Substitute: adopted, BertScore: 0.9754480123519897\n",
      "Substitute: admitted, BertScore: 0.973375678062439\n",
      "Substitute: accepted, BertScore: 0.9722920656204224\n",
      "Substitute: released, BertScore: 0.9718925952911377\n",
      "Substitute: delivered, BertScore: 0.9705619812011719\n",
      "Substitute: licensed, BertScore: 0.9689846038818359\n",
      "Substitute: offered, BertScore: 0.9687194228172302\n",
      "Substitute: added, BertScore: 0.96832275390625\n",
      "Substitute: marketed, BertScore: 0.9679906368255615\n",
      "Substitute: presented, BertScore: 0.9678349494934082\n",
      "Substitute: sold, BertScore: 0.9674085378646851\n",
      "Substitute: shipped, BertScore: 0.966957151889801\n",
      "Substitute: sent, BertScore: 0.965793788433075\n",
      "Substitute: moved, BertScore: 0.9650511145591736\n",
      "Substitute: transferred, BertScore: 0.9648575782775879\n",
      "Substitute: given, BertScore: 0.9647692441940308\n",
      "Substitute: promoted, BertScore: 0.9639222621917725\n",
      "Substitute: exported, BertScore: 0.9631056785583496\n",
      "Substitute: extended, BertScore: 0.9630277752876282\n",
      "Substitute: expanded, BertScore: 0.9621745347976685\n",
      "Substitute: opened, BertScore: 0.9619638919830322\n",
      "Substitute: returned, BertScore: 0.9612057209014893\n",
      "Substitute: issued, BertScore: 0.9604758620262146\n",
      "Substitute: withdrawn, BertScore: 0.9516947269439697\n",
      "Substitute: renamed, BertScore: 0.9169496297836304\n",
      "top-10 substitutes based on bertscores in context: ['brought', 'imported', 'reintroduced', 'distributed', 'adopted', 'admitted', 'accepted', 'released', 'delivered', 'licensed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: adamantly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: firmly, BertScore: 0.9823417663574219\n",
      "Substitute: flatly, BertScore: 0.9811801314353943\n",
      "Substitute: fiercely, BertScore: 0.9788081049919128\n",
      "Substitute: strongly, BertScore: 0.9777250289916992\n",
      "Substitute: vigorously, BertScore: 0.9775887727737427\n",
      "Substitute: bitterly, BertScore: 0.9768122434616089\n",
      "Substitute: aggressively, BertScore: 0.9764044284820557\n",
      "Substitute: openly, BertScore: 0.9762142896652222\n",
      "Substitute: deeply, BertScore: 0.9762136936187744\n",
      "Substitute: explicitly, BertScore: 0.9750612378120422\n",
      "Substitute: heavily, BertScore: 0.9748928546905518\n",
      "Substitute: publicly, BertScore: 0.9734319448471069\n",
      "Substitute: actively, BertScore: 0.9732732772827148\n",
      "Substitute: clearly, BertScore: 0.9714710116386414\n",
      "Substitute: sharply, BertScore: 0.9706913828849792\n",
      "Substitute: directly, BertScore: 0.9702125191688538\n",
      "Substitute: consistently, BertScore: 0.9699367880821228\n",
      "Substitute: primarily, BertScore: 0.9681161046028137\n",
      "Substitute: specifically, BertScore: 0.9679312109947205\n",
      "Substitute: overwhelmingly, BertScore: 0.9677232503890991\n",
      "Substitute: personally, BertScore: 0.9663814902305603\n",
      "Substitute: ultimately, BertScore: 0.9663060903549194\n",
      "Substitute: repeatedly, BertScore: 0.9660787582397461\n",
      "Substitute: initially, BertScore: 0.9660133719444275\n",
      "Substitute: outright, BertScore: 0.9631422758102417\n",
      "Substitute: reportedly, BertScore: 0.9629630446434021\n",
      "Substitute: further, BertScore: 0.9617313742637634\n",
      "Substitute: still, BertScore: 0.9597697854042053\n",
      "Substitute: also, BertScore: 0.9587936997413635\n",
      "Substitute: therefore, BertScore: 0.9534435272216797\n",
      "top-10 substitutes based on bertscores in context: ['firmly', 'flatly', 'fiercely', 'strongly', 'vigorously', 'bitterly', 'aggressively', 'openly', 'deeply', 'explicitly']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: candidacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: campaign, BertScore: 0.9939360618591309\n",
      "Substitute: bid, BertScore: 0.9925301671028137\n",
      "Substitute: nomination, BertScore: 0.9922389388084412\n",
      "Substitute: candidate, BertScore: 0.9917779564857483\n",
      "Substitute: primary, BertScore: 0.9915300607681274\n",
      "Substitute: election, BertScore: 0.9914887547492981\n",
      "Substitute: race, BertScore: 0.9906620383262634\n",
      "Substitute: campaigns, BertScore: 0.9904570579528809\n",
      "Substitute: candidates, BertScore: 0.9895753264427185\n",
      "Substitute: nominee, BertScore: 0.9891222715377808\n",
      "Substitute: presidency, BertScore: 0.9891129732131958\n",
      "Substitute: party, BertScore: 0.988989531993866\n",
      "Substitute: proposal, BertScore: 0.9880974292755127\n",
      "Substitute: vote, BertScore: 0.9880347847938538\n",
      "Substitute: position, BertScore: 0.9880309700965881\n",
      "Substitute: ticket, BertScore: 0.9874829053878784\n",
      "Substitute: movement, BertScore: 0.9872300624847412\n",
      "Substitute: administration, BertScore: 0.9869587421417236\n",
      "Substitute: platform, BertScore: 0.986947238445282\n",
      "Substitute: strategy, BertScore: 0.9855305552482605\n",
      "Substitute: victory, BertScore: 0.9852935075759888\n",
      "Substitute: establishment, BertScore: 0.9835164546966553\n",
      "Substitute: camp, BertScore: 0.9828060865402222\n",
      "Substitute: president, BertScore: 0.9827983379364014\n",
      "Substitute: issue, BertScore: 0.982150137424469\n",
      "Substitute: challenger, BertScore: 0.9820663928985596\n",
      "Substitute: win, BertScore: 0.9812372326850891\n",
      "Substitute: team, BertScore: 0.9782737493515015\n",
      "Substitute: trail, BertScore: 0.9775356650352478\n",
      "top-10 substitutes based on bertscores in context: ['campaign', 'bid', 'nomination', 'candidate', 'primary', 'election', 'race', 'campaigns', 'candidates', 'nominee']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: disputed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: contested, BertScore: 0.9917473196983337\n",
      "Substitute: questioned, BertScore: 0.9820897579193115\n",
      "Substitute: challenged, BertScore: 0.9789302349090576\n",
      "Substitute: denied, BertScore: 0.975321352481842\n",
      "Substitute: rejected, BertScore: 0.9686447381973267\n",
      "Substitute: asserted, BertScore: 0.9611196517944336\n",
      "Substitute: acknowledged, BertScore: 0.9589906334877014\n",
      "Substitute: claimed, BertScore: 0.9573620557785034\n",
      "Substitute: supported, BertScore: 0.9531761407852173\n",
      "Substitute: alleged, BertScore: 0.9517515897750854\n",
      "Substitute: confirmed, BertScore: 0.9510953426361084\n",
      "Substitute: cited, BertScore: 0.9467104077339172\n",
      "Substitute: conjecture, BertScore: 0.9451874494552612\n",
      "Substitute: accepted, BertScore: 0.9445589184761047\n",
      "Substitute: sought, BertScore: 0.9432938098907471\n",
      "Substitute: shared, BertScore: 0.9422948956489563\n",
      "Substitute: favored, BertScore: 0.941562294960022\n",
      "Substitute: claim, BertScore: 0.9403321743011475\n",
      "Substitute: claims, BertScore: 0.9400719404220581\n",
      "Substitute: mentioned, BertScore: 0.9351623058319092\n",
      "Substitute: held, BertScore: 0.9334620237350464\n",
      "Substitute: reported, BertScore: 0.9322216510772705\n",
      "Substitute: mixed, BertScore: 0.9313474893569946\n",
      "Substitute: controversy, BertScore: 0.9292583465576172\n",
      "Substitute: related, BertScore: 0.9285104870796204\n",
      "Substitute: used, BertScore: 0.9282457828521729\n",
      "Substitute: submitted, BertScore: 0.9263834357261658\n",
      "top-10 substitutes based on bertscores in context: ['contested', 'questioned', 'challenged', 'denied', 'rejected', 'asserted', 'acknowledged', 'claimed', 'supported', 'alleged']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: auctioneers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: dealers, BertScore: 0.9855882525444031\n",
      "Substitute: buyers, BertScore: 0.9843829274177551\n",
      "Substitute: sellers, BertScore: 0.9841419458389282\n",
      "Substitute: traders, BertScore: 0.9840997457504272\n",
      "Substitute: collectors, BertScore: 0.982591450214386\n",
      "Substitute: hunters, BertScore: 0.9821259379386902\n",
      "Substitute: merchants, BertScore: 0.9816728830337524\n",
      "Substitute: vendors, BertScore: 0.9814200401306152\n",
      "Substitute: owners, BertScore: 0.9813970327377319\n",
      "Substitute: producers, BertScore: 0.9808697700500488\n",
      "Substitute: makers, BertScore: 0.9806820154190063\n",
      "Substitute: agents, BertScore: 0.9802787899971008\n",
      "Substitute: specialists, BertScore: 0.9799677133560181\n",
      "Substitute: manufacturers, BertScore: 0.9797037243843079\n",
      "Substitute: retailers, BertScore: 0.9790843725204468\n",
      "Substitute: experts, BertScore: 0.9786802530288696\n",
      "Substitute: masters, BertScore: 0.9786491990089417\n",
      "Substitute: enthusiasts, BertScore: 0.9777924418449402\n",
      "Substitute: firms, BertScore: 0.9777905941009521\n",
      "Substitute: photographers, BertScore: 0.9771976470947266\n",
      "Substitute: galleries, BertScore: 0.9768593311309814\n",
      "Substitute: artists, BertScore: 0.9765101671218872\n",
      "Substitute: companies, BertScore: 0.9759498238563538\n",
      "Substitute: sales, BertScore: 0.974851131439209\n",
      "Substitute: commissions, BertScore: 0.9693442583084106\n",
      "Substitute: shows, BertScore: 0.9676852226257324\n",
      "Substitute: auction, BertScore: 0.9670724272727966\n",
      "Substitute: dealer, BertScore: 0.9645164012908936\n",
      "top-10 substitutes based on bertscores in context: ['dealers', 'buyers', 'sellers', 'traders', 'collectors', 'hunters', 'merchants', 'vendors', 'owners', 'producers']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: bloodshed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: fighting, BertScore: 0.9462143182754517\n",
      "Substitute: carnage, BertScore: 0.9432895183563232\n",
      "Substitute: violence, BertScore: 0.9396520256996155\n",
      "Substitute: slaughter, BertScore: 0.9344119429588318\n",
      "Substitute: chaos, BertScore: 0.9341493248939514\n",
      "Substitute: massacre, BertScore: 0.9285875558853149\n",
      "Substitute: fight, BertScore: 0.9278769493103027\n",
      "Substitute: unrest, BertScore: 0.9209190607070923\n",
      "Substitute: battle, BertScore: 0.9203159213066101\n",
      "Substitute: conflict, BertScore: 0.9194333553314209\n",
      "Substitute: riot, BertScore: 0.918075680732727\n",
      "Substitute: atrocities, BertScore: 0.9175854325294495\n",
      "Substitute: clashes, BertScore: 0.9175444841384888\n",
      "Substitute: looting, BertScore: 0.9165070056915283\n",
      "Substitute: riots, BertScore: 0.9151854515075684\n",
      "Substitute: killing, BertScore: 0.9123418927192688\n",
      "Substitute: bleeding, BertScore: 0.9105989336967468\n",
      "Substitute: assault, BertScore: 0.9094412326812744\n",
      "Substitute: protest, BertScore: 0.9057871103286743\n",
      "Substitute: damage, BertScore: 0.9056993126869202\n",
      "Substitute: suffering, BertScore: 0.9052085280418396\n",
      "Substitute: war, BertScore: 0.9047355651855469\n",
      "Substitute: killings, BertScore: 0.9027275443077087\n",
      "Substitute: protests, BertScore: 0.9014641642570496\n",
      "Substitute: outbreak, BertScore: 0.8984270095825195\n",
      "Substitute: situation, BertScore: 0.8886858820915222\n",
      "Substitute: action, BertScore: 0.8863893151283264\n",
      "Substitute: effort, BertScore: 0.8775034546852112\n",
      "Substitute: problem, BertScore: 0.8719397783279419\n",
      "Substitute: process, BertScore: 0.8712994456291199\n",
      "top-10 substitutes based on bertscores in context: ['fighting', 'carnage', 'violence', 'slaughter', 'chaos', 'massacre', 'fight', 'unrest', 'battle', 'conflict']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: relinquish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: reclaim, BertScore: 0.9414348006248474\n",
      "Substitute: retain, BertScore: 0.9406808614730835\n",
      "Substitute: return, BertScore: 0.939500629901886\n",
      "Substitute: restore, BertScore: 0.9386501312255859\n",
      "Substitute: reserve, BertScore: 0.9379042983055115\n",
      "Substitute: exercise, BertScore: 0.9375702142715454\n",
      "Substitute: regain, BertScore: 0.9369233250617981\n",
      "Substitute: accept, BertScore: 0.9360244870185852\n",
      "Substitute: clear, BertScore: 0.9357343912124634\n",
      "Substitute: maintain, BertScore: 0.9356189966201782\n",
      "Substitute: move, BertScore: 0.9351673126220703\n",
      "Substitute: raise, BertScore: 0.9349326491355896\n",
      "Substitute: change, BertScore: 0.9347823262214661\n",
      "Substitute: lift, BertScore: 0.9346807599067688\n",
      "Substitute: secure, BertScore: 0.9346732497215271\n",
      "Substitute: use, BertScore: 0.9346697330474854\n",
      "Substitute: take, BertScore: 0.9340488910675049\n",
      "Substitute: open, BertScore: 0.9336131811141968\n",
      "Substitute: defend, BertScore: 0.9330862760543823\n",
      "Substitute: control, BertScore: 0.9328538775444031\n",
      "Substitute: leave, BertScore: 0.9327503442764282\n",
      "Substitute: occupy, BertScore: 0.9327336549758911\n",
      "Substitute: compromise, BertScore: 0.9308985471725464\n",
      "Substitute: split, BertScore: 0.9307398796081543\n",
      "Substitute: balance, BertScore: 0.9305995106697083\n",
      "Substitute: share, BertScore: 0.9300251007080078\n",
      "Substitute: amend, BertScore: 0.9300189018249512\n",
      "Substitute: negotiate, BertScore: 0.9292712807655334\n",
      "Substitute: pay, BertScore: 0.9280499815940857\n",
      "Substitute: touch, BertScore: 0.9276625514030457\n",
      "top-10 substitutes based on bertscores in context: ['reclaim', 'retain', 'return', 'restore', 'reserve', 'exercise', 'regain', 'accept', 'clear', 'maintain']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: indicating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: stating, BertScore: 0.994257390499115\n",
      "Substitute: suggesting, BertScore: 0.9936875700950623\n",
      "Substitute: confirming, BertScore: 0.9933745265007019\n",
      "Substitute: implying, BertScore: 0.9929026365280151\n",
      "Substitute: showing, BertScore: 0.9925802946090698\n",
      "Substitute: saying, BertScore: 0.99236661195755\n",
      "Substitute: announcing, BertScore: 0.9919078350067139\n",
      "Substitute: declaring, BertScore: 0.991441011428833\n",
      "Substitute: revealing, BertScore: 0.9901012182235718\n",
      "Substitute: explaining, BertScore: 0.9897627830505371\n",
      "Substitute: mentioning, BertScore: 0.9895744323730469\n",
      "Substitute: informing, BertScore: 0.98886638879776\n",
      "Substitute: claiming, BertScore: 0.9885609745979309\n",
      "Substitute: describing, BertScore: 0.9875086545944214\n",
      "Substitute: adding, BertScore: 0.9859638214111328\n",
      "Substitute: telling, BertScore: 0.985706090927124\n",
      "Substitute: complaining, BertScore: 0.9845904111862183\n",
      "Substitute: requesting, BertScore: 0.9817031025886536\n",
      "Substitute: warning, BertScore: 0.9808858633041382\n",
      "Substitute: asking, BertScore: 0.98028165102005\n",
      "Substitute: knowing, BertScore: 0.9799030423164368\n",
      "Substitute: pleading, BertScore: 0.9792846441268921\n",
      "Substitute: being, BertScore: 0.9763301610946655\n",
      "Substitute: also, BertScore: 0.9745956659317017\n",
      "Substitute: and, BertScore: 0.9700616598129272\n",
      "Substitute: but, BertScore: 0.9657687544822693\n",
      "Substitute: listing, BertScore: 0.962570071220398\n",
      "Substitute: because, BertScore: 0.9617708921432495\n",
      "top-10 substitutes based on bertscores in context: ['stating', 'suggesting', 'confirming', 'implying', 'showing', 'saying', 'announcing', 'declaring', 'revealing', 'explaining']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: organisers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: organizers, BertScore: 0.9751669764518738\n",
      "Substitute: promoters, BertScore: 0.9707615375518799\n",
      "Substitute: sponsors, BertScore: 0.9682843089103699\n",
      "Substitute: participants, BertScore: 0.9635329246520996\n",
      "Substitute: owners, BertScore: 0.9620325565338135\n",
      "Substitute: officials, BertScore: 0.9609490633010864\n",
      "Substitute: holders, BertScore: 0.9608963131904602\n",
      "Substitute: group, BertScore: 0.9573408365249634\n",
      "Substitute: staff, BertScore: 0.9556850790977478\n",
      "Substitute: team, BertScore: 0.9534968733787537\n",
      "Substitute: council, BertScore: 0.95318603515625\n",
      "Substitute: crew, BertScore: 0.9529922008514404\n",
      "Substitute: board, BertScore: 0.9525688886642456\n",
      "Substitute: company, BertScore: 0.9522507190704346\n",
      "Substitute: party, BertScore: 0.9485877752304077\n",
      "Substitute: club, BertScore: 0.9472325444221497\n",
      "Substitute: workers, BertScore: 0.9408681392669678\n",
      "Substitute: had, BertScore: 0.9290010333061218\n",
      "Substitute: also, BertScore: 0.9283493161201477\n",
      "Substitute: has, BertScore: 0.9272947311401367\n",
      "top-10 substitutes based on bertscores in context: ['organizers', 'promoters', 'sponsors', 'participants', 'owners', 'officials', 'holders', 'group', 'staff', 'team']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: clearance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: authorization, BertScore: 0.9883682727813721\n",
      "Substitute: permission, BertScore: 0.9859326481819153\n",
      "Substitute: protection, BertScore: 0.9858949780464172\n",
      "Substitute: approval, BertScore: 0.9858249425888062\n",
      "Substitute: confirmation, BertScore: 0.985759973526001\n",
      "Substitute: certification, BertScore: 0.9857208728790283\n",
      "Substitute: registration, BertScore: 0.985122561454773\n",
      "Substitute: placement, BertScore: 0.9830237030982971\n",
      "Substitute: acceptance, BertScore: 0.9829567074775696\n",
      "Substitute: accreditation, BertScore: 0.9826374053955078\n",
      "Substitute: consent, BertScore: 0.9825665950775146\n",
      "Substitute: selection, BertScore: 0.9819515943527222\n",
      "Substitute: recognition, BertScore: 0.9819237589836121\n",
      "Substitute: removal, BertScore: 0.9818001985549927\n",
      "Substitute: screening, BertScore: 0.9814932346343994\n",
      "Substitute: entry, BertScore: 0.9812737703323364\n",
      "Substitute: endorsement, BertScore: 0.9808053970336914\n",
      "Substitute: inspection, BertScore: 0.9806138873100281\n",
      "Substitute: compliance, BertScore: 0.9803803563117981\n",
      "Substitute: assistance, BertScore: 0.9803029298782349\n",
      "Substitute: admission, BertScore: 0.979778528213501\n",
      "Substitute: identification, BertScore: 0.9790341854095459\n",
      "Substitute: qualification, BertScore: 0.9788877964019775\n",
      "Substitute: permit, BertScore: 0.9786770343780518\n",
      "Substitute: security, BertScore: 0.9785903692245483\n",
      "Substitute: cooperation, BertScore: 0.9768109917640686\n",
      "Substitute: license, BertScore: 0.9761207699775696\n",
      "Substitute: travel, BertScore: 0.9750329256057739\n",
      "Substitute: boarding, BertScore: 0.9728158116340637\n",
      "top-10 substitutes based on bertscores in context: ['authorization', 'permission', 'protection', 'approval', 'confirmation', 'certification', 'registration', 'placement', 'acceptance', 'accreditation']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sympathy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: empathy, BertScore: 0.9967949986457825\n",
      "Substitute: compassion, BertScore: 0.9960980415344238\n",
      "Substitute: pity, BertScore: 0.995830774307251\n",
      "Substitute: affection, BertScore: 0.9955220222473145\n",
      "Substitute: support, BertScore: 0.9950112104415894\n",
      "Substitute: solidarity, BertScore: 0.9948704838752747\n",
      "Substitute: admiration, BertScore: 0.9942813515663147\n",
      "Substitute: respect, BertScore: 0.9941957592964172\n",
      "Substitute: love, BertScore: 0.9939607381820679\n",
      "Substitute: disgust, BertScore: 0.9938990473747253\n",
      "Substitute: concern, BertScore: 0.9934444427490234\n",
      "Substitute: anger, BertScore: 0.9930635094642639\n",
      "Substitute: appreciation, BertScore: 0.9930269718170166\n",
      "Substitute: goodwill, BertScore: 0.9929981827735901\n",
      "Substitute: gratitude, BertScore: 0.9928731918334961\n",
      "Substitute: mercy, BertScore: 0.9922402501106262\n",
      "Substitute: sadness, BertScore: 0.9921958446502686\n",
      "Substitute: assistance, BertScore: 0.9921248555183411\n",
      "Substitute: help, BertScore: 0.9914488196372986\n",
      "Substitute: comfort, BertScore: 0.9914230704307556\n",
      "Substitute: consolation, BertScore: 0.9910045266151428\n",
      "Substitute: relief, BertScore: 0.990864098072052\n",
      "Substitute: aid, BertScore: 0.9908477663993835\n",
      "Substitute: hope, BertScore: 0.9905009269714355\n",
      "Substitute: happiness, BertScore: 0.9903373122215271\n",
      "Substitute: protection, BertScore: 0.9901198744773865\n",
      "Substitute: care, BertScore: 0.9899672865867615\n",
      "Substitute: compensation, BertScore: 0.9893509745597839\n",
      "Substitute: interest, BertScore: 0.9887480735778809\n",
      "top-10 substitutes based on bertscores in context: ['empathy', 'compassion', 'pity', 'affection', 'support', 'solidarity', 'admiration', 'respect', 'love', 'disgust']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: composition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: piece, BertScore: 0.9937700033187866\n",
      "Substitute: music, BertScore: 0.9910224676132202\n",
      "Substitute: work, BertScore: 0.9909952878952026\n",
      "Substitute: arrangement, BertScore: 0.9908798336982727\n",
      "Substitute: recording, BertScore: 0.9901506900787354\n",
      "Substitute: song, BertScore: 0.9894701838493347\n",
      "Substitute: performance, BertScore: 0.9889745712280273\n",
      "Substitute: record, BertScore: 0.9885162115097046\n",
      "Substitute: score, BertScore: 0.9883878231048584\n",
      "Substitute: writing, BertScore: 0.9882099628448486\n",
      "Substitute: text, BertScore: 0.987618625164032\n",
      "Substitute: set, BertScore: 0.987432599067688\n",
      "Substitute: artwork, BertScore: 0.9871208667755127\n",
      "Substitute: album, BertScore: 0.9870035648345947\n",
      "Substitute: material, BertScore: 0.9866150617599487\n",
      "Substitute: melody, BertScore: 0.9858517050743103\n",
      "Substitute: instrument, BertScore: 0.9854454398155212\n",
      "Substitute: composed, BertScore: 0.9852403402328491\n",
      "Substitute: composer, BertScore: 0.9850174188613892\n",
      "Substitute: structure, BertScore: 0.9848124980926514\n",
      "Substitute: design, BertScore: 0.984723687171936\n",
      "Substitute: product, BertScore: 0.9839826226234436\n",
      "Substitute: picture, BertScore: 0.9838853478431702\n",
      "Substitute: image, BertScore: 0.9822829365730286\n",
      "Substitute: ensemble, BertScore: 0.9816757440567017\n",
      "Substitute: version, BertScore: 0.9812171459197998\n",
      "Substitute: orchestra, BertScore: 0.9799242615699768\n",
      "Substitute: style, BertScore: 0.9784495830535889\n",
      "top-10 substitutes based on bertscores in context: ['piece', 'music', 'work', 'arrangement', 'recording', 'song', 'performance', 'record', 'score', 'writing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sanctions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: restrictions, BertScore: 0.9919207692146301\n",
      "Substitute: penalties, BertScore: 0.9890958666801453\n",
      "Substitute: regulations, BertScore: 0.9875480532646179\n",
      "Substitute: rules, BertScore: 0.9862054586410522\n",
      "Substitute: punishments, BertScore: 0.9858772158622742\n",
      "Substitute: limits, BertScore: 0.9854027032852173\n",
      "Substitute: fines, BertScore: 0.9852441549301147\n",
      "Substitute: controls, BertScore: 0.9845991730690002\n",
      "Substitute: ban, BertScore: 0.9843990206718445\n",
      "Substitute: tariffs, BertScore: 0.9841890335083008\n",
      "Substitute: measures, BertScore: 0.9840280413627625\n",
      "Substitute: sentences, BertScore: 0.9839302897453308\n",
      "Substitute: punishment, BertScore: 0.9829698801040649\n",
      "Substitute: restraint, BertScore: 0.9824274778366089\n",
      "Substitute: conditions, BertScore: 0.982261598110199\n",
      "Substitute: incentives, BertScore: 0.9815739393234253\n",
      "Substitute: policies, BertScore: 0.9812778234481812\n",
      "Substitute: charges, BertScore: 0.9809244871139526\n",
      "Substitute: terms, BertScore: 0.9793669581413269\n",
      "Substitute: demands, BertScore: 0.9790900945663452\n",
      "Substitute: resolutions, BertScore: 0.9787032008171082\n",
      "Substitute: threats, BertScore: 0.9775005578994751\n",
      "Substitute: pressures, BertScore: 0.9768808484077454\n",
      "Substitute: barriers, BertScore: 0.9768800735473633\n",
      "Substitute: pressure, BertScore: 0.9766056537628174\n",
      "Substitute: condemnation, BertScore: 0.9763159155845642\n",
      "Substitute: caps, BertScore: 0.97623211145401\n",
      "Substitute: consequences, BertScore: 0.9733297824859619\n",
      "Substitute: attacks, BertScore: 0.9724884033203125\n",
      "top-10 substitutes based on bertscores in context: ['restrictions', 'penalties', 'regulations', 'rules', 'punishments', 'limits', 'fines', 'controls', 'ban', 'tariffs']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: executed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: hanged, BertScore: 0.9895705580711365\n",
      "Substitute: murdered, BertScore: 0.9892910718917847\n",
      "Substitute: assassinated, BertScore: 0.9882625341415405\n",
      "Substitute: killed, BertScore: 0.9874081611633301\n",
      "Substitute: beheaded, BertScore: 0.9871948957443237\n",
      "Substitute: slain, BertScore: 0.9869322776794434\n",
      "Substitute: captured, BertScore: 0.986539900302887\n",
      "Substitute: deposed, BertScore: 0.9853147268295288\n",
      "Substitute: imprisoned, BertScore: 0.9849528074264526\n",
      "Substitute: arrested, BertScore: 0.9845665097236633\n",
      "Substitute: tried, BertScore: 0.9830456972122192\n",
      "Substitute: deported, BertScore: 0.982907235622406\n",
      "Substitute: kidnapped, BertScore: 0.9827898740768433\n",
      "Substitute: jailed, BertScore: 0.9827167391777039\n",
      "Substitute: detained, BertScore: 0.982661247253418\n",
      "Substitute: ousted, BertScore: 0.9818467497825623\n",
      "Substitute: tortured, BertScore: 0.9818267226219177\n",
      "Substitute: expelled, BertScore: 0.981711208820343\n",
      "Substitute: freed, BertScore: 0.98164302110672\n",
      "Substitute: convicted, BertScore: 0.9816293120384216\n",
      "Substitute: indicted, BertScore: 0.9812817573547363\n",
      "Substitute: shot, BertScore: 0.9810672998428345\n",
      "Substitute: sentenced, BertScore: 0.9800198674201965\n",
      "Substitute: fired, BertScore: 0.9785394072532654\n",
      "Substitute: punished, BertScore: 0.9784037470817566\n",
      "Substitute: prosecuted, BertScore: 0.9767455458641052\n",
      "Substitute: acquitted, BertScore: 0.9764949083328247\n",
      "Substitute: poisoned, BertScore: 0.9738979339599609\n",
      "Substitute: released, BertScore: 0.9706509113311768\n",
      "top-10 substitutes based on bertscores in context: ['hanged', 'murdered', 'assassinated', 'killed', 'beheaded', 'slain', 'captured', 'deposed', 'imprisoned', 'arrested']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: flashpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: objective, BertScore: 0.9424222111701965\n",
      "Substitute: buffer, BertScore: 0.9417638778686523\n",
      "Substitute: targeted, BertScore: 0.9385161399841309\n",
      "Substitute: observation, BertScore: 0.9378197193145752\n",
      "Substitute: target, BertScore: 0.9375699162483215\n",
      "Substitute: field, BertScore: 0.9371992349624634\n",
      "Substitute: surveillance, BertScore: 0.9363473653793335\n",
      "Substitute: tactical, BertScore: 0.9362359642982483\n",
      "Substitute: critical, BertScore: 0.9359483122825623\n",
      "Substitute: isolated, BertScore: 0.9352701306343079\n",
      "Substitute: open, BertScore: 0.9344135522842407\n",
      "Substitute: strategic, BertScore: 0.9333934783935547\n",
      "Substitute: battlefield, BertScore: 0.9333010911941528\n",
      "Substitute: vulnerable, BertScore: 0.933157205581665\n",
      "Substitute: mission, BertScore: 0.9330057501792908\n",
      "Substitute: reconnaissance, BertScore: 0.9318993091583252\n",
      "Substitute: deployed, BertScore: 0.9318523406982422\n",
      "Substitute: security, BertScore: 0.9309861063957214\n",
      "Substitute: operational, BertScore: 0.9306730031967163\n",
      "Substitute: remote, BertScore: 0.9299479722976685\n",
      "Substitute: protected, BertScore: 0.9297996163368225\n",
      "Substitute: coastal, BertScore: 0.9293461441993713\n",
      "Substitute: safe, BertScore: 0.929027259349823\n",
      "Substitute: deployment, BertScore: 0.9280881285667419\n",
      "Substitute: combat, BertScore: 0.9267706274986267\n",
      "Substitute: military, BertScore: 0.9267000555992126\n",
      "Substitute: small, BertScore: 0.9224578142166138\n",
      "Substitute: large, BertScore: 0.9212789535522461\n",
      "Substitute: the, BertScore: 0.9156801104545593\n",
      "Substitute: these, BertScore: 0.9120566844940186\n",
      "top-10 substitutes based on bertscores in context: ['objective', 'buffer', 'targeted', 'observation', 'target', 'field', 'surveillance', 'tactical', 'critical', 'isolated']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: assumption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: assertion, BertScore: 0.9944528937339783\n",
      "Substitute: inference, BertScore: 0.9937606453895569\n",
      "Substitute: belief, BertScore: 0.993522047996521\n",
      "Substitute: assume, BertScore: 0.9933500289916992\n",
      "Substitute: hypothesis, BertScore: 0.9926526546478271\n",
      "Substitute: theory, BertScore: 0.9924906492233276\n",
      "Substitute: conclusion, BertScore: 0.9923141598701477\n",
      "Substitute: perception, BertScore: 0.9922653436660767\n",
      "Substitute: assessment, BertScore: 0.9920049905776978\n",
      "Substitute: premise, BertScore: 0.9919188618659973\n",
      "Substitute: estimate, BertScore: 0.9913028478622437\n",
      "Substitute: expectation, BertScore: 0.9907771944999695\n",
      "Substitute: claim, BertScore: 0.990598201751709\n",
      "Substitute: guess, BertScore: 0.9904546737670898\n",
      "Substitute: impression, BertScore: 0.9901976585388184\n",
      "Substitute: certainty, BertScore: 0.9899345636367798\n",
      "Substitute: prediction, BertScore: 0.9896343350410461\n",
      "Substitute: observation, BertScore: 0.9894703030586243\n",
      "Substitute: position, BertScore: 0.9890509843826294\n",
      "Substitute: proposition, BertScore: 0.988752007484436\n",
      "Substitute: idea, BertScore: 0.9885504841804504\n",
      "Substitute: statement, BertScore: 0.987949788570404\n",
      "Substitute: knowledge, BertScore: 0.986147403717041\n",
      "Substitute: finding, BertScore: 0.9845064282417297\n",
      "Substitute: decision, BertScore: 0.984125018119812\n",
      "Substitute: discovery, BertScore: 0.9840731024742126\n",
      "Substitute: bet, BertScore: 0.9832121133804321\n",
      "Substitute: experience, BertScore: 0.9764922857284546\n",
      "top-10 substitutes based on bertscores in context: ['assertion', 'inference', 'belief', 'assume', 'hypothesis', 'theory', 'conclusion', 'perception', 'assessment', 'premise']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: apparent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: obvious, BertScore: 0.9902149438858032\n",
      "Substitute: evident, BertScore: 0.9883602261543274\n",
      "Substitute: alleged, BertScore: 0.9839348793029785\n",
      "Substitute: identified, BertScore: 0.9809794425964355\n",
      "Substitute: visible, BertScore: 0.9809746146202087\n",
      "Substitute: unspecified, BertScore: 0.9793128967285156\n",
      "Substitute: unusual, BertScore: 0.9786696434020996\n",
      "Substitute: unmistakable, BertScore: 0.9780956506729126\n",
      "Substitute: unknown, BertScore: 0.9780436158180237\n",
      "Substitute: obscure, BertScore: 0.9780021905899048\n",
      "Substitute: unidentified, BertScore: 0.9761974215507507\n",
      "Substitute: explicit, BertScore: 0.9761260747909546\n",
      "Substitute: identifiable, BertScore: 0.975858211517334\n",
      "Substitute: invisible, BertScore: 0.9747140407562256\n",
      "Substitute: extensive, BertScore: 0.9739252328872681\n",
      "Substitute: extreme, BertScore: 0.9739185571670532\n",
      "Substitute: actual, BertScore: 0.9731515049934387\n",
      "Substitute: angry, BertScore: 0.9726276993751526\n",
      "Substitute: immediate, BertScore: 0.9723194241523743\n",
      "Substitute: overall, BertScore: 0.9717953205108643\n",
      "Substitute: official, BertScore: 0.970994770526886\n",
      "Substitute: absolute, BertScore: 0.9708060026168823\n",
      "Substitute: instant, BertScore: 0.9698415994644165\n",
      "Substitute: iraqi, BertScore: 0.9676069021224976\n",
      "Substitute: electronic, BertScore: 0.9666211009025574\n",
      "Substitute: enlarged, BertScore: 0.9660605192184448\n",
      "Substitute: accompanying, BertScore: 0.965763509273529\n",
      "Substitute: additional, BertScore: 0.965380847454071\n",
      "Substitute: automatic, BertScore: 0.9644444584846497\n",
      "top-10 substitutes based on bertscores in context: ['obvious', 'evident', 'alleged', 'identified', 'visible', 'unspecified', 'unusual', 'unmistakable', 'unknown', 'obscure']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: appealed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: petitioned, BertScore: 0.9856243133544922\n",
      "Substitute: lobbied, BertScore: 0.9756020307540894\n",
      "Substitute: pleaded, BertScore: 0.9754073023796082\n",
      "Substitute: begged, BertScore: 0.9720268249511719\n",
      "Substitute: argued, BertScore: 0.9712799787521362\n",
      "Substitute: pushed, BertScore: 0.9685420989990234\n",
      "Substitute: pressed, BertScore: 0.9678127765655518\n",
      "Substitute: urged, BertScore: 0.9670939445495605\n",
      "Substitute: requested, BertScore: 0.9666547775268555\n",
      "Substitute: demanded, BertScore: 0.9648627042770386\n",
      "Substitute: asked, BertScore: 0.9637056589126587\n",
      "Substitute: called, BertScore: 0.9616420269012451\n",
      "Substitute: applied, BertScore: 0.9592596292495728\n",
      "Substitute: offered, BertScore: 0.9570061564445496\n",
      "Substitute: sought, BertScore: 0.9565857648849487\n",
      "Substitute: sued, BertScore: 0.9551138877868652\n",
      "Substitute: motioned, BertScore: 0.9539632797241211\n",
      "Substitute: wished, BertScore: 0.9482694268226624\n",
      "Substitute: voted, BertScore: 0.9482437372207642\n",
      "Substitute: threatened, BertScore: 0.9481350183486938\n",
      "Substitute: filed, BertScore: 0.9475088119506836\n",
      "Substitute: arranged, BertScore: 0.9464045763015747\n",
      "Substitute: tried, BertScore: 0.9451439380645752\n",
      "Substitute: refused, BertScore: 0.9450399875640869\n",
      "Substitute: fought, BertScore: 0.9426884651184082\n",
      "Substitute: declined, BertScore: 0.9424307346343994\n",
      "Substitute: written, BertScore: 0.942216694355011\n",
      "Substitute: waited, BertScore: 0.909752607345581\n",
      "top-10 substitutes based on bertscores in context: ['petitioned', 'lobbied', 'pleaded', 'begged', 'argued', 'pushed', 'pressed', 'urged', 'requested', 'demanded']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: casualties\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: fatalities, BertScore: 0.9574570059776306\n",
      "Substitute: losses, BertScore: 0.9392591714859009\n",
      "Substitute: deaths, BertScore: 0.9381786584854126\n",
      "Substitute: injured, BertScore: 0.9324800968170166\n",
      "Substitute: injuries, BertScore: 0.9312499165534973\n",
      "Substitute: wounded, BertScore: 0.9288800954818726\n",
      "Substitute: killed, BertScore: 0.9273474216461182\n",
      "Substitute: victims, BertScore: 0.9149296283721924\n",
      "Substitute: dead, BertScore: 0.9139841198921204\n",
      "Substitute: killings, BertScore: 0.911151647567749\n",
      "Substitute: survivors, BertScore: 0.8973489999771118\n",
      "Substitute: damage, BertScore: 0.897082507610321\n",
      "Substitute: incidents, BertScore: 0.8947056531906128\n",
      "Substitute: civilians, BertScore: 0.8919413089752197\n",
      "Substitute: attacks, BertScore: 0.8895079493522644\n",
      "Substitute: bodies, BertScore: 0.8881876468658447\n",
      "Substitute: damages, BertScore: 0.8847537636756897\n",
      "Substitute: loss, BertScore: 0.8820189833641052\n",
      "Substitute: cases, BertScore: 0.8758875131607056\n",
      "Substitute: soldiers, BertScore: 0.8702771663665771\n",
      "Substitute: figures, BertScore: 0.859807014465332\n",
      "Substitute: numbers, BertScore: 0.8577867746353149\n",
      "Substitute: reports, BertScore: 0.8509789705276489\n",
      "Substitute: total, BertScore: 0.8297240734100342\n",
      "Substitute: others, BertScore: 0.8255023956298828\n",
      "Substitute: results, BertScore: 0.8227130174636841\n",
      "Substitute: rest, BertScore: 0.8142946362495422\n",
      "Substitute: scores, BertScore: 0.7877592444419861\n",
      "top-10 substitutes based on bertscores in context: ['fatalities', 'losses', 'deaths', 'injured', 'injuries', 'wounded', 'killed', 'victims', 'dead', 'killings']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: qualify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: qualified, BertScore: 0.992877721786499\n",
      "Substitute: advance, BertScore: 0.988720178604126\n",
      "Substitute: register, BertScore: 0.9882291555404663\n",
      "Substitute: enter, BertScore: 0.984075129032135\n",
      "Substitute: apply, BertScore: 0.9838602542877197\n",
      "Substitute: prepare, BertScore: 0.982996940612793\n",
      "Substitute: compete, BertScore: 0.9819520711898804\n",
      "Substitute: participate, BertScore: 0.9818990230560303\n",
      "Substitute: appear, BertScore: 0.9811954498291016\n",
      "Substitute: tie, BertScore: 0.9806719422340393\n",
      "Substitute: prep, BertScore: 0.9799020886421204\n",
      "Substitute: win, BertScore: 0.9798986315727234\n",
      "Substitute: audition, BertScore: 0.9797969460487366\n",
      "Substitute: bid, BertScore: 0.9787650108337402\n",
      "Substitute: make, BertScore: 0.9786803126335144\n",
      "Substitute: return, BertScore: 0.9784792065620422\n",
      "Substitute: land, BertScore: 0.9783246517181396\n",
      "Substitute: pass, BertScore: 0.9782458543777466\n",
      "Substitute: test, BertScore: 0.9777714014053345\n",
      "Substitute: train, BertScore: 0.9767610430717468\n",
      "Substitute: play, BertScore: 0.9754636287689209\n",
      "Substitute: act, BertScore: 0.9748867750167847\n",
      "Substitute: pitch, BertScore: 0.9745035171508789\n",
      "Substitute: remain, BertScore: 0.9742357134819031\n",
      "Substitute: score, BertScore: 0.9741820096969604\n",
      "Substitute: form, BertScore: 0.9739239811897278\n",
      "Substitute: sign, BertScore: 0.9738900661468506\n",
      "Substitute: skate, BertScore: 0.9699856042861938\n",
      "top-10 substitutes based on bertscores in context: ['qualified', 'advance', 'register', 'enter', 'apply', 'prepare', 'compete', 'participate', 'appear', 'tie']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: acquisition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: purchase, BertScore: 0.9918375611305237\n",
      "Substitute: sale, BertScore: 0.9854167699813843\n",
      "Substitute: transaction, BertScore: 0.9846919775009155\n",
      "Substitute: takeover, BertScore: 0.984235405921936\n",
      "Substitute: merger, BertScore: 0.9827613234519958\n",
      "Substitute: deal, BertScore: 0.9819526076316833\n",
      "Substitute: investment, BertScore: 0.981395959854126\n",
      "Substitute: move, BertScore: 0.98103928565979\n",
      "Substitute: venture, BertScore: 0.9770066142082214\n",
      "Substitute: development, BertScore: 0.9753925800323486\n",
      "Substitute: offer, BertScore: 0.9749001264572144\n",
      "Substitute: contract, BertScore: 0.9743180274963379\n",
      "Substitute: bid, BertScore: 0.9736932516098022\n",
      "Substitute: announcement, BertScore: 0.9734014868736267\n",
      "Substitute: project, BertScore: 0.9728833436965942\n",
      "Substitute: agreement, BertScore: 0.971932053565979\n",
      "Substitute: initiative, BertScore: 0.9707193374633789\n",
      "Substitute: decision, BertScore: 0.9692381620407104\n",
      "Substitute: program, BertScore: 0.9687439203262329\n",
      "Substitute: package, BertScore: 0.9685962796211243\n",
      "Substitute: proposal, BertScore: 0.9683067798614502\n",
      "Substitute: plan, BertScore: 0.9674254059791565\n",
      "Substitute: product, BertScore: 0.9650546908378601\n",
      "Substitute: company, BertScore: 0.9643404483795166\n",
      "Substitute: document, BertScore: 0.9605228900909424\n",
      "Substitute: result, BertScore: 0.9559177160263062\n",
      "Substitute: results, BertScore: 0.950390636920929\n",
      "Substitute: first, BertScore: 0.9378174543380737\n",
      "top-10 substitutes based on bertscores in context: ['purchase', 'sale', 'transaction', 'takeover', 'merger', 'deal', 'investment', 'move', 'venture', 'development']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: pedestal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: podium, BertScore: 0.9931181073188782\n",
      "Substitute: stand, BertScore: 0.9926131963729858\n",
      "Substitute: platform, BertScore: 0.9925316572189331\n",
      "Substitute: mount, BertScore: 0.9924923181533813\n",
      "Substitute: slab, BertScore: 0.9907257556915283\n",
      "Substitute: bench, BertScore: 0.9905377626419067\n",
      "Substitute: throne, BertScore: 0.990190863609314\n",
      "Substitute: pillar, BertScore: 0.9899417161941528\n",
      "Substitute: tray, BertScore: 0.9895837903022766\n",
      "Substitute: shelf, BertScore: 0.9889636039733887\n",
      "Substitute: perch, BertScore: 0.9882713556289673\n",
      "Substitute: table, BertScore: 0.9882463216781616\n",
      "Substitute: ledge, BertScore: 0.9881175756454468\n",
      "Substitute: plate, BertScore: 0.9876362681388855\n",
      "Substitute: row, BertScore: 0.987200915813446\n",
      "Substitute: panel, BertScore: 0.9871706366539001\n",
      "Substitute: stage, BertScore: 0.9870796203613281\n",
      "Substitute: chair, BertScore: 0.9864076375961304\n",
      "Substitute: floor, BertScore: 0.9856151938438416\n",
      "Substitute: heap, BertScore: 0.9853895306587219\n",
      "Substitute: mound, BertScore: 0.9852836728096008\n",
      "Substitute: peak, BertScore: 0.9850096702575684\n",
      "Substitute: altar, BertScore: 0.984436571598053\n",
      "Substitute: level, BertScore: 0.9840410351753235\n",
      "Substitute: plateau, BertScore: 0.9818344116210938\n",
      "Substitute: scale, BertScore: 0.9817612767219543\n",
      "Substitute: rock, BertScore: 0.9803391695022583\n",
      "Substitute: hill, BertScore: 0.9764044284820557\n",
      "Substitute: mountain, BertScore: 0.9738367795944214\n",
      "top-10 substitutes based on bertscores in context: ['podium', 'stand', 'platform', 'mount', 'slab', 'bench', 'throne', 'pillar', 'tray', 'shelf']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sustained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: severe, BertScore: 0.9950611591339111\n",
      "Substitute: strong, BertScore: 0.9950059652328491\n",
      "Substitute: consistent, BertScore: 0.9949545860290527\n",
      "Substitute: persistent, BertScore: 0.9949118494987488\n",
      "Substitute: prolonged, BertScore: 0.994910478591919\n",
      "Substitute: heavy, BertScore: 0.9948732852935791\n",
      "Substitute: repeated, BertScore: 0.9947088956832886\n",
      "Substitute: serious, BertScore: 0.9947032928466797\n",
      "Substitute: intense, BertScore: 0.9946134686470032\n",
      "Substitute: significant, BertScore: 0.994604766368866\n",
      "Substitute: fierce, BertScore: 0.9942740797996521\n",
      "Substitute: vigorous, BertScore: 0.9942484498023987\n",
      "Substitute: sporadic, BertScore: 0.9941592812538147\n",
      "Substitute: steady, BertScore: 0.9940344095230103\n",
      "Substitute: sharp, BertScore: 0.9938493967056274\n",
      "Substitute: continued, BertScore: 0.993727445602417\n",
      "Substitute: swift, BertScore: 0.9936769008636475\n",
      "Substitute: constant, BertScore: 0.9934216737747192\n",
      "Substitute: numerous, BertScore: 0.9933762550354004\n",
      "Substitute: active, BertScore: 0.9930183291435242\n",
      "Substitute: frequent, BertScore: 0.9929306507110596\n",
      "Substitute: focused, BertScore: 0.9929244518280029\n",
      "Substitute: painful, BertScore: 0.9927932024002075\n",
      "Substitute: coordinated, BertScore: 0.9927523136138916\n",
      "Substitute: widespread, BertScore: 0.9926275610923767\n",
      "Substitute: staged, BertScore: 0.9922787547111511\n",
      "Substitute: violent, BertScore: 0.9922099709510803\n",
      "Substitute: motivated, BertScore: 0.9915732145309448\n",
      "Substitute: recent, BertScore: 0.9890552163124084\n",
      "top-10 substitutes based on bertscores in context: ['severe', 'strong', 'consistent', 'persistent', 'prolonged', 'heavy', 'repeated', 'serious', 'intense', 'significant']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: prevailing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: prevalent, BertScore: 0.9718708992004395\n",
      "Substitute: predominant, BertScore: 0.9704686999320984\n",
      "Substitute: existing, BertScore: 0.9670150279998779\n",
      "Substitute: reigning, BertScore: 0.9643069505691528\n",
      "Substitute: competing, BertScore: 0.9635649919509888\n",
      "Substitute: operating, BertScore: 0.9613543152809143\n",
      "Substitute: dominant, BertScore: 0.9557771682739258\n",
      "Substitute: settling, BertScore: 0.9554493427276611\n",
      "Substitute: fighting, BertScore: 0.9542009830474854\n",
      "Substitute: winning, BertScore: 0.9541196227073669\n",
      "Substitute: present, BertScore: 0.9527061581611633\n",
      "Substitute: mixing, BertScore: 0.9521138668060303\n",
      "Substitute: growing, BertScore: 0.9514961838722229\n",
      "Substitute: participating, BertScore: 0.9513319134712219\n",
      "Substitute: working, BertScore: 0.9507794380187988\n",
      "Substitute: common, BertScore: 0.9506056904792786\n",
      "Substitute: neutral, BertScore: 0.9500160217285156\n",
      "Substitute: living, BertScore: 0.9483203291893005\n",
      "Substitute: engaging, BertScore: 0.9482791423797607\n",
      "Substitute: engaged, BertScore: 0.947428822517395\n",
      "Substitute: being, BertScore: 0.947348952293396\n",
      "Substitute: brewing, BertScore: 0.946752667427063\n",
      "Substitute: changing, BertScore: 0.9454132914543152\n",
      "Substitute: staying, BertScore: 0.9452193975448608\n",
      "Substitute: continuing, BertScore: 0.943213164806366\n",
      "Substitute: involved, BertScore: 0.9406325817108154\n",
      "Substitute: also, BertScore: 0.9380345940589905\n",
      "Substitute: consistent, BertScore: 0.9361213445663452\n",
      "Substitute: not, BertScore: 0.932237982749939\n",
      "top-10 substitutes based on bertscores in context: ['prevalent', 'predominant', 'existing', 'reigning', 'competing', 'operating', 'dominant', 'settling', 'fighting', 'winning']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: imposing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: enforcing, BertScore: 0.997650146484375\n",
      "Substitute: installing, BertScore: 0.9969402551651001\n",
      "Substitute: placing, BertScore: 0.9965530633926392\n",
      "Substitute: asserting, BertScore: 0.9964527487754822\n",
      "Substitute: implementing, BertScore: 0.9963135719299316\n",
      "Substitute: establishing, BertScore: 0.9960252046585083\n",
      "Substitute: projecting, BertScore: 0.9959115982055664\n",
      "Substitute: exercising, BertScore: 0.9959057569503784\n",
      "Substitute: forcing, BertScore: 0.9953371286392212\n",
      "Substitute: issuing, BertScore: 0.9952595829963684\n",
      "Substitute: maintaining, BertScore: 0.9951441287994385\n",
      "Substitute: applying, BertScore: 0.9951153993606567\n",
      "Substitute: setting, BertScore: 0.9951089024543762\n",
      "Substitute: putting, BertScore: 0.9949051141738892\n",
      "Substitute: creating, BertScore: 0.9948493242263794\n",
      "Substitute: employing, BertScore: 0.9947659969329834\n",
      "Substitute: building, BertScore: 0.9945856332778931\n",
      "Substitute: adding, BertScore: 0.9943795800209045\n",
      "Substitute: declaring, BertScore: 0.9942936897277832\n",
      "Substitute: forming, BertScore: 0.9941667318344116\n",
      "Substitute: developing, BertScore: 0.9941648244857788\n",
      "Substitute: insisting, BertScore: 0.9937441945075989\n",
      "Substitute: advocating, BertScore: 0.99362713098526\n",
      "Substitute: pressing, BertScore: 0.9935441017150879\n",
      "Substitute: pushing, BertScore: 0.9932048916816711\n",
      "Substitute: slapping, BertScore: 0.9920623302459717\n",
      "Substitute: crushing, BertScore: 0.9920238256454468\n",
      "Substitute: striking, BertScore: 0.9919068217277527\n",
      "top-10 substitutes based on bertscores in context: ['enforcing', 'installing', 'placing', 'asserting', 'implementing', 'establishing', 'projecting', 'exercising', 'forcing', 'issuing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: Initially\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: originally, BertScore: 0.9936692118644714\n",
      "Substitute: previously, BertScore: 0.9819890856742859\n",
      "Substitute: formerly, BertScore: 0.9798840880393982\n",
      "Substitute: earlier, BertScore: 0.9773321151733398\n",
      "Substitute: briefly, BertScore: 0.9703805446624756\n",
      "Substitute: officially, BertScore: 0.9684228897094727\n",
      "Substitute: historically, BertScore: 0.9658825993537903\n",
      "Substitute: eventually, BertScore: 0.9653818011283875\n",
      "Substitute: subsequently, BertScore: 0.964846670627594\n",
      "Substitute: ultimately, BertScore: 0.9644916653633118\n",
      "Substitute: later, BertScore: 0.9638703465461731\n",
      "Substitute: generally, BertScore: 0.9626949429512024\n",
      "Substitute: traditionally, BertScore: 0.9621003270149231\n",
      "Substitute: typically, BertScore: 0.9599213004112244\n",
      "Substitute: technically, BertScore: 0.9595427513122559\n",
      "Substitute: recently, BertScore: 0.9583367109298706\n",
      "Substitute: currently, BertScore: 0.9581928849220276\n",
      "Substitute: consequently, BertScore: 0.9556870460510254\n",
      "Substitute: first, BertScore: 0.954448938369751\n",
      "Substitute: finally, BertScore: 0.9539316892623901\n",
      "Substitute: however, BertScore: 0.9532119035720825\n",
      "Substitute: additionally, BertScore: 0.9530280232429504\n",
      "Substitute: alternatively, BertScore: 0.9516862630844116\n",
      "Substitute: instead, BertScore: 0.9513921737670898\n",
      "Substitute: thus, BertScore: 0.951254665851593\n",
      "Substitute: furthermore, BertScore: 0.9512530565261841\n",
      "Substitute: today, BertScore: 0.9510402679443359\n",
      "Substitute: then, BertScore: 0.9495065212249756\n",
      "Substitute: now, BertScore: 0.9364821314811707\n",
      "top-10 substitutes based on bertscores in context: ['originally', 'previously', 'formerly', 'earlier', 'briefly', 'officially', 'historically', 'eventually', 'subsequently', 'ultimately']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: regime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: government, BertScore: 0.9917852282524109\n",
      "Substitute: administration, BertScore: 0.9883639812469482\n",
      "Substitute: state, BertScore: 0.9875561594963074\n",
      "Substitute: authorities, BertScore: 0.985267162322998\n",
      "Substitute: opposition, BertScore: 0.9836839437484741\n",
      "Substitute: military, BertScore: 0.9828205108642578\n",
      "Substitute: authority, BertScore: 0.9824002981185913\n",
      "Substitute: leadership, BertScore: 0.9818239808082581\n",
      "Substitute: republic, BertScore: 0.981279730796814\n",
      "Substitute: nation, BertScore: 0.9804458618164062\n",
      "Substitute: forces, BertScore: 0.9804437160491943\n",
      "Substitute: rebels, BertScore: 0.9795956611633301\n",
      "Substitute: country, BertScore: 0.9787574410438538\n",
      "Substitute: army, BertScore: 0.9785510301589966\n",
      "Substitute: president, BertScore: 0.9768511056900024\n",
      "Substitute: leader, BertScore: 0.9762481451034546\n",
      "Substitute: people, BertScore: 0.9761918187141418\n",
      "Substitute: leaders, BertScore: 0.9750950932502747\n",
      "Substitute: community, BertScore: 0.9739388823509216\n",
      "Substitute: population, BertScore: 0.9732531309127808\n",
      "Substitute: minority, BertScore: 0.9703518152236938\n",
      "Substitute: countries, BertScore: 0.9700782299041748\n",
      "Substitute: side, BertScore: 0.9688275456428528\n",
      "Substitute: civilians, BertScore: 0.9671431183815002\n",
      "Substitute: embassy, BertScore: 0.9667256474494934\n",
      "Substitute: detainees, BertScore: 0.9642994999885559\n",
      "Substitute: prisoners, BertScore: 0.9614741802215576\n",
      "top-10 substitutes based on bertscores in context: ['government', 'administration', 'state', 'authorities', 'opposition', 'military', 'authority', 'leadership', 'republic', 'nation']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: dominated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: controlled, BertScore: 0.9930635690689087\n",
      "Substitute: commanded, BertScore: 0.9920982122421265\n",
      "Substitute: ruled, BertScore: 0.9907412528991699\n",
      "Substitute: governed, BertScore: 0.9885656833648682\n",
      "Substitute: powered, BertScore: 0.9880934357643127\n",
      "Substitute: led, BertScore: 0.9879640340805054\n",
      "Substitute: occupied, BertScore: 0.9872812628746033\n",
      "Substitute: defeated, BertScore: 0.9864351749420166\n",
      "Substitute: held, BertScore: 0.9862959384918213\n",
      "Substitute: run, BertScore: 0.9862285852432251\n",
      "Substitute: surrounded, BertScore: 0.9860863089561462\n",
      "Substitute: managed, BertScore: 0.9854742288589478\n",
      "Substitute: contested, BertScore: 0.9850291013717651\n",
      "Substitute: penetrated, BertScore: 0.984874427318573\n",
      "Substitute: owned, BertScore: 0.9846740365028381\n",
      "Substitute: won, BertScore: 0.984478771686554\n",
      "Substitute: represented, BertScore: 0.9835996031761169\n",
      "Substitute: organized, BertScore: 0.9827868938446045\n",
      "Substitute: invaded, BertScore: 0.9825620055198669\n",
      "Substitute: overseen, BertScore: 0.9825466871261597\n",
      "Substitute: battled, BertScore: 0.9824105501174927\n",
      "Substitute: opposed, BertScore: 0.9812074303627014\n",
      "Substitute: played, BertScore: 0.9807000756263733\n",
      "Substitute: driven, BertScore: 0.980617880821228\n",
      "Substitute: supported, BertScore: 0.9796231389045715\n",
      "Substitute: supervised, BertScore: 0.9792379140853882\n",
      "Substitute: backed, BertScore: 0.9787775278091431\n",
      "Substitute: watched, BertScore: 0.976365327835083\n",
      "top-10 substitutes based on bertscores in context: ['controlled', 'commanded', 'ruled', 'governed', 'powered', 'led', 'occupied', 'defeated', 'held', 'run']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: authorized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: authorised, BertScore: 0.9974228739738464\n",
      "Substitute: mandated, BertScore: 0.9937849044799805\n",
      "Substitute: empowered, BertScore: 0.993472695350647\n",
      "Substitute: permitted, BertScore: 0.9930097460746765\n",
      "Substitute: ordered, BertScore: 0.9925860166549683\n",
      "Substitute: sanctioned, BertScore: 0.9925398230552673\n",
      "Substitute: directed, BertScore: 0.991251528263092\n",
      "Substitute: licensed, BertScore: 0.9910281300544739\n",
      "Substitute: instructed, BertScore: 0.9909670948982239\n",
      "Substitute: allowed, BertScore: 0.9906595945358276\n",
      "Substitute: organized, BertScore: 0.9898908138275146\n",
      "Substitute: required, BertScore: 0.9896436333656311\n",
      "Substitute: approved, BertScore: 0.98957759141922\n",
      "Substitute: appointed, BertScore: 0.9879598617553711\n",
      "Substitute: initiated, BertScore: 0.9866437911987305\n",
      "Substitute: requested, BertScore: 0.9862691760063171\n",
      "Substitute: granted, BertScore: 0.9852586984634399\n",
      "Substitute: forced, BertScore: 0.9851551055908203\n",
      "Substitute: asked, BertScore: 0.9845481514930725\n",
      "Substitute: allotted, BertScore: 0.9845288395881653\n",
      "Substitute: authorization, BertScore: 0.9843684434890747\n",
      "Substitute: entitled, BertScore: 0.9841300845146179\n",
      "Substitute: extended, BertScore: 0.9837026000022888\n",
      "Substitute: appropriated, BertScore: 0.9824250936508179\n",
      "Substitute: established, BertScore: 0.9813544750213623\n",
      "Substitute: urged, BertScore: 0.980868935585022\n",
      "Substitute: elected, BertScore: 0.9786510467529297\n",
      "Substitute: enacted, BertScore: 0.9776796102523804\n",
      "Substitute: petitioned, BertScore: 0.9760330319404602\n",
      "top-10 substitutes based on bertscores in context: ['authorised', 'mandated', 'empowered', 'permitted', 'ordered', 'sanctioned', 'directed', 'licensed', 'instructed', 'allowed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: slated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: scheduled, BertScore: 0.9947842359542847\n",
      "Substitute: set, BertScore: 0.9912605881690979\n",
      "Substitute: planning, BertScore: 0.9907783269882202\n",
      "Substitute: due, BertScore: 0.9906206130981445\n",
      "Substitute: planned, BertScore: 0.9894896745681763\n",
      "Substitute: expected, BertScore: 0.9893639087677002\n",
      "Substitute: projected, BertScore: 0.9890020489692688\n",
      "Substitute: anticipated, BertScore: 0.9888778924942017\n",
      "Substitute: destined, BertScore: 0.9887640476226807\n",
      "Substitute: intended, BertScore: 0.9875137805938721\n",
      "Substitute: preparing, BertScore: 0.9869498610496521\n",
      "Substitute: about, BertScore: 0.9867540001869202\n",
      "Substitute: poised, BertScore: 0.9866648316383362\n",
      "Substitute: going, BertScore: 0.9864284992218018\n",
      "Substitute: aiming, BertScore: 0.9862126708030701\n",
      "Substitute: heading, BertScore: 0.9860192537307739\n",
      "Substitute: supposed, BertScore: 0.9859074354171753\n",
      "Substitute: predicted, BertScore: 0.9857154488563538\n",
      "Substitute: expecting, BertScore: 0.9851890802383423\n",
      "Substitute: likely, BertScore: 0.9849263429641724\n",
      "Substitute: hoping, BertScore: 0.9824490547180176\n",
      "Substitute: prepared, BertScore: 0.9821335077285767\n",
      "Substitute: certain, BertScore: 0.9795076847076416\n",
      "Substitute: ready, BertScore: 0.9794777631759644\n",
      "Substitute: unlikely, BertScore: 0.978151261806488\n",
      "Substitute: considered, BertScore: 0.9744222164154053\n",
      "Substitute: willing, BertScore: 0.973239004611969\n",
      "Substitute: probably, BertScore: 0.9723746180534363\n",
      "Substitute: yet, BertScore: 0.9715580344200134\n",
      "top-10 substitutes based on bertscores in context: ['scheduled', 'set', 'planning', 'due', 'planned', 'expected', 'projected', 'anticipated', 'destined', 'intended']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: regrettable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: terrible, BertScore: 0.9754520654678345\n",
      "Substitute: unfortunate, BertScore: 0.9739758968353271\n",
      "Substitute: painful, BertScore: 0.97358238697052\n",
      "Substitute: dreadful, BertScore: 0.9727730751037598\n",
      "Substitute: disastrous, BertScore: 0.9725322723388672\n",
      "Substitute: horrible, BertScore: 0.972281813621521\n",
      "Substitute: colossal, BertScore: 0.9717599153518677\n",
      "Substitute: tragic, BertScore: 0.9716135859489441\n",
      "Substitute: catastrophic, BertScore: 0.9711822867393494\n",
      "Substitute: serious, BertScore: 0.9707968235015869\n",
      "Substitute: great, BertScore: 0.9703038334846497\n",
      "Substitute: significant, BertScore: 0.970051109790802\n",
      "Substitute: embarrassing, BertScore: 0.9695849418640137\n",
      "Substitute: costly, BertScore: 0.9691305160522461\n",
      "Substitute: critical, BertScore: 0.9672541618347168\n",
      "Substitute: monumental, BertScore: 0.9672066569328308\n",
      "Substitute: major, BertScore: 0.9667074680328369\n",
      "Substitute: fundamental, BertScore: 0.9665112495422363\n",
      "Substitute: unexpected, BertScore: 0.9662210941314697\n",
      "Substitute: massive, BertScore: 0.9660806655883789\n",
      "Substitute: huge, BertScore: 0.9660303592681885\n",
      "Substitute: important, BertScore: 0.9650730490684509\n",
      "Substitute: failed, BertScore: 0.9647271633148193\n",
      "Substitute: recent, BertScore: 0.9630346894264221\n",
      "Substitute: sudden, BertScore: 0.9630045294761658\n",
      "Substitute: latest, BertScore: 0.9613678455352783\n",
      "Substitute: final, BertScore: 0.9608510732650757\n",
      "Substitute: very, BertScore: 0.9606009721755981\n",
      "Substitute: particular, BertScore: 0.9586211442947388\n",
      "Substitute: one, BertScore: 0.9527356624603271\n",
      "top-10 substitutes based on bertscores in context: ['terrible', 'unfortunate', 'painful', 'dreadful', 'disastrous', 'horrible', 'colossal', 'tragic', 'catastrophic', 'serious']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: regime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: government, BertScore: 0.9873647689819336\n",
      "Substitute: state, BertScore: 0.9844822287559509\n",
      "Substitute: rebel, BertScore: 0.9835927486419678\n",
      "Substitute: opposition, BertScore: 0.9831647872924805\n",
      "Substitute: junta, BertScore: 0.9831298589706421\n",
      "Substitute: occupation, BertScore: 0.9827345609664917\n",
      "Substitute: revolutionary, BertScore: 0.9822184443473816\n",
      "Substitute: loyalist, BertScore: 0.9809206128120422\n",
      "Substitute: political, BertScore: 0.9806103110313416\n",
      "Substitute: authorities, BertScore: 0.9800065159797668\n",
      "Substitute: resistance, BertScore: 0.979785680770874\n",
      "Substitute: army, BertScore: 0.9796264171600342\n",
      "Substitute: military, BertScore: 0.9787962436676025\n",
      "Substitute: administration, BertScore: 0.9783366918563843\n",
      "Substitute: paramilitary, BertScore: 0.9770410060882568\n",
      "Substitute: militia, BertScore: 0.976311981678009\n",
      "Substitute: foreign, BertScore: 0.9761641621589661\n",
      "Substitute: french, BertScore: 0.9746825695037842\n",
      "Substitute: local, BertScore: 0.9744541645050049\n",
      "Substitute: federal, BertScore: 0.9744427800178528\n",
      "Substitute: british, BertScore: 0.973626434803009\n",
      "Substitute: iraqi, BertScore: 0.9734557867050171\n",
      "Substitute: serb, BertScore: 0.9722415208816528\n",
      "Substitute: security, BertScore: 0.972100019454956\n",
      "Substitute: armed, BertScore: 0.9703922271728516\n",
      "Substitute: police, BertScore: 0.9691123962402344\n",
      "Substitute: street, BertScore: 0.9675845503807068\n",
      "Substitute: the, BertScore: 0.9651720523834229\n",
      "Substitute: their, BertScore: 0.9597528576850891\n",
      "top-10 substitutes based on bertscores in context: ['government', 'state', 'rebel', 'opposition', 'junta', 'occupation', 'revolutionary', 'loyalist', 'political', 'authorities']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: demonstrations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: protests, BertScore: 0.9895840287208557\n",
      "Substitute: rallies, BertScore: 0.9850932955741882\n",
      "Substitute: marches, BertScore: 0.981134295463562\n",
      "Substitute: strikes, BertScore: 0.9769248962402344\n",
      "Substitute: riots, BertScore: 0.975212037563324\n",
      "Substitute: disturbances, BertScore: 0.9746643304824829\n",
      "Substitute: protest, BertScore: 0.9714369773864746\n",
      "Substitute: movements, BertScore: 0.9658021926879883\n",
      "Substitute: clashes, BertScore: 0.9648197889328003\n",
      "Substitute: demonstrators, BertScore: 0.9632827639579773\n",
      "Substitute: celebrations, BertScore: 0.9625423550605774\n",
      "Substitute: meetings, BertScore: 0.9623832106590271\n",
      "Substitute: talks, BertScore: 0.9618371725082397\n",
      "Substitute: attacks, BertScore: 0.9609501361846924\n",
      "Substitute: events, BertScore: 0.958088755607605\n",
      "Substitute: arrests, BertScore: 0.9568237662315369\n",
      "Substitute: speeches, BertScore: 0.9563059210777283\n",
      "Substitute: protesters, BertScore: 0.9555955529212952\n",
      "Substitute: incidents, BertScore: 0.9532637000083923\n",
      "Substitute: actions, BertScore: 0.9526283740997314\n",
      "Substitute: efforts, BertScore: 0.9497030973434448\n",
      "Substitute: performances, BertScore: 0.9493707418441772\n",
      "Substitute: fireworks, BertScore: 0.9484289884567261\n",
      "Substitute: elections, BertScore: 0.9472044706344604\n",
      "Substitute: developments, BertScore: 0.9465567469596863\n",
      "Substitute: results, BertScore: 0.9331055879592896\n",
      "Substitute: parties, BertScore: 0.9263495802879333\n",
      "Substitute: two, BertScore: 0.915934145450592\n",
      "top-10 substitutes based on bertscores in context: ['protests', 'rallies', 'marches', 'strikes', 'riots', 'disturbances', 'protest', 'movements', 'clashes', 'demonstrators']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: summonsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: summoned, BertScore: 0.969860315322876\n",
      "Substitute: called, BertScore: 0.9626611471176147\n",
      "Substitute: summons, BertScore: 0.9567306041717529\n",
      "Substitute: brought, BertScore: 0.9520089030265808\n",
      "Substitute: requested, BertScore: 0.9508366584777832\n",
      "Substitute: sent, BertScore: 0.9500959515571594\n",
      "Substitute: appointed, BertScore: 0.947702169418335\n",
      "Substitute: nominated, BertScore: 0.9460594058036804\n",
      "Substitute: ordered, BertScore: 0.9456932544708252\n",
      "Substitute: admitted, BertScore: 0.945299506187439\n",
      "Substitute: asked, BertScore: 0.9452003836631775\n",
      "Substitute: invited, BertScore: 0.9406837821006775\n",
      "Substitute: authorised, BertScore: 0.9398871064186096\n",
      "Substitute: booked, BertScore: 0.939034640789032\n",
      "Substitute: designated, BertScore: 0.9374456405639648\n",
      "Substitute: taken, BertScore: 0.9372934103012085\n",
      "Substitute: cleared, BertScore: 0.9366388916969299\n",
      "Substitute: referred, BertScore: 0.9351500272750854\n",
      "Substitute: authorized, BertScore: 0.9335438013076782\n",
      "Substitute: required, BertScore: 0.9325841665267944\n",
      "Substitute: selected, BertScore: 0.9325044751167297\n",
      "Substitute: permitted, BertScore: 0.931658148765564\n",
      "Substitute: chosen, BertScore: 0.9299657940864563\n",
      "Substitute: allowed, BertScore: 0.9294509291648865\n",
      "Substitute: sentenced, BertScore: 0.9215951561927795\n",
      "Substitute: due, BertScore: 0.9186903834342957\n",
      "Substitute: considered, BertScore: 0.9177607893943787\n",
      "Substitute: scheduled, BertScore: 0.9162848591804504\n",
      "Substitute: confirmed, BertScore: 0.914372444152832\n",
      "Substitute: expected, BertScore: 0.9065071940422058\n",
      "top-10 substitutes based on bertscores in context: ['summoned', 'called', 'summons', 'brought', 'requested', 'sent', 'appointed', 'nominated', 'ordered', 'admitted']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sentiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: feelings, BertScore: 0.9883072972297668\n",
      "Substitute: feeling, BertScore: 0.9878036975860596\n",
      "Substitute: discourse, BertScore: 0.9876434206962585\n",
      "Substitute: opinion, BertScore: 0.9868073463439941\n",
      "Substitute: rhetoric, BertScore: 0.986800491809845\n",
      "Substitute: anger, BertScore: 0.9863197803497314\n",
      "Substitute: resentment, BertScore: 0.9862782955169678\n",
      "Substitute: discontent, BertScore: 0.986204981803894\n",
      "Substitute: concern, BertScore: 0.9854780435562134\n",
      "Substitute: support, BertScore: 0.985371470451355\n",
      "Substitute: mood, BertScore: 0.9850755929946899\n",
      "Substitute: attitudes, BertScore: 0.9842990636825562\n",
      "Substitute: rage, BertScore: 0.9841907024383545\n",
      "Substitute: expression, BertScore: 0.9834939241409302\n",
      "Substitute: violence, BertScore: 0.9833371639251709\n",
      "Substitute: outrage, BertScore: 0.9830349087715149\n",
      "Substitute: backlash, BertScore: 0.983024001121521\n",
      "Substitute: nationalism, BertScore: 0.9826935529708862\n",
      "Substitute: frustration, BertScore: 0.9821054339408875\n",
      "Substitute: reaction, BertScore: 0.9812738299369812\n",
      "Substitute: voices, BertScore: 0.9801576733589172\n",
      "Substitute: opposition, BertScore: 0.9780908823013306\n",
      "Substitute: criticism, BertScore: 0.9778191447257996\n",
      "Substitute: movement, BertScore: 0.9768093228340149\n",
      "Substitute: protest, BertScore: 0.9764783978462219\n",
      "Substitute: comments, BertScore: 0.9751471877098083\n",
      "Substitute: protests, BertScore: 0.9679459929466248\n",
      "top-10 substitutes based on bertscores in context: ['feelings', 'feeling', 'discourse', 'opinion', 'rhetoric', 'anger', 'resentment', 'discontent', 'concern', 'support']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: surveillance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: reconnaissance, BertScore: 0.9881657958030701\n",
      "Substitute: monitoring, BertScore: 0.9881361722946167\n",
      "Substitute: tracking, BertScore: 0.9872760772705078\n",
      "Substitute: observation, BertScore: 0.9863542914390564\n",
      "Substitute: protection, BertScore: 0.98612380027771\n",
      "Substitute: screening, BertScore: 0.9847859740257263\n",
      "Substitute: security, BertScore: 0.9833950400352478\n",
      "Substitute: inspection, BertScore: 0.9831611514091492\n",
      "Substitute: interception, BertScore: 0.9828126430511475\n",
      "Substitute: radar, BertScore: 0.9826889038085938\n",
      "Substitute: patrol, BertScore: 0.9824067950248718\n",
      "Substitute: spying, BertScore: 0.9823371767997742\n",
      "Substitute: interrogation, BertScore: 0.9821459054946899\n",
      "Substitute: investigation, BertScore: 0.9815596342086792\n",
      "Substitute: investigative, BertScore: 0.9809764623641968\n",
      "Substitute: monitor, BertScore: 0.9805609583854675\n",
      "Substitute: control, BertScore: 0.980548620223999\n",
      "Substitute: spy, BertScore: 0.9802539348602295\n",
      "Substitute: camera, BertScore: 0.980042576789856\n",
      "Substitute: intelligence, BertScore: 0.9799787402153015\n",
      "Substitute: research, BertScore: 0.9789935350418091\n",
      "Substitute: guard, BertScore: 0.978951096534729\n",
      "Substitute: containment, BertScore: 0.9774616360664368\n",
      "Substitute: drone, BertScore: 0.9774010181427002\n",
      "Substitute: torture, BertScore: 0.9773339629173279\n",
      "Substitute: capture, BertScore: 0.9768731594085693\n",
      "Substitute: pirate, BertScore: 0.9731990098953247\n",
      "Substitute: fishing, BertScore: 0.9716974496841431\n",
      "Substitute: piracy, BertScore: 0.9708743691444397\n",
      "top-10 substitutes based on bertscores in context: ['reconnaissance', 'monitoring', 'tracking', 'observation', 'protection', 'screening', 'security', 'inspection', 'interception', 'radar']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: preliminary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: initial, BertScore: 0.9927895069122314\n",
      "Substitute: provisional, BertScore: 0.9912407994270325\n",
      "Substitute: final, BertScore: 0.9909540414810181\n",
      "Substitute: tentative, BertScore: 0.9904607534408569\n",
      "Substitute: revised, BertScore: 0.9899632930755615\n",
      "Substitute: official, BertScore: 0.9887491464614868\n",
      "Substitute: draft, BertScore: 0.9883916974067688\n",
      "Substitute: formal, BertScore: 0.9882031083106995\n",
      "Substitute: interim, BertScore: 0.9879486560821533\n",
      "Substitute: partial, BertScore: 0.9878577589988708\n",
      "Substitute: published, BertScore: 0.9878026247024536\n",
      "Substitute: summary, BertScore: 0.9871923923492432\n",
      "Substitute: unofficial, BertScore: 0.9865965843200684\n",
      "Substitute: actual, BertScore: 0.9841212034225464\n",
      "Substitute: new, BertScore: 0.9834544062614441\n",
      "Substitute: current, BertScore: 0.9834206700325012\n",
      "Substitute: total, BertScore: 0.9830381870269775\n",
      "Substitute: latest, BertScore: 0.9824646711349487\n",
      "Substitute: recent, BertScore: 0.98175048828125\n",
      "Substitute: court, BertScore: 0.980010986328125\n",
      "Substitute: the, BertScore: 0.9799661040306091\n",
      "Substitute: party, BertScore: 0.9795004725456238\n",
      "Substitute: previous, BertScore: 0.9789389371871948\n",
      "Substitute: some, BertScore: 0.9771974086761475\n",
      "Substitute: other, BertScore: 0.977141261100769\n",
      "Substitute: all, BertScore: 0.9768426418304443\n",
      "Substitute: mixed, BertScore: 0.9765832424163818\n",
      "Substitute: conflicting, BertScore: 0.9762172102928162\n",
      "Substitute: these, BertScore: 0.9760298728942871\n",
      "top-10 substitutes based on bertscores in context: ['initial', 'provisional', 'final', 'tentative', 'revised', 'official', 'draft', 'formal', 'interim', 'partial']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: plethora\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: wealth, BertScore: 0.9724565148353577\n",
      "Substitute: array, BertScore: 0.9721229076385498\n",
      "Substitute: spectrum, BertScore: 0.9713841676712036\n",
      "Substitute: diversity, BertScore: 0.9710503816604614\n",
      "Substitute: breadth, BertScore: 0.9706295728683472\n",
      "Substitute: myriad, BertScore: 0.9704729914665222\n",
      "Substitute: multitude, BertScore: 0.9702236652374268\n",
      "Substitute: range, BertScore: 0.9699442386627197\n",
      "Substitute: host, BertScore: 0.9691788554191589\n",
      "Substitute: variety, BertScore: 0.9686301946640015\n",
      "Substitute: selection, BertScore: 0.9675650596618652\n",
      "Substitute: mix, BertScore: 0.9674932360649109\n",
      "Substitute: collection, BertScore: 0.9666758179664612\n",
      "Substitute: portfolio, BertScore: 0.9664615988731384\n",
      "Substitute: mixture, BertScore: 0.9648480415344238\n",
      "Substitute: suite, BertScore: 0.96473628282547\n",
      "Substitute: number, BertScore: 0.9646426439285278\n",
      "Substitute: core, BertScore: 0.9638674855232239\n",
      "Substitute: series, BertScore: 0.9638595581054688\n",
      "Substitute: total, BertScore: 0.9636338949203491\n",
      "Substitute: line, BertScore: 0.9634380340576172\n",
      "Substitute: base, BertScore: 0.963100016117096\n",
      "Substitute: combination, BertScore: 0.9620552062988281\n",
      "Substitute: fleet, BertScore: 0.9617749452590942\n",
      "Substitute: handful, BertScore: 0.9617681503295898\n",
      "Substitute: network, BertScore: 0.9614924788475037\n",
      "Substitute: set, BertScore: 0.9611958265304565\n",
      "Substitute: list, BertScore: 0.9604048132896423\n",
      "Substitute: lot, BertScore: 0.9549952149391174\n",
      "Substitute: couple, BertScore: 0.9529008865356445\n",
      "top-10 substitutes based on bertscores in context: ['wealth', 'array', 'spectrum', 'diversity', 'breadth', 'myriad', 'multitude', 'range', 'host', 'variety']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: implemented\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: enacted, BertScore: 0.9955955743789673\n",
      "Substitute: enforced, BertScore: 0.9950354695320129\n",
      "Substitute: adopted, BertScore: 0.9935230016708374\n",
      "Substitute: formulated, BertScore: 0.9933869242668152\n",
      "Substitute: introduced, BertScore: 0.9921782612800598\n",
      "Substitute: accomplished, BertScore: 0.9920017719268799\n",
      "Substitute: developed, BertScore: 0.9916922450065613\n",
      "Substitute: achieved, BertScore: 0.9916568994522095\n",
      "Substitute: established, BertScore: 0.9915111064910889\n",
      "Substitute: approved, BertScore: 0.9914816617965698\n",
      "Substitute: completed, BertScore: 0.9912858605384827\n",
      "Substitute: finalized, BertScore: 0.9909325242042542\n",
      "Substitute: fulfilled, BertScore: 0.9908190369606018\n",
      "Substitute: drafted, BertScore: 0.9902471303939819\n",
      "Substitute: negotiated, BertScore: 0.9901988506317139\n",
      "Substitute: outlined, BertScore: 0.9900727272033691\n",
      "Substitute: incorporated, BertScore: 0.9893981218338013\n",
      "Substitute: executed, BertScore: 0.9893739819526672\n",
      "Substitute: announced, BertScore: 0.9881104230880737\n",
      "Substitute: signed, BertScore: 0.9881038665771484\n",
      "Substitute: applied, BertScore: 0.9878451228141785\n",
      "Substitute: met, BertScore: 0.9877628087997437\n",
      "Substitute: effective, BertScore: 0.9873015880584717\n",
      "Substitute: followed, BertScore: 0.9866793155670166\n",
      "Substitute: proposed, BertScore: 0.9866328835487366\n",
      "Substitute: discussed, BertScore: 0.9854152798652649\n",
      "Substitute: implementation, BertScore: 0.9813758134841919\n",
      "top-10 substitutes based on bertscores in context: ['enacted', 'enforced', 'adopted', 'formulated', 'introduced', 'accomplished', 'developed', 'achieved', 'established', 'approved']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: concentration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: density, BertScore: 0.9956212043762207\n",
      "Substitute: composition, BertScore: 0.9948040246963501\n",
      "Substitute: distribution, BertScore: 0.9947924613952637\n",
      "Substitute: volume, BertScore: 0.9946706295013428\n",
      "Substitute: concentrate, BertScore: 0.9945799708366394\n",
      "Substitute: intensity, BertScore: 0.9944077134132385\n",
      "Substitute: level, BertScore: 0.9939448833465576\n",
      "Substitute: quantity, BertScore: 0.9939114451408386\n",
      "Substitute: accumulation, BertScore: 0.9937853813171387\n",
      "Substitute: orientation, BertScore: 0.993687093257904\n",
      "Substitute: depth, BertScore: 0.9934628009796143\n",
      "Substitute: placement, BertScore: 0.9933501482009888\n",
      "Substitute: amount, BertScore: 0.9930469393730164\n",
      "Substitute: presence, BertScore: 0.9930397868156433\n",
      "Substitute: position, BertScore: 0.9927787780761719\n",
      "Substitute: variety, BertScore: 0.9927293658256531\n",
      "Substitute: disposition, BertScore: 0.9924826622009277\n",
      "Substitute: ratio, BertScore: 0.9923303723335266\n",
      "Substitute: selection, BertScore: 0.9920144081115723\n",
      "Substitute: storage, BertScore: 0.991962194442749\n",
      "Substitute: inventory, BertScore: 0.9919395446777344\n",
      "Substitute: disposal, BertScore: 0.9918121099472046\n",
      "Substitute: location, BertScore: 0.9915238618850708\n",
      "Substitute: combination, BertScore: 0.9911431670188904\n",
      "Substitute: determination, BertScore: 0.9911060333251953\n",
      "Substitute: place, BertScore: 0.9909994602203369\n",
      "Substitute: type, BertScore: 0.9898877143859863\n",
      "Substitute: number, BertScore: 0.9897805452346802\n",
      "top-10 substitutes based on bertscores in context: ['density', 'composition', 'distribution', 'volume', 'concentrate', 'intensity', 'level', 'quantity', 'accumulation', 'orientation']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: controversial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: contentious, BertScore: 0.996061384677887\n",
      "Substitute: unpopular, BertScore: 0.9942026138305664\n",
      "Substitute: controversy, BertScore: 0.9932255744934082\n",
      "Substitute: problematic, BertScore: 0.9928379058837891\n",
      "Substitute: provocative, BertScore: 0.9925146102905273\n",
      "Substitute: taboo, BertScore: 0.9918667674064636\n",
      "Substitute: challenging, BertScore: 0.9907336235046387\n",
      "Substitute: ambiguous, BertScore: 0.989769697189331\n",
      "Substitute: conservative, BertScore: 0.9893157482147217\n",
      "Substitute: popular, BertScore: 0.9889787435531616\n",
      "Substitute: confusing, BertScore: 0.9887434840202332\n",
      "Substitute: debated, BertScore: 0.9886381030082703\n",
      "Substitute: topical, BertScore: 0.9884254336357117\n",
      "Substitute: political, BertScore: 0.9878800511360168\n",
      "Substitute: negative, BertScore: 0.9875729084014893\n",
      "Substitute: difficult, BertScore: 0.9875293970108032\n",
      "Substitute: risky, BertScore: 0.9872799515724182\n",
      "Substitute: moderate, BertScore: 0.9871761202812195\n",
      "Substitute: complicated, BertScore: 0.9862681031227112\n",
      "Substitute: complex, BertScore: 0.9859923720359802\n",
      "Substitute: uncomfortable, BertScore: 0.9858952164649963\n",
      "Substitute: philosophical, BertScore: 0.9856706261634827\n",
      "Substitute: tricky, BertScore: 0.9852560758590698\n",
      "Substitute: serious, BertScore: 0.9847716093063354\n",
      "Substitute: important, BertScore: 0.984693169593811\n",
      "Substitute: positive, BertScore: 0.9839698076248169\n",
      "Substitute: interesting, BertScore: 0.9816702604293823\n",
      "Substitute: ridiculous, BertScore: 0.9793296456336975\n",
      "Substitute: different, BertScore: 0.9776354432106018\n",
      "top-10 substitutes based on bertscores in context: ['contentious', 'unpopular', 'controversy', 'problematic', 'provocative', 'taboo', 'challenging', 'ambiguous', 'conservative', 'popular']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: acquisition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: purchase, BertScore: 0.9930758476257324\n",
      "Substitute: takeover, BertScore: 0.9908241629600525\n",
      "Substitute: sale, BertScore: 0.989737868309021\n",
      "Substitute: merger, BertScore: 0.9891924262046814\n",
      "Substitute: offering, BertScore: 0.987502932548523\n",
      "Substitute: investment, BertScore: 0.9857980012893677\n",
      "Substitute: transaction, BertScore: 0.9856163263320923\n",
      "Substitute: trade, BertScore: 0.9853130578994751\n",
      "Substitute: deal, BertScore: 0.9850913286209106\n",
      "Substitute: expansion, BertScore: 0.9842802286148071\n",
      "Substitute: move, BertScore: 0.9841349720954895\n",
      "Substitute: transfer, BertScore: 0.9841017723083496\n",
      "Substitute: offer, BertScore: 0.983375072479248\n",
      "Substitute: bid, BertScore: 0.982285737991333\n",
      "Substitute: contract, BertScore: 0.9814531207084656\n",
      "Substitute: agreement, BertScore: 0.9811579585075378\n",
      "Substitute: auction, BertScore: 0.9807553291320801\n",
      "Substitute: transactions, BertScore: 0.9805175065994263\n",
      "Substitute: loan, BertScore: 0.9798970222473145\n",
      "Substitute: lease, BertScore: 0.97950279712677\n",
      "Substitute: deals, BertScore: 0.979274570941925\n",
      "Substitute: bidding, BertScore: 0.979179859161377\n",
      "Substitute: development, BertScore: 0.9790834784507751\n",
      "Substitute: business, BertScore: 0.9788596630096436\n",
      "Substitute: project, BertScore: 0.9787265658378601\n",
      "Substitute: operation, BertScore: 0.9784548878669739\n",
      "Substitute: product, BertScore: 0.9771872162818909\n",
      "Substitute: process, BertScore: 0.9769133925437927\n",
      "top-10 substitutes based on bertscores in context: ['purchase', 'takeover', 'sale', 'merger', 'offering', 'investment', 'transaction', 'trade', 'deal', 'expansion']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: outlining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: detailing, BertScore: 0.9867075681686401\n",
      "Substitute: announcing, BertScore: 0.9836312532424927\n",
      "Substitute: highlighting, BertScore: 0.9835013151168823\n",
      "Substitute: discussing, BertScore: 0.9824213981628418\n",
      "Substitute: confirming, BertScore: 0.9822800159454346\n",
      "Substitute: promoting, BertScore: 0.9817556142807007\n",
      "Substitute: covering, BertScore: 0.9814611673355103\n",
      "Substitute: concerning, BertScore: 0.981182336807251\n",
      "Substitute: declaring, BertScore: 0.9809261560440063\n",
      "Substitute: explaining, BertScore: 0.9808569550514221\n",
      "Substitute: regarding, BertScore: 0.9803445339202881\n",
      "Substitute: about, BertScore: 0.9798072576522827\n",
      "Substitute: showing, BertScore: 0.9794529676437378\n",
      "Substitute: establishing, BertScore: 0.9791780114173889\n",
      "Substitute: defending, BertScore: 0.9763281941413879\n",
      "Substitute: supporting, BertScore: 0.9761919379234314\n",
      "Substitute: defining, BertScore: 0.9761242270469666\n",
      "Substitute: on, BertScore: 0.9759966731071472\n",
      "Substitute: listing, BertScore: 0.9758977293968201\n",
      "Substitute: stating, BertScore: 0.9756131172180176\n",
      "Substitute: of, BertScore: 0.9745325446128845\n",
      "Substitute: for, BertScore: 0.9742948412895203\n",
      "Substitute: describing, BertScore: 0.9738306999206543\n",
      "Substitute: over, BertScore: 0.9728442430496216\n",
      "Substitute: with, BertScore: 0.9721760749816895\n",
      "Substitute: opposing, BertScore: 0.9704384803771973\n",
      "Substitute: condemning, BertScore: 0.9679968357086182\n",
      "Substitute: ending, BertScore: 0.966918408870697\n",
      "Substitute: criticizing, BertScore: 0.9662076234817505\n",
      "top-10 substitutes based on bertscores in context: ['detailing', 'announcing', 'highlighting', 'discussing', 'confirming', 'promoting', 'covering', 'concerning', 'declaring', 'explaining']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: approximately\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: roughly, BertScore: 0.9952977299690247\n",
      "Substitute: about, BertScore: 0.9946763515472412\n",
      "Substitute: around, BertScore: 0.9921210408210754\n",
      "Substitute: nearly, BertScore: 0.9907675385475159\n",
      "Substitute: almost, BertScore: 0.9903255701065063\n",
      "Substitute: exactly, BertScore: 0.988228440284729\n",
      "Substitute: some, BertScore: 0.9881706237792969\n",
      "Substitute: just, BertScore: 0.9876670837402344\n",
      "Substitute: approx, BertScore: 0.9861916303634644\n",
      "Substitute: near, BertScore: 0.9831655025482178\n",
      "Substitute: over, BertScore: 0.9823259115219116\n",
      "Substitute: only, BertScore: 0.981620728969574\n",
      "Substitute: located, BertScore: 0.9777911305427551\n",
      "Substitute: situated, BertScore: 0.97651207447052\n",
      "Substitute: at, BertScore: 0.9755225777626038\n",
      "Substitute: within, BertScore: 0.9721848368644714\n",
      "Substitute: or, BertScore: 0.9713233113288879\n",
      "Substitute: being, BertScore: 0.968724250793457\n",
      "Substitute: another, BertScore: 0.9673336148262024\n",
      "Substitute: currently, BertScore: 0.9671557545661926\n",
      "Substitute: also, BertScore: 0.9658000469207764\n",
      "Substitute: approaching, BertScore: 0.9648168683052063\n",
      "Substitute: a, BertScore: 0.9634818434715271\n",
      "Substitute: one, BertScore: 0.9631811380386353\n",
      "Substitute: extending, BertScore: 0.9610288739204407\n",
      "Substitute: now, BertScore: 0.9606832265853882\n",
      "Substitute: but, BertScore: 0.9602287411689758\n",
      "Substitute: is, BertScore: 0.9596477746963501\n",
      "Substitute: and, BertScore: 0.9580991268157959\n",
      "top-10 substitutes based on bertscores in context: ['roughly', 'about', 'around', 'nearly', 'almost', 'exactly', 'some', 'just', 'approx', 'near']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: pinnacle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: apex, BertScore: 0.9934850335121155\n",
      "Substitute: spire, BertScore: 0.9928085803985596\n",
      "Substitute: summit, BertScore: 0.9916915893554688\n",
      "Substitute: zenith, BertScore: 0.9909144639968872\n",
      "Substitute: tower, BertScore: 0.9901974201202393\n",
      "Substitute: colossal, BertScore: 0.9894651770591736\n",
      "Substitute: skyscraper, BertScore: 0.9892473816871643\n",
      "Substitute: soaring, BertScore: 0.9890226721763611\n",
      "Substitute: peak, BertScore: 0.9886525273323059\n",
      "Substitute: high, BertScore: 0.9880661964416504\n",
      "Substitute: height, BertScore: 0.9873874187469482\n",
      "Substitute: top, BertScore: 0.9872398972511292\n",
      "Substitute: grand, BertScore: 0.9871380925178528\n",
      "Substitute: massive, BertScore: 0.9871082305908203\n",
      "Substitute: towering, BertScore: 0.9866710901260376\n",
      "Substitute: bottom, BertScore: 0.9860033988952637\n",
      "Substitute: head, BertScore: 0.9858419895172119\n",
      "Substitute: major, BertScore: 0.9855287075042725\n",
      "Substitute: standard, BertScore: 0.985124945640564\n",
      "Substitute: low, BertScore: 0.9849375486373901\n",
      "Substitute: minimum, BertScore: 0.984747588634491\n",
      "Substitute: star, BertScore: 0.9844739437103271\n",
      "Substitute: tallest, BertScore: 0.9843533635139465\n",
      "Substitute: maximum, BertScore: 0.9843454360961914\n",
      "Substitute: full, BertScore: 0.9835402965545654\n",
      "Substitute: average, BertScore: 0.9818611145019531\n",
      "Substitute: highest, BertScore: 0.9817990660667419\n",
      "Substitute: lowest, BertScore: 0.9817073345184326\n",
      "Substitute: its, BertScore: 0.9774530529975891\n",
      "top-10 substitutes based on bertscores in context: ['apex', 'spire', 'summit', 'zenith', 'tower', 'colossal', 'skyscraper', 'soaring', 'peak', 'high']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: uprising\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: rebellion, BertScore: 0.9952380061149597\n",
      "Substitute: insurrection, BertScore: 0.994772732257843\n",
      "Substitute: revolt, BertScore: 0.9941315650939941\n",
      "Substitute: revolution, BertScore: 0.9862853288650513\n",
      "Substitute: unrest, BertScore: 0.9861965179443359\n",
      "Substitute: coup, BertScore: 0.9841179251670837\n",
      "Substitute: insurgency, BertScore: 0.98383629322052\n",
      "Substitute: struggle, BertScore: 0.9836527109146118\n",
      "Substitute: mutiny, BertScore: 0.982338011264801\n",
      "Substitute: conflict, BertScore: 0.9817032814025879\n",
      "Substitute: resistance, BertScore: 0.981494128704071\n",
      "Substitute: riots, BertScore: 0.9813472032546997\n",
      "Substitute: protests, BertScore: 0.9807138442993164\n",
      "Substitute: demonstrations, BertScore: 0.9806317090988159\n",
      "Substitute: campaign, BertScore: 0.9798496961593628\n",
      "Substitute: fighting, BertScore: 0.9795447587966919\n",
      "Substitute: offensive, BertScore: 0.9792582988739014\n",
      "Substitute: violence, BertScore: 0.9791675209999084\n",
      "Substitute: movement, BertScore: 0.9784150123596191\n",
      "Substitute: riot, BertScore: 0.9758462905883789\n",
      "Substitute: crisis, BertScore: 0.9757089018821716\n",
      "Substitute: war, BertScore: 0.9754853248596191\n",
      "Substitute: clashes, BertScore: 0.9740088582038879\n",
      "Substitute: assault, BertScore: 0.9738072156906128\n",
      "Substitute: massacre, BertScore: 0.9737334251403809\n",
      "Substitute: march, BertScore: 0.9710135459899902\n",
      "Substitute: attacks, BertScore: 0.9706194996833801\n",
      "Substitute: attack, BertScore: 0.9703789353370667\n",
      "Substitute: operation, BertScore: 0.968994140625\n",
      "top-10 substitutes based on bertscores in context: ['rebellion', 'insurrection', 'revolt', 'revolution', 'unrest', 'coup', 'insurgency', 'struggle', 'mutiny', 'conflict']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: overt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: heavy, BertScore: 0.9787573218345642\n",
      "Substitute: excessive, BertScore: 0.978115439414978\n",
      "Substitute: extreme, BertScore: 0.9765362739562988\n",
      "Substitute: deliberate, BertScore: 0.9754680395126343\n",
      "Substitute: elaborate, BertScore: 0.9750455617904663\n",
      "Substitute: intentional, BertScore: 0.9743576645851135\n",
      "Substitute: exaggerated, BertScore: 0.9733997583389282\n",
      "Substitute: rough, BertScore: 0.9731623530387878\n",
      "Substitute: aggressive, BertScore: 0.9729176163673401\n",
      "Substitute: low, BertScore: 0.9723553657531738\n",
      "Substitute: casual, BertScore: 0.9723491668701172\n",
      "Substitute: formal, BertScore: 0.9719243049621582\n",
      "Substitute: over, BertScore: 0.9719052314758301\n",
      "Substitute: slight, BertScore: 0.97182297706604\n",
      "Substitute: accidental, BertScore: 0.9715495705604553\n",
      "Substitute: indirect, BertScore: 0.971327006816864\n",
      "Substitute: slow, BertScore: 0.9712850451469421\n",
      "Substitute: passive, BertScore: 0.9711795449256897\n",
      "Substitute: clumsy, BertScore: 0.9704509973526001\n",
      "Substitute: inappropriate, BertScore: 0.9702925682067871\n",
      "Substitute: awkward, BertScore: 0.970035195350647\n",
      "Substitute: improper, BertScore: 0.9699081182479858\n",
      "Substitute: late, BertScore: 0.9689043760299683\n",
      "Substitute: foul, BertScore: 0.9688066244125366\n",
      "Substitute: short, BertScore: 0.9687756299972534\n",
      "Substitute: unusual, BertScore: 0.9679537415504456\n",
      "Substitute: uneven, BertScore: 0.9678856134414673\n",
      "Substitute: amateur, BertScore: 0.9677151441574097\n",
      "Substitute: expressive, BertScore: 0.9676524996757507\n",
      "Substitute: poor, BertScore: 0.9672754406929016\n",
      "top-10 substitutes based on bertscores in context: ['heavy', 'excessive', 'extreme', 'deliberate', 'elaborate', 'intentional', 'exaggerated', 'rough', 'aggressive', 'low']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: probe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: investigation, BertScore: 0.9937384128570557\n",
      "Substitute: inquiry, BertScore: 0.9929715394973755\n",
      "Substitute: investigations, BertScore: 0.9924172759056091\n",
      "Substitute: review, BertScore: 0.9854917526245117\n",
      "Substitute: report, BertScore: 0.9847484827041626\n",
      "Substitute: check, BertScore: 0.9845558404922485\n",
      "Substitute: search, BertScore: 0.983289897441864\n",
      "Substitute: correction, BertScore: 0.9832766056060791\n",
      "Substitute: hearing, BertScore: 0.9832640290260315\n",
      "Substitute: look, BertScore: 0.9827440977096558\n",
      "Substitute: dig, BertScore: 0.9825733304023743\n",
      "Substitute: sweep, BertScore: 0.9818161129951477\n",
      "Substitute: research, BertScore: 0.9816238880157471\n",
      "Substitute: watch, BertScore: 0.9810624122619629\n",
      "Substitute: study, BertScore: 0.9804804921150208\n",
      "Substitute: crack, BertScore: 0.980065107345581\n",
      "Substitute: trial, BertScore: 0.979536235332489\n",
      "Substitute: looking, BertScore: 0.9787338972091675\n",
      "Substitute: peek, BertScore: 0.9785295724868774\n",
      "Substitute: digging, BertScore: 0.9779061675071716\n",
      "Substitute: insight, BertScore: 0.9733631610870361\n",
      "Substitute: view, BertScore: 0.9703382849693298\n",
      "Substitute: glimpse, BertScore: 0.9699869751930237\n",
      "Substitute: deeper, BertScore: 0.9693844318389893\n",
      "Substitute: window, BertScore: 0.9690168499946594\n",
      "Substitute: widening, BertScore: 0.9605278372764587\n",
      "Substitute: way, BertScore: 0.9587292671203613\n",
      "Substitute: turn, BertScore: 0.9584615230560303\n",
      "top-10 substitutes based on bertscores in context: ['investigation', 'inquiry', 'investigations', 'review', 'report', 'check', 'search', 'correction', 'hearing', 'look']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: herald\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: mark, BertScore: 0.9933106899261475\n",
      "Substitute: signal, BertScore: 0.9929647445678711\n",
      "Substitute: spark, BertScore: 0.9906958341598511\n",
      "Substitute: announce, BertScore: 0.9902686476707458\n",
      "Substitute: highlight, BertScore: 0.9902405142784119\n",
      "Substitute: inspire, BertScore: 0.9898951053619385\n",
      "Substitute: indicate, BertScore: 0.9897703528404236\n",
      "Substitute: celebrate, BertScore: 0.9897544384002686\n",
      "Substitute: present, BertScore: 0.9897379875183105\n",
      "Substitute: forecast, BertScore: 0.9896097183227539\n",
      "Substitute: promote, BertScore: 0.9883927702903748\n",
      "Substitute: predict, BertScore: 0.988366961479187\n",
      "Substitute: introduce, BertScore: 0.9883145689964294\n",
      "Substitute: portray, BertScore: 0.9883058071136475\n",
      "Substitute: represent, BertScore: 0.9882498979568481\n",
      "Substitute: recognise, BertScore: 0.988183856010437\n",
      "Substitute: declare, BertScore: 0.988159716129303\n",
      "Substitute: forge, BertScore: 0.9877421855926514\n",
      "Substitute: observe, BertScore: 0.9873595833778381\n",
      "Substitute: establish, BertScore: 0.987249493598938\n",
      "Substitute: create, BertScore: 0.9869906902313232\n",
      "Substitute: describe, BertScore: 0.9869582056999207\n",
      "Substitute: suggest, BertScore: 0.9864475727081299\n",
      "Substitute: see, BertScore: 0.9863608479499817\n",
      "Substitute: advocate, BertScore: 0.9861159324645996\n",
      "Substitute: sign, BertScore: 0.9859363436698914\n",
      "Substitute: witness, BertScore: 0.9858610033988953\n",
      "Substitute: discuss, BertScore: 0.9845300316810608\n",
      "Substitute: propose, BertScore: 0.9840899705886841\n",
      "top-10 substitutes based on bertscores in context: ['mark', 'signal', 'spark', 'announce', 'highlight', 'inspire', 'indicate', 'celebrate', 'present', 'forecast']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: disgraceful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: embarrassing, BertScore: 0.9855589270591736\n",
      "Substitute: disgrace, BertScore: 0.9854414463043213\n",
      "Substitute: humiliating, BertScore: 0.983751118183136\n",
      "Substitute: terrible, BertScore: 0.9825224280357361\n",
      "Substitute: outrageous, BertScore: 0.9815901517868042\n",
      "Substitute: unacceptable, BertScore: 0.9808518886566162\n",
      "Substitute: unfair, BertScore: 0.9798255562782288\n",
      "Substitute: improper, BertScore: 0.9796726703643799\n",
      "Substitute: foolish, BertScore: 0.9794715046882629\n",
      "Substitute: dangerous, BertScore: 0.9794083833694458\n",
      "Substitute: bad, BertScore: 0.9791343808174133\n",
      "Substitute: disgusting, BertScore: 0.9791162610054016\n",
      "Substitute: rude, BertScore: 0.978890597820282\n",
      "Substitute: ridiculous, BertScore: 0.9787557721138\n",
      "Substitute: cruel, BertScore: 0.9786346554756165\n",
      "Substitute: folly, BertScore: 0.9774963855743408\n",
      "Substitute: absurd, BertScore: 0.9774859547615051\n",
      "Substitute: inappropriate, BertScore: 0.9773601293563843\n",
      "Substitute: wrong, BertScore: 0.977209746837616\n",
      "Substitute: unsafe, BertScore: 0.9748648405075073\n",
      "Substitute: useless, BertScore: 0.9747270941734314\n",
      "Substitute: acceptable, BertScore: 0.9740846157073975\n",
      "Substitute: false, BertScore: 0.9713311195373535\n",
      "Substitute: heresy, BertScore: 0.971099317073822\n",
      "Substitute: unnecessary, BertScore: 0.9705847501754761\n",
      "Substitute: illegal, BertScore: 0.9703041315078735\n",
      "Substitute: evil, BertScore: 0.9697611331939697\n",
      "Substitute: impossible, BertScore: 0.9683080315589905\n",
      "Substitute: necessary, BertScore: 0.965925931930542\n",
      "Substitute: obscene, BertScore: 0.965604305267334\n",
      "top-10 substitutes based on bertscores in context: ['embarrassing', 'disgrace', 'humiliating', 'terrible', 'outrageous', 'unacceptable', 'unfair', 'improper', 'foolish', 'dangerous']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: ominous\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: sinister, BertScore: 0.9724767208099365\n",
      "Substitute: disturbing, BertScore: 0.9700327515602112\n",
      "Substitute: scary, BertScore: 0.9686301946640015\n",
      "Substitute: strange, BertScore: 0.9669804573059082\n",
      "Substitute: odd, BertScore: 0.9658939242362976\n",
      "Substitute: suspicious, BertScore: 0.9642436504364014\n",
      "Substitute: terrible, BertScore: 0.9638926386833191\n",
      "Substitute: ugly, BertScore: 0.9638911485671997\n",
      "Substitute: cryptic, BertScore: 0.9628815650939941\n",
      "Substitute: dark, BertScore: 0.9583749771118164\n",
      "Substitute: bad, BertScore: 0.9581397771835327\n",
      "Substitute: ironic, BertScore: 0.9576733112335205\n",
      "Substitute: urgent, BertScore: 0.9576473236083984\n",
      "Substitute: vague, BertScore: 0.953277587890625\n",
      "Substitute: threatening, BertScore: 0.9527561664581299\n",
      "Substitute: appropriate, BertScore: 0.9490835666656494\n",
      "Substitute: evil, BertScore: 0.9480479955673218\n",
      "Substitute: hopeful, BertScore: 0.9469460248947144\n",
      "Substitute: old, BertScore: 0.9438517093658447\n",
      "Substitute: sad, BertScore: 0.9400335550308228\n",
      "Substitute: empty, BertScore: 0.9368733167648315\n",
      "Substitute: ambiguous, BertScore: 0.936123251914978\n",
      "Substitute: negative, BertScore: 0.9335132837295532\n",
      "Substitute: bold, BertScore: 0.9299002289772034\n",
      "Substitute: false, BertScore: 0.9282190799713135\n",
      "Substitute: misleading, BertScore: 0.924291729927063\n",
      "Substitute: concerned, BertScore: 0.9214600920677185\n",
      "Substitute: something, BertScore: 0.9211547374725342\n",
      "Substitute: incomplete, BertScore: 0.8950278759002686\n",
      "top-10 substitutes based on bertscores in context: ['sinister', 'disturbing', 'scary', 'strange', 'odd', 'suspicious', 'terrible', 'ugly', 'cryptic', 'dark']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: indication\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: indicator, BertScore: 0.9849880337715149\n",
      "Substitute: sign, BertScore: 0.9741328358650208\n",
      "Substitute: evidence, BertScore: 0.9708884954452515\n",
      "Substitute: confirmation, BertScore: 0.9696407318115234\n",
      "Substitute: proof, BertScore: 0.9661685228347778\n",
      "Substitute: signal, BertScore: 0.9584939479827881\n",
      "Substitute: indicating, BertScore: 0.9570930004119873\n",
      "Substitute: indicative, BertScore: 0.955619752407074\n",
      "Substitute: implication, BertScore: 0.9552140235900879\n",
      "Substitute: impression, BertScore: 0.9540891051292419\n",
      "Substitute: admission, BertScore: 0.9514327645301819\n",
      "Substitute: assurance, BertScore: 0.9479642510414124\n",
      "Substitute: assertion, BertScore: 0.9461176991462708\n",
      "Substitute: endorsement, BertScore: 0.9455891847610474\n",
      "Substitute: observation, BertScore: 0.9444243907928467\n",
      "Substitute: appearance, BertScore: 0.9438655376434326\n",
      "Substitute: estimate, BertScore: 0.9412400126457214\n",
      "Substitute: explanation, BertScore: 0.9400996565818787\n",
      "Substitute: assessment, BertScore: 0.9392032623291016\n",
      "Substitute: assumption, BertScore: 0.9388867020606995\n",
      "Substitute: indicate, BertScore: 0.9287555813789368\n",
      "Substitute: announcement, BertScore: 0.9236067533493042\n",
      "Substitute: expression, BertScore: 0.9208921194076538\n",
      "Substitute: information, BertScore: 0.9197240471839905\n",
      "Substitute: example, BertScore: 0.9171174764633179\n",
      "Substitute: alert, BertScore: 0.9136978387832642\n",
      "Substitute: idea, BertScore: 0.9046211242675781\n",
      "Substitute: image, BertScore: 0.9019752144813538\n",
      "top-10 substitutes based on bertscores in context: ['indicator', 'sign', 'evidence', 'confirmation', 'proof', 'signal', 'indicating', 'indicative', 'implication', 'impression']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: attributed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: ascribed, BertScore: 0.99552983045578\n",
      "Substitute: credited, BertScore: 0.9901890754699707\n",
      "Substitute: cited, BertScore: 0.9852748513221741\n",
      "Substitute: acknowledged, BertScore: 0.9845289587974548\n",
      "Substitute: admitted, BertScore: 0.9844263792037964\n",
      "Substitute: reported, BertScore: 0.9843654632568359\n",
      "Substitute: claimed, BertScore: 0.9841470122337341\n",
      "Substitute: given, BertScore: 0.9838799238204956\n",
      "Substitute: identified, BertScore: 0.9836011528968811\n",
      "Substitute: blamed, BertScore: 0.9834516048431396\n",
      "Substitute: noted, BertScore: 0.9831172227859497\n",
      "Substitute: described, BertScore: 0.9829784631729126\n",
      "Substitute: said, BertScore: 0.9828691482543945\n",
      "Substitute: compared, BertScore: 0.9827181100845337\n",
      "Substitute: named, BertScore: 0.9827079772949219\n",
      "Substitute: alleged, BertScore: 0.9820983409881592\n",
      "Substitute: seen, BertScore: 0.9813269376754761\n",
      "Substitute: attested, BertScore: 0.9811996817588806\n",
      "Substitute: explained, BertScore: 0.9811389446258545\n",
      "Substitute: estimated, BertScore: 0.9811114072799683\n",
      "Substitute: recorded, BertScore: 0.9809446334838867\n",
      "Substitute: recounted, BertScore: 0.9807729721069336\n",
      "Substitute: mentioned, BertScore: 0.9803624153137207\n",
      "Substitute: interpreted, BertScore: 0.9795607328414917\n",
      "Substitute: quoted, BertScore: 0.9789350032806396\n",
      "Substitute: recalled, BertScore: 0.9789143800735474\n",
      "Substitute: added, BertScore: 0.9780091643333435\n",
      "Substitute: known, BertScore: 0.9777981638908386\n",
      "Substitute: found, BertScore: 0.9751645922660828\n",
      "top-10 substitutes based on bertscores in context: ['ascribed', 'credited', 'cited', 'acknowledged', 'admitted', 'reported', 'claimed', 'given', 'identified', 'blamed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: impeachment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: resignation, BertScore: 0.9665613770484924\n",
      "Substitute: reelection, BertScore: 0.9664438962936401\n",
      "Substitute: expulsion, BertScore: 0.9661307334899902\n",
      "Substitute: indictment, BertScore: 0.9649280309677124\n",
      "Substitute: removal, BertScore: 0.9644719362258911\n",
      "Substitute: dismissal, BertScore: 0.9641475081443787\n",
      "Substitute: pardon, BertScore: 0.9635989665985107\n",
      "Substitute: assassination, BertScore: 0.9635016918182373\n",
      "Substitute: execution, BertScore: 0.963275134563446\n",
      "Substitute: arrest, BertScore: 0.9632071852684021\n",
      "Substitute: disqualification, BertScore: 0.9630765318870544\n",
      "Substitute: election, BertScore: 0.962904691696167\n",
      "Substitute: death, BertScore: 0.9615497589111328\n",
      "Substitute: nomination, BertScore: 0.9615083336830139\n",
      "Substitute: ascension, BertScore: 0.9611867666244507\n",
      "Substitute: murder, BertScore: 0.9610716104507446\n",
      "Substitute: prosecution, BertScore: 0.9608926177024841\n",
      "Substitute: bribery, BertScore: 0.960729718208313\n",
      "Substitute: sentencing, BertScore: 0.9607097506523132\n",
      "Substitute: immunity, BertScore: 0.9603719115257263\n",
      "Substitute: selection, BertScore: 0.9602808356285095\n",
      "Substitute: inauguration, BertScore: 0.9602106213569641\n",
      "Substitute: appointment, BertScore: 0.9600919485092163\n",
      "Substitute: candidacy, BertScore: 0.9595851302146912\n",
      "Substitute: treason, BertScore: 0.9592670798301697\n",
      "Substitute: confirmation, BertScore: 0.9582110047340393\n",
      "Substitute: rape, BertScore: 0.9571526050567627\n",
      "Substitute: marriage, BertScore: 0.954641580581665\n",
      "Substitute: submission, BertScore: 0.9507266283035278\n",
      "top-10 substitutes based on bertscores in context: ['resignation', 'reelection', 'expulsion', 'indictment', 'removal', 'dismissal', 'pardon', 'assassination', 'execution', 'arrest']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: infamous\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: notorious, BertScore: 0.9983923435211182\n",
      "Substitute: famous, BertScore: 0.9963588118553162\n",
      "Substitute: memorable, BertScore: 0.9949982762336731\n",
      "Substitute: known, BertScore: 0.9947386980056763\n",
      "Substitute: notable, BertScore: 0.9946923851966858\n",
      "Substitute: prominent, BertScore: 0.9942388534545898\n",
      "Substitute: controversial, BertScore: 0.9941629767417908\n",
      "Substitute: brutal, BertScore: 0.9941039681434631\n",
      "Substitute: vicious, BertScore: 0.9940834045410156\n",
      "Substitute: serious, BertScore: 0.9938420057296753\n",
      "Substitute: popular, BertScore: 0.9937888383865356\n",
      "Substitute: severe, BertScore: 0.9934519529342651\n",
      "Substitute: publicized, BertScore: 0.9934484362602234\n",
      "Substitute: violent, BertScore: 0.9932790994644165\n",
      "Substitute: horrific, BertScore: 0.9926558136940002\n",
      "Substitute: prevalent, BertScore: 0.9926378130912781\n",
      "Substitute: powerful, BertScore: 0.9926050305366516\n",
      "Substitute: significant, BertScore: 0.9925552010536194\n",
      "Substitute: numerous, BertScore: 0.9925404787063599\n",
      "Substitute: important, BertScore: 0.9923097491264343\n",
      "Substitute: hideous, BertScore: 0.9922763705253601\n",
      "Substitute: common, BertScore: 0.9916881322860718\n",
      "Substitute: outrageous, BertScore: 0.9915124773979187\n",
      "Substitute: bizarre, BertScore: 0.9913222789764404\n",
      "Substitute: problematic, BertScore: 0.9910207390785217\n",
      "Substitute: extreme, BertScore: 0.9907338619232178\n",
      "Substitute: obvious, BertScore: 0.9903342127799988\n",
      "Substitute: ridiculous, BertScore: 0.9896093606948853\n",
      "Substitute: recent, BertScore: 0.98912513256073\n",
      "top-10 substitutes based on bertscores in context: ['notorious', 'famous', 'memorable', 'known', 'notable', 'prominent', 'controversial', 'brutal', 'vicious', 'serious']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: annul\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: cancel, BertScore: 0.9741036891937256\n",
      "Substitute: terminate, BertScore: 0.9735567569732666\n",
      "Substitute: suspend, BertScore: 0.9713689684867859\n",
      "Substitute: modify, BertScore: 0.9685894846916199\n",
      "Substitute: alter, BertScore: 0.9655601382255554\n",
      "Substitute: ignore, BertScore: 0.9641444087028503\n",
      "Substitute: amend, BertScore: 0.9637817740440369\n",
      "Substitute: honor, BertScore: 0.9632570743560791\n",
      "Substitute: change, BertScore: 0.9631340503692627\n",
      "Substitute: confirm, BertScore: 0.9622755646705627\n",
      "Substitute: disregard, BertScore: 0.961784303188324\n",
      "Substitute: accept, BertScore: 0.9592452049255371\n",
      "Substitute: approve, BertScore: 0.9586548209190369\n",
      "Substitute: implement, BertScore: 0.9575244784355164\n",
      "Substitute: review, BertScore: 0.9566988348960876\n",
      "Substitute: contest, BertScore: 0.9538679122924805\n",
      "Substitute: respect, BertScore: 0.9537341594696045\n",
      "Substitute: complete, BertScore: 0.9536221027374268\n",
      "Substitute: observe, BertScore: 0.95354163646698\n",
      "Substitute: announce, BertScore: 0.9533030986785889\n",
      "Substitute: pass, BertScore: 0.9532132744789124\n",
      "Substitute: publish, BertScore: 0.9527899622917175\n",
      "Substitute: verify, BertScore: 0.9522742629051208\n",
      "Substitute: follow, BertScore: 0.9521671533584595\n",
      "Substitute: check, BertScore: 0.9521054029464722\n",
      "Substitute: process, BertScore: 0.9517489075660706\n",
      "Substitute: interpret, BertScore: 0.9516460299491882\n",
      "Substitute: control, BertScore: 0.9508441090583801\n",
      "Substitute: monitor, BertScore: 0.9477880001068115\n",
      "Substitute: write, BertScore: 0.9468228816986084\n",
      "top-10 substitutes based on bertscores in context: ['cancel', 'terminate', 'suspend', 'modify', 'alter', 'ignore', 'amend', 'honor', 'change', 'confirm']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: disassociate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: divorce, BertScore: 0.9546005725860596\n",
      "Substitute: isolate, BertScore: 0.9542183876037598\n",
      "Substitute: withdraw, BertScore: 0.9538547396659851\n",
      "Substitute: remove, BertScore: 0.9529387950897217\n",
      "Substitute: distance, BertScore: 0.9520300030708313\n",
      "Substitute: exclude, BertScore: 0.9519587159156799\n",
      "Substitute: eliminate, BertScore: 0.9508354663848877\n",
      "Substitute: separate, BertScore: 0.9506792426109314\n",
      "Substitute: purge, BertScore: 0.9493156671524048\n",
      "Substitute: divert, BertScore: 0.9452913403511047\n",
      "Substitute: hide, BertScore: 0.9447066187858582\n",
      "Substitute: differentiate, BertScore: 0.9445583820343018\n",
      "Substitute: shield, BertScore: 0.9443048238754272\n",
      "Substitute: restrain, BertScore: 0.9441574215888977\n",
      "Substitute: conceal, BertScore: 0.9439355731010437\n",
      "Substitute: distract, BertScore: 0.9438597559928894\n",
      "Substitute: distinguish, BertScore: 0.9432768821716309\n",
      "Substitute: free, BertScore: 0.9430732727050781\n",
      "Substitute: transform, BertScore: 0.9385946989059448\n",
      "Substitute: prevent, BertScore: 0.938448429107666\n",
      "Substitute: protect, BertScore: 0.938282310962677\n",
      "Substitute: save, BertScore: 0.9369981288909912\n",
      "Substitute: maintain, BertScore: 0.935927152633667\n",
      "Substitute: defend, BertScore: 0.9346374869346619\n",
      "Substitute: derive, BertScore: 0.9340313076972961\n",
      "Substitute: profit, BertScore: 0.9337159395217896\n",
      "Substitute: establish, BertScore: 0.931839108467102\n",
      "Substitute: create, BertScore: 0.9310693144798279\n",
      "Substitute: avail, BertScore: 0.9307951927185059\n",
      "Substitute: convince, BertScore: 0.9267556667327881\n",
      "top-10 substitutes based on bertscores in context: ['divorce', 'isolate', 'withdraw', 'remove', 'distance', 'exclude', 'eliminate', 'separate', 'purge', 'divert']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: electoral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: election, BertScore: 0.9886778593063354\n",
      "Substitute: voting, BertScore: 0.9800835847854614\n",
      "Substitute: electorate, BertScore: 0.9791872501373291\n",
      "Substitute: political, BertScore: 0.9785863757133484\n",
      "Substitute: campaign, BertScore: 0.9783347845077515\n",
      "Substitute: party, BertScore: 0.977635383605957\n",
      "Substitute: voter, BertScore: 0.9767473936080933\n",
      "Substitute: legislative, BertScore: 0.9751105904579163\n",
      "Substitute: primary, BertScore: 0.9749448299407959\n",
      "Substitute: presidential, BertScore: 0.9744951725006104\n",
      "Substitute: democratic, BertScore: 0.9733668565750122\n",
      "Substitute: race, BertScore: 0.9704949855804443\n",
      "Substitute: constitutional, BertScore: 0.9695128798484802\n",
      "Substitute: national, BertScore: 0.9683471918106079\n",
      "Substitute: regional, BertScore: 0.963743269443512\n",
      "Substitute: overall, BertScore: 0.9633694887161255\n",
      "Substitute: local, BertScore: 0.9627423286437988\n",
      "Substitute: actual, BertScore: 0.9618325233459473\n",
      "Substitute: historic, BertScore: 0.9615470767021179\n",
      "Substitute: economic, BertScore: 0.9603732824325562\n",
      "Substitute: achieving, BertScore: 0.9562594890594482\n",
      "Substitute: such, BertScore: 0.9561884999275208\n",
      "Substitute: his, BertScore: 0.9510302543640137\n",
      "Substitute: both, BertScore: 0.9492207169532776\n",
      "Substitute: that, BertScore: 0.9490216970443726\n",
      "Substitute: their, BertScore: 0.947760820388794\n",
      "Substitute: this, BertScore: 0.9476653337478638\n",
      "Substitute: the, BertScore: 0.9471747279167175\n",
      "Substitute: its, BertScore: 0.9449833631515503\n",
      "top-10 substitutes based on bertscores in context: ['election', 'voting', 'electorate', 'political', 'campaign', 'party', 'voter', 'legislative', 'primary', 'presidential']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: emissions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: signals, BertScore: 0.9884459972381592\n",
      "Substitute: sources, BertScore: 0.9832147359848022\n",
      "Substitute: peaks, BertScore: 0.9830684065818787\n",
      "Substitute: spectra, BertScore: 0.9829913973808289\n",
      "Substitute: output, BertScore: 0.9828783869743347\n",
      "Substitute: outputs, BertScore: 0.9827622771263123\n",
      "Substitute: concentrations, BertScore: 0.9825937747955322\n",
      "Substitute: losses, BertScore: 0.9824526906013489\n",
      "Substitute: measurements, BertScore: 0.9814696907997131\n",
      "Substitute: impacts, BertScore: 0.9805480241775513\n",
      "Substitute: levels, BertScore: 0.9793344140052795\n",
      "Substitute: effects, BertScore: 0.9789716005325317\n",
      "Substitute: numbers, BertScore: 0.9784221649169922\n",
      "Substitute: components, BertScore: 0.9782571196556091\n",
      "Substitute: filters, BertScore: 0.977830708026886\n",
      "Substitute: hits, BertScore: 0.9769498109817505\n",
      "Substitute: gases, BertScore: 0.9768846035003662\n",
      "Substitute: footprints, BertScore: 0.9759789109230042\n",
      "Substitute: constituents, BertScore: 0.9756871461868286\n",
      "Substitute: products, BertScore: 0.9756717681884766\n",
      "Substitute: targets, BertScore: 0.9746254086494446\n",
      "Substitute: results, BertScore: 0.9743413925170898\n",
      "Substitute: ones, BertScore: 0.9731801152229309\n",
      "Substitute: footprint, BertScore: 0.9728395938873291\n",
      "Substitute: reductions, BertScore: 0.9726158380508423\n",
      "Substitute: metals, BertScore: 0.970893383026123\n",
      "Substitute: counterparts, BertScore: 0.970433235168457\n",
      "Substitute: differences, BertScore: 0.9657053351402283\n",
      "top-10 substitutes based on bertscores in context: ['signals', 'sources', 'peaks', 'spectra', 'output', 'outputs', 'concentrations', 'losses', 'measurements', 'impacts']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: eligibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: qualifying, BertScore: 0.9876275658607483\n",
      "Substitute: qualification, BertScore: 0.986034095287323\n",
      "Substitute: eligible, BertScore: 0.9858142733573914\n",
      "Substitute: entry, BertScore: 0.9810898900032043\n",
      "Substitute: registration, BertScore: 0.9810168147087097\n",
      "Substitute: selection, BertScore: 0.9794199466705322\n",
      "Substitute: applicants, BertScore: 0.9790213108062744\n",
      "Substitute: acceptance, BertScore: 0.9778386354446411\n",
      "Substitute: exemption, BertScore: 0.9777219295501709\n",
      "Substitute: applying, BertScore: 0.9769863486289978\n",
      "Substitute: enrollment, BertScore: 0.9753062725067139\n",
      "Substitute: ineligible, BertScore: 0.9748476147651672\n",
      "Substitute: application, BertScore: 0.9741392731666565\n",
      "Substitute: disqualification, BertScore: 0.9729906916618347\n",
      "Substitute: approval, BertScore: 0.9728503823280334\n",
      "Substitute: requirement, BertScore: 0.9725799560546875\n",
      "Substitute: consideration, BertScore: 0.9715486168861389\n",
      "Substitute: opportunities, BertScore: 0.9714380502700806\n",
      "Substitute: applications, BertScore: 0.9712111949920654\n",
      "Substitute: authorization, BertScore: 0.9708151817321777\n",
      "Substitute: requirements, BertScore: 0.9702982306480408\n",
      "Substitute: preference, BertScore: 0.9702134728431702\n",
      "Substitute: coverage, BertScore: 0.9695520401000977\n",
      "Substitute: funding, BertScore: 0.9680095314979553\n",
      "Substitute: scholarships, BertScore: 0.9676491618156433\n",
      "Substitute: status, BertScore: 0.966681718826294\n",
      "Substitute: membership, BertScore: 0.9657220840454102\n",
      "Substitute: competition, BertScore: 0.9651532173156738\n",
      "Substitute: payment, BertScore: 0.9632604718208313\n",
      "top-10 substitutes based on bertscores in context: ['qualifying', 'qualification', 'eligible', 'entry', 'registration', 'selection', 'applicants', 'acceptance', 'exemption', 'applying']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: bombardment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: bombing, BertScore: 0.9650436639785767\n",
      "Substitute: assault, BertScore: 0.959029495716095\n",
      "Substitute: attack, BertScore: 0.9570005536079407\n",
      "Substitute: raid, BertScore: 0.9563854336738586\n",
      "Substitute: bombings, BertScore: 0.9552428126335144\n",
      "Substitute: attacks, BertScore: 0.9545433521270752\n",
      "Substitute: siege, BertScore: 0.9519073963165283\n",
      "Substitute: explosions, BertScore: 0.9500316977500916\n",
      "Substitute: raids, BertScore: 0.9482707977294922\n",
      "Substitute: blast, BertScore: 0.9475691914558411\n",
      "Substitute: shooting, BertScore: 0.946129560470581\n",
      "Substitute: battle, BertScore: 0.9438263773918152\n",
      "Substitute: clash, BertScore: 0.9427382946014404\n",
      "Substitute: explosion, BertScore: 0.9423888921737671\n",
      "Substitute: fire, BertScore: 0.9419466257095337\n",
      "Substitute: fighting, BertScore: 0.9416605830192566\n",
      "Substitute: violence, BertScore: 0.9412278532981873\n",
      "Substitute: ambush, BertScore: 0.9409553408622742\n",
      "Substitute: offensive, BertScore: 0.9398537874221802\n",
      "Substitute: shootout, BertScore: 0.9396422505378723\n",
      "Substitute: clashes, BertScore: 0.9338027238845825\n",
      "Substitute: operation, BertScore: 0.9335795044898987\n",
      "Substitute: incident, BertScore: 0.929297924041748\n",
      "Substitute: blasts, BertScore: 0.9254422187805176\n",
      "Substitute: conflict, BertScore: 0.9221857786178589\n",
      "Substitute: killing, BertScore: 0.9217091798782349\n",
      "Substitute: crash, BertScore: 0.9063905477523804\n",
      "Substitute: war, BertScore: 0.9059370756149292\n",
      "Substitute: area, BertScore: 0.8597102165222168\n",
      "top-10 substitutes based on bertscores in context: ['bombing', 'assault', 'attack', 'raid', 'bombings', 'attacks', 'siege', 'explosions', 'raids', 'blast']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: crippling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: damaging, BertScore: 0.9756804704666138\n",
      "Substitute: crushing, BertScore: 0.9754513502120972\n",
      "Substitute: devastating, BertScore: 0.9754043817520142\n",
      "Substitute: falling, BertScore: 0.9734519720077515\n",
      "Substitute: failing, BertScore: 0.9732313752174377\n",
      "Substitute: severe, BertScore: 0.973008394241333\n",
      "Substitute: hitting, BertScore: 0.9719438552856445\n",
      "Substitute: increasing, BertScore: 0.971391499042511\n",
      "Substitute: massive, BertScore: 0.9712396860122681\n",
      "Substitute: continuing, BertScore: 0.9709828495979309\n",
      "Substitute: passing, BertScore: 0.9706349968910217\n",
      "Substitute: coming, BertScore: 0.9706206321716309\n",
      "Substitute: huge, BertScore: 0.9698852896690369\n",
      "Substitute: getting, BertScore: 0.9698362350463867\n",
      "Substitute: suffering, BertScore: 0.9697941541671753\n",
      "Substitute: facing, BertScore: 0.9695615768432617\n",
      "Substitute: receiving, BertScore: 0.9694551825523376\n",
      "Substitute: making, BertScore: 0.9690442085266113\n",
      "Substitute: big, BertScore: 0.9687472581863403\n",
      "Substitute: taking, BertScore: 0.9687412977218628\n",
      "Substitute: some, BertScore: 0.9687329530715942\n",
      "Substitute: more, BertScore: 0.9686609506607056\n",
      "Substitute: further, BertScore: 0.9685692191123962\n",
      "Substitute: going, BertScore: 0.9683496356010437\n",
      "Substitute: many, BertScore: 0.9683157801628113\n",
      "Substitute: any, BertScore: 0.9679757356643677\n",
      "Substitute: all, BertScore: 0.9673980474472046\n",
      "Substitute: its, BertScore: 0.965657114982605\n",
      "Substitute: the, BertScore: 0.9650145769119263\n",
      "Substitute: other, BertScore: 0.964285135269165\n",
      "top-10 substitutes based on bertscores in context: ['damaging', 'crushing', 'devastating', 'falling', 'failing', 'severe', 'hitting', 'increasing', 'massive', 'continuing']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: regime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: dictatorship, BertScore: 0.9935705661773682\n",
      "Substitute: government, BertScore: 0.9934703707695007\n",
      "Substitute: administration, BertScore: 0.9933128952980042\n",
      "Substitute: junta, BertScore: 0.9898262619972229\n",
      "Substitute: leadership, BertScore: 0.9890602827072144\n",
      "Substitute: state, BertScore: 0.9882177114486694\n",
      "Substitute: authorities, BertScore: 0.9881826043128967\n",
      "Substitute: authority, BertScore: 0.9878553152084351\n",
      "Substitute: country, BertScore: 0.9877234697341919\n",
      "Substitute: revolution, BertScore: 0.9877094030380249\n",
      "Substitute: cabinet, BertScore: 0.9876111149787903\n",
      "Substitute: people, BertScore: 0.9871900081634521\n",
      "Substitute: party, BertScore: 0.9871740937232971\n",
      "Substitute: rule, BertScore: 0.9871448278427124\n",
      "Substitute: forces, BertScore: 0.9870166778564453\n",
      "Substitute: leader, BertScore: 0.9868426322937012\n",
      "Substitute: policies, BertScore: 0.986492931842804\n",
      "Substitute: leaders, BertScore: 0.9864869117736816\n",
      "Substitute: loyalists, BertScore: 0.9863610863685608\n",
      "Substitute: army, BertScore: 0.985966682434082\n",
      "Substitute: officials, BertScore: 0.9859481453895569\n",
      "Substitute: supporters, BertScore: 0.9857061505317688\n",
      "Substitute: era, BertScore: 0.9856122136116028\n",
      "Substitute: opponents, BertScore: 0.9852770566940308\n",
      "Substitute: side, BertScore: 0.9852523803710938\n",
      "Substitute: rulers, BertScore: 0.9851565957069397\n",
      "Substitute: ou, BertScore: 0.984342098236084\n",
      "Substitute: king, BertScore: 0.983390748500824\n",
      "top-10 substitutes based on bertscores in context: ['dictatorship', 'government', 'administration', 'junta', 'leadership', 'state', 'authorities', 'authority', 'country', 'revolution']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: mandated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: authorized, BertScore: 0.992384672164917\n",
      "Substitute: allowed, BertScore: 0.9909533262252808\n",
      "Substitute: imposed, BertScore: 0.9908141493797302\n",
      "Substitute: instituted, BertScore: 0.9906989336013794\n",
      "Substitute: sanctioned, BertScore: 0.9903026819229126\n",
      "Substitute: demanded, BertScore: 0.9885343313217163\n",
      "Substitute: ordered, BertScore: 0.9876934885978699\n",
      "Substitute: enacted, BertScore: 0.9875640869140625\n",
      "Substitute: initiated, BertScore: 0.9871889352798462\n",
      "Substitute: required, BertScore: 0.9868984222412109\n",
      "Substitute: introduced, BertScore: 0.9866033792495728\n",
      "Substitute: endorsed, BertScore: 0.9865186810493469\n",
      "Substitute: announced, BertScore: 0.9861584901809692\n",
      "Substitute: supported, BertScore: 0.9858222603797913\n",
      "Substitute: proposed, BertScore: 0.9857214689254761\n",
      "Substitute: approved, BertScore: 0.985588550567627\n",
      "Substitute: adopted, BertScore: 0.9854887127876282\n",
      "Substitute: issued, BertScore: 0.9853566884994507\n",
      "Substitute: recommended, BertScore: 0.9852094650268555\n",
      "Substitute: requested, BertScore: 0.9834797382354736\n",
      "Substitute: reintroduced, BertScore: 0.9826647639274597\n",
      "Substitute: began, BertScore: 0.9821099042892456\n",
      "Substitute: made, BertScore: 0.9805176258087158\n",
      "Substitute: declared, BertScore: 0.9803705215454102\n",
      "Substitute: discontinued, BertScore: 0.9768211245536804\n",
      "Substitute: abolished, BertScore: 0.9755363464355469\n",
      "Substitute: passed, BertScore: 0.973875105381012\n",
      "Substitute: repealed, BertScore: 0.9729228019714355\n",
      "top-10 substitutes based on bertscores in context: ['authorized', 'allowed', 'imposed', 'instituted', 'sanctioned', 'demanded', 'ordered', 'enacted', 'initiated', 'required']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: rendition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: rendering, BertScore: 0.9722316861152649\n",
      "Substitute: staging, BertScore: 0.9626374840736389\n",
      "Substitute: performance, BertScore: 0.9610759615898132\n",
      "Substitute: presentation, BertScore: 0.9561482667922974\n",
      "Substitute: representation, BertScore: 0.9506773948669434\n",
      "Substitute: depiction, BertScore: 0.9490075707435608\n",
      "Substitute: recording, BertScore: 0.9417991042137146\n",
      "Substitute: image, BertScore: 0.9412159323692322\n",
      "Substitute: portrait, BertScore: 0.9395637512207031\n",
      "Substitute: portrayal, BertScore: 0.9392727613449097\n",
      "Substitute: installation, BertScore: 0.9373399019241333\n",
      "Substitute: production, BertScore: 0.9337865114212036\n",
      "Substitute: versions, BertScore: 0.93099045753479\n",
      "Substitute: version, BertScore: 0.9301867485046387\n",
      "Substitute: display, BertScore: 0.92728590965271\n",
      "Substitute: interpretation, BertScore: 0.9270656108856201\n",
      "Substitute: imitation, BertScore: 0.9265559315681458\n",
      "Substitute: translation, BertScore: 0.9250959753990173\n",
      "Substitute: description, BertScore: 0.9214621782302856\n",
      "Substitute: interpretations, BertScore: 0.9089719653129578\n",
      "Substitute: characterization, BertScore: 0.9043740034103394\n",
      "Substitute: expression, BertScore: 0.9009472131729126\n",
      "Substitute: use, BertScore: 0.9006521701812744\n",
      "Substitute: delivery, BertScore: 0.9000413417816162\n",
      "Substitute: treatment, BertScore: 0.8884245753288269\n",
      "Substitute: style, BertScore: 0.856110155582428\n",
      "Substitute: definition, BertScore: 0.8548077940940857\n",
      "Substitute: voice, BertScore: 0.8488240838050842\n",
      "Substitute: speaking, BertScore: 0.8355158567428589\n",
      "top-10 substitutes based on bertscores in context: ['rendering', 'staging', 'performance', 'presentation', 'representation', 'depiction', 'recording', 'image', 'portrait', 'portrayal']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: morph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: transform, BertScore: 0.9861448407173157\n",
      "Substitute: evolve, BertScore: 0.9852075576782227\n",
      "Substitute: blossom, BertScore: 0.9845925569534302\n",
      "Substitute: develop, BertScore: 0.9845818877220154\n",
      "Substitute: turn, BertScore: 0.9842573404312134\n",
      "Substitute: shift, BertScore: 0.9835386872291565\n",
      "Substitute: grow, BertScore: 0.9834244251251221\n",
      "Substitute: dip, BertScore: 0.9802713990211487\n",
      "Substitute: spiral, BertScore: 0.9795023798942566\n",
      "Substitute: explode, BertScore: 0.9780893325805664\n",
      "Substitute: descend, BertScore: 0.9776613712310791\n",
      "Substitute: expand, BertScore: 0.9775598049163818\n",
      "Substitute: fade, BertScore: 0.9772536158561707\n",
      "Substitute: settle, BertScore: 0.9757331013679504\n",
      "Substitute: merge, BertScore: 0.9754740595817566\n",
      "Substitute: slide, BertScore: 0.9753860235214233\n",
      "Substitute: slip, BertScore: 0.9751887321472168\n",
      "Substitute: rise, BertScore: 0.9748124480247498\n",
      "Substitute: sink, BertScore: 0.9738448262214661\n",
      "Substitute: spill, BertScore: 0.9732190370559692\n",
      "Substitute: plunge, BertScore: 0.9730556607246399\n",
      "Substitute: break, BertScore: 0.9728320240974426\n",
      "Substitute: run, BertScore: 0.972648024559021\n",
      "Substitute: divide, BertScore: 0.9726442098617554\n",
      "Substitute: move, BertScore: 0.971953272819519\n",
      "Substitute: fall, BertScore: 0.9697790145874023\n",
      "Substitute: retreat, BertScore: 0.9679824113845825\n",
      "Substitute: tap, BertScore: 0.9671026468276978\n",
      "Substitute: enter, BertScore: 0.9651007056236267\n",
      "top-10 substitutes based on bertscores in context: ['transform', 'evolve', 'blossom', 'develop', 'turn', 'shift', 'grow', 'dip', 'spiral', 'explode']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: authorized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: permitted, BertScore: 0.9837483167648315\n",
      "Substitute: authorised, BertScore: 0.9809382557868958\n",
      "Substitute: allowed, BertScore: 0.97895348072052\n",
      "Substitute: empowered, BertScore: 0.9768897294998169\n",
      "Substitute: licensed, BertScore: 0.9758867621421814\n",
      "Substitute: ordered, BertScore: 0.9740376472473145\n",
      "Substitute: eligible, BertScore: 0.9726653099060059\n",
      "Substitute: required, BertScore: 0.9726063013076782\n",
      "Substitute: qualified, BertScore: 0.9700202941894531\n",
      "Substitute: directed, BertScore: 0.9697439670562744\n",
      "Substitute: invited, BertScore: 0.9697417616844177\n",
      "Substitute: entitled, BertScore: 0.9678204655647278\n",
      "Substitute: expected, BertScore: 0.9677513837814331\n",
      "Substitute: requested, BertScore: 0.9676783680915833\n",
      "Substitute: scheduled, BertScore: 0.9664127826690674\n",
      "Substitute: registered, BertScore: 0.9649158716201782\n",
      "Substitute: asked, BertScore: 0.9611208438873291\n",
      "Substitute: available, BertScore: 0.9599781036376953\n",
      "Substitute: permission, BertScore: 0.9580330848693848\n",
      "Substitute: prompted, BertScore: 0.9575735926628113\n",
      "Substitute: able, BertScore: 0.9570376873016357\n",
      "Substitute: willing, BertScore: 0.9563778638839722\n",
      "Substitute: informed, BertScore: 0.9542748928070068\n",
      "Substitute: responsible, BertScore: 0.9529792070388794\n",
      "Substitute: necessary, BertScore: 0.9520203471183777\n",
      "Substitute: requesting, BertScore: 0.947845458984375\n",
      "Substitute: going, BertScore: 0.9434896111488342\n",
      "Substitute: ready, BertScore: 0.9424754977226257\n",
      "Substitute: intending, BertScore: 0.9404674172401428\n",
      "top-10 substitutes based on bertscores in context: ['permitted', 'authorised', 'allowed', 'empowered', 'licensed', 'ordered', 'eligible', 'required', 'qualified', 'directed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: internship\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: job, BertScore: 0.9778270125389099\n",
      "Substitute: residency, BertScore: 0.9732668995857239\n",
      "Substitute: intern, BertScore: 0.9719401001930237\n",
      "Substitute: employment, BertScore: 0.9707505702972412\n",
      "Substitute: apprenticeship, BertScore: 0.96966153383255\n",
      "Substitute: assignment, BertScore: 0.9689761400222778\n",
      "Substitute: interview, BertScore: 0.9685304164886475\n",
      "Substitute: audition, BertScore: 0.9620485901832581\n",
      "Substitute: appointment, BertScore: 0.9582549929618835\n",
      "Substitute: orientation, BertScore: 0.9577654600143433\n",
      "Substitute: extension, BertScore: 0.9559685587882996\n",
      "Substitute: application, BertScore: 0.9551703929901123\n",
      "Substitute: assistant, BertScore: 0.9514304399490356\n",
      "Substitute: apartment, BertScore: 0.9502536654472351\n",
      "Substitute: award, BertScore: 0.9496898651123047\n",
      "Substitute: opportunity, BertScore: 0.9492137432098389\n",
      "Substitute: opening, BertScore: 0.9491599798202515\n",
      "Substitute: office, BertScore: 0.9482391476631165\n",
      "Substitute: offer, BertScore: 0.9481141567230225\n",
      "Substitute: education, BertScore: 0.948034942150116\n",
      "Substitute: occupation, BertScore: 0.9466825723648071\n",
      "Substitute: agency, BertScore: 0.9447286128997803\n",
      "Substitute: evaluation, BertScore: 0.9426642656326294\n",
      "Substitute: experience, BertScore: 0.9399073123931885\n",
      "Substitute: agent, BertScore: 0.9390178918838501\n",
      "Substitute: organization, BertScore: 0.9384814500808716\n",
      "Substitute: employer, BertScore: 0.9365728497505188\n",
      "Substitute: option, BertScore: 0.9299198389053345\n",
      "Substitute: idea, BertScore: 0.9297598600387573\n",
      "top-10 substitutes based on bertscores in context: ['job', 'residency', 'intern', 'employment', 'apprenticeship', 'assignment', 'interview', 'audition', 'appointment', 'orientation']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: tragedy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: disaster, BertScore: 0.9796443581581116\n",
      "Substitute: catastrophe, BertScore: 0.9754495620727539\n",
      "Substitute: crisis, BertScore: 0.9599798917770386\n",
      "Substitute: crime, BertScore: 0.9474563598632812\n",
      "Substitute: nightmare, BertScore: 0.9428759813308716\n",
      "Substitute: danger, BertScore: 0.9417718052864075\n",
      "Substitute: loss, BertScore: 0.9406147003173828\n",
      "Substitute: miracle, BertScore: 0.9396626353263855\n",
      "Substitute: death, BertScore: 0.9371703863143921\n",
      "Substitute: conflict, BertScore: 0.9363163709640503\n",
      "Substitute: mistake, BertScore: 0.9345561861991882\n",
      "Substitute: famine, BertScore: 0.93218994140625\n",
      "Substitute: revolution, BertScore: 0.9321573376655579\n",
      "Substitute: storm, BertScore: 0.9308785796165466\n",
      "Substitute: failure, BertScore: 0.9306861162185669\n",
      "Substitute: earthquake, BertScore: 0.930208683013916\n",
      "Substitute: fire, BertScore: 0.92613285779953\n",
      "Substitute: depression, BertScore: 0.9251623153686523\n",
      "Substitute: war, BertScore: 0.9251283407211304\n",
      "Substitute: quake, BertScore: 0.9182681441307068\n",
      "Substitute: tsunami, BertScore: 0.9169619679450989\n",
      "Substitute: panic, BertScore: 0.9112575054168701\n",
      "Substitute: hurricane, BertScore: 0.9107483625411987\n",
      "Substitute: dream, BertScore: 0.9087172150611877\n",
      "Substitute: bomb, BertScore: 0.9084938168525696\n",
      "Substitute: recession, BertScore: 0.9082232713699341\n",
      "Substitute: tornado, BertScore: 0.9055361747741699\n",
      "Substitute: day, BertScore: 0.900132954120636\n",
      "Substitute: bridge, BertScore: 0.8988995552062988\n",
      "top-10 substitutes based on bertscores in context: ['disaster', 'catastrophe', 'crisis', 'crime', 'nightmare', 'danger', 'loss', 'miracle', 'death', 'conflict']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: monitoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: observing, BertScore: 0.9937516450881958\n",
      "Substitute: tracking, BertScore: 0.9937359094619751\n",
      "Substitute: inspecting, BertScore: 0.9932481050491333\n",
      "Substitute: studying, BertScore: 0.9926625490188599\n",
      "Substitute: checking, BertScore: 0.9922182559967041\n",
      "Substitute: reviewing, BertScore: 0.9921491146087646\n",
      "Substitute: analyzing, BertScore: 0.9915192127227783\n",
      "Substitute: investigating, BertScore: 0.9907293319702148\n",
      "Substitute: examining, BertScore: 0.9906947612762451\n",
      "Substitute: surveying, BertScore: 0.9904670119285583\n",
      "Substitute: watching, BertScore: 0.9901240468025208\n",
      "Substitute: supervising, BertScore: 0.9899080991744995\n",
      "Substitute: measuring, BertScore: 0.9895827174186707\n",
      "Substitute: overseeing, BertScore: 0.9893230199813843\n",
      "Substitute: assessing, BertScore: 0.9892855882644653\n",
      "Substitute: evaluating, BertScore: 0.9884499311447144\n",
      "Substitute: probing, BertScore: 0.988215982913971\n",
      "Substitute: reporting, BertScore: 0.9863726496696472\n",
      "Substitute: managing, BertScore: 0.9859928488731384\n",
      "Substitute: controlling, BertScore: 0.9848254323005676\n",
      "Substitute: handling, BertScore: 0.984237551689148\n",
      "Substitute: testing, BertScore: 0.9836555123329163\n",
      "Substitute: discussing, BertScore: 0.9834772348403931\n",
      "Substitute: seeing, BertScore: 0.9809296131134033\n",
      "Substitute: fixing, BertScore: 0.9803183078765869\n",
      "Substitute: sensing, BertScore: 0.9783530235290527\n",
      "Substitute: improving, BertScore: 0.9716253876686096\n",
      "top-10 substitutes based on bertscores in context: ['observing', 'tracking', 'inspecting', 'studying', 'checking', 'reviewing', 'analyzing', 'investigating', 'examining', 'surveying']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: provisioning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: delivery, BertScore: 0.9792642593383789\n",
      "Substitute: support, BertScore: 0.9771716594696045\n",
      "Substitute: providing, BertScore: 0.9770097732543945\n",
      "Substitute: supply, BertScore: 0.976631760597229\n",
      "Substitute: supporting, BertScore: 0.9757730960845947\n",
      "Substitute: distribution, BertScore: 0.9754171371459961\n",
      "Substitute: service, BertScore: 0.9752877354621887\n",
      "Substitute: procurement, BertScore: 0.9751482009887695\n",
      "Substitute: operating, BertScore: 0.9749223589897156\n",
      "Substitute: funding, BertScore: 0.9739991426467896\n",
      "Substitute: financing, BertScore: 0.9738448858261108\n",
      "Substitute: filling, BertScore: 0.9737312197685242\n",
      "Substitute: contracting, BertScore: 0.9729968309402466\n",
      "Substitute: logistics, BertScore: 0.9729030728340149\n",
      "Substitute: management, BertScore: 0.9728860259056091\n",
      "Substitute: payment, BertScore: 0.9727350473403931\n",
      "Substitute: services, BertScore: 0.9726607799530029\n",
      "Substitute: infrastructure, BertScore: 0.9724046587944031\n",
      "Substitute: building, BertScore: 0.9711194038391113\n",
      "Substitute: overall, BertScore: 0.9710192680358887\n",
      "Substitute: financial, BertScore: 0.9709903001785278\n",
      "Substitute: disposal, BertScore: 0.9708758592605591\n",
      "Substitute: finance, BertScore: 0.9698712229728699\n",
      "Substitute: banking, BertScore: 0.9693818092346191\n",
      "Substitute: business, BertScore: 0.9693422913551331\n",
      "Substitute: manufacturing, BertScore: 0.9691236019134521\n",
      "Substitute: expansion, BertScore: 0.9669485688209534\n",
      "Substitute: restructuring, BertScore: 0.9642540216445923\n",
      "Substitute: other, BertScore: 0.9635352492332458\n",
      "top-10 substitutes based on bertscores in context: ['delivery', 'support', 'providing', 'supply', 'supporting', 'distribution', 'service', 'procurement', 'operating', 'funding']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: downplayed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: ignored, BertScore: 0.9707894921302795\n",
      "Substitute: exploited, BertScore: 0.9649659395217896\n",
      "Substitute: rejected, BertScore: 0.9638649225234985\n",
      "Substitute: acknowledged, BertScore: 0.9627317786216736\n",
      "Substitute: upheld, BertScore: 0.9626254439353943\n",
      "Substitute: challenged, BertScore: 0.9625135660171509\n",
      "Substitute: defended, BertScore: 0.9624855518341064\n",
      "Substitute: embraced, BertScore: 0.9612658023834229\n",
      "Substitute: pushed, BertScore: 0.9609556198120117\n",
      "Substitute: accepted, BertScore: 0.9601784348487854\n",
      "Substitute: used, BertScore: 0.9573861956596375\n",
      "Substitute: repeated, BertScore: 0.9571839570999146\n",
      "Substitute: adopted, BertScore: 0.9564130306243896\n",
      "Substitute: criticized, BertScore: 0.9549626708030701\n",
      "Substitute: beaten, BertScore: 0.9538148641586304\n",
      "Substitute: maintained, BertScore: 0.9537851214408875\n",
      "Substitute: taken, BertScore: 0.9530077576637268\n",
      "Substitute: enjoyed, BertScore: 0.9521045684814453\n",
      "Substitute: lost, BertScore: 0.9519096612930298\n",
      "Substitute: criticised, BertScore: 0.9513723254203796\n",
      "Substitute: chosen, BertScore: 0.9506445527076721\n",
      "Substitute: retained, BertScore: 0.9504451155662537\n",
      "Substitute: achieved, BertScore: 0.9503952860832214\n",
      "Substitute: kept, BertScore: 0.9490987658500671\n",
      "Substitute: played, BertScore: 0.9471139907836914\n",
      "Substitute: blamed, BertScore: 0.9457109570503235\n",
      "Substitute: had, BertScore: 0.9455342292785645\n",
      "Substitute: reached, BertScore: 0.9454081654548645\n",
      "Substitute: provided, BertScore: 0.9447625279426575\n",
      "Substitute: won, BertScore: 0.9438778162002563\n",
      "top-10 substitutes based on bertscores in context: ['ignored', 'exploited', 'rejected', 'acknowledged', 'upheld', 'challenged', 'defended', 'embraced', 'pushed', 'accepted']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: tragedy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: disaster, BertScore: 0.9925372004508972\n",
      "Substitute: catastrophe, BertScore: 0.9899319410324097\n",
      "Substitute: trauma, BertScore: 0.9880512952804565\n",
      "Substitute: crisis, BertScore: 0.9873234033584595\n",
      "Substitute: drama, BertScore: 0.9856026768684387\n",
      "Substitute: devastation, BertScore: 0.9855254888534546\n",
      "Substitute: accident, BertScore: 0.9850561618804932\n",
      "Substitute: incident, BertScore: 0.9844722747802734\n",
      "Substitute: scandal, BertScore: 0.9840695261955261\n",
      "Substitute: loss, BertScore: 0.9828925728797913\n",
      "Substitute: carnage, BertScore: 0.982873797416687\n",
      "Substitute: tragic, BertScore: 0.9827924966812134\n",
      "Substitute: mess, BertScore: 0.9825239777565002\n",
      "Substitute: event, BertScore: 0.9824196696281433\n",
      "Substitute: suffering, BertScore: 0.981793224811554\n",
      "Substitute: situation, BertScore: 0.9810699820518494\n",
      "Substitute: death, BertScore: 0.9808014631271362\n",
      "Substitute: violence, BertScore: 0.9799750447273254\n",
      "Substitute: problem, BertScore: 0.9792566895484924\n",
      "Substitute: failure, BertScore: 0.9782063364982605\n",
      "Substitute: miracle, BertScore: 0.9777971506118774\n",
      "Substitute: crime, BertScore: 0.9774217009544373\n",
      "Substitute: sorrow, BertScore: 0.9765174388885498\n",
      "Substitute: story, BertScore: 0.9757336974143982\n",
      "Substitute: war, BertScore: 0.9754845499992371\n",
      "Substitute: happening, BertScore: 0.9707812666893005\n",
      "Substitute: disease, BertScore: 0.9705002903938293\n",
      "Substitute: case, BertScore: 0.966411292552948\n",
      "Substitute: happened, BertScore: 0.9575833678245544\n",
      "top-10 substitutes based on bertscores in context: ['disaster', 'catastrophe', 'trauma', 'crisis', 'drama', 'devastation', 'accident', 'incident', 'scandal', 'loss']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: authoritarian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: corrupt, BertScore: 0.9873502850532532\n",
      "Substitute: aggressive, BertScore: 0.9873373508453369\n",
      "Substitute: violent, BertScore: 0.9868538975715637\n",
      "Substitute: radical, BertScore: 0.9860602617263794\n",
      "Substitute: conservative, BertScore: 0.9856269955635071\n",
      "Substitute: militant, BertScore: 0.9856248497962952\n",
      "Substitute: moderate, BertScore: 0.984571099281311\n",
      "Substitute: liberal, BertScore: 0.9843067526817322\n",
      "Substitute: unstable, BertScore: 0.9842119216918945\n",
      "Substitute: reactive, BertScore: 0.9829888939857483\n",
      "Substitute: political, BertScore: 0.9825850129127502\n",
      "Substitute: nationalist, BertScore: 0.982008159160614\n",
      "Substitute: erratic, BertScore: 0.9814232587814331\n",
      "Substitute: unpopular, BertScore: 0.9812735915184021\n",
      "Substitute: independent, BertScore: 0.9810722470283508\n",
      "Substitute: democratic, BertScore: 0.9810090065002441\n",
      "Substitute: centralized, BertScore: 0.9800530076026917\n",
      "Substitute: charismatic, BertScore: 0.97968989610672\n",
      "Substitute: paranoid, BertScore: 0.9796442985534668\n",
      "Substitute: dangerous, BertScore: 0.9782927632331848\n",
      "Substitute: competitive, BertScore: 0.9780961275100708\n",
      "Substitute: powerful, BertScore: 0.977290153503418\n",
      "Substitute: senior, BertScore: 0.9738017320632935\n",
      "Substitute: influential, BertScore: 0.973178505897522\n",
      "Substitute: ambitious, BertScore: 0.9729713201522827\n",
      "Substitute: effective, BertScore: 0.9722508788108826\n",
      "Substitute: popular, BertScore: 0.9708268642425537\n",
      "Substitute: power, BertScore: 0.9705749154090881\n",
      "Substitute: confident, BertScore: 0.9697831869125366\n",
      "top-10 substitutes based on bertscores in context: ['corrupt', 'aggressive', 'violent', 'radical', 'conservative', 'militant', 'moderate', 'liberal', 'unstable', 'reactive']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: prohibits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: prevents, BertScore: 0.99784916639328\n",
      "Substitute: outlaws, BertScore: 0.9978377223014832\n",
      "Substitute: permits, BertScore: 0.997534453868866\n",
      "Substitute: bars, BertScore: 0.9971364140510559\n",
      "Substitute: restrictions, BertScore: 0.9969194531440735\n",
      "Substitute: allows, BertScore: 0.9967817068099976\n",
      "Substitute: mandates, BertScore: 0.9965170621871948\n",
      "Substitute: regulates, BertScore: 0.9961625337600708\n",
      "Substitute: forbid, BertScore: 0.9959810972213745\n",
      "Substitute: controls, BertScore: 0.9959476590156555\n",
      "Substitute: forbade, BertScore: 0.9959261417388916\n",
      "Substitute: limits, BertScore: 0.9958720803260803\n",
      "Substitute: requires, BertScore: 0.9958535432815552\n",
      "Substitute: outlawed, BertScore: 0.9954599738121033\n",
      "Substitute: banned, BertScore: 0.9952385425567627\n",
      "Substitute: protects, BertScore: 0.995083212852478\n",
      "Substitute: stops, BertScore: 0.9949162006378174\n",
      "Substitute: blocks, BertScore: 0.9947724938392639\n",
      "Substitute: rules, BertScore: 0.9946779012680054\n",
      "Substitute: banning, BertScore: 0.9946609735488892\n",
      "Substitute: defines, BertScore: 0.9943605065345764\n",
      "Substitute: provides, BertScore: 0.9938321113586426\n",
      "Substitute: ban, BertScore: 0.9928336143493652\n",
      "Substitute: opposes, BertScore: 0.99223792552948\n",
      "Substitute: states, BertScore: 0.9916552305221558\n",
      "Substitute: includes, BertScore: 0.9909418821334839\n",
      "top-10 substitutes based on bertscores in context: ['prevents', 'outlaws', 'permits', 'bars', 'restrictions', 'allows', 'mandates', 'regulates', 'forbid', 'controls']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: prevailing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: prevalent, BertScore: 0.9711556434631348\n",
      "Substitute: predominant, BertScore: 0.9695826768875122\n",
      "Substitute: competing, BertScore: 0.9613857269287109\n",
      "Substitute: reigning, BertScore: 0.960864782333374\n",
      "Substitute: operating, BertScore: 0.9588374495506287\n",
      "Substitute: dominant, BertScore: 0.9534741044044495\n",
      "Substitute: settling, BertScore: 0.9527242183685303\n",
      "Substitute: winning, BertScore: 0.9523317217826843\n",
      "Substitute: fighting, BertScore: 0.9523255228996277\n",
      "Substitute: present, BertScore: 0.9505776762962341\n",
      "Substitute: common, BertScore: 0.9495869874954224\n",
      "Substitute: growing, BertScore: 0.9492328763008118\n",
      "Substitute: neutral, BertScore: 0.949123740196228\n",
      "Substitute: mixing, BertScore: 0.9489548206329346\n",
      "Substitute: working, BertScore: 0.9485063552856445\n",
      "Substitute: participating, BertScore: 0.9484590291976929\n",
      "Substitute: living, BertScore: 0.945975124835968\n",
      "Substitute: engaged, BertScore: 0.9456070065498352\n",
      "Substitute: engaging, BertScore: 0.9453146457672119\n",
      "Substitute: brewing, BertScore: 0.9450865983963013\n",
      "Substitute: being, BertScore: 0.9450240135192871\n",
      "Substitute: changing, BertScore: 0.9430115818977356\n",
      "Substitute: staying, BertScore: 0.9418449401855469\n",
      "Substitute: continuing, BertScore: 0.9410564303398132\n",
      "Substitute: involved, BertScore: 0.9388982057571411\n",
      "Substitute: sharing, BertScore: 0.9377472996711731\n",
      "Substitute: also, BertScore: 0.9352931380271912\n",
      "Substitute: consistent, BertScore: 0.9331483840942383\n",
      "Substitute: not, BertScore: 0.9297834634780884\n",
      "top-10 substitutes based on bertscores in context: ['prevalent', 'predominant', 'competing', 'reigning', 'operating', 'dominant', 'settling', 'winning', 'fighting', 'present']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: skittish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: shy, BertScore: 0.9755640029907227\n",
      "Substitute: arrogant, BertScore: 0.9755265116691589\n",
      "Substitute: erratic, BertScore: 0.9754549860954285\n",
      "Substitute: stubborn, BertScore: 0.9751744270324707\n",
      "Substitute: reckless, BertScore: 0.9748843908309937\n",
      "Substitute: cocky, BertScore: 0.974884033203125\n",
      "Substitute: angry, BertScore: 0.9734632968902588\n",
      "Substitute: fiery, BertScore: 0.9730808138847351\n",
      "Substitute: quiet, BertScore: 0.9727603197097778\n",
      "Substitute: rude, BertScore: 0.9725168347358704\n",
      "Substitute: bewildered, BertScore: 0.9723690748214722\n",
      "Substitute: humble, BertScore: 0.9721496105194092\n",
      "Substitute: confused, BertScore: 0.9715878963470459\n",
      "Substitute: selfish, BertScore: 0.9713571667671204\n",
      "Substitute: determined, BertScore: 0.971356987953186\n",
      "Substitute: crazy, BertScore: 0.9705493450164795\n",
      "Substitute: ignorant, BertScore: 0.970359206199646\n",
      "Substitute: mad, BertScore: 0.9703484177589417\n",
      "Substitute: tired, BertScore: 0.969955563545227\n",
      "Substitute: bald, BertScore: 0.9698329567909241\n",
      "Substitute: stupid, BertScore: 0.9697355628013611\n",
      "Substitute: reserved, BertScore: 0.9696434736251831\n",
      "Substitute: drunken, BertScore: 0.9684817790985107\n",
      "Substitute: cold, BertScore: 0.9682118892669678\n",
      "Substitute: corrupt, BertScore: 0.9678121209144592\n",
      "Substitute: bearded, BertScore: 0.9669947028160095\n",
      "Substitute: young, BertScore: 0.9664695262908936\n",
      "Substitute: absent, BertScore: 0.9663589596748352\n",
      "Substitute: drunk, BertScore: 0.966270923614502\n",
      "Substitute: ill, BertScore: 0.9658626914024353\n",
      "top-10 substitutes based on bertscores in context: ['shy', 'arrogant', 'erratic', 'stubborn', 'reckless', 'cocky', 'angry', 'fiery', 'quiet', 'rude']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: obliged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: compelled, BertScore: 0.9897960424423218\n",
      "Substitute: required, BertScore: 0.9888017773628235\n",
      "Substitute: forced, BertScore: 0.9870613217353821\n",
      "Substitute: permitted, BertScore: 0.9863511323928833\n",
      "Substitute: empowered, BertScore: 0.9849568605422974\n",
      "Substitute: ordered, BertScore: 0.9843682050704956\n",
      "Substitute: authorised, BertScore: 0.9839305281639099\n",
      "Substitute: allowed, BertScore: 0.983870267868042\n",
      "Substitute: directed, BertScore: 0.9836711883544922\n",
      "Substitute: induced, BertScore: 0.9836364984512329\n",
      "Substitute: encouraged, BertScore: 0.9833457469940186\n",
      "Substitute: instructed, BertScore: 0.982499897480011\n",
      "Substitute: pressured, BertScore: 0.9823283553123474\n",
      "Substitute: authorized, BertScore: 0.9818320274353027\n",
      "Substitute: prompted, BertScore: 0.9815139770507812\n",
      "Substitute: enabled, BertScore: 0.9811540246009827\n",
      "Substitute: advised, BertScore: 0.9799718856811523\n",
      "Substitute: invited, BertScore: 0.9797491431236267\n",
      "Substitute: demanded, BertScore: 0.9790058732032776\n",
      "Substitute: persuaded, BertScore: 0.9785977602005005\n",
      "Substitute: urged, BertScore: 0.9774668216705322\n",
      "Substitute: contracted, BertScore: 0.9771076440811157\n",
      "Substitute: requested, BertScore: 0.9769695997238159\n",
      "Substitute: asked, BertScore: 0.9761743545532227\n",
      "Substitute: told, BertScore: 0.9745557308197021\n",
      "Substitute: promised, BertScore: 0.9739495515823364\n",
      "Substitute: commissioned, BertScore: 0.9738724231719971\n",
      "Substitute: paid, BertScore: 0.971839189529419\n",
      "Substitute: expected, BertScore: 0.9607359766960144\n",
      "top-10 substitutes based on bertscores in context: ['compelled', 'required', 'forced', 'permitted', 'empowered', 'ordered', 'authorised', 'allowed', 'directed', 'induced']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: ouster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: downfall, BertScore: 0.9776194095611572\n",
      "Substitute: removal, BertScore: 0.9773551225662231\n",
      "Substitute: dismissal, BertScore: 0.9762080907821655\n",
      "Substitute: elimination, BertScore: 0.9761086702346802\n",
      "Substitute: departure, BertScore: 0.9746485948562622\n",
      "Substitute: arrest, BertScore: 0.9743605852127075\n",
      "Substitute: fall, BertScore: 0.9742059111595154\n",
      "Substitute: overthrow, BertScore: 0.9740157723426819\n",
      "Substitute: capture, BertScore: 0.9728305339813232\n",
      "Substitute: retirement, BertScore: 0.9723864793777466\n",
      "Substitute: demise, BertScore: 0.9721556305885315\n",
      "Substitute: liberation, BertScore: 0.9717082381248474\n",
      "Substitute: resignation, BertScore: 0.9716665744781494\n",
      "Substitute: collapse, BertScore: 0.9713608026504517\n",
      "Substitute: destruction, BertScore: 0.9702209830284119\n",
      "Substitute: death, BertScore: 0.9697333574295044\n",
      "Substitute: execution, BertScore: 0.9697256088256836\n",
      "Substitute: release, BertScore: 0.9696564078330994\n",
      "Substitute: seizure, BertScore: 0.9685801267623901\n",
      "Substitute: ou, BertScore: 0.96602463722229\n",
      "Substitute: abolition, BertScore: 0.9656296968460083\n",
      "Substitute: return, BertScore: 0.9655348658561707\n",
      "Substitute: replacement, BertScore: 0.9653016924858093\n",
      "Substitute: freedom, BertScore: 0.9636492133140564\n",
      "Substitute: restoration, BertScore: 0.9635934829711914\n",
      "Substitute: end, BertScore: 0.9624667167663574\n",
      "Substitute: reform, BertScore: 0.9622101783752441\n",
      "Substitute: recognition, BertScore: 0.9586170315742493\n",
      "Substitute: control, BertScore: 0.9530212879180908\n",
      "Substitute: leadership, BertScore: 0.9509682059288025\n",
      "top-10 substitutes based on bertscores in context: ['downfall', 'removal', 'dismissal', 'elimination', 'departure', 'arrest', 'fall', 'overthrow', 'capture', 'retirement']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: mainstream\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: widespread, BertScore: 0.9939720034599304\n",
      "Substitute: worldwide, BertScore: 0.9928357601165771\n",
      "Substitute: international, BertScore: 0.9927244186401367\n",
      "Substitute: broad, BertScore: 0.992283046245575\n",
      "Substitute: global, BertScore: 0.9917786121368408\n",
      "Substitute: western, BertScore: 0.9917533993721008\n",
      "Substitute: wider, BertScore: 0.991420567035675\n",
      "Substitute: serious, BertScore: 0.9908850193023682\n",
      "Substitute: significant, BertScore: 0.9908372759819031\n",
      "Substitute: major, BertScore: 0.9904887080192566\n",
      "Substitute: crossover, BertScore: 0.9904082417488098\n",
      "Substitute: critical, BertScore: 0.990036129951477\n",
      "Substitute: broader, BertScore: 0.9896619915962219\n",
      "Substitute: media, BertScore: 0.989396333694458\n",
      "Substitute: massive, BertScore: 0.9893004894256592\n",
      "Substitute: moderate, BertScore: 0.9884204268455505\n",
      "Substitute: much, BertScore: 0.9878444075584412\n",
      "Substitute: heavy, BertScore: 0.9876625537872314\n",
      "Substitute: some, BertScore: 0.987034797668457\n",
      "Substitute: further, BertScore: 0.9870001673698425\n",
      "Substitute: big, BertScore: 0.9865108728408813\n",
      "Substitute: full, BertScore: 0.9859001636505127\n",
      "Substitute: new, BertScore: 0.9857942461967468\n",
      "Substitute: most, BertScore: 0.985778272151947\n",
      "Substitute: greater, BertScore: 0.9848393797874451\n",
      "Substitute: back, BertScore: 0.9846359491348267\n",
      "Substitute: more, BertScore: 0.9846060872077942\n",
      "Substitute: the, BertScore: 0.9809529185295105\n",
      "Substitute: its, BertScore: 0.9804520010948181\n",
      "top-10 substitutes based on bertscores in context: ['widespread', 'worldwide', 'international', 'broad', 'global', 'western', 'wider', 'serious', 'significant', 'major']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: appealing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: lobbying, BertScore: 0.986584484577179\n",
      "Substitute: begging, BertScore: 0.9854758977890015\n",
      "Substitute: pleading, BertScore: 0.985302209854126\n",
      "Substitute: pressing, BertScore: 0.9845736026763916\n",
      "Substitute: calling, BertScore: 0.9842057228088379\n",
      "Substitute: asking, BertScore: 0.9841806888580322\n",
      "Substitute: applying, BertScore: 0.9837876558303833\n",
      "Substitute: pushing, BertScore: 0.9828161597251892\n",
      "Substitute: requesting, BertScore: 0.9825339913368225\n",
      "Substitute: demanding, BertScore: 0.981372594833374\n",
      "Substitute: challenging, BertScore: 0.9809591174125671\n",
      "Substitute: campaigning, BertScore: 0.9808610677719116\n",
      "Substitute: seeking, BertScore: 0.9773973226547241\n",
      "Substitute: arguing, BertScore: 0.9764271974563599\n",
      "Substitute: promising, BertScore: 0.974923312664032\n",
      "Substitute: wanting, BertScore: 0.9741054773330688\n",
      "Substitute: desperate, BertScore: 0.9722440838813782\n",
      "Substitute: trying, BertScore: 0.9716505408287048\n",
      "Substitute: fighting, BertScore: 0.971061646938324\n",
      "Substitute: hoping, BertScore: 0.9708822965621948\n",
      "Substitute: eager, BertScore: 0.9706921577453613\n",
      "Substitute: encouraging, BertScore: 0.9693081974983215\n",
      "Substitute: looking, BertScore: 0.9686035513877869\n",
      "Substitute: competing, BertScore: 0.9680736064910889\n",
      "Substitute: anxious, BertScore: 0.9676764607429504\n",
      "Substitute: searching, BertScore: 0.9668693542480469\n",
      "Substitute: striking, BertScore: 0.9654802083969116\n",
      "Substitute: waiting, BertScore: 0.9645531177520752\n",
      "Substitute: checking, BertScore: 0.9602757096290588\n",
      "top-10 substitutes based on bertscores in context: ['lobbying', 'begging', 'pleading', 'pressing', 'calling', 'asking', 'applying', 'pushing', 'requesting', 'demanding']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: surveillance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: monitoring, BertScore: 0.9788630604743958\n",
      "Substitute: tracking, BertScore: 0.9767565727233887\n",
      "Substitute: protection, BertScore: 0.9744737148284912\n",
      "Substitute: reconnaissance, BertScore: 0.973080575466156\n",
      "Substitute: security, BertScore: 0.9725749492645264\n",
      "Substitute: interrogation, BertScore: 0.9707487225532532\n",
      "Substitute: intelligence, BertScore: 0.9699920415878296\n",
      "Substitute: spying, BertScore: 0.9699258804321289\n",
      "Substitute: observation, BertScore: 0.9693955183029175\n",
      "Substitute: spy, BertScore: 0.9692696928977966\n",
      "Substitute: investigation, BertScore: 0.9688215851783752\n",
      "Substitute: patrol, BertScore: 0.9669936299324036\n",
      "Substitute: watch, BertScore: 0.9663349986076355\n",
      "Substitute: drone, BertScore: 0.9641420245170593\n",
      "Substitute: investigative, BertScore: 0.9639718532562256\n",
      "Substitute: monitor, BertScore: 0.9633400440216064\n",
      "Substitute: camera, BertScore: 0.9632695913314819\n",
      "Substitute: defense, BertScore: 0.9630105495452881\n",
      "Substitute: guard, BertScore: 0.9621671438217163\n",
      "Substitute: control, BertScore: 0.9599384069442749\n",
      "Substitute: video, BertScore: 0.9589521884918213\n",
      "Substitute: containment, BertScore: 0.9579922556877136\n",
      "Substitute: police, BertScore: 0.9575067758560181\n",
      "Substitute: escort, BertScore: 0.956614077091217\n",
      "Substitute: blockade, BertScore: 0.9556068181991577\n",
      "Substitute: cargo, BertScore: 0.9537032842636108\n",
      "Substitute: military, BertScore: 0.9518449902534485\n",
      "Substitute: cruise, BertScore: 0.9420415163040161\n",
      "Substitute: government, BertScore: 0.936346709728241\n",
      "top-10 substitutes based on bertscores in context: ['monitoring', 'tracking', 'protection', 'reconnaissance', 'security', 'interrogation', 'intelligence', 'spying', 'observation', 'spy']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: cooperated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: collaborated, BertScore: 0.9742672443389893\n",
      "Substitute: participated, BertScore: 0.965954065322876\n",
      "Substitute: partnered, BertScore: 0.9639047384262085\n",
      "Substitute: engaged, BertScore: 0.9629224538803101\n",
      "Substitute: coordinated, BertScore: 0.9615750908851624\n",
      "Substitute: assisted, BertScore: 0.9599556922912598\n",
      "Substitute: collaborate, BertScore: 0.9591727256774902\n",
      "Substitute: acted, BertScore: 0.9583668112754822\n",
      "Substitute: operated, BertScore: 0.9559793472290039\n",
      "Substitute: worked, BertScore: 0.9546833634376526\n",
      "Substitute: competed, BertScore: 0.9515917897224426\n",
      "Substitute: contributed, BertScore: 0.9513354897499084\n",
      "Substitute: agreed, BertScore: 0.9493911266326904\n",
      "Substitute: intervened, BertScore: 0.9493042826652527\n",
      "Substitute: helped, BertScore: 0.9490808844566345\n",
      "Substitute: carried, BertScore: 0.9485150575637817\n",
      "Substitute: supported, BertScore: 0.9457664489746094\n",
      "Substitute: consulted, BertScore: 0.9451800584793091\n",
      "Substitute: advanced, BertScore: 0.9421040415763855\n",
      "Substitute: advised, BertScore: 0.940563440322876\n",
      "Substitute: joined, BertScore: 0.9380440711975098\n",
      "Substitute: continued, BertScore: 0.9364851713180542\n",
      "Substitute: were, BertScore: 0.9337702989578247\n",
      "Substitute: focused, BertScore: 0.933763861656189\n",
      "Substitute: relied, BertScore: 0.9327291250228882\n",
      "Substitute: served, BertScore: 0.929658055305481\n",
      "Substitute: reported, BertScore: 0.9294412136077881\n",
      "Substitute: went, BertScore: 0.9276198744773865\n",
      "Substitute: cooperation, BertScore: 0.9228837490081787\n",
      "top-10 substitutes based on bertscores in context: ['collaborated', 'participated', 'partnered', 'engaged', 'coordinated', 'assisted', 'collaborate', 'acted', 'operated', 'worked']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sought\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: requested, BertScore: 0.9963076710700989\n",
      "Substitute: demanded, BertScore: 0.9947957396507263\n",
      "Substitute: obtained, BertScore: 0.9935586452484131\n",
      "Substitute: asked, BertScore: 0.9933180212974548\n",
      "Substitute: begged, BertScore: 0.9932177662849426\n",
      "Substitute: received, BertScore: 0.9926178455352783\n",
      "Substitute: craved, BertScore: 0.992551863193512\n",
      "Substitute: gotten, BertScore: 0.9918826818466187\n",
      "Substitute: got, BertScore: 0.9912770986557007\n",
      "Substitute: needed, BertScore: 0.9912729263305664\n",
      "Substitute: accepted, BertScore: 0.991241991519928\n",
      "Substitute: wanted, BertScore: 0.991040825843811\n",
      "Substitute: attempted, BertScore: 0.9900529384613037\n",
      "Substitute: drawn, BertScore: 0.990043580532074\n",
      "Substitute: found, BertScore: 0.9899511933326721\n",
      "Substitute: taken, BertScore: 0.9892585277557373\n",
      "Substitute: offered, BertScore: 0.9890797138214111\n",
      "Substitute: refused, BertScore: 0.9887583255767822\n",
      "Substitute: ordered, BertScore: 0.9882944226264954\n",
      "Substitute: declined, BertScore: 0.9882028698921204\n",
      "Substitute: won, BertScore: 0.9876960515975952\n",
      "Substitute: urged, BertScore: 0.987154483795166\n",
      "Substitute: provided, BertScore: 0.9859856367111206\n",
      "Substitute: given, BertScore: 0.9852768778800964\n",
      "Substitute: denied, BertScore: 0.9839522838592529\n",
      "Substitute: for, BertScore: 0.9761411547660828\n",
      "Substitute: the, BertScore: 0.973345160484314\n",
      "top-10 substitutes based on bertscores in context: ['requested', 'demanded', 'obtained', 'asked', 'begged', 'received', 'craved', 'gotten', 'got', 'needed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: debris\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: rubble, BertScore: 0.9929073452949524\n",
      "Substitute: wreckage, BertScore: 0.9927685856819153\n",
      "Substitute: junk, BertScore: 0.9879997968673706\n",
      "Substitute: trash, BertScore: 0.9867955446243286\n",
      "Substitute: dust, BertScore: 0.9867539405822754\n",
      "Substitute: garbage, BertScore: 0.9861514568328857\n",
      "Substitute: dirt, BertScore: 0.9861093163490295\n",
      "Substitute: mud, BertScore: 0.9859617948532104\n",
      "Substitute: rubbish, BertScore: 0.9849160313606262\n",
      "Substitute: damage, BertScore: 0.9848107695579529\n",
      "Substitute: rocks, BertScore: 0.9847634434700012\n",
      "Substitute: concrete, BertScore: 0.9841634035110474\n",
      "Substitute: ash, BertScore: 0.9838730096817017\n",
      "Substitute: rock, BertScore: 0.9833810329437256\n",
      "Substitute: sand, BertScore: 0.9832488298416138\n",
      "Substitute: objects, BertScore: 0.9829198122024536\n",
      "Substitute: material, BertScore: 0.9825892448425293\n",
      "Substitute: metal, BertScore: 0.9825707674026489\n",
      "Substitute: materials, BertScore: 0.9824526309967041\n",
      "Substitute: earth, BertScore: 0.9821001887321472\n",
      "Substitute: wood, BertScore: 0.9809027910232544\n",
      "Substitute: lumber, BertScore: 0.9806848764419556\n",
      "Substitute: water, BertScore: 0.9805018305778503\n",
      "Substitute: stuff, BertScore: 0.9802886843681335\n",
      "Substitute: space, BertScore: 0.9798814058303833\n",
      "Substitute: food, BertScore: 0.9785477519035339\n",
      "Substitute: furniture, BertScore: 0.9784057140350342\n",
      "Substitute: equipment, BertScore: 0.9775875806808472\n",
      "Substitute: waste, BertScore: 0.976091742515564\n",
      "top-10 substitutes based on bertscores in context: ['rubble', 'wreckage', 'junk', 'trash', 'dust', 'garbage', 'dirt', 'mud', 'rubbish', 'damage']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sanctions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: restrictions, BertScore: 0.9872609972953796\n",
      "Substitute: punishments, BertScore: 0.9853376150131226\n",
      "Substitute: penalties, BertScore: 0.9848333597183228\n",
      "Substitute: fines, BertScore: 0.9834180474281311\n",
      "Substitute: sentences, BertScore: 0.9817614555358887\n",
      "Substitute: punishment, BertScore: 0.9808257818222046\n",
      "Substitute: tariffs, BertScore: 0.9799633622169495\n",
      "Substitute: measures, BertScore: 0.9797578454017639\n",
      "Substitute: inspections, BertScore: 0.9788825511932373\n",
      "Substitute: charges, BertScore: 0.9781538844108582\n",
      "Substitute: rules, BertScore: 0.9781337976455688\n",
      "Substitute: incentives, BertScore: 0.9777939915657043\n",
      "Substitute: threats, BertScore: 0.9756959676742554\n",
      "Substitute: retaliation, BertScore: 0.9755369424819946\n",
      "Substitute: actions, BertScore: 0.9751538038253784\n",
      "Substitute: strikes, BertScore: 0.974327802658081\n",
      "Substitute: arms, BertScore: 0.9738170504570007\n",
      "Substitute: action, BertScore: 0.9733536243438721\n",
      "Substitute: condemnation, BertScore: 0.973030149936676\n",
      "Substitute: consequences, BertScore: 0.9726746678352356\n",
      "Substitute: weapons, BertScore: 0.9724180698394775\n",
      "Substitute: pressure, BertScore: 0.9723808169364929\n",
      "Substitute: attacks, BertScore: 0.9723739624023438\n",
      "Substitute: resolutions, BertScore: 0.9710624814033508\n",
      "Substitute: demands, BertScore: 0.970970094203949\n",
      "Substitute: accusations, BertScore: 0.9699175357818604\n",
      "Substitute: steps, BertScore: 0.9696540236473083\n",
      "Substitute: resolution, BertScore: 0.9628573656082153\n",
      "Substitute: protests, BertScore: 0.9623451828956604\n",
      "top-10 substitutes based on bertscores in context: ['restrictions', 'punishments', 'penalties', 'fines', 'sentences', 'punishment', 'tariffs', 'measures', 'inspections', 'charges']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: acquisition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: purchase, BertScore: 0.9945096969604492\n",
      "Substitute: acquire, BertScore: 0.9928906559944153\n",
      "Substitute: acquiring, BertScore: 0.9924159646034241\n",
      "Substitute: sale, BertScore: 0.9922961592674255\n",
      "Substitute: merger, BertScore: 0.9913535118103027\n",
      "Substitute: deal, BertScore: 0.9900498986244202\n",
      "Substitute: takeover, BertScore: 0.9895153045654297\n",
      "Substitute: expansion, BertScore: 0.9887726902961731\n",
      "Substitute: transaction, BertScore: 0.9884520173072815\n",
      "Substitute: move, BertScore: 0.9881089329719543\n",
      "Substitute: investment, BertScore: 0.9874587655067444\n",
      "Substitute: offering, BertScore: 0.9859293699264526\n",
      "Substitute: offer, BertScore: 0.9858720898628235\n",
      "Substitute: venture, BertScore: 0.9851599335670471\n",
      "Substitute: purchases, BertScore: 0.9849874377250671\n",
      "Substitute: operation, BertScore: 0.9849376082420349\n",
      "Substitute: decision, BertScore: 0.984279453754425\n",
      "Substitute: contract, BertScore: 0.9840669631958008\n",
      "Substitute: announcement, BertScore: 0.9839507341384888\n",
      "Substitute: agreement, BertScore: 0.9834721684455872\n",
      "Substitute: upgrade, BertScore: 0.9834592342376709\n",
      "Substitute: acquired, BertScore: 0.9818769693374634\n",
      "Substitute: project, BertScore: 0.9813964366912842\n",
      "Substitute: development, BertScore: 0.9811142086982727\n",
      "Substitute: transfer, BertScore: 0.9802440404891968\n",
      "Substitute: initiative, BertScore: 0.9788090586662292\n",
      "Substitute: unit, BertScore: 0.9777743220329285\n",
      "Substitute: product, BertScore: 0.9775081872940063\n",
      "top-10 substitutes based on bertscores in context: ['purchase', 'acquire', 'acquiring', 'sale', 'merger', 'deal', 'takeover', 'expansion', 'transaction', 'move']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: pledges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: promises, BertScore: 0.9814267158508301\n",
      "Substitute: emphasizes, BertScore: 0.9754524230957031\n",
      "Substitute: seeks, BertScore: 0.9752752780914307\n",
      "Substitute: guarantees, BertScore: 0.9752638339996338\n",
      "Substitute: declares, BertScore: 0.9747505187988281\n",
      "Substitute: promotes, BertScore: 0.9740941524505615\n",
      "Substitute: outlines, BertScore: 0.9738636016845703\n",
      "Substitute: offers, BertScore: 0.9723042845726013\n",
      "Substitute: recognizes, BertScore: 0.9715724587440491\n",
      "Substitute: measures, BertScore: 0.9712907671928406\n",
      "Substitute: establishes, BertScore: 0.9709290862083435\n",
      "Substitute: supports, BertScore: 0.970137357711792\n",
      "Substitute: confirms, BertScore: 0.9700894355773926\n",
      "Substitute: states, BertScore: 0.9698559641838074\n",
      "Substitute: highlights, BertScore: 0.9696881175041199\n",
      "Substitute: grants, BertScore: 0.9685312509536743\n",
      "Substitute: indicates, BertScore: 0.9684932827949524\n",
      "Substitute: addresses, BertScore: 0.9675108194351196\n",
      "Substitute: ensures, BertScore: 0.9667981266975403\n",
      "Substitute: adds, BertScore: 0.9667598009109497\n",
      "Substitute: extends, BertScore: 0.9666304588317871\n",
      "Substitute: provides, BertScore: 0.9656743407249451\n",
      "Substitute: tracks, BertScore: 0.9644253253936768\n",
      "Substitute: requires, BertScore: 0.9643021821975708\n",
      "Substitute: maintains, BertScore: 0.9633129835128784\n",
      "Substitute: includes, BertScore: 0.962450385093689\n",
      "Substitute: builds, BertScore: 0.959453821182251\n",
      "Substitute: ends, BertScore: 0.9571653008460999\n",
      "Substitute: follows, BertScore: 0.9496004581451416\n",
      "top-10 substitutes based on bertscores in context: ['promises', 'emphasizes', 'seeks', 'guarantees', 'declares', 'promotes', 'outlines', 'offers', 'recognizes', 'measures']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: debris\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: wreckage, BertScore: 0.9867141842842102\n",
      "Substitute: rubble, BertScore: 0.9857410788536072\n",
      "Substitute: dust, BertScore: 0.9821553826332092\n",
      "Substitute: damage, BertScore: 0.981755256652832\n",
      "Substitute: junk, BertScore: 0.980898916721344\n",
      "Substitute: fragments, BertScore: 0.9807206392288208\n",
      "Substitute: ash, BertScore: 0.9786621928215027\n",
      "Substitute: material, BertScore: 0.9783381223678589\n",
      "Substitute: waste, BertScore: 0.9778125286102295\n",
      "Substitute: mess, BertScore: 0.9775111675262451\n",
      "Substitute: fragment, BertScore: 0.97707200050354\n",
      "Substitute: object, BertScore: 0.9770265817642212\n",
      "Substitute: remains, BertScore: 0.9769103527069092\n",
      "Substitute: trash, BertScore: 0.9743161201477051\n",
      "Substitute: structure, BertScore: 0.9741183519363403\n",
      "Substitute: pile, BertScore: 0.9738696813583374\n",
      "Substitute: garbage, BertScore: 0.9724554419517517\n",
      "Substitute: data, BertScore: 0.9715791344642639\n",
      "Substitute: substance, BertScore: 0.9712790846824646\n",
      "Substitute: site, BertScore: 0.9711935520172119\n",
      "Substitute: contents, BertScore: 0.9700554609298706\n",
      "Substitute: piece, BertScore: 0.9697694182395935\n",
      "Substitute: missing, BertScore: 0.9683482646942139\n",
      "Substitute: area, BertScore: 0.967650294303894\n",
      "Substitute: vehicle, BertScore: 0.9676188826560974\n",
      "Substitute: body, BertScore: 0.9670838713645935\n",
      "Substitute: tree, BertScore: 0.9659999012947083\n",
      "Substitute: work, BertScore: 0.9654966592788696\n",
      "Substitute: matter, BertScore: 0.9611402153968811\n",
      "top-10 substitutes based on bertscores in context: ['wreckage', 'rubble', 'dust', 'damage', 'junk', 'fragments', 'ash', 'material', 'waste', 'mess']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: suspicious\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: concerned, BertScore: 0.9768597483634949\n",
      "Substitute: alarmed, BertScore: 0.97669917345047\n",
      "Substitute: wary, BertScore: 0.9758816957473755\n",
      "Substitute: paranoid, BertScore: 0.9757938981056213\n",
      "Substitute: skeptical, BertScore: 0.9738438725471497\n",
      "Substitute: worried, BertScore: 0.9731904864311218\n",
      "Substitute: fearful, BertScore: 0.9730561971664429\n",
      "Substitute: curious, BertScore: 0.9727940559387207\n",
      "Substitute: suspicions, BertScore: 0.9723129868507385\n",
      "Substitute: cautious, BertScore: 0.9720151424407959\n",
      "Substitute: unsure, BertScore: 0.9717671275138855\n",
      "Substitute: suspicion, BertScore: 0.9717563986778259\n",
      "Substitute: frightened, BertScore: 0.9714788794517517\n",
      "Substitute: suspect, BertScore: 0.9710006713867188\n",
      "Substitute: informed, BertScore: 0.9706770777702332\n",
      "Substitute: nervous, BertScore: 0.9701769948005676\n",
      "Substitute: unaware, BertScore: 0.9692111015319824\n",
      "Substitute: aware, BertScore: 0.9691429138183594\n",
      "Substitute: scared, BertScore: 0.9686880707740784\n",
      "Substitute: convinced, BertScore: 0.9675977230072021\n",
      "Substitute: afraid, BertScore: 0.9665937423706055\n",
      "Substitute: alert, BertScore: 0.965518593788147\n",
      "Substitute: jealous, BertScore: 0.9650856256484985\n",
      "Substitute: certain, BertScore: 0.9649287462234497\n",
      "Substitute: terrified, BertScore: 0.9645045399665833\n",
      "Substitute: critical, BertScore: 0.9638916850090027\n",
      "Substitute: conscious, BertScore: 0.9612497091293335\n",
      "Substitute: suspected, BertScore: 0.9591629505157471\n",
      "Substitute: suspects, BertScore: 0.955407977104187\n",
      "top-10 substitutes based on bertscores in context: ['concerned', 'alarmed', 'wary', 'paranoid', 'skeptical', 'worried', 'fearful', 'curious', 'suspicions', 'cautious']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: condolences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: apologies, BertScore: 0.9265012145042419\n",
      "Substitute: sympathy, BertScore: 0.9118692874908447\n",
      "Substitute: prayers, BertScore: 0.8986585140228271\n",
      "Substitute: support, BertScore: 0.8977316617965698\n",
      "Substitute: assistance, BertScore: 0.8926880955696106\n",
      "Substitute: pleas, BertScore: 0.891629695892334\n",
      "Substitute: concerns, BertScore: 0.8898110389709473\n",
      "Substitute: warnings, BertScore: 0.8877848982810974\n",
      "Substitute: comments, BertScore: 0.8876724243164062\n",
      "Substitute: complaints, BertScore: 0.8876607418060303\n",
      "Substitute: protest, BertScore: 0.8865921497344971\n",
      "Substitute: statements, BertScore: 0.8817011713981628\n",
      "Substitute: threats, BertScore: 0.8803016543388367\n",
      "Substitute: petitions, BertScore: 0.8794327974319458\n",
      "Substitute: messages, BertScore: 0.8758642077445984\n",
      "Substitute: stories, BertScore: 0.8745924830436707\n",
      "Substitute: message, BertScore: 0.8744150996208191\n",
      "Substitute: letters, BertScore: 0.8730323314666748\n",
      "Substitute: requests, BertScore: 0.8729997277259827\n",
      "Substitute: calls, BertScore: 0.8724406361579895\n",
      "Substitute: voices, BertScore: 0.8696142435073853\n",
      "Substitute: orders, BertScore: 0.8688740134239197\n",
      "Substitute: flags, BertScore: 0.8666677474975586\n",
      "Substitute: information, BertScore: 0.8658514022827148\n",
      "Substitute: thoughts, BertScore: 0.8644644618034363\n",
      "Substitute: photos, BertScore: 0.8643506169319153\n",
      "Substitute: emails, BertScore: 0.8586229681968689\n",
      "Substitute: mail, BertScore: 0.8575668334960938\n",
      "Substitute: names, BertScore: 0.8564547896385193\n",
      "top-10 substitutes based on bertscores in context: ['apologies', 'sympathy', 'prayers', 'support', 'assistance', 'pleas', 'concerns', 'warnings', 'comments', 'complaints']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: impeach\n",
      "Error occurred: list indices must be integers or slices, not str\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: unleashed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: ignited, BertScore: 0.9963138699531555\n",
      "Substitute: initiated, BertScore: 0.9960628747940063\n",
      "Substitute: launched, BertScore: 0.995954692363739\n",
      "Substitute: triggered, BertScore: 0.995715856552124\n",
      "Substitute: generated, BertScore: 0.9954493045806885\n",
      "Substitute: created, BertScore: 0.9953342080116272\n",
      "Substitute: introduced, BertScore: 0.9953333139419556\n",
      "Substitute: sparked, BertScore: 0.9952275156974792\n",
      "Substitute: provoked, BertScore: 0.9951193332672119\n",
      "Substitute: induced, BertScore: 0.9946786165237427\n",
      "Substitute: caused, BertScore: 0.9945416450500488\n",
      "Substitute: produced, BertScore: 0.9944553375244141\n",
      "Substitute: started, BertScore: 0.9943842887878418\n",
      "Substitute: opened, BertScore: 0.9941277503967285\n",
      "Substitute: spawned, BertScore: 0.9934769868850708\n",
      "Substitute: prompted, BertScore: 0.9932629466056824\n",
      "Substitute: began, BertScore: 0.9931490421295166\n",
      "Substitute: intensified, BertScore: 0.9930446743965149\n",
      "Substitute: brought, BertScore: 0.9928483366966248\n",
      "Substitute: forced, BertScore: 0.9903716444969177\n",
      "Substitute: exposed, BertScore: 0.989789605140686\n",
      "Substitute: threatened, BertScore: 0.9891481995582581\n",
      "Substitute: entered, BertScore: 0.9884677529335022\n",
      "Substitute: ended, BertScore: 0.9882575273513794\n",
      "Substitute: presented, BertScore: 0.987545907497406\n",
      "Substitute: confronted, BertScore: 0.9875226020812988\n",
      "Substitute: revealed, BertScore: 0.9857239127159119\n",
      "Substitute: became, BertScore: 0.9827361702919006\n",
      "Substitute: was, BertScore: 0.9767681956291199\n",
      "top-10 substitutes based on bertscores in context: ['ignited', 'initiated', 'launched', 'triggered', 'generated', 'created', 'introduced', 'sparked', 'provoked', 'induced']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: inaugural\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: first, BertScore: 0.9902604222297668\n",
      "Substitute: original, BertScore: 0.9851561784744263\n",
      "Substitute: founding, BertScore: 0.9845743179321289\n",
      "Substitute: 1st, BertScore: 0.9823899269104004\n",
      "Substitute: final, BertScore: 0.9814363121986389\n",
      "Substitute: second, BertScore: 0.9804246425628662\n",
      "Substitute: eighth, BertScore: 0.9792118072509766\n",
      "Substitute: third, BertScore: 0.9790779948234558\n",
      "Substitute: fourth, BertScore: 0.9788841605186462\n",
      "Substitute: sixth, BertScore: 0.9781277775764465\n",
      "Substitute: official, BertScore: 0.9780415296554565\n",
      "Substitute: fifth, BertScore: 0.977932870388031\n",
      "Substitute: premier, BertScore: 0.97761070728302\n",
      "Substitute: new, BertScore: 0.9767043590545654\n",
      "Substitute: youngest, BertScore: 0.9759734272956848\n",
      "Substitute: 25th, BertScore: 0.9758564233779907\n",
      "Substitute: 35th, BertScore: 0.9758303761482239\n",
      "Substitute: 100th, BertScore: 0.9752636551856995\n",
      "Substitute: 50th, BertScore: 0.9750680923461914\n",
      "Substitute: current, BertScore: 0.9748650193214417\n",
      "Substitute: annual, BertScore: 0.9741438031196594\n",
      "Substitute: next, BertScore: 0.9739276170730591\n",
      "Substitute: previous, BertScore: 0.9738064408302307\n",
      "Substitute: last, BertScore: 0.9737634062767029\n",
      "Substitute: senior, BertScore: 0.9731087684631348\n",
      "Substitute: overall, BertScore: 0.9729195833206177\n",
      "Substitute: only, BertScore: 0.972119927406311\n",
      "Substitute: executive, BertScore: 0.963105320930481\n",
      "Substitute: honorary, BertScore: 0.9528946876525879\n",
      "top-10 substitutes based on bertscores in context: ['first', 'original', 'founding', '1st', 'final', 'second', 'eighth', 'third', 'fourth', 'sixth']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: ongoing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: evolving, BertScore: 0.9751901626586914\n",
      "Substitute: active, BertScore: 0.97121262550354\n",
      "Substitute: increasing, BertScore: 0.9697707891464233\n",
      "Substitute: immediate, BertScore: 0.9663426876068115\n",
      "Substitute: intense, BertScore: 0.9658387899398804\n",
      "Substitute: acute, BertScore: 0.965537965297699\n",
      "Substitute: extensive, BertScore: 0.9654140472412109\n",
      "Substitute: intermittent, BertScore: 0.963351845741272\n",
      "Substitute: inherent, BertScore: 0.9620711207389832\n",
      "Substitute: urgent, BertScore: 0.9619831442832947\n",
      "Substitute: increased, BertScore: 0.9594987034797668\n",
      "Substitute: underlying, BertScore: 0.9591567516326904\n",
      "Substitute: annual, BertScore: 0.9589564800262451\n",
      "Substitute: enormous, BertScore: 0.9577887058258057\n",
      "Substitute: operational, BertScore: 0.957412838935852\n",
      "Substitute: extended, BertScore: 0.956441342830658\n",
      "Substitute: open, BertScore: 0.955512285232544\n",
      "Substitute: important, BertScore: 0.955307126045227\n",
      "Substitute: existing, BertScore: 0.9539098143577576\n",
      "Substitute: obvious, BertScore: 0.953068733215332\n",
      "Substitute: internal, BertScore: 0.9526125192642212\n",
      "Substitute: administrative, BertScore: 0.9511081576347351\n",
      "Substitute: old, BertScore: 0.9496986865997314\n",
      "Substitute: additional, BertScore: 0.9485832452774048\n",
      "Substitute: actual, BertScore: 0.9470317363739014\n",
      "Substitute: isolated, BertScore: 0.9465256929397583\n",
      "Substitute: environmental, BertScore: 0.9440262913703918\n",
      "Substitute: interesting, BertScore: 0.9415463209152222\n",
      "Substitute: unrelated, BertScore: 0.9403483271598816\n",
      "top-10 substitutes based on bertscores in context: ['evolving', 'active', 'increasing', 'immediate', 'intense', 'acute', 'extensive', 'intermittent', 'inherent', 'urgent']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: hostility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: distrust, BertScore: 0.991490364074707\n",
      "Substitute: resentment, BertScore: 0.9904366135597229\n",
      "Substitute: disdain, BertScore: 0.990420937538147\n",
      "Substitute: hatred, BertScore: 0.9881359934806824\n",
      "Substitute: indifference, BertScore: 0.9879973530769348\n",
      "Substitute: suspicion, BertScore: 0.9875384569168091\n",
      "Substitute: anger, BertScore: 0.9864934682846069\n",
      "Substitute: bitterness, BertScore: 0.9858327507972717\n",
      "Substitute: prejudice, BertScore: 0.9857466220855713\n",
      "Substitute: contempt, BertScore: 0.9848792552947998\n",
      "Substitute: resistance, BertScore: 0.9838162064552307\n",
      "Substitute: apprehension, BertScore: 0.9835114479064941\n",
      "Substitute: opposition, BertScore: 0.9831254482269287\n",
      "Substitute: disappointment, BertScore: 0.983048677444458\n",
      "Substitute: violence, BertScore: 0.9826238751411438\n",
      "Substitute: skepticism, BertScore: 0.9822681546211243\n",
      "Substitute: dismay, BertScore: 0.9822232723236084\n",
      "Substitute: concern, BertScore: 0.981686532497406\n",
      "Substitute: disagreement, BertScore: 0.9815778732299805\n",
      "Substitute: hate, BertScore: 0.9806297421455383\n",
      "Substitute: fear, BertScore: 0.9789926409721375\n",
      "Substitute: uncertainty, BertScore: 0.9781218767166138\n",
      "Substitute: regret, BertScore: 0.9774467945098877\n",
      "Substitute: controversy, BertScore: 0.9771956205368042\n",
      "Substitute: reservations, BertScore: 0.9767050743103027\n",
      "Substitute: conflict, BertScore: 0.976011335849762\n",
      "Substitute: objections, BertScore: 0.9736202955245972\n",
      "Substitute: terrorism, BertScore: 0.9735321402549744\n",
      "Substitute: agreement, BertScore: 0.9672250151634216\n",
      "top-10 substitutes based on bertscores in context: ['distrust', 'resentment', 'disdain', 'hatred', 'indifference', 'suspicion', 'anger', 'bitterness', 'prejudice', 'contempt']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: incurred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: sustained, BertScore: 0.9948209524154663\n",
      "Substitute: suffered, BertScore: 0.9930354356765747\n",
      "Substitute: borne, BertScore: 0.9925864338874817\n",
      "Substitute: generated, BertScore: 0.9922524094581604\n",
      "Substitute: raised, BertScore: 0.9920737743377686\n",
      "Substitute: experienced, BertScore: 0.9919888377189636\n",
      "Substitute: accumulated, BertScore: 0.9918212294578552\n",
      "Substitute: faced, BertScore: 0.9917807579040527\n",
      "Substitute: caused, BertScore: 0.9914901852607727\n",
      "Substitute: inflicted, BertScore: 0.9913152456283569\n",
      "Substitute: paid, BertScore: 0.991182267665863\n",
      "Substitute: accomplished, BertScore: 0.9909501075744629\n",
      "Substitute: earned, BertScore: 0.9905438423156738\n",
      "Substitute: imposed, BertScore: 0.9901847243309021\n",
      "Substitute: brought, BertScore: 0.989830732345581\n",
      "Substitute: endured, BertScore: 0.989798367023468\n",
      "Substitute: received, BertScore: 0.9896200895309448\n",
      "Substitute: made, BertScore: 0.9895889163017273\n",
      "Substitute: taken, BertScore: 0.9895278215408325\n",
      "Substitute: involved, BertScore: 0.9892383217811584\n",
      "Substitute: had, BertScore: 0.9888564944267273\n",
      "Substitute: done, BertScore: 0.9888067841529846\n",
      "Substitute: posed, BertScore: 0.988735020160675\n",
      "Substitute: created, BertScore: 0.98847895860672\n",
      "Substitute: produced, BertScore: 0.9883092045783997\n",
      "Substitute: associated, BertScore: 0.9873063564300537\n",
      "Substitute: included, BertScore: 0.9830178022384644\n",
      "Substitute: cost, BertScore: 0.9820106029510498\n",
      "Substitute: been, BertScore: 0.9770799279212952\n",
      "top-10 substitutes based on bertscores in context: ['sustained', 'suffered', 'borne', 'generated', 'raised', 'experienced', 'accumulated', 'faced', 'caused', 'inflicted']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: quelled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: suppressed, BertScore: 0.9685522317886353\n",
      "Substitute: subdued, BertScore: 0.9671341180801392\n",
      "Substitute: stopped, BertScore: 0.9661068320274353\n",
      "Substitute: prevented, BertScore: 0.9654192328453064\n",
      "Substitute: extinguished, BertScore: 0.9626953601837158\n",
      "Substitute: halted, BertScore: 0.9608010053634644\n",
      "Substitute: escalated, BertScore: 0.9571825861930847\n",
      "Substitute: dispersed, BertScore: 0.9561213254928589\n",
      "Substitute: ended, BertScore: 0.9560348391532898\n",
      "Substitute: ceased, BertScore: 0.9544650316238403\n",
      "Substitute: cleared, BertScore: 0.9542022347450256\n",
      "Substitute: triggered, BertScore: 0.9521964192390442\n",
      "Substitute: disrupted, BertScore: 0.9520677328109741\n",
      "Substitute: provoked, BertScore: 0.9506015181541443\n",
      "Substitute: sparked, BertScore: 0.9503202438354492\n",
      "Substitute: intensified, BertScore: 0.9482037425041199\n",
      "Substitute: ignited, BertScore: 0.9472253918647766\n",
      "Substitute: detected, BertScore: 0.9469841718673706\n",
      "Substitute: reopened, BertScore: 0.9465534687042236\n",
      "Substitute: increased, BertScore: 0.9462092518806458\n",
      "Substitute: unleashed, BertScore: 0.9447601437568665\n",
      "Substitute: resumed, BertScore: 0.9441566467285156\n",
      "Substitute: started, BertScore: 0.943057656288147\n",
      "Substitute: conducted, BertScore: 0.9427147507667542\n",
      "Substitute: launched, BertScore: 0.9417840242385864\n",
      "Substitute: began, BertScore: 0.9408953189849854\n",
      "Substitute: opened, BertScore: 0.9403655529022217\n",
      "Substitute: continued, BertScore: 0.9400302171707153\n",
      "Substitute: heard, BertScore: 0.936953067779541\n",
      "Substitute: joined, BertScore: 0.936934232711792\n",
      "top-10 substitutes based on bertscores in context: ['suppressed', 'subdued', 'stopped', 'prevented', 'extinguished', 'halted', 'escalated', 'dispersed', 'ended', 'ceased']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: detained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: arrested, BertScore: 0.9586552381515503\n",
      "Substitute: jailed, BertScore: 0.9581636786460876\n",
      "Substitute: imprisoned, BertScore: 0.9448241591453552\n",
      "Substitute: captured, BertScore: 0.9420198798179626\n",
      "Substitute: questioned, BertScore: 0.9410828948020935\n",
      "Substitute: incarcerated, BertScore: 0.9397228956222534\n",
      "Substitute: seized, BertScore: 0.9395248293876648\n",
      "Substitute: deported, BertScore: 0.9394225478172302\n",
      "Substitute: executed, BertScore: 0.9288885593414307\n",
      "Substitute: expelled, BertScore: 0.9273532032966614\n",
      "Substitute: harassed, BertScore: 0.9248096942901611\n",
      "Substitute: killed, BertScore: 0.9223381280899048\n",
      "Substitute: hanged, BertScore: 0.9209291934967041\n",
      "Substitute: persecuted, BertScore: 0.9198474287986755\n",
      "Substitute: released, BertScore: 0.9189516305923462\n",
      "Substitute: convicted, BertScore: 0.9138914942741394\n",
      "Substitute: treated, BertScore: 0.910868763923645\n",
      "Substitute: injured, BertScore: 0.9083212614059448\n",
      "Substitute: raped, BertScore: 0.905784010887146\n",
      "Substitute: humiliated, BertScore: 0.9051432013511658\n",
      "Substitute: tortured, BertScore: 0.90506911277771\n",
      "Substitute: murdered, BertScore: 0.9031627178192139\n",
      "Substitute: abused, BertScore: 0.9003000855445862\n",
      "Substitute: held, BertScore: 0.8998021483421326\n",
      "Substitute: robbed, BertScore: 0.8977829217910767\n",
      "Substitute: punished, BertScore: 0.8948934674263\n",
      "Substitute: freed, BertScore: 0.8913860321044922\n",
      "Substitute: disappeared, BertScore: 0.8832260370254517\n",
      "Substitute: beaten, BertScore: 0.8341948390007019\n",
      "top-10 substitutes based on bertscores in context: ['arrested', 'jailed', 'imprisoned', 'captured', 'questioned', 'incarcerated', 'seized', 'deported', 'executed', 'expelled']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: insurgents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: rebels, BertScore: 0.9925408363342285\n",
      "Substitute: guerrillas, BertScore: 0.9910979270935059\n",
      "Substitute: militants, BertScore: 0.9906969666481018\n",
      "Substitute: radicals, BertScore: 0.9865837693214417\n",
      "Substitute: fighters, BertScore: 0.9851090312004089\n",
      "Substitute: militias, BertScore: 0.9847451448440552\n",
      "Substitute: terrorists, BertScore: 0.9844439029693604\n",
      "Substitute: forces, BertScore: 0.9823158979415894\n",
      "Substitute: soldiers, BertScore: 0.9812929630279541\n",
      "Substitute: gunmen, BertScore: 0.9807933568954468\n",
      "Substitute: tribes, BertScore: 0.9793533086776733\n",
      "Substitute: groups, BertScore: 0.97889244556427\n",
      "Substitute: civilians, BertScore: 0.9788039922714233\n",
      "Substitute: troops, BertScore: 0.9785834550857544\n",
      "Substitute: leaders, BertScore: 0.9778878688812256\n",
      "Substitute: activists, BertScore: 0.9772841930389404\n",
      "Substitute: arabs, BertScore: 0.9755216836929321\n",
      "Substitute: people, BertScore: 0.975445032119751\n",
      "Substitute: youths, BertScore: 0.9742581844329834\n",
      "Substitute: villagers, BertScore: 0.9737963676452637\n",
      "Substitute: refugees, BertScore: 0.9737907648086548\n",
      "Substitute: officials, BertScore: 0.972436785697937\n",
      "Substitute: communities, BertScore: 0.972134530544281\n",
      "Substitute: muslims, BertScore: 0.970479428768158\n",
      "Substitute: students, BertScore: 0.9695331454277039\n",
      "Substitute: pilgrims, BertScore: 0.9681838154792786\n",
      "Substitute: residents, BertScore: 0.967671275138855\n",
      "Substitute: targets, BertScore: 0.9662982821464539\n",
      "Substitute: albanians, BertScore: 0.9647933840751648\n",
      "top-10 substitutes based on bertscores in context: ['rebels', 'guerrillas', 'militants', 'radicals', 'fighters', 'militias', 'terrorists', 'forces', 'soldiers', 'gunmen']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: distinct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: distinctive, BertScore: 0.9976882934570312\n",
      "Substitute: unique, BertScore: 0.9970806241035461\n",
      "Substitute: characteristic, BertScore: 0.9960646033287048\n",
      "Substitute: diverse, BertScore: 0.9954456686973572\n",
      "Substitute: distinguished, BertScore: 0.9953537583351135\n",
      "Substitute: varied, BertScore: 0.9948413372039795\n",
      "Substitute: particular, BertScore: 0.9943020939826965\n",
      "Substitute: striking, BertScore: 0.994138777256012\n",
      "Substitute: complex, BertScore: 0.9941291809082031\n",
      "Substitute: subtle, BertScore: 0.9937151074409485\n",
      "Substitute: original, BertScore: 0.9936916828155518\n",
      "Substitute: signature, BertScore: 0.9933773279190063\n",
      "Substitute: beautiful, BertScore: 0.9933769106864929\n",
      "Substitute: simple, BertScore: 0.9931169748306274\n",
      "Substitute: fine, BertScore: 0.9929705262184143\n",
      "Substitute: elaborate, BertScore: 0.9926234483718872\n",
      "Substitute: expressive, BertScore: 0.9926052689552307\n",
      "Substitute: elegant, BertScore: 0.9924425482749939\n",
      "Substitute: creative, BertScore: 0.992124080657959\n",
      "Substitute: own, BertScore: 0.9917341470718384\n",
      "Substitute: classic, BertScore: 0.991694450378418\n",
      "Substitute: stylistic, BertScore: 0.9914515018463135\n",
      "Substitute: modern, BertScore: 0.9911856055259705\n",
      "Substitute: artistic, BertScore: 0.9910534024238586\n",
      "Substitute: classical, BertScore: 0.9908577799797058\n",
      "Substitute: decorative, BertScore: 0.9900687336921692\n",
      "Substitute: baroque, BertScore: 0.9898987412452698\n",
      "Substitute: musical, BertScore: 0.9893466830253601\n",
      "Substitute: vocal, BertScore: 0.9892476201057434\n",
      "top-10 substitutes based on bertscores in context: ['distinctive', 'unique', 'characteristic', 'diverse', 'distinguished', 'varied', 'particular', 'striking', 'complex', 'subtle']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: defected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: fled, BertScore: 0.9697887301445007\n",
      "Substitute: surrendered, BertScore: 0.9620348811149597\n",
      "Substitute: emigrated, BertScore: 0.9606167078018188\n",
      "Substitute: resigned, BertScore: 0.9605212807655334\n",
      "Substitute: escaped, BertScore: 0.9603779315948486\n",
      "Substitute: disappeared, BertScore: 0.9595891237258911\n",
      "Substitute: vanished, BertScore: 0.9586098790168762\n",
      "Substitute: converted, BertScore: 0.9573356509208679\n",
      "Substitute: departed, BertScore: 0.9540249109268188\n",
      "Substitute: withdrawn, BertScore: 0.9515188932418823\n",
      "Substitute: left, BertScore: 0.9489843249320984\n",
      "Substitute: enlisted, BertScore: 0.9480019807815552\n",
      "Substitute: failed, BertScore: 0.94793301820755\n",
      "Substitute: turned, BertScore: 0.9478291273117065\n",
      "Substitute: retired, BertScore: 0.9476364850997925\n",
      "Substitute: fallen, BertScore: 0.9472876191139221\n",
      "Substitute: returned, BertScore: 0.9461224675178528\n",
      "Substitute: lost, BertScore: 0.9459354877471924\n",
      "Substitute: moved, BertScore: 0.9454057216644287\n",
      "Substitute: joined, BertScore: 0.9448003768920898\n",
      "Substitute: volunteered, BertScore: 0.9416248798370361\n",
      "Substitute: gone, BertScore: 0.9405553340911865\n",
      "Substitute: arrived, BertScore: 0.9403564929962158\n",
      "Substitute: died, BertScore: 0.9394413828849792\n",
      "Substitute: survived, BertScore: 0.9373612999916077\n",
      "Substitute: recovered, BertScore: 0.9350236058235168\n",
      "Substitute: appeared, BertScore: 0.9349045753479004\n",
      "Substitute: flown, BertScore: 0.929878294467926\n",
      "top-10 substitutes based on bertscores in context: ['fled', 'surrendered', 'emigrated', 'resigned', 'escaped', 'disappeared', 'vanished', 'converted', 'departed', 'withdrawn']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: critically\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: seriously, BertScore: 0.9871039390563965\n",
      "Substitute: gravely, BertScore: 0.9829771518707275\n",
      "Substitute: severely, BertScore: 0.9822675585746765\n",
      "Substitute: badly, BertScore: 0.9789381623268127\n",
      "Substitute: deeply, BertScore: 0.9776501655578613\n",
      "Substitute: fatally, BertScore: 0.977149248123169\n",
      "Substitute: heavily, BertScore: 0.9747337698936462\n",
      "Substitute: profoundly, BertScore: 0.9743894338607788\n",
      "Substitute: highly, BertScore: 0.9742029309272766\n",
      "Substitute: permanently, BertScore: 0.9739159345626831\n",
      "Substitute: physically, BertScore: 0.9709410667419434\n",
      "Substitute: horribly, BertScore: 0.9700499773025513\n",
      "Substitute: extremely, BertScore: 0.9690235257148743\n",
      "Substitute: greatly, BertScore: 0.9676921367645264\n",
      "Substitute: terribly, BertScore: 0.9665453433990479\n",
      "Substitute: slightly, BertScore: 0.9657003879547119\n",
      "Substitute: dangerously, BertScore: 0.9630263447761536\n",
      "Substitute: immediately, BertScore: 0.9627095460891724\n",
      "Substitute: moderately, BertScore: 0.9620248079299927\n",
      "Substitute: very, BertScore: 0.9612702131271362\n",
      "Substitute: still, BertScore: 0.9602115154266357\n",
      "Substitute: particularly, BertScore: 0.9586909413337708\n",
      "Substitute: mentally, BertScore: 0.9582609534263611\n",
      "Substitute: equally, BertScore: 0.9559091329574585\n",
      "Substitute: apparently, BertScore: 0.9557499885559082\n",
      "Substitute: currently, BertScore: 0.953244686126709\n",
      "Substitute: rather, BertScore: 0.9518996477127075\n",
      "Substitute: also, BertScore: 0.950046181678772\n",
      "Substitute: an, BertScore: 0.9197227954864502\n",
      "top-10 substitutes based on bertscores in context: ['seriously', 'gravely', 'severely', 'badly', 'deeply', 'fatally', 'heavily', 'profoundly', 'highly', 'permanently']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: authorities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: officials, BertScore: 0.9891623258590698\n",
      "Substitute: police, BertScore: 0.9853978157043457\n",
      "Substitute: officers, BertScore: 0.9804869294166565\n",
      "Substitute: personnel, BertScore: 0.9802931547164917\n",
      "Substitute: administrators, BertScore: 0.9768068790435791\n",
      "Substitute: guards, BertScore: 0.975999653339386\n",
      "Substitute: staff, BertScore: 0.9752177596092224\n",
      "Substitute: agents, BertScore: 0.9747896790504456\n",
      "Substitute: agencies, BertScore: 0.9743136167526245\n",
      "Substitute: investigators, BertScore: 0.9739864468574524\n",
      "Substitute: inspectors, BertScore: 0.9731302261352539\n",
      "Substitute: representatives, BertScore: 0.9730692505836487\n",
      "Substitute: workers, BertScore: 0.9727829694747925\n",
      "Substitute: residents, BertScore: 0.9720581769943237\n",
      "Substitute: doctors, BertScore: 0.9688917398452759\n",
      "Substitute: experts, BertScore: 0.9677888751029968\n",
      "Substitute: employees, BertScore: 0.96778804063797\n",
      "Substitute: prosecutors, BertScore: 0.9672409296035767\n",
      "Substitute: sources, BertScore: 0.9664084315299988\n",
      "Substitute: activists, BertScore: 0.9624907374382019\n",
      "Substitute: members, BertScore: 0.9611290097236633\n",
      "Substitute: leaders, BertScore: 0.9598871469497681\n",
      "Substitute: lawyers, BertScore: 0.9598379731178284\n",
      "Substitute: media, BertScore: 0.9582526683807373\n",
      "Substitute: official, BertScore: 0.9577615261077881\n",
      "Substitute: inmates, BertScore: 0.9550837278366089\n",
      "Substitute: witnesses, BertScore: 0.9520508050918579\n",
      "Substitute: reports, BertScore: 0.9417885541915894\n",
      "Substitute: records, BertScore: 0.9395309686660767\n",
      "top-10 substitutes based on bertscores in context: ['officials', 'police', 'officers', 'personnel', 'administrators', 'guards', 'staff', 'agents', 'agencies', 'investigators']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: regime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: government, BertScore: 0.994418740272522\n",
      "Substitute: dictatorship, BertScore: 0.9932260513305664\n",
      "Substitute: administration, BertScore: 0.9930612444877625\n",
      "Substitute: rule, BertScore: 0.9897803068161011\n",
      "Substitute: junta, BertScore: 0.9878686666488647\n",
      "Substitute: cabinet, BertScore: 0.9876618981361389\n",
      "Substitute: leadership, BertScore: 0.9865641593933105\n",
      "Substitute: authority, BertScore: 0.9865381121635437\n",
      "Substitute: revolution, BertScore: 0.9862430095672607\n",
      "Substitute: coup, BertScore: 0.9859153032302856\n",
      "Substitute: overthrow, BertScore: 0.9848616719245911\n",
      "Substitute: opposition, BertScore: 0.9837592244148254\n",
      "Substitute: army, BertScore: 0.9837251901626587\n",
      "Substitute: military, BertScore: 0.9837203025817871\n",
      "Substitute: party, BertScore: 0.9836301803588867\n",
      "Substitute: forces, BertScore: 0.9824227690696716\n",
      "Substitute: movement, BertScore: 0.982277512550354\n",
      "Substitute: power, BertScore: 0.9817796945571899\n",
      "Substitute: shah, BertScore: 0.9805409908294678\n",
      "Substitute: program, BertScore: 0.9792963266372681\n",
      "Substitute: leader, BertScore: 0.9783465266227722\n",
      "Substitute: era, BertScore: 0.9781865477561951\n",
      "Substitute: plan, BertScore: 0.9775773882865906\n",
      "Substitute: country, BertScore: 0.976837158203125\n",
      "Substitute: camp, BertScore: 0.9753608703613281\n",
      "Substitute: ou, BertScore: 0.9742486476898193\n",
      "Substitute: and, BertScore: 0.9544264674186707\n",
      "top-10 substitutes based on bertscores in context: ['government', 'dictatorship', 'administration', 'rule', 'junta', 'cabinet', 'leadership', 'authority', 'revolution', 'coup']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: envisions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: proposes, BertScore: 0.9681738615036011\n",
      "Substitute: advocates, BertScore: 0.9624629020690918\n",
      "Substitute: promises, BertScore: 0.9611861109733582\n",
      "Substitute: plans, BertScore: 0.9601477980613708\n",
      "Substitute: recommends, BertScore: 0.9600104689598083\n",
      "Substitute: targets, BertScore: 0.9596776962280273\n",
      "Substitute: considers, BertScore: 0.9590945243835449\n",
      "Substitute: seeks, BertScore: 0.9584785103797913\n",
      "Substitute: charters, BertScore: 0.9577032923698425\n",
      "Substitute: supports, BertScore: 0.9566748142242432\n",
      "Substitute: promotes, BertScore: 0.9566662311553955\n",
      "Substitute: establishes, BertScore: 0.9559727311134338\n",
      "Substitute: guarantees, BertScore: 0.9558831453323364\n",
      "Substitute: includes, BertScore: 0.953697681427002\n",
      "Substitute: permits, BertScore: 0.9534770846366882\n",
      "Substitute: encourages, BertScore: 0.9526125192642212\n",
      "Substitute: sees, BertScore: 0.9521651268005371\n",
      "Substitute: offers, BertScore: 0.9511886835098267\n",
      "Substitute: requires, BertScore: 0.9511747360229492\n",
      "Substitute: enables, BertScore: 0.9511006474494934\n",
      "Substitute: provides, BertScore: 0.9503682851791382\n",
      "Substitute: allows, BertScore: 0.9474261403083801\n",
      "Substitute: represents, BertScore: 0.9465015530586243\n",
      "Substitute: extends, BertScore: 0.9459553956985474\n",
      "Substitute: grants, BertScore: 0.94480299949646\n",
      "Substitute: opposes, BertScore: 0.939149022102356\n",
      "Substitute: limits, BertScore: 0.937307596206665\n",
      "Substitute: prohibits, BertScore: 0.9329408407211304\n",
      "Substitute: has, BertScore: 0.9279632568359375\n",
      "top-10 substitutes based on bertscores in context: ['proposes', 'advocates', 'promises', 'plans', 'recommends', 'targets', 'considers', 'seeks', 'charters', 'supports']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: estimate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: estimation, BertScore: 0.9877966642379761\n",
      "Substitute: assessment, BertScore: 0.9706352949142456\n",
      "Substitute: calculation, BertScore: 0.9684847593307495\n",
      "Substitute: forecast, BertScore: 0.9679054021835327\n",
      "Substitute: report, BertScore: 0.9666398763656616\n",
      "Substitute: prediction, BertScore: 0.9663757681846619\n",
      "Substitute: tally, BertScore: 0.965181291103363\n",
      "Substitute: figure, BertScore: 0.9643484354019165\n",
      "Substitute: guess, BertScore: 0.9632829427719116\n",
      "Substitute: finding, BertScore: 0.9628840088844299\n",
      "Substitute: analysis, BertScore: 0.9626973271369934\n",
      "Substitute: comparison, BertScore: 0.9593175649642944\n",
      "Substitute: rate, BertScore: 0.9563430547714233\n",
      "Substitute: count, BertScore: 0.9557315111160278\n",
      "Substitute: total, BertScore: 0.9536736607551575\n",
      "Substitute: average, BertScore: 0.9516324400901794\n",
      "Substitute: number, BertScore: 0.9504225254058838\n",
      "Substitute: sum, BertScore: 0.9486500024795532\n",
      "Substitute: percentage, BertScore: 0.9481045603752136\n",
      "Substitute: amount, BertScore: 0.9456732869148254\n",
      "Substitute: result, BertScore: 0.9434309005737305\n",
      "Substitute: chance, BertScore: 0.9418517351150513\n",
      "Substitute: sample, BertScore: 0.9390966892242432\n",
      "Substitute: point, BertScore: 0.9313414692878723\n",
      "Substitute: score, BertScore: 0.9291634559631348\n",
      "Substitute: projection, BertScore: 0.9272174835205078\n",
      "Substitute: one, BertScore: 0.9115058779716492\n",
      "top-10 substitutes based on bertscores in context: ['estimation', 'assessment', 'calculation', 'forecast', 'report', 'prediction', 'tally', 'figure', 'guess', 'finding']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: significance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: relevance, BertScore: 0.9952580332756042\n",
      "Substitute: importance, BertScore: 0.9941086769104004\n",
      "Substitute: value, BertScore: 0.9924572110176086\n",
      "Substitute: meaning, BertScore: 0.9906461238861084\n",
      "Substitute: implications, BertScore: 0.9901818633079529\n",
      "Substitute: seriousness, BertScore: 0.9884191155433655\n",
      "Substitute: legitimacy, BertScore: 0.9883620142936707\n",
      "Substitute: purpose, BertScore: 0.9875465631484985\n",
      "Substitute: magnitude, BertScore: 0.9875307083129883\n",
      "Substitute: impact, BertScore: 0.9872221350669861\n",
      "Substitute: nature, BertScore: 0.9872170090675354\n",
      "Substitute: meanings, BertScore: 0.9868826866149902\n",
      "Substitute: symbolism, BertScore: 0.9868384599685669\n",
      "Substitute: scope, BertScore: 0.9852988123893738\n",
      "Substitute: timing, BertScore: 0.9843412637710571\n",
      "Substitute: context, BertScore: 0.9827183485031128\n",
      "Substitute: cost, BertScore: 0.9819653034210205\n",
      "Substitute: scale, BertScore: 0.9817678332328796\n",
      "Substitute: fact, BertScore: 0.981429398059845\n",
      "Substitute: influence, BertScore: 0.9807148575782776\n",
      "Substitute: details, BertScore: 0.9804618954658508\n",
      "Substitute: location, BertScore: 0.9773695468902588\n",
      "Substitute: symbolic, BertScore: 0.9758298993110657\n",
      "Substitute: story, BertScore: 0.9746906757354736\n",
      "Substitute: history, BertScore: 0.9746700525283813\n",
      "Substitute: name, BertScore: 0.973646342754364\n",
      "Substitute: memory, BertScore: 0.9722706079483032\n",
      "Substitute: role, BertScore: 0.9710140824317932\n",
      "Substitute: character, BertScore: 0.9611876606941223\n",
      "top-10 substitutes based on bertscores in context: ['relevance', 'importance', 'value', 'meaning', 'implications', 'seriousness', 'legitimacy', 'purpose', 'magnitude', 'impact']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: neighbouring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: neighboring, BertScore: 0.9938272833824158\n",
      "Substitute: adjacent, BertScore: 0.9911828637123108\n",
      "Substitute: nearby, BertScore: 0.9878876805305481\n",
      "Substitute: adjoining, BertScore: 0.9860758781433105\n",
      "Substitute: bordering, BertScore: 0.9810104966163635\n",
      "Substitute: surrounding, BertScore: 0.9798954725265503\n",
      "Substitute: northern, BertScore: 0.9761185050010681\n",
      "Substitute: southwestern, BertScore: 0.9761179685592651\n",
      "Substitute: northwestern, BertScore: 0.975685179233551\n",
      "Substitute: western, BertScore: 0.9744254946708679\n",
      "Substitute: northeastern, BertScore: 0.974109411239624\n",
      "Substitute: southern, BertScore: 0.9736570119857788\n",
      "Substitute: southeastern, BertScore: 0.9736125469207764\n",
      "Substitute: central, BertScore: 0.973076343536377\n",
      "Substitute: eastern, BertScore: 0.9725029468536377\n",
      "Substitute: greater, BertScore: 0.9713556170463562\n",
      "Substitute: north, BertScore: 0.970609188079834\n",
      "Substitute: west, BertScore: 0.9694600105285645\n",
      "Substitute: south, BertScore: 0.9693605899810791\n",
      "Substitute: separate, BertScore: 0.9681207537651062\n",
      "Substitute: new, BertScore: 0.9677809476852417\n",
      "Substitute: the, BertScore: 0.9666675329208374\n",
      "Substitute: former, BertScore: 0.9647363424301147\n",
      "Substitute: both, BertScore: 0.9634225368499756\n",
      "Substitute: either, BertScore: 0.9602900147438049\n",
      "Substitute: between, BertScore: 0.9460091590881348\n",
      "Substitute: visiting, BertScore: 0.9429090023040771\n",
      "top-10 substitutes based on bertscores in context: ['neighboring', 'adjacent', 'nearby', 'adjoining', 'bordering', 'surrounding', 'northern', 'southwestern', 'northwestern', 'western']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: insurgents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: militants, BertScore: 0.9971299171447754\n",
      "Substitute: rebels, BertScore: 0.9970488548278809\n",
      "Substitute: guerrillas, BertScore: 0.9968171119689941\n",
      "Substitute: terrorists, BertScore: 0.9962344765663147\n",
      "Substitute: attackers, BertScore: 0.9945846199989319\n",
      "Substitute: insurgency, BertScore: 0.9941362738609314\n",
      "Substitute: taliban, BertScore: 0.9938030242919922\n",
      "Substitute: militias, BertScore: 0.9933080673217773\n",
      "Substitute: fighters, BertScore: 0.993304967880249\n",
      "Substitute: loyalists, BertScore: 0.9929705858230591\n",
      "Substitute: refugees, BertScore: 0.9925055503845215\n",
      "Substitute: protesters, BertScore: 0.9923174381256104\n",
      "Substitute: civilians, BertScore: 0.9922096133232117\n",
      "Substitute: troops, BertScore: 0.9912733435630798\n",
      "Substitute: soldiers, BertScore: 0.9912168383598328\n",
      "Substitute: isis, BertScore: 0.9909337759017944\n",
      "Substitute: americans, BertScore: 0.9905562400817871\n",
      "Substitute: isil, BertScore: 0.9902438521385193\n",
      "Substitute: convoys, BertScore: 0.9893942475318909\n",
      "Substitute: iraq, BertScore: 0.9891633987426758\n",
      "Substitute: iraqi, BertScore: 0.9886968731880188\n",
      "Substitute: afghan, BertScore: 0.9882476329803467\n",
      "Substitute: targets, BertScore: 0.9882346987724304\n",
      "Substitute: afghanistan, BertScore: 0.9878562092781067\n",
      "Substitute: others, BertScore: 0.9874411821365356\n",
      "Substitute: military, BertScore: 0.9871355295181274\n",
      "Substitute: baghdad, BertScore: 0.9867092967033386\n",
      "Substitute: kabul, BertScore: 0.9861606955528259\n",
      "Substitute: them, BertScore: 0.9850042462348938\n",
      "top-10 substitutes based on bertscores in context: ['militants', 'rebels', 'guerrillas', 'terrorists', 'attackers', 'insurgency', 'taliban', 'militias', 'fighters', 'loyalists']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: clemency\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: immunity, BertScore: 0.9244951009750366\n",
      "Substitute: pardon, BertScore: 0.9218870997428894\n",
      "Substitute: amnesty, BertScore: 0.9210554361343384\n",
      "Substitute: bail, BertScore: 0.9200010299682617\n",
      "Substitute: relief, BertScore: 0.9194900989532471\n",
      "Substitute: benefits, BertScore: 0.9179672598838806\n",
      "Substitute: discretion, BertScore: 0.9170878529548645\n",
      "Substitute: exemption, BertScore: 0.9168039560317993\n",
      "Substitute: probation, BertScore: 0.9162099361419678\n",
      "Substitute: protection, BertScore: 0.9153297543525696\n",
      "Substitute: liberty, BertScore: 0.9152953028678894\n",
      "Substitute: status, BertScore: 0.9139289855957031\n",
      "Substitute: privilege, BertScore: 0.9115718603134155\n",
      "Substitute: authority, BertScore: 0.9107176065444946\n",
      "Substitute: retirement, BertScore: 0.9100235104560852\n",
      "Substitute: justice, BertScore: 0.9091699123382568\n",
      "Substitute: security, BertScore: 0.9085413813591003\n",
      "Substitute: support, BertScore: 0.9070415496826172\n",
      "Substitute: service, BertScore: 0.9064046144485474\n",
      "Substitute: citizenship, BertScore: 0.9059900045394897\n",
      "Substitute: honor, BertScore: 0.9058499336242676\n",
      "Substitute: merit, BertScore: 0.9039660692214966\n",
      "Substitute: it, BertScore: 0.8908862471580505\n",
      "Substitute: them, BertScore: 0.8846130967140198\n",
      "Substitute: trump, BertScore: 0.8841759562492371\n",
      "Substitute: himself, BertScore: 0.8810327053070068\n",
      "Substitute: obama, BertScore: 0.8799493312835693\n",
      "Substitute: him, BertScore: 0.8776604533195496\n",
      "Substitute: back, BertScore: 0.8744577765464783\n",
      "top-10 substitutes based on bertscores in context: ['immunity', 'pardon', 'amnesty', 'bail', 'relief', 'benefits', 'discretion', 'exemption', 'probation', 'protection']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: authorities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: officials, BertScore: 0.9966415166854858\n",
      "Substitute: police, BertScore: 0.9965810775756836\n",
      "Substitute: investigators, BertScore: 0.9959667325019836\n",
      "Substitute: officers, BertScore: 0.9934667348861694\n",
      "Substitute: sources, BertScore: 0.9933953881263733\n",
      "Substitute: reports, BertScore: 0.9925235509872437\n",
      "Substitute: prosecutors, BertScore: 0.9922226071357727\n",
      "Substitute: detectives, BertScore: 0.9921342134475708\n",
      "Substitute: doctors, BertScore: 0.9916852712631226\n",
      "Substitute: witnesses, BertScore: 0.9914420247077942\n",
      "Substitute: residents, BertScore: 0.9911321997642517\n",
      "Substitute: lawyers, BertScore: 0.9906884431838989\n",
      "Substitute: villagers, BertScore: 0.9901679754257202\n",
      "Substitute: legislators, BertScore: 0.9898868799209595\n",
      "Substitute: troopers, BertScore: 0.989480197429657\n",
      "Substitute: deputies, BertScore: 0.9893254041671753\n",
      "Substitute: firefighters, BertScore: 0.9891712665557861\n",
      "Substitute: others, BertScore: 0.9878461360931396\n",
      "Substitute: some, BertScore: 0.98784339427948\n",
      "Substitute: he, BertScore: 0.9878100156784058\n",
      "Substitute: neighbors, BertScore: 0.9876291751861572\n",
      "Substitute: they, BertScore: 0.9876027703285217\n",
      "Substitute: she, BertScore: 0.9875352382659912\n",
      "Substitute: it, BertScore: 0.9863826036453247\n",
      "Substitute: most, BertScore: 0.9863444566726685\n",
      "Substitute: sheriff, BertScore: 0.986251711845398\n",
      "Substitute: one, BertScore: 0.9839910268783569\n",
      "Substitute: counties, BertScore: 0.9838690757751465\n",
      "Substitute: both, BertScore: 0.9806836843490601\n",
      "top-10 substitutes based on bertscores in context: ['officials', 'police', 'investigators', 'officers', 'sources', 'reports', 'prosecutors', 'detectives', 'doctors', 'witnesses']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: obscene\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: pornographic, BertScore: 0.9935521483421326\n",
      "Substitute: vulgar, BertScore: 0.9925501346588135\n",
      "Substitute: offensive, BertScore: 0.9920194149017334\n",
      "Substitute: insulting, BertScore: 0.9911868572235107\n",
      "Substitute: unlawful, BertScore: 0.9910180568695068\n",
      "Substitute: filthy, BertScore: 0.9905649423599243\n",
      "Substitute: outrageous, BertScore: 0.9904621839523315\n",
      "Substitute: inappropriate, BertScore: 0.9899539947509766\n",
      "Substitute: disgusting, BertScore: 0.9898946285247803\n",
      "Substitute: violent, BertScore: 0.9896658062934875\n",
      "Substitute: vile, BertScore: 0.9894337058067322\n",
      "Substitute: ridiculous, BertScore: 0.989339292049408\n",
      "Substitute: abusive, BertScore: 0.9890766739845276\n",
      "Substitute: sexual, BertScore: 0.9890515804290771\n",
      "Substitute: inflammatory, BertScore: 0.9887298941612244\n",
      "Substitute: crude, BertScore: 0.9886869192123413\n",
      "Substitute: rude, BertScore: 0.9886283874511719\n",
      "Substitute: foul, BertScore: 0.9884922504425049\n",
      "Substitute: stupid, BertScore: 0.9883807897567749\n",
      "Substitute: explicit, BertScore: 0.9883113503456116\n",
      "Substitute: improper, BertScore: 0.9882519841194153\n",
      "Substitute: aggressive, BertScore: 0.9882012009620667\n",
      "Substitute: unacceptable, BertScore: 0.9879956245422363\n",
      "Substitute: excessive, BertScore: 0.9874635934829712\n",
      "Substitute: graphic, BertScore: 0.9873985052108765\n",
      "Substitute: attractive, BertScore: 0.9868590235710144\n",
      "Substitute: rich, BertScore: 0.9850160479545593\n",
      "Substitute: other, BertScore: 0.983330249786377\n",
      "Substitute: provocative, BertScore: 0.98243647813797\n",
      "top-10 substitutes based on bertscores in context: ['pornographic', 'vulgar', 'offensive', 'insulting', 'unlawful', 'filthy', 'outrageous', 'inappropriate', 'disgusting', 'violent']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: bespoke\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: prompt, BertScore: 0.9769631624221802\n",
      "Substitute: live, BertScore: 0.9765360355377197\n",
      "Substitute: innovative, BertScore: 0.9759812951087952\n",
      "Substitute: advance, BertScore: 0.9758288264274597\n",
      "Substitute: enhanced, BertScore: 0.9757910966873169\n",
      "Substitute: direct, BertScore: 0.9755859375\n",
      "Substitute: intensive, BertScore: 0.9753829836845398\n",
      "Substitute: intense, BertScore: 0.9752058386802673\n",
      "Substitute: extended, BertScore: 0.9752025604248047\n",
      "Substitute: stimulating, BertScore: 0.975109338760376\n",
      "Substitute: practical, BertScore: 0.9750769138336182\n",
      "Substitute: outstanding, BertScore: 0.9749026298522949\n",
      "Substitute: special, BertScore: 0.9747787714004517\n",
      "Substitute: valuable, BertScore: 0.9747284054756165\n",
      "Substitute: advanced, BertScore: 0.9745973944664001\n",
      "Substitute: exciting, BertScore: 0.9745339751243591\n",
      "Substitute: free, BertScore: 0.974389374256134\n",
      "Substitute: additional, BertScore: 0.9741645455360413\n",
      "Substitute: new, BertScore: 0.9737818241119385\n",
      "Substitute: varied, BertScore: 0.9736593961715698\n",
      "Substitute: field, BertScore: 0.9736174941062927\n",
      "Substitute: extensive, BertScore: 0.9735949635505676\n",
      "Substitute: creative, BertScore: 0.9735301733016968\n",
      "Substitute: training, BertScore: 0.9734706282615662\n",
      "Substitute: excellent, BertScore: 0.9734485745429993\n",
      "Substitute: educational, BertScore: 0.9733397364616394\n",
      "Substitute: further, BertScore: 0.9733153581619263\n",
      "Substitute: music, BertScore: 0.9726756811141968\n",
      "Substitute: various, BertScore: 0.972530722618103\n",
      "Substitute: both, BertScore: 0.9710903167724609\n",
      "top-10 substitutes based on bertscores in context: ['prompt', 'live', 'innovative', 'advance', 'enhanced', 'direct', 'intensive', 'intense', 'extended', 'stimulating']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: instrument\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: organ, BertScore: 0.9903237819671631\n",
      "Substitute: item, BertScore: 0.9900880455970764\n",
      "Substitute: object, BertScore: 0.9898867011070251\n",
      "Substitute: instrumentation, BertScore: 0.9898847341537476\n",
      "Substitute: apparatus, BertScore: 0.9893816709518433\n",
      "Substitute: obligation, BertScore: 0.9891502261161804\n",
      "Substitute: asset, BertScore: 0.9890967607498169\n",
      "Substitute: undertaking, BertScore: 0.9887478947639465\n",
      "Substitute: agreement, BertScore: 0.9886322617530823\n",
      "Substitute: act, BertScore: 0.9886263608932495\n",
      "Substitute: arrangement, BertScore: 0.9883046746253967\n",
      "Substitute: engine, BertScore: 0.9881528615951538\n",
      "Substitute: equipment, BertScore: 0.9875186085700989\n",
      "Substitute: option, BertScore: 0.9870611429214478\n",
      "Substitute: institution, BertScore: 0.986136257648468\n",
      "Substitute: investment, BertScore: 0.9859058856964111\n",
      "Substitute: element, BertScore: 0.9858789443969727\n",
      "Substitute: amount, BertScore: 0.9857182502746582\n",
      "Substitute: activity, BertScore: 0.9856690764427185\n",
      "Substitute: adjustment, BertScore: 0.9852292537689209\n",
      "Substitute: amplifier, BertScore: 0.9846068620681763\n",
      "Substitute: application, BertScore: 0.9845255613327026\n",
      "Substitute: agent, BertScore: 0.9843850135803223\n",
      "Substitute: arbitration, BertScore: 0.9834285378456116\n",
      "Substitute: arm, BertScore: 0.983380138874054\n",
      "Substitute: initiative, BertScore: 0.9833531379699707\n",
      "Substitute: approach, BertScore: 0.9826396107673645\n",
      "Substitute: example, BertScore: 0.9732574224472046\n",
      "top-10 substitutes based on bertscores in context: ['organ', 'item', 'object', 'instrumentation', 'apparatus', 'obligation', 'asset', 'undertaking', 'agreement', 'act']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: emerge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: arise, BertScore: 0.9914364814758301\n",
      "Substitute: enter, BertScore: 0.9907771348953247\n",
      "Substitute: arrive, BertScore: 0.9906958341598511\n",
      "Substitute: appear, BertScore: 0.9905681014060974\n",
      "Substitute: rise, BertScore: 0.9889644384384155\n",
      "Substitute: form, BertScore: 0.9878181219100952\n",
      "Substitute: descend, BertScore: 0.9877885580062866\n",
      "Substitute: converge, BertScore: 0.9872803092002869\n",
      "Substitute: appears, BertScore: 0.9858260750770569\n",
      "Substitute: spring, BertScore: 0.9857016801834106\n",
      "Substitute: grow, BertScore: 0.9851702451705933\n",
      "Substitute: come, BertScore: 0.9843391180038452\n",
      "Substitute: disappear, BertScore: 0.9831644296646118\n",
      "Substitute: spawn, BertScore: 0.9814242720603943\n",
      "Substitute: burst, BertScore: 0.9812608361244202\n",
      "Substitute: fall, BertScore: 0.9807860851287842\n",
      "Substitute: vanish, BertScore: 0.9799965620040894\n",
      "Substitute: leave, BertScore: 0.9795620441436768\n",
      "Substitute: develop, BertScore: 0.9787108898162842\n",
      "Substitute: hide, BertScore: 0.9784291982650757\n",
      "Substitute: exist, BertScore: 0.9776520729064941\n",
      "Substitute: remain, BertScore: 0.9756855368614197\n",
      "Substitute: are, BertScore: 0.9746395945549011\n",
      "Substitute: strike, BertScore: 0.9744199514389038\n",
      "Substitute: die, BertScore: 0.9714397192001343\n",
      "Substitute: occur, BertScore: 0.969069242477417\n",
      "top-10 substitutes based on bertscores in context: ['arise', 'enter', 'arrive', 'appear', 'rise', 'form', 'descend', 'converge', 'appears', 'spring']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: insurgency\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: rebellion, BertScore: 0.9906384944915771\n",
      "Substitute: insurgents, BertScore: 0.9898884296417236\n",
      "Substitute: conflict, BertScore: 0.9890692234039307\n",
      "Substitute: uprising, BertScore: 0.988850474357605\n",
      "Substitute: resistance, BertScore: 0.9886077046394348\n",
      "Substitute: rebels, BertScore: 0.9880415201187134\n",
      "Substitute: insurrection, BertScore: 0.9874086380004883\n",
      "Substitute: militants, BertScore: 0.9870069026947021\n",
      "Substitute: regime, BertScore: 0.9868009090423584\n",
      "Substitute: militia, BertScore: 0.9862058162689209\n",
      "Substitute: movement, BertScore: 0.9859687089920044\n",
      "Substitute: fighting, BertScore: 0.9858871698379517\n",
      "Substitute: war, BertScore: 0.9855625629425049\n",
      "Substitute: taliban, BertScore: 0.9852859973907471\n",
      "Substitute: violence, BertScore: 0.9848576188087463\n",
      "Substitute: campaign, BertScore: 0.9845834970474243\n",
      "Substitute: army, BertScore: 0.9833906888961792\n",
      "Substitute: military, BertScore: 0.9831302762031555\n",
      "Substitute: coalition, BertScore: 0.9826237559318542\n",
      "Substitute: alliance, BertScore: 0.9825702905654907\n",
      "Substitute: situation, BertScore: 0.9824483394622803\n",
      "Substitute: government, BertScore: 0.9819896817207336\n",
      "Substitute: enemy, BertScore: 0.9819570779800415\n",
      "Substitute: forces, BertScore: 0.9811606407165527\n",
      "Substitute: operation, BertScore: 0.9804613590240479\n",
      "Substitute: group, BertScore: 0.9804096817970276\n",
      "Substitute: country, BertScore: 0.9796302318572998\n",
      "Substitute: troops, BertScore: 0.9794626235961914\n",
      "Substitute: force, BertScore: 0.9790200591087341\n",
      "top-10 substitutes based on bertscores in context: ['rebellion', 'insurgents', 'conflict', 'uprising', 'resistance', 'rebels', 'insurrection', 'militants', 'regime', 'militia']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: emerge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: rise, BertScore: 0.9915944337844849\n",
      "Substitute: arise, BertScore: 0.9901609420776367\n",
      "Substitute: descend, BertScore: 0.9897711277008057\n",
      "Substitute: wake, BertScore: 0.9894382953643799\n",
      "Substitute: arrive, BertScore: 0.9893450736999512\n",
      "Substitute: exit, BertScore: 0.9885804057121277\n",
      "Substitute: break, BertScore: 0.9882367253303528\n",
      "Substitute: enter, BertScore: 0.9879626631736755\n",
      "Substitute: usher, BertScore: 0.9875805974006653\n",
      "Substitute: develop, BertScore: 0.9875295758247375\n",
      "Substitute: recover, BertScore: 0.9872064590454102\n",
      "Substitute: evolve, BertScore: 0.9867374897003174\n",
      "Substitute: advance, BertScore: 0.9864386320114136\n",
      "Substitute: depart, BertScore: 0.9862433671951294\n",
      "Substitute: return, BertScore: 0.986204981803894\n",
      "Substitute: graduate, BertScore: 0.9859710335731506\n",
      "Substitute: proceed, BertScore: 0.9858550429344177\n",
      "Substitute: grow, BertScore: 0.9853479862213135\n",
      "Substitute: transition, BertScore: 0.9838243722915649\n",
      "Substitute: result, BertScore: 0.9828553199768066\n",
      "Substitute: heal, BertScore: 0.9822844862937927\n",
      "Substitute: withdraw, BertScore: 0.9822590351104736\n",
      "Substitute: come, BertScore: 0.9819278717041016\n",
      "Substitute: retire, BertScore: 0.9814430475234985\n",
      "Substitute: move, BertScore: 0.9810017347335815\n",
      "Substitute: learn, BertScore: 0.9730185270309448\n",
      "top-10 substitutes based on bertscores in context: ['rise', 'arise', 'descend', 'wake', 'arrive', 'exit', 'break', 'enter', 'usher', 'develop']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: ensued\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: proceeded, BertScore: 0.992253839969635\n",
      "Substitute: erupted, BertScore: 0.9919320940971375\n",
      "Substitute: followed, BertScore: 0.9914631247520447\n",
      "Substitute: commenced, BertScore: 0.9904694557189941\n",
      "Substitute: resulted, BertScore: 0.9897634983062744\n",
      "Substitute: began, BertScore: 0.9879217147827148\n",
      "Substitute: unfolded, BertScore: 0.9875645637512207\n",
      "Substitute: occurred, BertScore: 0.9868751168251038\n",
      "Substitute: continued, BertScore: 0.9868610501289368\n",
      "Substitute: arose, BertScore: 0.9865342378616333\n",
      "Substitute: emerged, BertScore: 0.9865325093269348\n",
      "Substitute: materialized, BertScore: 0.9856436252593994\n",
      "Substitute: lasted, BertScore: 0.9855084419250488\n",
      "Substitute: started, BertScore: 0.9850447177886963\n",
      "Substitute: arrived, BertScore: 0.9847736358642578\n",
      "Substitute: culminated, BertScore: 0.9845235347747803\n",
      "Substitute: happened, BertScore: 0.9844545125961304\n",
      "Substitute: came, BertScore: 0.9843952655792236\n",
      "Substitute: appeared, BertScore: 0.9841945171356201\n",
      "Substitute: led, BertScore: 0.982995331287384\n",
      "Substitute: prevailed, BertScore: 0.9828928709030151\n",
      "Substitute: concluded, BertScore: 0.9828022718429565\n",
      "Substitute: intensified, BertScore: 0.9827820062637329\n",
      "Substitute: escalated, BertScore: 0.982398509979248\n",
      "Substitute: opened, BertScore: 0.9815545678138733\n",
      "Substitute: resumed, BertScore: 0.9813533425331116\n",
      "Substitute: ended, BertScore: 0.9751291275024414\n",
      "Substitute: ceased, BertScore: 0.9734854698181152\n",
      "Substitute: interrupted, BertScore: 0.9726098775863647\n",
      "top-10 substitutes based on bertscores in context: ['proceeded', 'erupted', 'followed', 'commenced', 'resulted', 'began', 'unfolded', 'occurred', 'continued', 'arose']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: regime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: administration, BertScore: 0.989405632019043\n",
      "Substitute: dictatorship, BertScore: 0.9872896671295166\n",
      "Substitute: system, BertScore: 0.9864864349365234\n",
      "Substitute: government, BertScore: 0.9864490032196045\n",
      "Substitute: policy, BertScore: 0.984992265701294\n",
      "Substitute: authorities, BertScore: 0.984641432762146\n",
      "Substitute: program, BertScore: 0.9843183755874634\n",
      "Substitute: programme, BertScore: 0.9839317202568054\n",
      "Substitute: policies, BertScore: 0.9838204383850098\n",
      "Substitute: scheme, BertScore: 0.9837773442268372\n",
      "Substitute: state, BertScore: 0.9835922122001648\n",
      "Substitute: law, BertScore: 0.983062207698822\n",
      "Substitute: institution, BertScore: 0.9827127456665039\n",
      "Substitute: revolution, BertScore: 0.9823964834213257\n",
      "Substitute: junta, BertScore: 0.9821842312812805\n",
      "Substitute: era, BertScore: 0.9817516207695007\n",
      "Substitute: sanctions, BertScore: 0.9809730648994446\n",
      "Substitute: country, BertScore: 0.9809391498565674\n",
      "Substitute: process, BertScore: 0.9807295203208923\n",
      "Substitute: model, BertScore: 0.9795755743980408\n",
      "Substitute: situation, BertScore: 0.9787133932113647\n",
      "Substitute: deal, BertScore: 0.9786061644554138\n",
      "Substitute: military, BertScore: 0.9781326055526733\n",
      "Substitute: ban, BertScore: 0.9779455065727234\n",
      "Substitute: crisis, BertScore: 0.9772141575813293\n",
      "Substitute: project, BertScore: 0.9769831895828247\n",
      "Substitute: period, BertScore: 0.9765534400939941\n",
      "Substitute: year, BertScore: 0.9659669399261475\n",
      "top-10 substitutes based on bertscores in context: ['administration', 'dictatorship', 'system', 'government', 'policy', 'authorities', 'program', 'programme', 'policies', 'scheme']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: unearthed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: uncovered, BertScore: 0.9969452619552612\n",
      "Substitute: recovered, BertScore: 0.9952250719070435\n",
      "Substitute: discovered, BertScore: 0.9943467378616333\n",
      "Substitute: excavated, BertScore: 0.9934373497962952\n",
      "Substitute: retrieved, BertScore: 0.9917632341384888\n",
      "Substitute: revealed, BertScore: 0.9914898872375488\n",
      "Substitute: detected, BertScore: 0.9913972616195679\n",
      "Substitute: deposited, BertScore: 0.9904239177703857\n",
      "Substitute: identified, BertScore: 0.9902689456939697\n",
      "Substitute: dug, BertScore: 0.9901015162467957\n",
      "Substitute: found, BertScore: 0.9900966882705688\n",
      "Substitute: rediscovered, BertScore: 0.9897335767745972\n",
      "Substitute: explored, BertScore: 0.9891021847724915\n",
      "Substitute: investigated, BertScore: 0.9884570837020874\n",
      "Substitute: examined, BertScore: 0.9872362017631531\n",
      "Substitute: buried, BertScore: 0.9871506690979004\n",
      "Substitute: acquired, BertScore: 0.98696368932724\n",
      "Substitute: hidden, BertScore: 0.9868050217628479\n",
      "Substitute: seen, BertScore: 0.9862782955169678\n",
      "Substitute: mined, BertScore: 0.9860074520111084\n",
      "Substitute: located, BertScore: 0.985690176486969\n",
      "Substitute: encountered, BertScore: 0.9853042960166931\n",
      "Substitute: collected, BertScore: 0.9852764010429382\n",
      "Substitute: arrived, BertScore: 0.9852094054222107\n",
      "Substitute: spotted, BertScore: 0.9850203394889832\n",
      "Substitute: made, BertScore: 0.9846457839012146\n",
      "Substitute: obtained, BertScore: 0.9842244982719421\n",
      "Substitute: used, BertScore: 0.9798495769500732\n",
      "Substitute: harvested, BertScore: 0.9767054319381714\n",
      "top-10 substitutes based on bertscores in context: ['uncovered', 'recovered', 'discovered', 'excavated', 'retrieved', 'revealed', 'detected', 'deposited', 'identified', 'dug']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: strategic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: tactical, BertScore: 0.9954127073287964\n",
      "Substitute: operational, BertScore: 0.9952270984649658\n",
      "Substitute: strategy, BertScore: 0.9948405027389526\n",
      "Substitute: security, BertScore: 0.9938420653343201\n",
      "Substitute: regional, BertScore: 0.9937258958816528\n",
      "Substitute: joint, BertScore: 0.993657112121582\n",
      "Substitute: critical, BertScore: 0.9934179186820984\n",
      "Substitute: comprehensive, BertScore: 0.9934074282646179\n",
      "Substitute: global, BertScore: 0.9932413697242737\n",
      "Substitute: military, BertScore: 0.9929330348968506\n",
      "Substitute: economic, BertScore: 0.9928392171859741\n",
      "Substitute: fiscal, BertScore: 0.9922707676887512\n",
      "Substitute: partnership, BertScore: 0.9922119379043579\n",
      "Substitute: investment, BertScore: 0.9921971559524536\n",
      "Substitute: diplomatic, BertScore: 0.9921638369560242\n",
      "Substitute: strategically, BertScore: 0.9921004772186279\n",
      "Substitute: financial, BertScore: 0.9920064806938171\n",
      "Substitute: central, BertScore: 0.9919921159744263\n",
      "Substitute: new, BertScore: 0.9919621348381042\n",
      "Substitute: alliance, BertScore: 0.9919137358665466\n",
      "Substitute: crucial, BertScore: 0.9919061660766602\n",
      "Substitute: key, BertScore: 0.9918559193611145\n",
      "Substitute: political, BertScore: 0.9918152689933777\n",
      "Substitute: bilateral, BertScore: 0.9916634559631348\n",
      "Substitute: nuclear, BertScore: 0.9915177226066589\n",
      "Substitute: presidential, BertScore: 0.991300642490387\n",
      "Substitute: historic, BertScore: 0.9912805557250977\n",
      "Substitute: historical, BertScore: 0.9912172555923462\n",
      "Substitute: the, BertScore: 0.9902071952819824\n",
      "top-10 substitutes based on bertscores in context: ['tactical', 'operational', 'strategy', 'security', 'regional', 'joint', 'critical', 'comprehensive', 'global', 'military']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: metropolitan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: metro, BertScore: 0.9857136607170105\n",
      "Substitute: metropolis, BertScore: 0.9810943007469177\n",
      "Substitute: urban, BertScore: 0.9795454144477844\n",
      "Substitute: city, BertScore: 0.9769171476364136\n",
      "Substitute: suburban, BertScore: 0.973565936088562\n",
      "Substitute: regional, BertScore: 0.9722251892089844\n",
      "Substitute: municipal, BertScore: 0.9719544053077698\n",
      "Substitute: capital, BertScore: 0.9715997576713562\n",
      "Substitute: downtown, BertScore: 0.970283567905426\n",
      "Substitute: administrative, BertScore: 0.9676517844200134\n",
      "Substitute: national, BertScore: 0.9668152332305908\n",
      "Substitute: geographical, BertScore: 0.9658111929893494\n",
      "Substitute: central, BertScore: 0.964794933795929\n",
      "Substitute: local, BertScore: 0.9624296426773071\n",
      "Substitute: residential, BertScore: 0.9617602825164795\n",
      "Substitute: surrounding, BertScore: 0.9611647129058838\n",
      "Substitute: catchment, BertScore: 0.9609700441360474\n",
      "Substitute: populated, BertScore: 0.9605446457862854\n",
      "Substitute: outlying, BertScore: 0.9605011940002441\n",
      "Substitute: rural, BertScore: 0.9601761698722839\n",
      "Substitute: public, BertScore: 0.9597984552383423\n",
      "Substitute: northern, BertScore: 0.9585716724395752\n",
      "Substitute: population, BertScore: 0.9577755331993103\n",
      "Substitute: domestic, BertScore: 0.9574527740478516\n",
      "Substitute: census, BertScore: 0.9563685059547424\n",
      "Substitute: industrial, BertScore: 0.9550747871398926\n",
      "Substitute: home, BertScore: 0.9548712968826294\n",
      "Substitute: london, BertScore: 0.9532351493835449\n",
      "Substitute: statistical, BertScore: 0.9504384994506836\n",
      "top-10 substitutes based on bertscores in context: ['metro', 'metropolis', 'urban', 'city', 'suburban', 'regional', 'municipal', 'capital', 'downtown', 'administrative']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: exhibitions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: exhibits, BertScore: 0.9960606098175049\n",
      "Substitute: shows, BertScore: 0.9947365522384644\n",
      "Substitute: displays, BertScore: 0.9941454529762268\n",
      "Substitute: galleries, BertScore: 0.9912455081939697\n",
      "Substitute: presentations, BertScore: 0.9909690022468567\n",
      "Substitute: demonstrations, BertScore: 0.9907736778259277\n",
      "Substitute: festivals, BertScore: 0.9904118776321411\n",
      "Substitute: installations, BertScore: 0.9899855852127075\n",
      "Substitute: performances, BertScore: 0.9899388551712036\n",
      "Substitute: collections, BertScore: 0.9895288944244385\n",
      "Substitute: concerts, BertScore: 0.9894644021987915\n",
      "Substitute: lectures, BertScore: 0.9880775809288025\n",
      "Substitute: sculptures, BertScore: 0.9873911738395691\n",
      "Substitute: tours, BertScore: 0.9869817495346069\n",
      "Substitute: museums, BertScore: 0.986449122428894\n",
      "Substitute: paintings, BertScore: 0.9864133596420288\n",
      "Substitute: studies, BertScore: 0.9857798218727112\n",
      "Substitute: activities, BertScore: 0.9855366349220276\n",
      "Substitute: acts, BertScore: 0.9854963421821594\n",
      "Substitute: expressions, BertScore: 0.9853169918060303\n",
      "Substitute: objects, BertScore: 0.9844331741333008\n",
      "Substitute: books, BertScore: 0.9843181371688843\n",
      "Substitute: trials, BertScore: 0.9833117127418518\n",
      "Substitute: pieces, BertScore: 0.9830569624900818\n",
      "Substitute: works, BertScore: 0.9820513725280762\n",
      "Substitute: work, BertScore: 0.9809820652008057\n",
      "Substitute: forms, BertScore: 0.9779943227767944\n",
      "Substitute: lots, BertScore: 0.9767274856567383\n",
      "top-10 substitutes based on bertscores in context: ['exhibits', 'shows', 'displays', 'galleries', 'presentations', 'demonstrations', 'festivals', 'installations', 'performances', 'collections']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: prospects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: chances, BertScore: 0.9936410188674927\n",
      "Substitute: possibilities, BertScore: 0.9917045831680298\n",
      "Substitute: potential, BertScore: 0.9902327060699463\n",
      "Substitute: likelihood, BertScore: 0.9899771809577942\n",
      "Substitute: opportunities, BertScore: 0.9893307089805603\n",
      "Substitute: possibility, BertScore: 0.9892318248748779\n",
      "Substitute: chance, BertScore: 0.9881173372268677\n",
      "Substitute: outlook, BertScore: 0.9878216981887817\n",
      "Substitute: hopes, BertScore: 0.9876667261123657\n",
      "Substitute: options, BertScore: 0.9868909120559692\n",
      "Substitute: probability, BertScore: 0.9855334758758545\n",
      "Substitute: hope, BertScore: 0.9845183491706848\n",
      "Substitute: opportunity, BertScore: 0.9844682216644287\n",
      "Substitute: conditions, BertScore: 0.9835585355758667\n",
      "Substitute: plans, BertScore: 0.9830807447433472\n",
      "Substitute: future, BertScore: 0.9829694628715515\n",
      "Substitute: forecast, BertScore: 0.9821971654891968\n",
      "Substitute: path, BertScore: 0.9803481698036194\n",
      "Substitute: stakes, BertScore: 0.9797655940055847\n",
      "Substitute: implications, BertScore: 0.979701578617096\n",
      "Substitute: odds, BertScore: 0.9792246222496033\n",
      "Substitute: risks, BertScore: 0.97871994972229\n",
      "Substitute: need, BertScore: 0.9781786203384399\n",
      "Substitute: rewards, BertScore: 0.9781234264373779\n",
      "Substitute: road, BertScore: 0.9746614098548889\n",
      "Substitute: search, BertScore: 0.9745261669158936\n",
      "Substitute: plan, BertScore: 0.9718027710914612\n",
      "Substitute: candidates, BertScore: 0.9710912108421326\n",
      "top-10 substitutes based on bertscores in context: ['chances', 'possibilities', 'potential', 'likelihood', 'opportunities', 'possibility', 'chance', 'outlook', 'hopes', 'options']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: surveillance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: monitoring, BertScore: 0.9932463765144348\n",
      "Substitute: tracking, BertScore: 0.9925634860992432\n",
      "Substitute: reconnaissance, BertScore: 0.9922218322753906\n",
      "Substitute: protection, BertScore: 0.9914194941520691\n",
      "Substitute: observation, BertScore: 0.9912622570991516\n",
      "Substitute: patrol, BertScore: 0.9909798502922058\n",
      "Substitute: communications, BertScore: 0.9907361268997192\n",
      "Substitute: spying, BertScore: 0.9906556606292725\n",
      "Substitute: monitor, BertScore: 0.9906022548675537\n",
      "Substitute: security, BertScore: 0.9900172352790833\n",
      "Substitute: radar, BertScore: 0.9899348616600037\n",
      "Substitute: spy, BertScore: 0.9899160861968994\n",
      "Substitute: camera, BertScore: 0.9895693063735962\n",
      "Substitute: inspection, BertScore: 0.9891296625137329\n",
      "Substitute: escort, BertScore: 0.9890843033790588\n",
      "Substitute: satellite, BertScore: 0.988976776599884\n",
      "Substitute: control, BertScore: 0.9888071417808533\n",
      "Substitute: intelligence, BertScore: 0.9885877966880798\n",
      "Substitute: watch, BertScore: 0.9884766340255737\n",
      "Substitute: maintenance, BertScore: 0.9881137013435364\n",
      "Substitute: unmanned, BertScore: 0.9879552721977234\n",
      "Substitute: liaison, BertScore: 0.987937867641449\n",
      "Substitute: research, BertScore: 0.987398624420166\n",
      "Substitute: drone, BertScore: 0.9873425960540771\n",
      "Substitute: transport, BertScore: 0.9871353507041931\n",
      "Substitute: military, BertScore: 0.9865348935127258\n",
      "Substitute: observing, BertScore: 0.9857004284858704\n",
      "Substitute: guard, BertScore: 0.9853570461273193\n",
      "Substitute: monitored, BertScore: 0.982925295829773\n",
      "top-10 substitutes based on bertscores in context: ['monitoring', 'tracking', 'reconnaissance', 'protection', 'observation', 'patrol', 'communications', 'spying', 'monitor', 'security']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: preoccupied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: distracted, BertScore: 0.9861223697662354\n",
      "Substitute: occupied, BertScore: 0.9854965806007385\n",
      "Substitute: consumed, BertScore: 0.9850492477416992\n",
      "Substitute: obsessed, BertScore: 0.9837136268615723\n",
      "Substitute: overwhelmed, BertScore: 0.9795740246772766\n",
      "Substitute: concerned, BertScore: 0.9789585471153259\n",
      "Substitute: engaged, BertScore: 0.9785122275352478\n",
      "Substitute: troubled, BertScore: 0.9783822894096375\n",
      "Substitute: dominated, BertScore: 0.9783095121383667\n",
      "Substitute: agitated, BertScore: 0.976781964302063\n",
      "Substitute: confronted, BertScore: 0.9748079776763916\n",
      "Substitute: frustrated, BertScore: 0.9742016196250916\n",
      "Substitute: plagued, BertScore: 0.9741305708885193\n",
      "Substitute: driven, BertScore: 0.9740374088287354\n",
      "Substitute: motivated, BertScore: 0.9737155437469482\n",
      "Substitute: disturbed, BertScore: 0.9733278155326843\n",
      "Substitute: bothered, BertScore: 0.9728493094444275\n",
      "Substitute: fascinated, BertScore: 0.9714652299880981\n",
      "Substitute: worried, BertScore: 0.9702376127243042\n",
      "Substitute: constrained, BertScore: 0.9698511362075806\n",
      "Substitute: bored, BertScore: 0.96901535987854\n",
      "Substitute: blinded, BertScore: 0.9686715006828308\n",
      "Substitute: threatened, BertScore: 0.9675701856613159\n",
      "Substitute: affected, BertScore: 0.9669417142868042\n",
      "Substitute: involved, BertScore: 0.9669132828712463\n",
      "Substitute: confused, BertScore: 0.9668794274330139\n",
      "Substitute: alarmed, BertScore: 0.9659024477005005\n",
      "Substitute: satisfied, BertScore: 0.9595350027084351\n",
      "top-10 substitutes based on bertscores in context: ['distracted', 'occupied', 'consumed', 'obsessed', 'overwhelmed', 'concerned', 'engaged', 'troubled', 'dominated', 'agitated']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: conservative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: liberal, BertScore: 0.9962325096130371\n",
      "Substitute: affluent, BertScore: 0.9930498003959656\n",
      "Substitute: moderate, BertScore: 0.992376446723938\n",
      "Substitute: secular, BertScore: 0.9920297861099243\n",
      "Substitute: radical, BertScore: 0.9911588430404663\n",
      "Substitute: leftist, BertScore: 0.9909965395927429\n",
      "Substitute: wealthy, BertScore: 0.9907527565956116\n",
      "Substitute: orthodox, BertScore: 0.9904465079307556\n",
      "Substitute: mainstream, BertScore: 0.9901246428489685\n",
      "Substitute: senior, BertScore: 0.989569365978241\n",
      "Substitute: tory, BertScore: 0.989310085773468\n",
      "Substitute: pious, BertScore: 0.9880324006080627\n",
      "Substitute: militant, BertScore: 0.987696647644043\n",
      "Substitute: minority, BertScore: 0.9875360727310181\n",
      "Substitute: muslim, BertScore: 0.9868760108947754\n",
      "Substitute: western, BertScore: 0.9867826104164124\n",
      "Substitute: christian, BertScore: 0.9865007400512695\n",
      "Substitute: young, BertScore: 0.9863039255142212\n",
      "Substitute: sunni, BertScore: 0.9862985014915466\n",
      "Substitute: traditional, BertScore: 0.9861630201339722\n",
      "Substitute: local, BertScore: 0.9860285520553589\n",
      "Substitute: modern, BertScore: 0.9852874279022217\n",
      "Substitute: northern, BertScore: 0.9847583770751953\n",
      "Substitute: eastern, BertScore: 0.9843747615814209\n",
      "Substitute: some, BertScore: 0.9835116267204285\n",
      "Substitute: other, BertScore: 0.9818167686462402\n",
      "Substitute: the, BertScore: 0.979652464389801\n",
      "Substitute: two, BertScore: 0.9773193597793579\n",
      "Substitute: both, BertScore: 0.9701550006866455\n",
      "top-10 substitutes based on bertscores in context: ['liberal', 'affluent', 'moderate', 'secular', 'radical', 'leftist', 'wealthy', 'orthodox', 'mainstream', 'senior']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: documented\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: recorded, BertScore: 0.9914734959602356\n",
      "Substitute: reported, BertScore: 0.9853605031967163\n",
      "Substitute: uncovered, BertScore: 0.9837409257888794\n",
      "Substitute: discovered, BertScore: 0.9830877184867859\n",
      "Substitute: identified, BertScore: 0.9828984141349792\n",
      "Substitute: confirmed, BertScore: 0.980860710144043\n",
      "Substitute: listed, BertScore: 0.9807643294334412\n",
      "Substitute: found, BertScore: 0.9794896245002747\n",
      "Substitute: investigated, BertScore: 0.9785226583480835\n",
      "Substitute: recognized, BertScore: 0.9773668050765991\n",
      "Substitute: established, BertScore: 0.9756637811660767\n",
      "Substitute: represented, BertScore: 0.9750534892082214\n",
      "Substitute: done, BertScore: 0.972532331943512\n",
      "Substitute: resolved, BertScore: 0.9701079726219177\n",
      "Substitute: emerged, BertScore: 0.9700770378112793\n",
      "Substitute: made, BertScore: 0.9690054059028625\n",
      "Substitute: solved, BertScore: 0.9681956768035889\n",
      "Substitute: settled, BertScore: 0.9668026566505432\n",
      "Substitute: emerging, BertScore: 0.9663453102111816\n",
      "Substitute: related, BertScore: 0.9643043279647827\n",
      "Substitute: involved, BertScore: 0.9633778929710388\n",
      "Substitute: out, BertScore: 0.963279664516449\n",
      "Substitute: lost, BertScore: 0.9586485624313354\n",
      "Substitute: there, BertScore: 0.9568820595741272\n",
      "Substitute: pending, BertScore: 0.9564273357391357\n",
      "Substitute: here, BertScore: 0.9550582766532898\n",
      "Substitute: now, BertScore: 0.9505999684333801\n",
      "Substitute: again, BertScore: 0.949471116065979\n",
      "Substitute: more, BertScore: 0.9485132694244385\n",
      "top-10 substitutes based on bertscores in context: ['recorded', 'reported', 'uncovered', 'discovered', 'identified', 'confirmed', 'listed', 'found', 'investigated', 'recognized']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: awoken\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: awakened, BertScore: 0.9886128902435303\n",
      "Substitute: woke, BertScore: 0.9865995645523071\n",
      "Substitute: woken, BertScore: 0.9865840673446655\n",
      "Substitute: waking, BertScore: 0.9804620146751404\n",
      "Substitute: startled, BertScore: 0.9792228937149048\n",
      "Substitute: disturbed, BertScore: 0.9783579111099243\n",
      "Substitute: aroused, BertScore: 0.9783561825752258\n",
      "Substitute: alarmed, BertScore: 0.9780982732772827\n",
      "Substitute: alerted, BertScore: 0.9776400327682495\n",
      "Substitute: surprised, BertScore: 0.9771876335144043\n",
      "Substitute: confronted, BertScore: 0.9763627648353577\n",
      "Substitute: interrupted, BertScore: 0.9756423830986023\n",
      "Substitute: jolted, BertScore: 0.9754409790039062\n",
      "Substitute: wake, BertScore: 0.9752141833305359\n",
      "Substitute: frightened, BertScore: 0.9751763343811035\n",
      "Substitute: shocked, BertScore: 0.9744385480880737\n",
      "Substitute: shaken, BertScore: 0.9735589027404785\n",
      "Substitute: triggered, BertScore: 0.9732323884963989\n",
      "Substitute: struck, BertScore: 0.9715824127197266\n",
      "Substitute: attacked, BertScore: 0.9710899591445923\n",
      "Substitute: ambushed, BertScore: 0.9705246090888977\n",
      "Substitute: hit, BertScore: 0.9688852429389954\n",
      "Substitute: driven, BertScore: 0.9685097932815552\n",
      "Substitute: assaulted, BertScore: 0.9675031304359436\n",
      "Substitute: bitten, BertScore: 0.9672149419784546\n",
      "Substitute: wounded, BertScore: 0.9668136835098267\n",
      "Substitute: injured, BertScore: 0.9664769172668457\n",
      "Substitute: killed, BertScore: 0.9645512700080872\n",
      "top-10 substitutes based on bertscores in context: ['awakened', 'woke', 'woken', 'waking', 'startled', 'disturbed', 'aroused', 'alarmed', 'alerted', 'surprised']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: inadequate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: insufficient, BertScore: 0.9968157410621643\n",
      "Substitute: ineffective, BertScore: 0.9934080839157104\n",
      "Substitute: incomplete, BertScore: 0.9931524395942688\n",
      "Substitute: weak, BertScore: 0.991896390914917\n",
      "Substitute: faulty, BertScore: 0.99188232421875\n",
      "Substitute: failing, BertScore: 0.9917857646942139\n",
      "Substitute: poor, BertScore: 0.9912799596786499\n",
      "Substitute: incorrect, BertScore: 0.9897541999816895\n",
      "Substitute: inappropriate, BertScore: 0.9891068935394287\n",
      "Substitute: lacking, BertScore: 0.9890161752700806\n",
      "Substitute: unreliable, BertScore: 0.9889256954193115\n",
      "Substitute: lack, BertScore: 0.9888432621955872\n",
      "Substitute: lax, BertScore: 0.9888116121292114\n",
      "Substitute: low, BertScore: 0.9883294701576233\n",
      "Substitute: unsafe, BertScore: 0.9883291721343994\n",
      "Substitute: improper, BertScore: 0.9883276224136353\n",
      "Substitute: impaired, BertScore: 0.988067090511322\n",
      "Substitute: inaccurate, BertScore: 0.9878683686256409\n",
      "Substitute: unsuitable, BertScore: 0.9873696565628052\n",
      "Substitute: excessive, BertScore: 0.9870732426643372\n",
      "Substitute: limited, BertScore: 0.9867436289787292\n",
      "Substitute: reduced, BertScore: 0.9854190349578857\n",
      "Substitute: unfair, BertScore: 0.9847022294998169\n",
      "Substitute: ill, BertScore: 0.9839657545089722\n",
      "Substitute: not, BertScore: 0.9804797768592834\n",
      "Substitute: improved, BertScore: 0.9804633855819702\n",
      "Substitute: no, BertScore: 0.9797681570053101\n",
      "Substitute: adequate, BertScore: 0.9795299172401428\n",
      "Substitute: better, BertScore: 0.9742953777313232\n",
      "top-10 substitutes based on bertscores in context: ['insufficient', 'ineffective', 'incomplete', 'weak', 'faulty', 'failing', 'poor', 'incorrect', 'inappropriate', 'lacking']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: challenging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: defending, BertScore: 0.9965732097625732\n",
      "Substitute: attacking, BertScore: 0.9961375594139099\n",
      "Substitute: questioning, BertScore: 0.9951069355010986\n",
      "Substitute: opposing, BertScore: 0.9945509433746338\n",
      "Substitute: protesting, BertScore: 0.9938021898269653\n",
      "Substitute: asserting, BertScore: 0.993787407875061\n",
      "Substitute: criticizing, BertScore: 0.9933217763900757\n",
      "Substitute: rejecting, BertScore: 0.9932490587234497\n",
      "Substitute: arguing, BertScore: 0.9926620721817017\n",
      "Substitute: claiming, BertScore: 0.9920740127563477\n",
      "Substitute: condemning, BertScore: 0.9916712641716003\n",
      "Substitute: pursuing, BertScore: 0.9916048049926758\n",
      "Substitute: supporting, BertScore: 0.991429328918457\n",
      "Substitute: proving, BertScore: 0.9913085699081421\n",
      "Substitute: dismissing, BertScore: 0.99117112159729\n",
      "Substitute: alleging, BertScore: 0.9911413192749023\n",
      "Substitute: recognizing, BertScore: 0.9907711148262024\n",
      "Substitute: respecting, BertScore: 0.9901840090751648\n",
      "Substitute: demanding, BertScore: 0.9901134371757507\n",
      "Substitute: compelling, BertScore: 0.9900913238525391\n",
      "Substitute: against, BertScore: 0.9898706078529358\n",
      "Substitute: denying, BertScore: 0.9898476004600525\n",
      "Substitute: concerning, BertScore: 0.9895548820495605\n",
      "Substitute: regarding, BertScore: 0.9894458055496216\n",
      "Substitute: involving, BertScore: 0.9883400797843933\n",
      "Substitute: about, BertScore: 0.987649142742157\n",
      "Substitute: requiring, BertScore: 0.9864343404769897\n",
      "top-10 substitutes based on bertscores in context: ['defending', 'attacking', 'questioning', 'opposing', 'protesting', 'asserting', 'criticizing', 'rejecting', 'arguing', 'claiming']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: assassinated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: murdered, BertScore: 0.9884964823722839\n",
      "Substitute: killed, BertScore: 0.9853973388671875\n",
      "Substitute: slain, BertScore: 0.9810976982116699\n",
      "Substitute: executed, BertScore: 0.9767690300941467\n",
      "Substitute: shot, BertScore: 0.9752572178840637\n",
      "Substitute: beheaded, BertScore: 0.9740467071533203\n",
      "Substitute: kidnapped, BertScore: 0.9707383513450623\n",
      "Substitute: attacked, BertScore: 0.9704222679138184\n",
      "Substitute: captured, BertScore: 0.9678729772567749\n",
      "Substitute: abducted, BertScore: 0.9676867127418518\n",
      "Substitute: arrested, BertScore: 0.9664164781570435\n",
      "Substitute: wounded, BertScore: 0.9663642644882202\n",
      "Substitute: ambushed, BertScore: 0.9603287577629089\n",
      "Substitute: targeted, BertScore: 0.9585813283920288\n",
      "Substitute: beaten, BertScore: 0.958001971244812\n",
      "Substitute: seized, BertScore: 0.9578981995582581\n",
      "Substitute: detained, BertScore: 0.9552417993545532\n",
      "Substitute: snatched, BertScore: 0.94983971118927\n",
      "Substitute: pursued, BertScore: 0.9443535804748535\n",
      "Substitute: questioned, BertScore: 0.9408687353134155\n",
      "Substitute: seen, BertScore: 0.9381526708602905\n",
      "Substitute: met, BertScore: 0.9376624822616577\n",
      "Substitute: visited, BertScore: 0.9372085928916931\n",
      "Substitute: approached, BertScore: 0.9356685876846313\n",
      "Substitute: identified, BertScore: 0.9354186058044434\n",
      "Substitute: held, BertScore: 0.9351139068603516\n",
      "Substitute: contacted, BertScore: 0.9335803985595703\n",
      "Substitute: aided, BertScore: 0.9296383261680603\n",
      "Substitute: accompanied, BertScore: 0.9198823571205139\n",
      "top-10 substitutes based on bertscores in context: ['murdered', 'killed', 'slain', 'executed', 'shot', 'beheaded', 'kidnapped', 'attacked', 'captured', 'abducted']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: datum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: point, BertScore: 0.9711366295814514\n",
      "Substitute: mark, BertScore: 0.9704326391220093\n",
      "Substitute: material, BertScore: 0.9702082872390747\n",
      "Substitute: dat, BertScore: 0.9697893261909485\n",
      "Substitute: area, BertScore: 0.969487190246582\n",
      "Substitute: surface, BertScore: 0.9694150686264038\n",
      "Substitute: level, BertScore: 0.9688704609870911\n",
      "Substitute: index, BertScore: 0.9685460329055786\n",
      "Substitute: sign, BertScore: 0.9683296084403992\n",
      "Substitute: zone, BertScore: 0.9682662487030029\n",
      "Substitute: signal, BertScore: 0.967787504196167\n",
      "Substitute: spot, BertScore: 0.9677138924598694\n",
      "Substitute: ground, BertScore: 0.9675031900405884\n",
      "Substitute: locality, BertScore: 0.9673757553100586\n",
      "Substitute: record, BertScore: 0.967338502407074\n",
      "Substitute: map, BertScore: 0.9671746492385864\n",
      "Substitute: location, BertScore: 0.9671419858932495\n",
      "Substitute: mean, BertScore: 0.9668912887573242\n",
      "Substitute: code, BertScore: 0.9662205576896667\n",
      "Substitute: altitude, BertScore: 0.966206431388855\n",
      "Substitute: site, BertScore: 0.9660556316375732\n",
      "Substitute: limit, BertScore: 0.9659603834152222\n",
      "Substitute: norm, BertScore: 0.9659167528152466\n",
      "Substitute: basis, BertScore: 0.9658588767051697\n",
      "Substitute: measure, BertScore: 0.9655756950378418\n",
      "Substitute: standard, BertScore: 0.9653222560882568\n",
      "Substitute: estimate, BertScore: 0.9637126326560974\n",
      "Substitute: definition, BertScore: 0.9605990052223206\n",
      "Substitute: north, BertScore: 0.9598824977874756\n",
      "top-10 substitutes based on bertscores in context: ['point', 'mark', 'material', 'dat', 'area', 'surface', 'level', 'index', 'sign', 'zone']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: eligible\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: eligibility, BertScore: 0.9953228831291199\n",
      "Substitute: qualified, BertScore: 0.9935992956161499\n",
      "Substitute: qualifying, BertScore: 0.9933825135231018\n",
      "Substitute: qualify, BertScore: 0.9929407238960266\n",
      "Substitute: ineligible, BertScore: 0.9917060732841492\n",
      "Substitute: enrolled, BertScore: 0.9914783239364624\n",
      "Substitute: registered, BertScore: 0.9903829097747803\n",
      "Substitute: authorized, BertScore: 0.9890612363815308\n",
      "Substitute: considered, BertScore: 0.9890458583831787\n",
      "Substitute: available, BertScore: 0.9890300035476685\n",
      "Substitute: approved, BertScore: 0.9890215992927551\n",
      "Substitute: fit, BertScore: 0.9889651536941528\n",
      "Substitute: certified, BertScore: 0.9889259338378906\n",
      "Substitute: accepted, BertScore: 0.9889053106307983\n",
      "Substitute: permitted, BertScore: 0.9887531399726868\n",
      "Substitute: able, BertScore: 0.9887034296989441\n",
      "Substitute: allowed, BertScore: 0.9885455369949341\n",
      "Substitute: selected, BertScore: 0.9883187413215637\n",
      "Substitute: willing, BertScore: 0.9881229400634766\n",
      "Substitute: suitable, BertScore: 0.9881166219711304\n",
      "Substitute: exempt, BertScore: 0.987931489944458\n",
      "Substitute: ready, BertScore: 0.9877303242683411\n",
      "Substitute: required, BertScore: 0.9869409799575806\n",
      "Substitute: unfit, BertScore: 0.9865317344665527\n",
      "Substitute: prepared, BertScore: 0.9858671426773071\n",
      "Substitute: acceptable, BertScore: 0.98539137840271\n",
      "Substitute: submitted, BertScore: 0.9852758049964905\n",
      "Substitute: intended, BertScore: 0.9832302331924438\n",
      "Substitute: waiting, BertScore: 0.9813624024391174\n",
      "top-10 substitutes based on bertscores in context: ['eligibility', 'qualified', 'qualifying', 'qualify', 'ineligible', 'enrolled', 'registered', 'authorized', 'considered', 'available']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: roamed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: dotted, BertScore: 0.9884470105171204\n",
      "Substitute: circled, BertScore: 0.9874649047851562\n",
      "Substitute: swept, BertScore: 0.9870862364768982\n",
      "Substitute: crossed, BertScore: 0.9865064024925232\n",
      "Substitute: littered, BertScore: 0.9861255288124084\n",
      "Substitute: lined, BertScore: 0.985540509223938\n",
      "Substitute: buzzed, BertScore: 0.9846341609954834\n",
      "Substitute: scanned, BertScore: 0.9846089482307434\n",
      "Substitute: raked, BertScore: 0.9844982028007507\n",
      "Substitute: filled, BertScore: 0.9844751954078674\n",
      "Substitute: stalked, BertScore: 0.9843505024909973\n",
      "Substitute: streaked, BertScore: 0.9840909838676453\n",
      "Substitute: flooded, BertScore: 0.9840726852416992\n",
      "Substitute: entered, BertScore: 0.9837660193443298\n",
      "Substitute: darkened, BertScore: 0.9834030866622925\n",
      "Substitute: pierced, BertScore: 0.983351469039917\n",
      "Substitute: pounded, BertScore: 0.9828929305076599\n",
      "Substitute: illuminated, BertScore: 0.9826835989952087\n",
      "Substitute: rocked, BertScore: 0.9822946190834045\n",
      "Substitute: clouded, BertScore: 0.9819537401199341\n",
      "Substitute: roared, BertScore: 0.9810753464698792\n",
      "Substitute: covered, BertScore: 0.9806778430938721\n",
      "Substitute: hit, BertScore: 0.9797754287719727\n",
      "Substitute: flew, BertScore: 0.9793580770492554\n",
      "Substitute: blasted, BertScore: 0.9788140654563904\n",
      "Substitute: searched, BertScore: 0.9783401489257812\n",
      "Substitute: lit, BertScore: 0.9776445627212524\n",
      "Substitute: invaded, BertScore: 0.9774512052536011\n",
      "Substitute: watched, BertScore: 0.9692062735557556\n",
      "top-10 substitutes based on bertscores in context: ['dotted', 'circled', 'swept', 'crossed', 'littered', 'lined', 'buzzed', 'scanned', 'raked', 'filled']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: diplomatically\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: politically, BertScore: 0.9798600673675537\n",
      "Substitute: informally, BertScore: 0.9759944677352905\n",
      "Substitute: formally, BertScore: 0.9755865335464478\n",
      "Substitute: peacefully, BertScore: 0.9755327701568604\n",
      "Substitute: legally, BertScore: 0.9754915833473206\n",
      "Substitute: directly, BertScore: 0.9746788740158081\n",
      "Substitute: technically, BertScore: 0.9736528992652893\n",
      "Substitute: temporarily, BertScore: 0.9736323952674866\n",
      "Substitute: effectively, BertScore: 0.9735220670700073\n",
      "Substitute: successfully, BertScore: 0.9734641313552856\n",
      "Substitute: administratively, BertScore: 0.9729188680648804\n",
      "Substitute: fully, BertScore: 0.9725587368011475\n",
      "Substitute: briefly, BertScore: 0.9716318249702454\n",
      "Substitute: again, BertScore: 0.9694974422454834\n",
      "Substitute: a, BertScore: 0.9691228866577148\n",
      "Substitute: primarily, BertScore: 0.9678377509117126\n",
      "Substitute: both, BertScore: 0.966188907623291\n",
      "Substitute: yet, BertScore: 0.9660266637802124\n",
      "Substitute: to, BertScore: 0.9630809426307678\n",
      "Substitute: quite, BertScore: 0.9627138376235962\n",
      "Substitute: not, BertScore: 0.9615985155105591\n",
      "Substitute: with, BertScore: 0.9615259170532227\n",
      "Substitute: such, BertScore: 0.9605443477630615\n",
      "Substitute: only, BertScore: 0.9594408869743347\n",
      "Substitute: this, BertScore: 0.9593263268470764\n",
      "Substitute: in, BertScore: 0.9585714936256409\n",
      "Substitute: for, BertScore: 0.9585010409355164\n",
      "Substitute: as, BertScore: 0.9554573893547058\n",
      "top-10 substitutes based on bertscores in context: ['politically', 'informally', 'formally', 'peacefully', 'legally', 'directly', 'technically', 'temporarily', 'effectively', 'successfully']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: conjure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: summon, BertScore: 0.9908720850944519\n",
      "Substitute: stir, BertScore: 0.9896939396858215\n",
      "Substitute: bring, BertScore: 0.9896246194839478\n",
      "Substitute: strike, BertScore: 0.9884925484657288\n",
      "Substitute: kick, BertScore: 0.9884201288223267\n",
      "Substitute: weave, BertScore: 0.9883285760879517\n",
      "Substitute: create, BertScore: 0.9882444739341736\n",
      "Substitute: forge, BertScore: 0.9881798624992371\n",
      "Substitute: pick, BertScore: 0.9879840612411499\n",
      "Substitute: tie, BertScore: 0.9877980947494507\n",
      "Substitute: draw, BertScore: 0.9877852201461792\n",
      "Substitute: set, BertScore: 0.9877068996429443\n",
      "Substitute: shape, BertScore: 0.9874597191810608\n",
      "Substitute: build, BertScore: 0.9872947931289673\n",
      "Substitute: shake, BertScore: 0.9860206842422485\n",
      "Substitute: hold, BertScore: 0.9851264953613281\n",
      "Substitute: force, BertScore: 0.9850441217422485\n",
      "Substitute: offer, BertScore: 0.9846359491348267\n",
      "Substitute: free, BertScore: 0.9845443964004517\n",
      "Substitute: put, BertScore: 0.9845382571220398\n",
      "Substitute: firm, BertScore: 0.984397828578949\n",
      "Substitute: open, BertScore: 0.9843029379844666\n",
      "Substitute: setting, BertScore: 0.9836503863334656\n",
      "Substitute: break, BertScore: 0.9832576513290405\n",
      "Substitute: take, BertScore: 0.9830471873283386\n",
      "Substitute: make, BertScore: 0.9824011325836182\n",
      "Substitute: blow, BertScore: 0.9822084903717041\n",
      "Substitute: lock, BertScore: 0.9820764064788818\n",
      "Substitute: give, BertScore: 0.9734821915626526\n",
      "top-10 substitutes based on bertscores in context: ['summon', 'stir', 'bring', 'strike', 'kick', 'weave', 'create', 'forge', 'pick', 'tie']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: commemorating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: celebrating, BertScore: 0.997677743434906\n",
      "Substitute: honoring, BertScore: 0.9974896907806396\n",
      "Substitute: marking, BertScore: 0.9971798062324524\n",
      "Substitute: remembering, BertScore: 0.9963369369506836\n",
      "Substitute: recognizing, BertScore: 0.9956845641136169\n",
      "Substitute: highlighting, BertScore: 0.9954014420509338\n",
      "Substitute: acknowledging, BertScore: 0.9951231479644775\n",
      "Substitute: celebrate, BertScore: 0.9945018887519836\n",
      "Substitute: recalling, BertScore: 0.9943332076072693\n",
      "Substitute: reflecting, BertScore: 0.9940258264541626\n",
      "Substitute: representing, BertScore: 0.993841290473938\n",
      "Substitute: depicting, BertScore: 0.9927083253860474\n",
      "Substitute: documenting, BertScore: 0.9926168918609619\n",
      "Substitute: celebrated, BertScore: 0.991975724697113\n",
      "Substitute: announcing, BertScore: 0.9917945265769958\n",
      "Substitute: mark, BertScore: 0.991400420665741\n",
      "Substitute: about, BertScore: 0.9904091358184814\n",
      "Substitute: showing, BertScore: 0.9900773763656616\n",
      "Substitute: for, BertScore: 0.9898067712783813\n",
      "Substitute: marked, BertScore: 0.989641547203064\n",
      "Substitute: on, BertScore: 0.9889622926712036\n",
      "Substitute: of, BertScore: 0.9872930645942688\n",
      "Substitute: around, BertScore: 0.9857056736946106\n",
      "Substitute: after, BertScore: 0.9852897524833679\n",
      "Substitute: at, BertScore: 0.9851295948028564\n",
      "Substitute: during, BertScore: 0.9843394756317139\n",
      "top-10 substitutes based on bertscores in context: ['celebrating', 'honoring', 'marking', 'remembering', 'recognizing', 'highlighting', 'acknowledging', 'celebrate', 'recalling', 'reflecting']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: legislaton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: action, BertScore: 0.961286723613739\n",
      "Substitute: law, BertScore: 0.9600099325180054\n",
      "Substitute: acts, BertScore: 0.959157407283783\n",
      "Substitute: actions, BertScore: 0.9589877724647522\n",
      "Substitute: policy, BertScore: 0.9589550495147705\n",
      "Substitute: relief, BertScore: 0.9588503837585449\n",
      "Substitute: legislation, BertScore: 0.9586953520774841\n",
      "Substitute: laws, BertScore: 0.9585307836532593\n",
      "Substitute: independence, BertScore: 0.9581282138824463\n",
      "Substitute: bill, BertScore: 0.958080530166626\n",
      "Substitute: rights, BertScore: 0.9578902125358582\n",
      "Substitute: protest, BertScore: 0.9576950073242188\n",
      "Substitute: act, BertScore: 0.9576741456985474\n",
      "Substitute: petition, BertScore: 0.9575880765914917\n",
      "Substitute: reform, BertScore: 0.9575825929641724\n",
      "Substitute: reforms, BertScore: 0.9572551250457764\n",
      "Substitute: discrimination, BertScore: 0.9572522640228271\n",
      "Substitute: movement, BertScore: 0.9570492506027222\n",
      "Substitute: petitions, BertScore: 0.9561297297477722\n",
      "Substitute: demonstration, BertScore: 0.9559646844863892\n",
      "Substitute: activism, BertScore: 0.9554225206375122\n",
      "Substitute: movements, BertScore: 0.9547927975654602\n",
      "Substitute: marches, BertScore: 0.9543221592903137\n",
      "Substitute: protests, BertScore: 0.9540718197822571\n",
      "Substitute: riots, BertScore: 0.9537298083305359\n",
      "Substitute: demonstrations, BertScore: 0.9534038305282593\n",
      "Substitute: violations, BertScore: 0.953130841255188\n",
      "Substitute: abuses, BertScore: 0.9530621767044067\n",
      "Substitute: protesters, BertScore: 0.9514240026473999\n",
      "Substitute: activists, BertScore: 0.9503676891326904\n",
      "top-10 substitutes based on bertscores in context: ['action', 'law', 'acts', 'actions', 'policy', 'relief', 'legislation', 'laws', 'independence', 'bill']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: dissidents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: rebels, BertScore: 0.9604828953742981\n",
      "Substitute: militants, BertScore: 0.9597934484481812\n",
      "Substitute: activists, BertScore: 0.9597774744033813\n",
      "Substitute: protesters, BertScore: 0.9590670466423035\n",
      "Substitute: revolutionaries, BertScore: 0.9590267539024353\n",
      "Substitute: refugees, BertScore: 0.958957314491272\n",
      "Substitute: minorities, BertScore: 0.9588178992271423\n",
      "Substitute: migrants, BertScore: 0.9583786725997925\n",
      "Substitute: civilians, BertScore: 0.9576513767242432\n",
      "Substitute: dissent, BertScore: 0.9576165080070496\n",
      "Substitute: demonstrators, BertScore: 0.9574890732765198\n",
      "Substitute: terrorists, BertScore: 0.9572675228118896\n",
      "Substitute: citizens, BertScore: 0.956926703453064\n",
      "Substitute: individuals, BertScore: 0.9569210410118103\n",
      "Substitute: detainees, BertScore: 0.9568862915039062\n",
      "Substitute: prisoners, BertScore: 0.9566938281059265\n",
      "Substitute: journalists, BertScore: 0.9566597938537598\n",
      "Substitute: opposition, BertScore: 0.9563697576522827\n",
      "Substitute: criminals, BertScore: 0.9560565948486328\n",
      "Substitute: inmates, BertScore: 0.954920768737793\n",
      "Substitute: youth, BertScore: 0.9546501040458679\n",
      "Substitute: christians, BertScore: 0.954252302646637\n",
      "Substitute: victims, BertScore: 0.9542412757873535\n",
      "Substitute: jews, BertScore: 0.9532427787780762\n",
      "Substitute: foreigners, BertScore: 0.9530665874481201\n",
      "Substitute: armenians, BertScore: 0.9525895118713379\n",
      "Substitute: people, BertScore: 0.9519465565681458\n",
      "Substitute: women, BertScore: 0.9511516690254211\n",
      "Substitute: democracy, BertScore: 0.9483975768089294\n",
      "Substitute: others, BertScore: 0.9465436935424805\n",
      "top-10 substitutes based on bertscores in context: ['rebels', 'militants', 'activists', 'protesters', 'revolutionaries', 'refugees', 'minorities', 'migrants', 'civilians', 'dissent']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: problematic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: difficult, BertScore: 0.9720621109008789\n",
      "Substitute: problems, BertScore: 0.9659373164176941\n",
      "Substitute: problem, BertScore: 0.9652025699615479\n",
      "Substitute: excessive, BertScore: 0.9627051949501038\n",
      "Substitute: dangerous, BertScore: 0.9607271552085876\n",
      "Substitute: inadequate, BertScore: 0.9606040716171265\n",
      "Substitute: inappropriate, BertScore: 0.9585350155830383\n",
      "Substitute: unacceptable, BertScore: 0.9562687277793884\n",
      "Substitute: unnecessary, BertScore: 0.9555959105491638\n",
      "Substitute: irrelevant, BertScore: 0.9553784728050232\n",
      "Substitute: desirable, BertScore: 0.955352246761322\n",
      "Substitute: insufficient, BertScore: 0.9532532095909119\n",
      "Substitute: helpful, BertScore: 0.9529713988304138\n",
      "Substitute: significant, BertScore: 0.952754020690918\n",
      "Substitute: trivial, BertScore: 0.951335072517395\n",
      "Substitute: beneficial, BertScore: 0.9505420327186584\n",
      "Substitute: illegal, BertScore: 0.9503889083862305\n",
      "Substitute: bad, BertScore: 0.9485780596733093\n",
      "Substitute: useless, BertScore: 0.9470385313034058\n",
      "Substitute: negative, BertScore: 0.9448555111885071\n",
      "Substitute: evil, BertScore: 0.9425928592681885\n",
      "Substitute: acceptable, BertScore: 0.9425387978553772\n",
      "Substitute: useful, BertScore: 0.9414461255073547\n",
      "Substitute: good, BertScore: 0.9348623752593994\n",
      "Substitute: relevant, BertScore: 0.932147204875946\n",
      "Substitute: positive, BertScore: 0.9313863515853882\n",
      "Substitute: necessary, BertScore: 0.9298563003540039\n",
      "Substitute: redundant, BertScore: 0.9240626692771912\n",
      "Substitute: rubbish, BertScore: 0.9045678973197937\n",
      "top-10 substitutes based on bertscores in context: ['difficult', 'problems', 'problem', 'excessive', 'dangerous', 'inadequate', 'inappropriate', 'unacceptable', 'unnecessary', 'irrelevant']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: ingested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: consumed, BertScore: 0.977636456489563\n",
      "Substitute: ate, BertScore: 0.9753414988517761\n",
      "Substitute: drunk, BertScore: 0.9746505618095398\n",
      "Substitute: swallowed, BertScore: 0.9740819931030273\n",
      "Substitute: tasted, BertScore: 0.9733918905258179\n",
      "Substitute: drank, BertScore: 0.9733126163482666\n",
      "Substitute: eaten, BertScore: 0.972357988357544\n",
      "Substitute: absorbed, BertScore: 0.9709555506706238\n",
      "Substitute: stirred, BertScore: 0.96626877784729\n",
      "Substitute: touched, BertScore: 0.9660699367523193\n",
      "Substitute: processed, BertScore: 0.9645424485206604\n",
      "Substitute: fed, BertScore: 0.9636037349700928\n",
      "Substitute: took, BertScore: 0.9620725512504578\n",
      "Substitute: administered, BertScore: 0.9615591168403625\n",
      "Substitute: stored, BertScore: 0.9608379602432251\n",
      "Substitute: burned, BertScore: 0.9605624079704285\n",
      "Substitute: extracted, BertScore: 0.9604780673980713\n",
      "Substitute: infused, BertScore: 0.9601406455039978\n",
      "Substitute: soaked, BertScore: 0.9599409699440002\n",
      "Substitute: squeezed, BertScore: 0.9597848057746887\n",
      "Substitute: gathered, BertScore: 0.959737241268158\n",
      "Substitute: injected, BertScore: 0.9590914249420166\n",
      "Substitute: used, BertScore: 0.9582454562187195\n",
      "Substitute: obtained, BertScore: 0.9573241472244263\n",
      "Substitute: mixed, BertScore: 0.9548827409744263\n",
      "Substitute: contaminated, BertScore: 0.953410267829895\n",
      "Substitute: made, BertScore: 0.9532701969146729\n",
      "Substitute: filled, BertScore: 0.9531233310699463\n",
      "Substitute: reacted, BertScore: 0.94887775182724\n",
      "top-10 substitutes based on bertscores in context: ['consumed', 'ate', 'drunk', 'swallowed', 'tasted', 'drank', 'eaten', 'absorbed', 'stirred', 'touched']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: definitive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: formal, BertScore: 0.9959049820899963\n",
      "Substitute: concrete, BertScore: 0.9956476092338562\n",
      "Substitute: permanent, BertScore: 0.9955772757530212\n",
      "Substitute: definite, BertScore: 0.9951876997947693\n",
      "Substitute: comprehensive, BertScore: 0.9950939416885376\n",
      "Substitute: meaningful, BertScore: 0.9950718879699707\n",
      "Substitute: substantive, BertScore: 0.9949195384979248\n",
      "Substitute: final, BertScore: 0.9948670268058777\n",
      "Substitute: provisional, BertScore: 0.9946960210800171\n",
      "Substitute: complete, BertScore: 0.9946761131286621\n",
      "Substitute: tentative, BertScore: 0.9943708181381226\n",
      "Substitute: full, BertScore: 0.9941977858543396\n",
      "Substitute: partial, BertScore: 0.9940943121910095\n",
      "Substitute: precise, BertScore: 0.9938529133796692\n",
      "Substitute: quick, BertScore: 0.9937757253646851\n",
      "Substitute: solid, BertScore: 0.9937405586242676\n",
      "Substitute: gradual, BertScore: 0.9936595559120178\n",
      "Substitute: general, BertScore: 0.9932538866996765\n",
      "Substitute: clear, BertScore: 0.9930102825164795\n",
      "Substitute: major, BertScore: 0.992960512638092\n",
      "Substitute: substantial, BertScore: 0.992856502532959\n",
      "Substitute: successful, BertScore: 0.9928151965141296\n",
      "Substitute: sweeping, BertScore: 0.99269700050354\n",
      "Substitute: thorough, BertScore: 0.992580771446228\n",
      "Substitute: detailed, BertScore: 0.9925419092178345\n",
      "Substitute: significant, BertScore: 0.9925136566162109\n",
      "Substitute: further, BertScore: 0.9924555420875549\n",
      "Substitute: total, BertScore: 0.9922532439231873\n",
      "Substitute: possible, BertScore: 0.990580141544342\n",
      "top-10 substitutes based on bertscores in context: ['formal', 'concrete', 'permanent', 'definite', 'comprehensive', 'meaningful', 'substantive', 'final', 'provisional', 'complete']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: compiled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: prepared, BertScore: 0.990682065486908\n",
      "Substitute: derived, BertScore: 0.9895126819610596\n",
      "Substitute: assembled, BertScore: 0.9887294769287109\n",
      "Substitute: gathered, BertScore: 0.9886298775672913\n",
      "Substitute: retrieved, BertScore: 0.9879215359687805\n",
      "Substitute: collected, BertScore: 0.9870924949645996\n",
      "Substitute: analyzed, BertScore: 0.9870607852935791\n",
      "Substitute: updated, BertScore: 0.9869288802146912\n",
      "Substitute: submitted, BertScore: 0.9865701794624329\n",
      "Substitute: published, BertScore: 0.9861907362937927\n",
      "Substitute: created, BertScore: 0.9860314130783081\n",
      "Substitute: released, BertScore: 0.985979437828064\n",
      "Substitute: accumulated, BertScore: 0.9859705567359924\n",
      "Substitute: conducted, BertScore: 0.985867440700531\n",
      "Substitute: issued, BertScore: 0.9851184487342834\n",
      "Substitute: produced, BertScore: 0.9851029515266418\n",
      "Substitute: obtained, BertScore: 0.9845428466796875\n",
      "Substitute: developed, BertScore: 0.9844308495521545\n",
      "Substitute: generated, BertScore: 0.9838892817497253\n",
      "Substitute: reported, BertScore: 0.9827179312705994\n",
      "Substitute: given, BertScore: 0.9825246334075928\n",
      "Substitute: provided, BertScore: 0.9824752807617188\n",
      "Substitute: summarized, BertScore: 0.9807078242301941\n",
      "Substitute: made, BertScore: 0.9806811809539795\n",
      "Substitute: polled, BertScore: 0.9783154129981995\n",
      "Substitute: recovered, BertScore: 0.977351188659668\n",
      "Substitute: supplied, BertScore: 0.975642740726471\n",
      "Substitute: divided, BertScore: 0.9747744202613831\n",
      "Substitute: received, BertScore: 0.9742748141288757\n",
      "top-10 substitutes based on bertscores in context: ['prepared', 'derived', 'assembled', 'gathered', 'retrieved', 'collected', 'analyzed', 'updated', 'submitted', 'published']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: criteria\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: requirements, BertScore: 0.9852422475814819\n",
      "Substitute: qualifications, BertScore: 0.981048583984375\n",
      "Substitute: guidelines, BertScore: 0.980135440826416\n",
      "Substitute: standards, BertScore: 0.9770674705505371\n",
      "Substitute: parameters, BertScore: 0.9735425710678101\n",
      "Substitute: rules, BertScore: 0.9733647704124451\n",
      "Substitute: requirement, BertScore: 0.9731840491294861\n",
      "Substitute: norms, BertScore: 0.9719798564910889\n",
      "Substitute: conditions, BertScore: 0.9707929491996765\n",
      "Substitute: procedures, BertScore: 0.9704850912094116\n",
      "Substitute: specifications, BertScore: 0.9702877998352051\n",
      "Substitute: standard, BertScore: 0.9702259302139282\n",
      "Substitute: threshold, BertScore: 0.9697937965393066\n",
      "Substitute: definition, BertScore: 0.9694871306419373\n",
      "Substitute: terms, BertScore: 0.9688509106636047\n",
      "Substitute: framework, BertScore: 0.9685731530189514\n",
      "Substitute: rule, BertScore: 0.9661208391189575\n",
      "Substitute: targets, BertScore: 0.9660749435424805\n",
      "Substitute: goals, BertScore: 0.9659739136695862\n",
      "Substitute: expectations, BertScore: 0.9658533930778503\n",
      "Substitute: objectives, BertScore: 0.9653782248497009\n",
      "Substitute: boundaries, BertScore: 0.9653047919273376\n",
      "Substitute: scores, BertScore: 0.9625012874603271\n",
      "Substitute: methodology, BertScore: 0.9616643786430359\n",
      "Substitute: objective, BertScore: 0.9598472714424133\n",
      "Substitute: characteristics, BertScore: 0.9592527747154236\n",
      "Substitute: deadline, BertScore: 0.9583909511566162\n",
      "Substitute: goal, BertScore: 0.9577339291572571\n",
      "top-10 substitutes based on bertscores in context: ['requirements', 'qualifications', 'guidelines', 'standards', 'parameters', 'rules', 'requirement', 'norms', 'conditions', 'procedures']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: crippling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: devastating, BertScore: 0.9865540266036987\n",
      "Substitute: damaging, BertScore: 0.9864817261695862\n",
      "Substitute: crushing, BertScore: 0.9862707853317261\n",
      "Substitute: failing, BertScore: 0.9856017827987671\n",
      "Substitute: falling, BertScore: 0.9853349328041077\n",
      "Substitute: massive, BertScore: 0.9845632314682007\n",
      "Substitute: hitting, BertScore: 0.9844515919685364\n",
      "Substitute: rising, BertScore: 0.984417200088501\n",
      "Substitute: increasing, BertScore: 0.9842821359634399\n",
      "Substitute: triggering, BertScore: 0.9840956926345825\n",
      "Substitute: passing, BertScore: 0.9840542674064636\n",
      "Substitute: contracting, BertScore: 0.9837893843650818\n",
      "Substitute: suffering, BertScore: 0.9834519624710083\n",
      "Substitute: getting, BertScore: 0.9834469556808472\n",
      "Substitute: coming, BertScore: 0.9833889603614807\n",
      "Substitute: continuing, BertScore: 0.983313262462616\n",
      "Substitute: receiving, BertScore: 0.9832842946052551\n",
      "Substitute: making, BertScore: 0.9831959009170532\n",
      "Substitute: reaching, BertScore: 0.9830766916275024\n",
      "Substitute: facing, BertScore: 0.9830319285392761\n",
      "Substitute: some, BertScore: 0.9829094409942627\n",
      "Substitute: more, BertScore: 0.9827052354812622\n",
      "Substitute: many, BertScore: 0.9825934767723083\n",
      "Substitute: taking, BertScore: 0.982580840587616\n",
      "Substitute: using, BertScore: 0.9823224544525146\n",
      "Substitute: further, BertScore: 0.9820945262908936\n",
      "Substitute: going, BertScore: 0.982017993927002\n",
      "Substitute: its, BertScore: 0.9814658164978027\n",
      "Substitute: the, BertScore: 0.981052815914154\n",
      "Substitute: other, BertScore: 0.9805198907852173\n",
      "top-10 substitutes based on bertscores in context: ['devastating', 'damaging', 'crushing', 'failing', 'falling', 'massive', 'hitting', 'rising', 'increasing', 'triggering']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: unsanctioned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: unauthorized, BertScore: 0.9484722018241882\n",
      "Substitute: open, BertScore: 0.9464191794395447\n",
      "Substitute: unofficial, BertScore: 0.9463859796524048\n",
      "Substitute: isolated, BertScore: 0.9457930326461792\n",
      "Substitute: impromptu, BertScore: 0.9457178711891174\n",
      "Substitute: unarmed, BertScore: 0.9455524682998657\n",
      "Substitute: unsuccessful, BertScore: 0.9453955292701721\n",
      "Substitute: empty, BertScore: 0.9453172087669373\n",
      "Substitute: organized, BertScore: 0.9448121190071106\n",
      "Substitute: illegal, BertScore: 0.9447056651115417\n",
      "Substitute: emergency, BertScore: 0.9442378878593445\n",
      "Substitute: alternative, BertScore: 0.9442322254180908\n",
      "Substitute: armed, BertScore: 0.9442107081413269\n",
      "Substitute: independent, BertScore: 0.9438779354095459\n",
      "Substitute: overnight, BertScore: 0.9438696503639221\n",
      "Substitute: underground, BertScore: 0.9437970519065857\n",
      "Substitute: official, BertScore: 0.9436169266700745\n",
      "Substitute: angry, BertScore: 0.9432777166366577\n",
      "Substitute: attempted, BertScore: 0.9429978132247925\n",
      "Substitute: outdoor, BertScore: 0.9429857134819031\n",
      "Substitute: evening, BertScore: 0.9429065585136414\n",
      "Substitute: alleged, BertScore: 0.9422224760055542\n",
      "Substitute: upcoming, BertScore: 0.9411190748214722\n",
      "Substitute: anarchist, BertScore: 0.940618097782135\n",
      "Substitute: election, BertScore: 0.9405335783958435\n",
      "Substitute: opposition, BertScore: 0.9405142068862915\n",
      "Substitute: annual, BertScore: 0.9400162696838379\n",
      "Substitute: army, BertScore: 0.9398396015167236\n",
      "Substitute: olympic, BertScore: 0.9397913813591003\n",
      "Substitute: earlier, BertScore: 0.9389745593070984\n",
      "top-10 substitutes based on bertscores in context: ['unauthorized', 'open', 'unofficial', 'isolated', 'impromptu', 'unarmed', 'unsuccessful', 'empty', 'organized', 'illegal']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: traumatised\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: disturbed, BertScore: 0.957282304763794\n",
      "Substitute: distressed, BertScore: 0.9561716914176941\n",
      "Substitute: troubled, BertScore: 0.9550225734710693\n",
      "Substitute: distraught, BertScore: 0.9547078013420105\n",
      "Substitute: pained, BertScore: 0.954656720161438\n",
      "Substitute: frightened, BertScore: 0.9529038667678833\n",
      "Substitute: devastated, BertScore: 0.950962245464325\n",
      "Substitute: hurt, BertScore: 0.9507240056991577\n",
      "Substitute: upset, BertScore: 0.9500965476036072\n",
      "Substitute: shaken, BertScore: 0.949624240398407\n",
      "Substitute: terrified, BertScore: 0.9473150372505188\n",
      "Substitute: worried, BertScore: 0.9453186392784119\n",
      "Substitute: broken, BertScore: 0.9452663064002991\n",
      "Substitute: overwhelmed, BertScore: 0.944872260093689\n",
      "Substitute: bewildered, BertScore: 0.944188117980957\n",
      "Substitute: horrified, BertScore: 0.9438570737838745\n",
      "Substitute: frustrated, BertScore: 0.9438127279281616\n",
      "Substitute: embarrassed, BertScore: 0.9437819719314575\n",
      "Substitute: confused, BertScore: 0.9431596398353577\n",
      "Substitute: sad, BertScore: 0.9426047205924988\n",
      "Substitute: disappointed, BertScore: 0.9418788552284241\n",
      "Substitute: angry, BertScore: 0.9411223530769348\n",
      "Substitute: outraged, BertScore: 0.9410452246665955\n",
      "Substitute: appalled, BertScore: 0.9400530457496643\n",
      "Substitute: disgusted, BertScore: 0.9392818212509155\n",
      "Substitute: stunned, BertScore: 0.9386883974075317\n",
      "Substitute: haunted, BertScore: 0.9382156729698181\n",
      "Substitute: shocked, BertScore: 0.935366153717041\n",
      "Substitute: excited, BertScore: 0.9342467784881592\n",
      "Substitute: relieved, BertScore: 0.9334050416946411\n",
      "top-10 substitutes based on bertscores in context: ['disturbed', 'distressed', 'troubled', 'distraught', 'pained', 'frightened', 'devastated', 'hurt', 'upset', 'shaken']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: bole\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: ridge, BertScore: 0.9561535716056824\n",
      "Substitute: crest, BertScore: 0.9557365775108337\n",
      "Substitute: cone, BertScore: 0.9516696929931641\n",
      "Substitute: tail, BertScore: 0.949518084526062\n",
      "Substitute: groove, BertScore: 0.9492632150650024\n",
      "Substitute: base, BertScore: 0.9479708671569824\n",
      "Substitute: body, BertScore: 0.947867214679718\n",
      "Substitute: bundle, BertScore: 0.9466694593429565\n",
      "Substitute: pyramid, BertScore: 0.9461827874183655\n",
      "Substitute: ring, BertScore: 0.9458581209182739\n",
      "Substitute: fin, BertScore: 0.9456470012664795\n",
      "Substitute: triangle, BertScore: 0.9456225633621216\n",
      "Substitute: shell, BertScore: 0.9456106424331665\n",
      "Substitute: line, BertScore: 0.9443575739860535\n",
      "Substitute: branch, BertScore: 0.944031298160553\n",
      "Substitute: surface, BertScore: 0.9427679181098938\n",
      "Substitute: stem, BertScore: 0.9427062273025513\n",
      "Substitute: layer, BertScore: 0.9424654245376587\n",
      "Substitute: structure, BertScore: 0.9424431324005127\n",
      "Substitute: leaf, BertScore: 0.9417226314544678\n",
      "Substitute: portion, BertScore: 0.9406902194023132\n",
      "Substitute: bark, BertScore: 0.9402021765708923\n",
      "Substitute: trunk, BertScore: 0.9395747184753418\n",
      "Substitute: crown, BertScore: 0.9387887120246887\n",
      "Substitute: shape, BertScore: 0.9386430978775024\n",
      "Substitute: form, BertScore: 0.938151478767395\n",
      "Substitute: path, BertScore: 0.9377977848052979\n",
      "Substitute: pattern, BertScore: 0.9356735348701477\n",
      "Substitute: canopy, BertScore: 0.934781551361084\n",
      "Substitute: tree, BertScore: 0.9288372993469238\n",
      "top-10 substitutes based on bertscores in context: ['ridge', 'crest', 'cone', 'tail', 'groove', 'base', 'body', 'bundle', 'pyramid', 'ring']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: ignited\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: sparked, BertScore: 0.996126651763916\n",
      "Substitute: flared, BertScore: 0.9955308437347412\n",
      "Substitute: erupted, BertScore: 0.9946082830429077\n",
      "Substitute: escalated, BertScore: 0.9938861131668091\n",
      "Substitute: started, BertScore: 0.9937722682952881\n",
      "Substitute: began, BertScore: 0.9937012195587158\n",
      "Substitute: intensified, BertScore: 0.993572473526001\n",
      "Substitute: heightened, BertScore: 0.9931800961494446\n",
      "Substitute: deepened, BertScore: 0.9931797385215759\n",
      "Substitute: arose, BertScore: 0.9930734634399414\n",
      "Substitute: opened, BertScore: 0.9930487871170044\n",
      "Substitute: culminated, BertScore: 0.9929961562156677\n",
      "Substitute: provoked, BertScore: 0.9927833080291748\n",
      "Substitute: stirred, BertScore: 0.9927185773849487\n",
      "Substitute: ensued, BertScore: 0.9924819469451904\n",
      "Substitute: heated, BertScore: 0.9924116730690002\n",
      "Substitute: raged, BertScore: 0.9922142028808594\n",
      "Substitute: occurred, BertScore: 0.9921791553497314\n",
      "Substitute: resulted, BertScore: 0.9912711381912231\n",
      "Substitute: triggered, BertScore: 0.9910345673561096\n",
      "Substitute: continued, BertScore: 0.9909347891807556\n",
      "Substitute: fueled, BertScore: 0.9905122518539429\n",
      "Substitute: followed, BertScore: 0.9903967380523682\n",
      "Substitute: prompted, BertScore: 0.9902763366699219\n",
      "Substitute: drew, BertScore: 0.9894790053367615\n",
      "Substitute: spark, BertScore: 0.9888352751731873\n",
      "Substitute: ended, BertScore: 0.9885193705558777\n",
      "Substitute: led, BertScore: 0.9883209466934204\n",
      "Substitute: centered, BertScore: 0.9877966046333313\n",
      "top-10 substitutes based on bertscores in context: ['sparked', 'flared', 'erupted', 'escalated', 'started', 'began', 'intensified', 'heightened', 'deepened', 'arose']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: pertaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: relating, BertScore: 0.994434118270874\n",
      "Substitute: related, BertScore: 0.9900360703468323\n",
      "Substitute: regarding, BertScore: 0.988258421421051\n",
      "Substitute: referring, BertScore: 0.9832093715667725\n",
      "Substitute: concerning, BertScore: 0.9831991195678711\n",
      "Substitute: unrelated, BertScore: 0.9778655171394348\n",
      "Substitute: corresponding, BertScore: 0.9772286415100098\n",
      "Substitute: pointing, BertScore: 0.9754180908203125\n",
      "Substitute: linked, BertScore: 0.9738219976425171\n",
      "Substitute: as, BertScore: 0.9732534289360046\n",
      "Substitute: regard, BertScore: 0.9732058048248291\n",
      "Substitute: regards, BertScore: 0.9729518890380859\n",
      "Substitute: referred, BertScore: 0.9725576639175415\n",
      "Substitute: pursuant, BertScore: 0.9695021510124207\n",
      "Substitute: leading, BertScore: 0.9662135243415833\n",
      "Substitute: due, BertScore: 0.9657681584358215\n",
      "Substitute: owing, BertScore: 0.9650627374649048\n",
      "Substitute: tied, BertScore: 0.963485062122345\n",
      "Substitute: attributed, BertScore: 0.963478684425354\n",
      "Substitute: looking, BertScore: 0.9616857171058655\n",
      "Substitute: admitting, BertScore: 0.9609113335609436\n",
      "Substitute: relative, BertScore: 0.9571152925491333\n",
      "Substitute: belonging, BertScore: 0.9564535021781921\n",
      "Substitute: over, BertScore: 0.953680694103241\n",
      "Substitute: subject, BertScore: 0.9536235928535461\n",
      "Substitute: prior, BertScore: 0.9534111618995667\n",
      "Substitute: tending, BertScore: 0.9532914161682129\n",
      "Substitute: according, BertScore: 0.9484803080558777\n",
      "Substitute: not, BertScore: 0.9390964508056641\n",
      "top-10 substitutes based on bertscores in context: ['relating', 'related', 'regarding', 'referring', 'concerning', 'unrelated', 'corresponding', 'pointing', 'linked', 'as']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: operative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: agent, BertScore: 0.9935881495475769\n",
      "Substitute: associate, BertScore: 0.9907608032226562\n",
      "Substitute: employee, BertScore: 0.9893454909324646\n",
      "Substitute: officer, BertScore: 0.9890859723091125\n",
      "Substitute: organizer, BertScore: 0.9886907935142517\n",
      "Substitute: affiliate, BertScore: 0.988474428653717\n",
      "Substitute: activist, BertScore: 0.987777829170227\n",
      "Substitute: official, BertScore: 0.9876635074615479\n",
      "Substitute: informant, BertScore: 0.9867905974388123\n",
      "Substitute: aide, BertScore: 0.9862552881240845\n",
      "Substitute: ally, BertScore: 0.9862544536590576\n",
      "Substitute: insider, BertScore: 0.9855689406394958\n",
      "Substitute: investigator, BertScore: 0.9854417443275452\n",
      "Substitute: intern, BertScore: 0.9841681718826294\n",
      "Substitute: element, BertScore: 0.9839738607406616\n",
      "Substitute: active, BertScore: 0.9836002588272095\n",
      "Substitute: inmate, BertScore: 0.9835747480392456\n",
      "Substitute: accessory, BertScore: 0.9835029244422913\n",
      "Substitute: involved, BertScore: 0.9833898544311523\n",
      "Substitute: assassin, BertScore: 0.9820338487625122\n",
      "Substitute: expert, BertScore: 0.9787479043006897\n",
      "Substitute: outlaw, BertScore: 0.9787025451660156\n",
      "Substitute: adult, BertScore: 0.9778467416763306\n",
      "Substitute: islamist, BertScore: 0.9753540754318237\n",
      "Substitute: american, BertScore: 0.9750412702560425\n",
      "Substitute: interest, BertScore: 0.9710007905960083\n",
      "Substitute: operation, BertScore: 0.970898449420929\n",
      "Substitute: advance, BertScore: 0.9677837491035461\n",
      "top-10 substitutes based on bertscores in context: ['agent', 'associate', 'employee', 'officer', 'organizer', 'affiliate', 'activist', 'official', 'informant', 'aide']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sole\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: ultimate, BertScore: 0.9875953197479248\n",
      "Substitute: primary, BertScore: 0.9872575402259827\n",
      "Substitute: final, BertScore: 0.9858347177505493\n",
      "Substitute: definitive, BertScore: 0.9857702851295471\n",
      "Substitute: single, BertScore: 0.9855373501777649\n",
      "Substitute: direct, BertScore: 0.9850804805755615\n",
      "Substitute: permanent, BertScore: 0.983633816242218\n",
      "Substitute: true, BertScore: 0.9834568500518799\n",
      "Substitute: complete, BertScore: 0.9831851124763489\n",
      "Substitute: first, BertScore: 0.9831702709197998\n",
      "Substitute: full, BertScore: 0.9825184345245361\n",
      "Substitute: last, BertScore: 0.9823497533798218\n",
      "Substitute: meaningful, BertScore: 0.9823238849639893\n",
      "Substitute: real, BertScore: 0.9819437265396118\n",
      "Substitute: rightful, BertScore: 0.9813582897186279\n",
      "Substitute: major, BertScore: 0.9809137582778931\n",
      "Substitute: genuine, BertScore: 0.9809014201164246\n",
      "Substitute: legitimate, BertScore: 0.9805617332458496\n",
      "Substitute: second, BertScore: 0.9803891181945801\n",
      "Substitute: third, BertScore: 0.9798939228057861\n",
      "Substitute: proper, BertScore: 0.9796334505081177\n",
      "Substitute: specific, BertScore: 0.97927325963974\n",
      "Substitute: significant, BertScore: 0.9790768027305603\n",
      "Substitute: legal, BertScore: 0.9790167212486267\n",
      "Substitute: greater, BertScore: 0.9784099459648132\n",
      "Substitute: particular, BertScore: 0.9782864451408386\n",
      "Substitute: further, BertScore: 0.9778285622596741\n",
      "Substitute: right, BertScore: 0.9773800373077393\n",
      "Substitute: new, BertScore: 0.9770928621292114\n",
      "top-10 substitutes based on bertscores in context: ['ultimate', 'primary', 'final', 'definitive', 'single', 'direct', 'permanent', 'true', 'complete', 'first']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: collaborated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: worked, BertScore: 0.9824087023735046\n",
      "Substitute: partnered, BertScore: 0.9808355569839478\n",
      "Substitute: participated, BertScore: 0.978238582611084\n",
      "Substitute: assisted, BertScore: 0.9754773378372192\n",
      "Substitute: contributed, BertScore: 0.9746981859207153\n",
      "Substitute: engaged, BertScore: 0.973456084728241\n",
      "Substitute: helped, BertScore: 0.9717792868614197\n",
      "Substitute: involved, BertScore: 0.9699633121490479\n",
      "Substitute: teamed, BertScore: 0.9689642786979675\n",
      "Substitute: connected, BertScore: 0.9684416055679321\n",
      "Substitute: coordinated, BertScore: 0.9670701622962952\n",
      "Substitute: joined, BertScore: 0.9562129974365234\n",
      "Substitute: performed, BertScore: 0.9559202194213867\n",
      "Substitute: competed, BertScore: 0.9493484497070312\n",
      "Substitute: met, BertScore: 0.9481762051582336\n",
      "Substitute: agreed, BertScore: 0.9472842216491699\n",
      "Substitute: works, BertScore: 0.946151852607727\n",
      "Substitute: succeeded, BertScore: 0.945517897605896\n",
      "Substitute: experimented, BertScore: 0.9447153210639954\n",
      "Substitute: cooperate, BertScore: 0.9438174962997437\n",
      "Substitute: continued, BertScore: 0.943738579750061\n",
      "Substitute: collaboration, BertScore: 0.9422077536582947\n",
      "Substitute: merged, BertScore: 0.9421842098236084\n",
      "Substitute: combined, BertScore: 0.9376428127288818\n",
      "Substitute: credited, BertScore: 0.9321962594985962\n",
      "Substitute: work, BertScore: 0.9265009760856628\n",
      "Substitute: together, BertScore: 0.9242492318153381\n",
      "top-10 substitutes based on bertscores in context: ['worked', 'partnered', 'participated', 'assisted', 'contributed', 'engaged', 'helped', 'involved', 'teamed', 'connected']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: trophies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: championships, BertScore: 0.9807915091514587\n",
      "Substitute: titles, BertScore: 0.9803560972213745\n",
      "Substitute: competitions, BertScore: 0.9793971180915833\n",
      "Substitute: medals, BertScore: 0.9789003729820251\n",
      "Substitute: awards, BertScore: 0.9759225845336914\n",
      "Substitute: promotions, BertScore: 0.9726250171661377\n",
      "Substitute: victories, BertScore: 0.9701780676841736\n",
      "Substitute: finals, BertScore: 0.9699440002441406\n",
      "Substitute: contests, BertScore: 0.9686287045478821\n",
      "Substitute: records, BertScore: 0.9671355485916138\n",
      "Substitute: prizes, BertScore: 0.965608537197113\n",
      "Substitute: places, BertScore: 0.9652181267738342\n",
      "Substitute: matches, BertScore: 0.9642454981803894\n",
      "Substitute: honors, BertScore: 0.9631698131561279\n",
      "Substitute: positions, BertScore: 0.9618915319442749\n",
      "Substitute: wins, BertScore: 0.9579179286956787\n",
      "Substitute: tournaments, BertScore: 0.9577302932739258\n",
      "Substitute: points, BertScore: 0.9576314091682434\n",
      "Substitute: races, BertScore: 0.9558567404747009\n",
      "Substitute: games, BertScore: 0.9545703530311584\n",
      "Substitute: events, BertScore: 0.9536733627319336\n",
      "Substitute: years, BertScore: 0.9516247510910034\n",
      "Substitute: times, BertScore: 0.9490405917167664\n",
      "Substitute: rounds, BertScore: 0.9458893537521362\n",
      "Substitute: things, BertScore: 0.9454014301300049\n",
      "Substitute: more, BertScore: 0.9446548223495483\n",
      "Substitute: battles, BertScore: 0.942292332649231\n",
      "Substitute: fights, BertScore: 0.9416863322257996\n",
      "top-10 substitutes based on bertscores in context: ['championships', 'titles', 'competitions', 'medals', 'awards', 'promotions', 'victories', 'finals', 'contests', 'records']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: backlash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: outrage, BertScore: 0.9888918399810791\n",
      "Substitute: reaction, BertScore: 0.9888825416564941\n",
      "Substitute: resentment, BertScore: 0.9864647388458252\n",
      "Substitute: anger, BertScore: 0.9848941564559937\n",
      "Substitute: retaliation, BertScore: 0.9842073321342468\n",
      "Substitute: rebellion, BertScore: 0.9841886758804321\n",
      "Substitute: bias, BertScore: 0.98412024974823\n",
      "Substitute: uprising, BertScore: 0.9839930534362793\n",
      "Substitute: fallout, BertScore: 0.9838501214981079\n",
      "Substitute: revolt, BertScore: 0.9835453033447266\n",
      "Substitute: hostility, BertScore: 0.9830082654953003\n",
      "Substitute: opposition, BertScore: 0.9826425313949585\n",
      "Substitute: protests, BertScore: 0.9826265573501587\n",
      "Substitute: retribution, BertScore: 0.9825681447982788\n",
      "Substitute: protest, BertScore: 0.982498049736023\n",
      "Substitute: response, BertScore: 0.9816684126853943\n",
      "Substitute: resistance, BertScore: 0.980523943901062\n",
      "Substitute: rage, BertScore: 0.975921630859375\n",
      "Substitute: fight, BertScore: 0.9739770889282227\n",
      "Substitute: threat, BertScore: 0.9737045168876648\n",
      "Substitute: countered, BertScore: 0.9731082916259766\n",
      "Substitute: defense, BertScore: 0.9716428518295288\n",
      "Substitute: counter, BertScore: 0.9708455801010132\n",
      "Substitute: mixed, BertScore: 0.969111442565918\n",
      "Substitute: defending, BertScore: 0.9686625003814697\n",
      "Substitute: defend, BertScore: 0.9676885604858398\n",
      "Substitute: directly, BertScore: 0.9653539061546326\n",
      "Substitute: back, BertScore: 0.9634264707565308\n",
      "Substitute: not, BertScore: 0.9615033864974976\n",
      "top-10 substitutes based on bertscores in context: ['outrage', 'reaction', 'resentment', 'anger', 'retaliation', 'rebellion', 'bias', 'uprising', 'fallout', 'revolt']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: counteractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: attacks, BertScore: 0.9770828485488892\n",
      "Substitute: responses, BertScore: 0.9760584235191345\n",
      "Substitute: retaliation, BertScore: 0.9759493470191956\n",
      "Substitute: aggression, BertScore: 0.9758539795875549\n",
      "Substitute: advances, BertScore: 0.9757819175720215\n",
      "Substitute: threats, BertScore: 0.9757112860679626\n",
      "Substitute: acts, BertScore: 0.9752188920974731\n",
      "Substitute: actions, BertScore: 0.9748255014419556\n",
      "Substitute: strikes, BertScore: 0.9746463298797607\n",
      "Substitute: moves, BertScore: 0.9744061231613159\n",
      "Substitute: efforts, BertScore: 0.9739946126937866\n",
      "Substitute: onslaught, BertScore: 0.9738516807556152\n",
      "Substitute: offensive, BertScore: 0.9738039374351501\n",
      "Substitute: operations, BertScore: 0.9737461805343628\n",
      "Substitute: intervention, BertScore: 0.973683774471283\n",
      "Substitute: action, BertScore: 0.9733390212059021\n",
      "Substitute: attack, BertScore: 0.9730722904205322\n",
      "Substitute: threat, BertScore: 0.9730533361434937\n",
      "Substitute: response, BertScore: 0.9729382991790771\n",
      "Substitute: counterattack, BertScore: 0.9722796678543091\n",
      "Substitute: successes, BertScore: 0.9718959927558899\n",
      "Substitute: resistance, BertScore: 0.9715485572814941\n",
      "Substitute: conduct, BertScore: 0.9708808660507202\n",
      "Substitute: results, BertScore: 0.9701441526412964\n",
      "Substitute: reaction, BertScore: 0.9700332283973694\n",
      "Substitute: use, BertScore: 0.9694995284080505\n",
      "Substitute: invasion, BertScore: 0.9691638350486755\n",
      "Substitute: destruction, BertScore: 0.968905508518219\n",
      "Substitute: defeat, BertScore: 0.9686099886894226\n",
      "Substitute: casualties, BertScore: 0.9685914516448975\n",
      "top-10 substitutes based on bertscores in context: ['attacks', 'responses', 'retaliation', 'aggression', 'advances', 'threats', 'acts', 'actions', 'strikes', 'moves']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: impasse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: tension, BertScore: 0.9652586579322815\n",
      "Substitute: breakdown, BertScore: 0.9644440412521362\n",
      "Substitute: crisis, BertScore: 0.9643689393997192\n",
      "Substitute: disagreement, BertScore: 0.9643136262893677\n",
      "Substitute: dispute, BertScore: 0.9636959433555603\n",
      "Substitute: conflict, BertScore: 0.9630193114280701\n",
      "Substitute: tensions, BertScore: 0.9604952335357666\n",
      "Substitute: disagreements, BertScore: 0.9599490761756897\n",
      "Substitute: compromise, BertScore: 0.9593541622161865\n",
      "Substitute: differences, BertScore: 0.9574037194252014\n",
      "Substitute: situation, BertScore: 0.9552654027938843\n",
      "Substitute: incident, BertScore: 0.9548502564430237\n",
      "Substitute: problem, BertScore: 0.9536929130554199\n",
      "Substitute: difficulties, BertScore: 0.9536190032958984\n",
      "Substitute: uncertainty, BertScore: 0.9535328149795532\n",
      "Substitute: problems, BertScore: 0.9529607892036438\n",
      "Substitute: agreement, BertScore: 0.9515904188156128\n",
      "Substitute: delay, BertScore: 0.9509183168411255\n",
      "Substitute: pressure, BertScore: 0.9489713311195374\n",
      "Substitute: developments, BertScore: 0.948871374130249\n",
      "Substitute: sanctions, BertScore: 0.9486304521560669\n",
      "Substitute: failure, BertScore: 0.9484031796455383\n",
      "Substitute: opposition, BertScore: 0.9475143551826477\n",
      "Substitute: delays, BertScore: 0.9460749626159668\n",
      "Substitute: talks, BertScore: 0.9460188746452332\n",
      "Substitute: negotiations, BertScore: 0.945817232131958\n",
      "Substitute: disappointment, BertScore: 0.9446101784706116\n",
      "Substitute: obstacles, BertScore: 0.9445920586585999\n",
      "Substitute: resolution, BertScore: 0.9443774819374084\n",
      "Substitute: progress, BertScore: 0.9421918392181396\n",
      "top-10 substitutes based on bertscores in context: ['tension', 'breakdown', 'crisis', 'disagreement', 'dispute', 'conflict', 'tensions', 'disagreements', 'compromise', 'differences']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: defiance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: violation, BertScore: 0.9891215562820435\n",
      "Substitute: disregard, BertScore: 0.9874178171157837\n",
      "Substitute: retaliation, BertScore: 0.9866859912872314\n",
      "Substitute: light, BertScore: 0.986177921295166\n",
      "Substitute: spite, BertScore: 0.985736608505249\n",
      "Substitute: consequence, BertScore: 0.9848517775535583\n",
      "Substitute: protest, BertScore: 0.9847584962844849\n",
      "Substitute: disapproval, BertScore: 0.9842215776443481\n",
      "Substitute: response, BertScore: 0.9835602641105652\n",
      "Substitute: recognition, BertScore: 0.9833664894104004\n",
      "Substitute: anticipation, BertScore: 0.9832990169525146\n",
      "Substitute: support, BertScore: 0.9818054437637329\n",
      "Substitute: opposition, BertScore: 0.9816673994064331\n",
      "Substitute: imitation, BertScore: 0.9804494976997375\n",
      "Substitute: advance, BertScore: 0.9794419407844543\n",
      "Substitute: pursuit, BertScore: 0.9781401753425598\n",
      "Substitute: honor, BertScore: 0.9768468141555786\n",
      "Substitute: front, BertScore: 0.9767019152641296\n",
      "Substitute: lieu, BertScore: 0.9762768149375916\n",
      "Substitute: acceptance, BertScore: 0.9762085676193237\n",
      "Substitute: fear, BertScore: 0.976179838180542\n",
      "Substitute: favour, BertScore: 0.975398063659668\n",
      "Substitute: favor, BertScore: 0.9753562211990356\n",
      "Substitute: warning, BertScore: 0.9749237298965454\n",
      "Substitute: breach, BertScore: 0.9713672399520874\n",
      "Substitute: defence, BertScore: 0.9706758260726929\n",
      "Substitute: case, BertScore: 0.9704462885856628\n",
      "Substitute: celebration, BertScore: 0.9704015254974365\n",
      "Substitute: defense, BertScore: 0.9678905606269836\n",
      "top-10 substitutes based on bertscores in context: ['violation', 'disregard', 'retaliation', 'light', 'spite', 'consequence', 'protest', 'disapproval', 'response', 'recognition']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: implied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: hinted, BertScore: 0.9892082810401917\n",
      "Substitute: suggested, BertScore: 0.9891552925109863\n",
      "Substitute: indicated, BertScore: 0.9887012243270874\n",
      "Substitute: asserted, BertScore: 0.9869790077209473\n",
      "Substitute: mentioned, BertScore: 0.9860233068466187\n",
      "Substitute: stated, BertScore: 0.98564213514328\n",
      "Substitute: claimed, BertScore: 0.9852648973464966\n",
      "Substitute: assumed, BertScore: 0.9850292801856995\n",
      "Substitute: predicted, BertScore: 0.9843304753303528\n",
      "Substitute: insisted, BertScore: 0.9842293858528137\n",
      "Substitute: said, BertScore: 0.9828459024429321\n",
      "Substitute: confirmed, BertScore: 0.9827132225036621\n",
      "Substitute: revealed, BertScore: 0.9825365543365479\n",
      "Substitute: promised, BertScore: 0.9819151163101196\n",
      "Substitute: explained, BertScore: 0.9817919135093689\n",
      "Substitute: admitted, BertScore: 0.9817390441894531\n",
      "Substitute: declared, BertScore: 0.9805822968482971\n",
      "Substitute: noted, BertScore: 0.9800448417663574\n",
      "Substitute: agreed, BertScore: 0.9798738360404968\n",
      "Substitute: added, BertScore: 0.9794281125068665\n",
      "Substitute: proposed, BertScore: 0.9791578650474548\n",
      "Substitute: announced, BertScore: 0.9775432348251343\n",
      "Substitute: believed, BertScore: 0.9771639704704285\n",
      "Substitute: assured, BertScore: 0.9768868684768677\n",
      "Substitute: meant, BertScore: 0.9746319651603699\n",
      "Substitute: felt, BertScore: 0.9742121696472168\n",
      "Substitute: ensured, BertScore: 0.9721211791038513\n",
      "Substitute: that, BertScore: 0.9366971254348755\n",
      "Substitute: and, BertScore: 0.9079138040542603\n",
      "top-10 substitutes based on bertscores in context: ['hinted', 'suggested', 'indicated', 'asserted', 'mentioned', 'stated', 'claimed', 'assumed', 'predicted', 'insisted']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: marred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: hampered, BertScore: 0.9858101010322571\n",
      "Substitute: tainted, BertScore: 0.9835922122001648\n",
      "Substitute: interrupted, BertScore: 0.9832150340080261\n",
      "Substitute: plagued, BertScore: 0.9831105470657349\n",
      "Substitute: clouded, BertScore: 0.9823780059814453\n",
      "Substitute: overshadowed, BertScore: 0.9810069799423218\n",
      "Substitute: disrupted, BertScore: 0.9809377193450928\n",
      "Substitute: marked, BertScore: 0.9804993867874146\n",
      "Substitute: complicated, BertScore: 0.9799035787582397\n",
      "Substitute: highlighted, BertScore: 0.9758567810058594\n",
      "Substitute: affected, BertScore: 0.9748926162719727\n",
      "Substitute: damaged, BertScore: 0.9744781255722046\n",
      "Substitute: accompanied, BertScore: 0.9737054705619812\n",
      "Substitute: threatened, BertScore: 0.9721997380256653\n",
      "Substitute: preceded, BertScore: 0.9720773100852966\n",
      "Substitute: characterised, BertScore: 0.9716698527336121\n",
      "Substitute: driven, BertScore: 0.9711753726005554\n",
      "Substitute: dominated, BertScore: 0.9709478616714478\n",
      "Substitute: haunted, BertScore: 0.9708232879638672\n",
      "Substitute: delayed, BertScore: 0.9705121517181396\n",
      "Substitute: sparked, BertScore: 0.9696856737136841\n",
      "Substitute: aided, BertScore: 0.9693346619606018\n",
      "Substitute: followed, BertScore: 0.9688149690628052\n",
      "Substitute: caused, BertScore: 0.9676734209060669\n",
      "Substitute: prompted, BertScore: 0.9657344818115234\n",
      "Substitute: triggered, BertScore: 0.9651272296905518\n",
      "Substitute: unaffected, BertScore: 0.9627927541732788\n",
      "Substitute: motivated, BertScore: 0.9615881443023682\n",
      "Substitute: inspired, BertScore: 0.954442024230957\n",
      "top-10 substitutes based on bertscores in context: ['hampered', 'tainted', 'interrupted', 'plagued', 'clouded', 'overshadowed', 'disrupted', 'marked', 'complicated', 'highlighted']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: departure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: leaving, BertScore: 0.9938468933105469\n",
      "Substitute: exit, BertScore: 0.9921573400497437\n",
      "Substitute: dismissal, BertScore: 0.9919654726982117\n",
      "Substitute: resignation, BertScore: 0.9917035102844238\n",
      "Substitute: resigning, BertScore: 0.991058886051178\n",
      "Substitute: removal, BertScore: 0.989435076713562\n",
      "Substitute: leave, BertScore: 0.9879216551780701\n",
      "Substitute: dissolution, BertScore: 0.9871057271957397\n",
      "Substitute: move, BertScore: 0.986676037311554\n",
      "Substitute: return, BertScore: 0.9862446784973145\n",
      "Substitute: release, BertScore: 0.9858579635620117\n",
      "Substitute: absence, BertScore: 0.9857903718948364\n",
      "Substitute: arrival, BertScore: 0.9851938486099243\n",
      "Substitute: retiring, BertScore: 0.9850971698760986\n",
      "Substitute: retirement, BertScore: 0.9850741028785706\n",
      "Substitute: appointment, BertScore: 0.9841976761817932\n",
      "Substitute: discharge, BertScore: 0.9824978113174438\n",
      "Substitute: stay, BertScore: 0.9818680882453918\n",
      "Substitute: tenure, BertScore: 0.9818150997161865\n",
      "Substitute: death, BertScore: 0.981360912322998\n",
      "Substitute: election, BertScore: 0.9810588359832764\n",
      "Substitute: divorce, BertScore: 0.9793561100959778\n",
      "Substitute: employment, BertScore: 0.978667140007019\n",
      "Substitute: presidency, BertScore: 0.9765747785568237\n",
      "Substitute: inauguration, BertScore: 0.9758446216583252\n",
      "Substitute: graduation, BertScore: 0.9738212823867798\n",
      "Substitute: administration, BertScore: 0.9727286696434021\n",
      "Substitute: career, BertScore: 0.9715538620948792\n",
      "Substitute: birth, BertScore: 0.9648213982582092\n",
      "top-10 substitutes based on bertscores in context: ['leaving', 'exit', 'dismissal', 'resignation', 'resigning', 'removal', 'leave', 'dissolution', 'move', 'return']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: compound\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: complex, BertScore: 0.9908562898635864\n",
      "Substitute: facility, BertScore: 0.9900308847427368\n",
      "Substitute: base, BertScore: 0.9890478849411011\n",
      "Substitute: building, BertScore: 0.9887930154800415\n",
      "Substitute: property, BertScore: 0.9877590537071228\n",
      "Substitute: hideout, BertScore: 0.9870652556419373\n",
      "Substitute: mansion, BertScore: 0.9870262145996094\n",
      "Substitute: residence, BertScore: 0.9857629537582397\n",
      "Substitute: hotel, BertScore: 0.9854001998901367\n",
      "Substitute: site, BertScore: 0.985083818435669\n",
      "Substitute: factory, BertScore: 0.9850718379020691\n",
      "Substitute: plant, BertScore: 0.9850208163261414\n",
      "Substitute: house, BertScore: 0.9849446415901184\n",
      "Substitute: warehouse, BertScore: 0.9848068356513977\n",
      "Substitute: home, BertScore: 0.983653724193573\n",
      "Substitute: ranch, BertScore: 0.983212947845459\n",
      "Substitute: station, BertScore: 0.9828713536262512\n",
      "Substitute: restaurant, BertScore: 0.9827524423599243\n",
      "Substitute: hospital, BertScore: 0.9813613891601562\n",
      "Substitute: room, BertScore: 0.9812854528427124\n",
      "Substitute: field, BertScore: 0.9812107086181641\n",
      "Substitute: motel, BertScore: 0.9807046055793762\n",
      "Substitute: school, BertScore: 0.9806775450706482\n",
      "Substitute: mosque, BertScore: 0.9806747436523438\n",
      "Substitute: vehicle, BertScore: 0.9802392721176147\n",
      "Substitute: car, BertScore: 0.9797224402427673\n",
      "Substitute: store, BertScore: 0.9797159433364868\n",
      "Substitute: temple, BertScore: 0.9785706400871277\n",
      "Substitute: truck, BertScore: 0.9785687923431396\n",
      "top-10 substitutes based on bertscores in context: ['complex', 'facility', 'base', 'building', 'property', 'hideout', 'mansion', 'residence', 'hotel', 'site']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: unprecedented\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: extraordinary, BertScore: 0.9884791970252991\n",
      "Substitute: incredible, BertScore: 0.9815534949302673\n",
      "Substitute: immense, BertScore: 0.9802871942520142\n",
      "Substitute: enormous, BertScore: 0.9800727367401123\n",
      "Substitute: extreme, BertScore: 0.9800377488136292\n",
      "Substitute: outrageous, BertScore: 0.9797400832176208\n",
      "Substitute: extensive, BertScore: 0.9785170555114746\n",
      "Substitute: intense, BertScore: 0.9782261848449707\n",
      "Substitute: overwhelming, BertScore: 0.9782150983810425\n",
      "Substitute: explosive, BertScore: 0.97813880443573\n",
      "Substitute: epic, BertScore: 0.9777978658676147\n",
      "Substitute: intensified, BertScore: 0.9775568246841431\n",
      "Substitute: immediate, BertScore: 0.9772351384162903\n",
      "Substitute: aggressive, BertScore: 0.9771624803543091\n",
      "Substitute: absolute, BertScore: 0.9744162559509277\n",
      "Substitute: extremely, BertScore: 0.9738779067993164\n",
      "Substitute: illegal, BertScore: 0.972282886505127\n",
      "Substitute: ambitious, BertScore: 0.972082257270813\n",
      "Substitute: increasing, BertScore: 0.9716775417327881\n",
      "Substitute: internal, BertScore: 0.9705612659454346\n",
      "Substitute: ongoing, BertScore: 0.9698824286460876\n",
      "Substitute: international, BertScore: 0.9694042205810547\n",
      "Substitute: outright, BertScore: 0.9693595767021179\n",
      "Substitute: imminent, BertScore: 0.9680697321891785\n",
      "Substitute: armed, BertScore: 0.9673790335655212\n",
      "Substitute: entire, BertScore: 0.9662885069847107\n",
      "Substitute: increasingly, BertScore: 0.9661952257156372\n",
      "Substitute: annual, BertScore: 0.9641553163528442\n",
      "Substitute: endless, BertScore: 0.9615471959114075\n",
      "top-10 substitutes based on bertscores in context: ['extraordinary', 'incredible', 'immense', 'enormous', 'extreme', 'outrageous', 'extensive', 'intense', 'overwhelming', 'explosive']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: enacted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: passed, BertScore: 0.9967318773269653\n",
      "Substitute: implemented, BertScore: 0.996667206287384\n",
      "Substitute: instituted, BertScore: 0.9957801103591919\n",
      "Substitute: introduced, BertScore: 0.9957097768783569\n",
      "Substitute: adopted, BertScore: 0.9954065084457397\n",
      "Substitute: enforced, BertScore: 0.9936058521270752\n",
      "Substitute: installed, BertScore: 0.9935433864593506\n",
      "Substitute: established, BertScore: 0.9932404160499573\n",
      "Substitute: executed, BertScore: 0.993044912815094\n",
      "Substitute: created, BertScore: 0.9930447340011597\n",
      "Substitute: issued, BertScore: 0.9929561614990234\n",
      "Substitute: mandated, BertScore: 0.9927924275398254\n",
      "Substitute: incorporated, BertScore: 0.9926817417144775\n",
      "Substitute: amended, BertScore: 0.9921760559082031\n",
      "Substitute: approved, BertScore: 0.9919543862342834\n",
      "Substitute: constructed, BertScore: 0.9916439056396484\n",
      "Substitute: completed, BertScore: 0.9913415908813477\n",
      "Substitute: developed, BertScore: 0.9912250638008118\n",
      "Substitute: proposed, BertScore: 0.9912041425704956\n",
      "Substitute: applied, BertScore: 0.9910885095596313\n",
      "Substitute: performed, BertScore: 0.9909573197364807\n",
      "Substitute: made, BertScore: 0.9908794164657593\n",
      "Substitute: done, BertScore: 0.9908033609390259\n",
      "Substitute: accomplished, BertScore: 0.9904656410217285\n",
      "Substitute: repealed, BertScore: 0.990102231502533\n",
      "Substitute: achieved, BertScore: 0.9899842143058777\n",
      "Substitute: administered, BertScore: 0.9893096089363098\n",
      "Substitute: used, BertScore: 0.988715648651123\n",
      "Substitute: improved, BertScore: 0.9877934455871582\n",
      "top-10 substitutes based on bertscores in context: ['passed', 'implemented', 'instituted', 'introduced', 'adopted', 'enforced', 'installed', 'established', 'executed', 'created']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: enactment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: implementation, BertScore: 0.9643584489822388\n",
      "Substitute: passage, BertScore: 0.9588260650634766\n",
      "Substitute: proclamation, BertScore: 0.9483758211135864\n",
      "Substitute: adoption, BertScore: 0.9434690475463867\n",
      "Substitute: introduction, BertScore: 0.9415218830108643\n",
      "Substitute: ratification, BertScore: 0.9403753280639648\n",
      "Substitute: approval, BertScore: 0.9370205402374268\n",
      "Substitute: signing, BertScore: 0.9342148303985596\n",
      "Substitute: establishment, BertScore: 0.9296384453773499\n",
      "Substitute: creation, BertScore: 0.9282379150390625\n",
      "Substitute: incorporation, BertScore: 0.9281346797943115\n",
      "Substitute: inauguration, BertScore: 0.9274672269821167\n",
      "Substitute: execution, BertScore: 0.9259690642356873\n",
      "Substitute: publication, BertScore: 0.9253811240196228\n",
      "Substitute: announcement, BertScore: 0.9235730171203613\n",
      "Substitute: passing, BertScore: 0.9220377802848816\n",
      "Substitute: inception, BertScore: 0.9210196733474731\n",
      "Substitute: abolition, BertScore: 0.9174336194992065\n",
      "Substitute: release, BertScore: 0.9154443740844727\n",
      "Substitute: formation, BertScore: 0.9108681678771973\n",
      "Substitute: conclusion, BertScore: 0.9106025099754333\n",
      "Substitute: existence, BertScore: 0.9097452759742737\n",
      "Substitute: intervention, BertScore: 0.906735897064209\n",
      "Substitute: election, BertScore: 0.906251847743988\n",
      "Substitute: founding, BertScore: 0.902612566947937\n",
      "Substitute: congress, BertScore: 0.8977026343345642\n",
      "Substitute: end, BertScore: 0.8964337706565857\n",
      "Substitute: death, BertScore: 0.8712745308876038\n",
      "Substitute: independence, BertScore: 0.8708773851394653\n",
      "top-10 substitutes based on bertscores in context: ['implementation', 'passage', 'proclamation', 'adoption', 'introduction', 'ratification', 'approval', 'signing', 'establishment', 'creation']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: evacuation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: withdrawal, BertScore: 0.9932395219802856\n",
      "Substitute: deportation, BertScore: 0.9930249452590942\n",
      "Substitute: relocation, BertScore: 0.992691159248352\n",
      "Substitute: expulsion, BertScore: 0.9924961924552917\n",
      "Substitute: retreat, BertScore: 0.9919777512550354\n",
      "Substitute: evacuate, BertScore: 0.991587221622467\n",
      "Substitute: departure, BertScore: 0.9912350177764893\n",
      "Substitute: removal, BertScore: 0.991047203540802\n",
      "Substitute: exodus, BertScore: 0.9909240007400513\n",
      "Substitute: surrender, BertScore: 0.9904916882514954\n",
      "Substitute: exit, BertScore: 0.9899260997772217\n",
      "Substitute: capture, BertScore: 0.989708662033081\n",
      "Substitute: recovery, BertScore: 0.9896504878997803\n",
      "Substitute: closure, BertScore: 0.9888821840286255\n",
      "Substitute: flight, BertScore: 0.9887802004814148\n",
      "Substitute: escape, BertScore: 0.9883137941360474\n",
      "Substitute: return, BertScore: 0.9882323741912842\n",
      "Substitute: disappearance, BertScore: 0.9879051446914673\n",
      "Substitute: landing, BertScore: 0.9876000881195068\n",
      "Substitute: deployment, BertScore: 0.98752760887146\n",
      "Substitute: dismissal, BertScore: 0.987509548664093\n",
      "Substitute: execution, BertScore: 0.9869202971458435\n",
      "Substitute: closing, BertScore: 0.9868075847625732\n",
      "Substitute: arrest, BertScore: 0.9865542650222778\n",
      "Substitute: release, BertScore: 0.9860765933990479\n",
      "Substitute: resignation, BertScore: 0.9858675599098206\n",
      "Substitute: entry, BertScore: 0.9855525493621826\n",
      "Substitute: cancellation, BertScore: 0.9854881763458252\n",
      "Substitute: arrival, BertScore: 0.9835795164108276\n",
      "top-10 substitutes based on bertscores in context: ['withdrawal', 'deportation', 'relocation', 'expulsion', 'retreat', 'evacuate', 'departure', 'removal', 'exodus', 'surrender']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: predict, BertScore: 0.9918923377990723\n",
      "Substitute: forecast, BertScore: 0.9897573590278625\n",
      "Substitute: predicting, BertScore: 0.9863629341125488\n",
      "Substitute: expectation, BertScore: 0.9861631393432617\n",
      "Substitute: assumption, BertScore: 0.985935628414154\n",
      "Substitute: theory, BertScore: 0.9849725365638733\n",
      "Substitute: calculation, BertScore: 0.9846734404563904\n",
      "Substitute: estimate, BertScore: 0.9844582676887512\n",
      "Substitute: scenario, BertScore: 0.9835913777351379\n",
      "Substitute: projection, BertScore: 0.9828698039054871\n",
      "Substitute: prophecy, BertScore: 0.9825639724731445\n",
      "Substitute: diagnosis, BertScore: 0.9822550415992737\n",
      "Substitute: suggestion, BertScore: 0.9820480942726135\n",
      "Substitute: predicted, BertScore: 0.9798611998558044\n",
      "Substitute: statement, BertScore: 0.9796321988105774\n",
      "Substitute: hope, BertScore: 0.9795675873756409\n",
      "Substitute: assessment, BertScore: 0.9795562624931335\n",
      "Substitute: idea, BertScore: 0.9793590903282166\n",
      "Substitute: warning, BertScore: 0.9792883396148682\n",
      "Substitute: report, BertScore: 0.9785150289535522\n",
      "Substitute: announcement, BertScore: 0.9781825542449951\n",
      "Substitute: proposal, BertScore: 0.9771044850349426\n",
      "Substitute: quote, BertScore: 0.9762344360351562\n",
      "Substitute: result, BertScore: 0.9761792421340942\n",
      "Substitute: advice, BertScore: 0.9736339449882507\n",
      "Substitute: model, BertScore: 0.9730392098426819\n",
      "Substitute: data, BertScore: 0.9721160531044006\n",
      "Substitute: news, BertScore: 0.97060227394104\n",
      "top-10 substitutes based on bertscores in context: ['predict', 'forecast', 'predicting', 'expectation', 'assumption', 'theory', 'calculation', 'estimate', 'scenario', 'projection']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: acquisition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: acquiring, BertScore: 0.9902635812759399\n",
      "Substitute: purchase, BertScore: 0.9847332239151001\n",
      "Substitute: takeover, BertScore: 0.9797677397727966\n",
      "Substitute: buying, BertScore: 0.9716442227363586\n",
      "Substitute: sale, BertScore: 0.9704576730728149\n",
      "Substitute: privatization, BertScore: 0.96982741355896\n",
      "Substitute: ownership, BertScore: 0.9657023549079895\n",
      "Substitute: procurement, BertScore: 0.9656533598899841\n",
      "Substitute: purchases, BertScore: 0.9647228717803955\n",
      "Substitute: seizure, BertScore: 0.9639173150062561\n",
      "Substitute: transfer, BertScore: 0.9628829956054688\n",
      "Substitute: merger, BertScore: 0.9620689153671265\n",
      "Substitute: expansion, BertScore: 0.9617996215820312\n",
      "Substitute: creation, BertScore: 0.9587328433990479\n",
      "Substitute: disposal, BertScore: 0.9579635858535767\n",
      "Substitute: launch, BertScore: 0.9564113616943359\n",
      "Substitute: introduction, BertScore: 0.955957293510437\n",
      "Substitute: establishment, BertScore: 0.9542876482009888\n",
      "Substitute: offering, BertScore: 0.9540978074073792\n",
      "Substitute: operation, BertScore: 0.954046368598938\n",
      "Substitute: development, BertScore: 0.9517410397529602\n",
      "Substitute: division, BertScore: 0.9495710730552673\n",
      "Substitute: offer, BertScore: 0.949258029460907\n",
      "Substitute: release, BertScore: 0.9489591121673584\n",
      "Substitute: possession, BertScore: 0.9482986927032471\n",
      "Substitute: selection, BertScore: 0.9468647837638855\n",
      "Substitute: approval, BertScore: 0.9462959170341492\n",
      "Substitute: use, BertScore: 0.9403894543647766\n",
      "top-10 substitutes based on bertscores in context: ['acquiring', 'purchase', 'takeover', 'buying', 'sale', 'privatization', 'ownership', 'procurement', 'purchases', 'seizure']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: investigate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: investigation, BertScore: 0.9919943809509277\n",
      "Substitute: search, BertScore: 0.9883424639701843\n",
      "Substitute: examine, BertScore: 0.9879149794578552\n",
      "Substitute: inquiry, BertScore: 0.9873058795928955\n",
      "Substitute: inspect, BertScore: 0.9867546558380127\n",
      "Substitute: check, BertScore: 0.986215353012085\n",
      "Substitute: probe, BertScore: 0.9857492446899414\n",
      "Substitute: study, BertScore: 0.9841589331626892\n",
      "Substitute: try, BertScore: 0.9833035469055176\n",
      "Substitute: look, BertScore: 0.9831228852272034\n",
      "Substitute: hunt, BertScore: 0.9830284714698792\n",
      "Substitute: explore, BertScore: 0.9824877977371216\n",
      "Substitute: research, BertScore: 0.9822020530700684\n",
      "Substitute: report, BertScore: 0.9818999171257019\n",
      "Substitute: observe, BertScore: 0.981418251991272\n",
      "Substitute: monitor, BertScore: 0.9812802672386169\n",
      "Substitute: analyze, BertScore: 0.9803364276885986\n",
      "Substitute: pursue, BertScore: 0.9802807569503784\n",
      "Substitute: watch, BertScore: 0.9797922372817993\n",
      "Substitute: review, BertScore: 0.9796561002731323\n",
      "Substitute: patrol, BertScore: 0.9765436053276062\n",
      "Substitute: work, BertScore: 0.9746763110160828\n",
      "Substitute: test, BertScore: 0.9745157361030579\n",
      "Substitute: police, BertScore: 0.9723873138427734\n",
      "Substitute: discuss, BertScore: 0.9700227975845337\n",
      "Substitute: investigators, BertScore: 0.9688733220100403\n",
      "top-10 substitutes based on bertscores in context: ['investigation', 'search', 'examine', 'inquiry', 'inspect', 'check', 'probe', 'study', 'try', 'look']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: slumped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: fallen, BertScore: 0.997450053691864\n",
      "Substitute: sagged, BertScore: 0.9973533153533936\n",
      "Substitute: declined, BertScore: 0.997298002243042\n",
      "Substitute: fell, BertScore: 0.997187614440918\n",
      "Substitute: dropped, BertScore: 0.9969573616981506\n",
      "Substitute: dipped, BertScore: 0.9967065453529358\n",
      "Substitute: tumbled, BertScore: 0.9962508678436279\n",
      "Substitute: weakened, BertScore: 0.9960198998451233\n",
      "Substitute: plunged, BertScore: 0.9958868622779846\n",
      "Substitute: surged, BertScore: 0.9951359033584595\n",
      "Substitute: retreated, BertScore: 0.9949162602424622\n",
      "Substitute: collapsed, BertScore: 0.9948863983154297\n",
      "Substitute: jumped, BertScore: 0.9948180317878723\n",
      "Substitute: climbed, BertScore: 0.9946774244308472\n",
      "Substitute: risen, BertScore: 0.9943544864654541\n",
      "Substitute: sunk, BertScore: 0.9942314028739929\n",
      "Substitute: slipped, BertScore: 0.993976354598999\n",
      "Substitute: eased, BertScore: 0.9929183721542358\n",
      "Substitute: increased, BertScore: 0.9928169250488281\n",
      "Substitute: improved, BertScore: 0.9923352599143982\n",
      "Substitute: moved, BertScore: 0.9919877052307129\n",
      "Substitute: advanced, BertScore: 0.9917289614677429\n",
      "Substitute: recovered, BertScore: 0.9913173317909241\n",
      "Substitute: slid, BertScore: 0.9909719228744507\n",
      "Substitute: rallied, BertScore: 0.9895022511482239\n",
      "Substitute: lost, BertScore: 0.9894051551818848\n",
      "Substitute: shed, BertScore: 0.9892880916595459\n",
      "Substitute: gained, BertScore: 0.9879276752471924\n",
      "Substitute: added, BertScore: 0.9841185212135315\n",
      "top-10 substitutes based on bertscores in context: ['fallen', 'sagged', 'declined', 'fell', 'dropped', 'dipped', 'tumbled', 'weakened', 'plunged', 'surged']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: ambushed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: attacked, BertScore: 0.9941479563713074\n",
      "Substitute: intercepted, BertScore: 0.9918088912963867\n",
      "Substitute: assaulted, BertScore: 0.9917769432067871\n",
      "Substitute: abducted, BertScore: 0.9902768135070801\n",
      "Substitute: targeted, BertScore: 0.9902087450027466\n",
      "Substitute: engaged, BertScore: 0.9899663329124451\n",
      "Substitute: hit, BertScore: 0.9896727800369263\n",
      "Substitute: harassed, BertScore: 0.9893310070037842\n",
      "Substitute: bombed, BertScore: 0.9891266226768494\n",
      "Substitute: kidnapped, BertScore: 0.9888123273849487\n",
      "Substitute: shot, BertScore: 0.9887568354606628\n",
      "Substitute: captured, BertScore: 0.9884300231933594\n",
      "Substitute: defeated, BertScore: 0.9884288907051086\n",
      "Substitute: chased, BertScore: 0.9882267117500305\n",
      "Substitute: seized, BertScore: 0.987893283367157\n",
      "Substitute: robbed, BertScore: 0.9876008629798889\n",
      "Substitute: threatened, BertScore: 0.9868777394294739\n",
      "Substitute: spotted, BertScore: 0.9865938425064087\n",
      "Substitute: beaten, BertScore: 0.9861788749694824\n",
      "Substitute: driven, BertScore: 0.9854823350906372\n",
      "Substitute: killed, BertScore: 0.984770655632019\n",
      "Substitute: arrested, BertScore: 0.9844628572463989\n",
      "Substitute: penetrated, BertScore: 0.9840002059936523\n",
      "Substitute: wounded, BertScore: 0.9838988780975342\n",
      "Substitute: injured, BertScore: 0.9837729930877686\n",
      "Substitute: betrayed, BertScore: 0.9835754632949829\n",
      "Substitute: met, BertScore: 0.9829106330871582\n",
      "Substitute: raped, BertScore: 0.9828789830207825\n",
      "Substitute: aided, BertScore: 0.9828450083732605\n",
      "top-10 substitutes based on bertscores in context: ['attacked', 'intercepted', 'assaulted', 'abducted', 'targeted', 'engaged', 'hit', 'harassed', 'bombed', 'kidnapped']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: conclusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: ending, BertScore: 0.9870378375053406\n",
      "Substitute: end, BertScore: 0.986497700214386\n",
      "Substitute: climax, BertScore: 0.9845014810562134\n",
      "Substitute: outcome, BertScore: 0.9830678701400757\n",
      "Substitute: result, BertScore: 0.9824629426002502\n",
      "Substitute: realization, BertScore: 0.9816521406173706\n",
      "Substitute: completion, BertScore: 0.97972172498703\n",
      "Substitute: finish, BertScore: 0.9785415530204773\n",
      "Substitute: start, BertScore: 0.9764389395713806\n",
      "Substitute: beginning, BertScore: 0.9751946926116943\n",
      "Substitute: point, BertScore: 0.9742735624313354\n",
      "Substitute: decision, BertScore: 0.9735978841781616\n",
      "Substitute: solution, BertScore: 0.9731138348579407\n",
      "Substitute: resolution, BertScore: 0.9730283617973328\n",
      "Substitute: course, BertScore: 0.9704092741012573\n",
      "Substitute: success, BertScore: 0.9700641632080078\n",
      "Substitute: stage, BertScore: 0.9695206880569458\n",
      "Substitute: date, BertScore: 0.9694557785987854\n",
      "Substitute: action, BertScore: 0.9687056541442871\n",
      "Substitute: objective, BertScore: 0.9677214622497559\n",
      "Substitute: level, BertScore: 0.9675679206848145\n",
      "Substitute: goal, BertScore: 0.9671918153762817\n",
      "Substitute: one, BertScore: 0.9665030837059021\n",
      "Substitute: event, BertScore: 0.9663342237472534\n",
      "Substitute: settlement, BertScore: 0.9661026000976562\n",
      "Substitute: degree, BertScore: 0.964999794960022\n",
      "Substitute: agreement, BertScore: 0.9625558853149414\n",
      "Substitute: development, BertScore: 0.9603049159049988\n",
      "top-10 substitutes based on bertscores in context: ['ending', 'end', 'climax', 'outcome', 'result', 'realization', 'completion', 'finish', 'start', 'beginning']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: rebound\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: recovery, BertScore: 0.9897592663764954\n",
      "Substitute: resurgence, BertScore: 0.9886736869812012\n",
      "Substitute: revival, BertScore: 0.9884490370750427\n",
      "Substitute: surge, BertScore: 0.986606776714325\n",
      "Substitute: boost, BertScore: 0.9846232533454895\n",
      "Substitute: spike, BertScore: 0.9842289090156555\n",
      "Substitute: breakout, BertScore: 0.9841970205307007\n",
      "Substitute: return, BertScore: 0.9841161370277405\n",
      "Substitute: improvement, BertScore: 0.9834766387939453\n",
      "Substitute: gain, BertScore: 0.982820987701416\n",
      "Substitute: rise, BertScore: 0.981978714466095\n",
      "Substitute: strengthening, BertScore: 0.9817693829536438\n",
      "Substitute: decline, BertScore: 0.981452465057373\n",
      "Substitute: reversal, BertScore: 0.9811117649078369\n",
      "Substitute: bounce, BertScore: 0.9802521467208862\n",
      "Substitute: comeback, BertScore: 0.9788219332695007\n",
      "Substitute: shift, BertScore: 0.9786403775215149\n",
      "Substitute: fall, BertScore: 0.9786075353622437\n",
      "Substitute: momentum, BertScore: 0.9766367673873901\n",
      "Substitute: correction, BertScore: 0.9749339818954468\n",
      "Substitute: move, BertScore: 0.9690982103347778\n",
      "Substitute: trend, BertScore: 0.9684593677520752\n",
      "Substitute: performance, BertScore: 0.9657772779464722\n",
      "Substitute: rally, BertScore: 0.9555271863937378\n",
      "Substitute: period, BertScore: 0.9501116275787354\n",
      "Substitute: quarter, BertScore: 0.9470901489257812\n",
      "Substitute: year, BertScore: 0.9399315714836121\n",
      "Substitute: week, BertScore: 0.9360154867172241\n",
      "Substitute: day, BertScore: 0.9358897805213928\n",
      "top-10 substitutes based on bertscores in context: ['recovery', 'resurgence', 'revival', 'surge', 'boost', 'spike', 'breakout', 'return', 'improvement', 'gain']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: diagnosed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: identified, BertScore: 0.9800314903259277\n",
      "Substitute: discovered, BertScore: 0.9774904847145081\n",
      "Substitute: detected, BertScore: 0.9769599437713623\n",
      "Substitute: treated, BertScore: 0.9765177965164185\n",
      "Substitute: found, BertScore: 0.9755422472953796\n",
      "Substitute: developed, BertScore: 0.974626898765564\n",
      "Substitute: registered, BertScore: 0.9744181632995605\n",
      "Substitute: experienced, BertScore: 0.9740347862243652\n",
      "Substitute: fixed, BertScore: 0.9737554788589478\n",
      "Substitute: introduced, BertScore: 0.9730627536773682\n",
      "Substitute: admitted, BertScore: 0.9728972911834717\n",
      "Substitute: started, BertScore: 0.9725017547607422\n",
      "Substitute: cured, BertScore: 0.9723159670829773\n",
      "Substitute: established, BertScore: 0.972076952457428\n",
      "Substitute: recognized, BertScore: 0.9706717729568481\n",
      "Substitute: presented, BertScore: 0.9705986380577087\n",
      "Substitute: committed, BertScore: 0.9702867269515991\n",
      "Substitute: born, BertScore: 0.9695701599121094\n",
      "Substitute: resolved, BertScore: 0.9687718152999878\n",
      "Substitute: listed, BertScore: 0.9681156873703003\n",
      "Substitute: addressed, BertScore: 0.967654824256897\n",
      "Substitute: defined, BertScore: 0.966355562210083\n",
      "Substitute: solved, BertScore: 0.9651018381118774\n",
      "Substitute: described, BertScore: 0.964850664138794\n",
      "Substitute: faced, BertScore: 0.9630293250083923\n",
      "Substitute: several, BertScore: 0.9516516923904419\n",
      "Substitute: many, BertScore: 0.9509245753288269\n",
      "Substitute: 30, BertScore: 0.9477719068527222\n",
      "Substitute: 50, BertScore: 0.9458414316177368\n",
      "top-10 substitutes based on bertscores in context: ['identified', 'discovered', 'detected', 'treated', 'found', 'developed', 'registered', 'experienced', 'fixed', 'introduced']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: boycott\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: skip, BertScore: 0.9908244013786316\n",
      "Substitute: abandon, BertScore: 0.9904758334159851\n",
      "Substitute: cancel, BertScore: 0.9900468587875366\n",
      "Substitute: block, BertScore: 0.989883303642273\n",
      "Substitute: reject, BertScore: 0.9887296557426453\n",
      "Substitute: ignore, BertScore: 0.9887117147445679\n",
      "Substitute: bypass, BertScore: 0.9884178042411804\n",
      "Substitute: withdraw, BertScore: 0.9883898496627808\n",
      "Substitute: avoid, BertScore: 0.9883820414543152\n",
      "Substitute: suspend, BertScore: 0.9878406524658203\n",
      "Substitute: close, BertScore: 0.9874653220176697\n",
      "Substitute: protest, BertScore: 0.9873117208480835\n",
      "Substitute: delay, BertScore: 0.9871272444725037\n",
      "Substitute: leave, BertScore: 0.9869985580444336\n",
      "Substitute: freeze, BertScore: 0.9867681264877319\n",
      "Substitute: oppose, BertScore: 0.986734926700592\n",
      "Substitute: disrupt, BertScore: 0.986687183380127\n",
      "Substitute: stop, BertScore: 0.9858492612838745\n",
      "Substitute: ban, BertScore: 0.9858142733573914\n",
      "Substitute: call, BertScore: 0.9848031997680664\n",
      "Substitute: attend, BertScore: 0.9847273826599121\n",
      "Substitute: join, BertScore: 0.9845853447914124\n",
      "Substitute: hold, BertScore: 0.9843162298202515\n",
      "Substitute: accept, BertScore: 0.9839657545089722\n",
      "Substitute: support, BertScore: 0.983957827091217\n",
      "Substitute: watch, BertScore: 0.9837034344673157\n",
      "Substitute: prevent, BertScore: 0.9835492372512817\n",
      "Substitute: condemn, BertScore: 0.983384370803833\n",
      "Substitute: win, BertScore: 0.9832005500793457\n",
      "top-10 substitutes based on bertscores in context: ['skip', 'abandon', 'cancel', 'block', 'reject', 'ignore', 'bypass', 'withdraw', 'avoid', 'suspend']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: campaigning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: fighting, BertScore: 0.9916813969612122\n",
      "Substitute: battle, BertScore: 0.9871222972869873\n",
      "Substitute: action, BertScore: 0.9862594604492188\n",
      "Substitute: running, BertScore: 0.9860634803771973\n",
      "Substitute: preparations, BertScore: 0.984210729598999\n",
      "Substitute: struggle, BertScore: 0.984112024307251\n",
      "Substitute: opposition, BertScore: 0.9837524890899658\n",
      "Substitute: war, BertScore: 0.9837299585342407\n",
      "Substitute: lobbying, BertScore: 0.9835753440856934\n",
      "Substitute: work, BertScore: 0.9834669828414917\n",
      "Substitute: training, BertScore: 0.983461320400238\n",
      "Substitute: preparation, BertScore: 0.9833292365074158\n",
      "Substitute: politics, BertScore: 0.983302891254425\n",
      "Substitute: planning, BertScore: 0.9829035401344299\n",
      "Substitute: polling, BertScore: 0.9825692772865295\n",
      "Substitute: violence, BertScore: 0.9824011325836182\n",
      "Substitute: occupation, BertScore: 0.9823530912399292\n",
      "Substitute: resistance, BertScore: 0.9820486307144165\n",
      "Substitute: waiting, BertScore: 0.9817614555358887\n",
      "Substitute: competition, BertScore: 0.9809423685073853\n",
      "Substitute: voting, BertScore: 0.9807558059692383\n",
      "Substitute: labour, BertScore: 0.98011314868927\n",
      "Substitute: support, BertScore: 0.9799390435218811\n",
      "Substitute: fundraising, BertScore: 0.9797559380531311\n",
      "Substitute: publicity, BertScore: 0.979284405708313\n",
      "Substitute: propaganda, BertScore: 0.9786657691001892\n",
      "Substitute: debate, BertScore: 0.9772195816040039\n",
      "top-10 substitutes based on bertscores in context: ['fighting', 'battle', 'action', 'running', 'preparations', 'struggle', 'opposition', 'war', 'lobbying', 'work']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: assassinated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: murdered, BertScore: 0.993453323841095\n",
      "Substitute: killed, BertScore: 0.990411102771759\n",
      "Substitute: deposed, BertScore: 0.9877689480781555\n",
      "Substitute: slain, BertScore: 0.9875746965408325\n",
      "Substitute: executed, BertScore: 0.9872885942459106\n",
      "Substitute: ousted, BertScore: 0.9843549132347107\n",
      "Substitute: toppled, BertScore: 0.9828460812568665\n",
      "Substitute: exiled, BertScore: 0.9825800657272339\n",
      "Substitute: beheaded, BertScore: 0.9815835952758789\n",
      "Substitute: sacked, BertScore: 0.9809288382530212\n",
      "Substitute: banished, BertScore: 0.9799116253852844\n",
      "Substitute: expelled, BertScore: 0.9795501232147217\n",
      "Substitute: shot, BertScore: 0.9793346524238586\n",
      "Substitute: captured, BertScore: 0.9789066910743713\n",
      "Substitute: imprisoned, BertScore: 0.978645384311676\n",
      "Substitute: defeated, BertScore: 0.9777737259864807\n",
      "Substitute: hanged, BertScore: 0.977772057056427\n",
      "Substitute: removed, BertScore: 0.9764531254768372\n",
      "Substitute: installed, BertScore: 0.9745681881904602\n",
      "Substitute: elected, BertScore: 0.973526656627655\n",
      "Substitute: crowned, BertScore: 0.9718702435493469\n",
      "Substitute: destroyed, BertScore: 0.9714705944061279\n",
      "Substitute: dead, BertScore: 0.9713142514228821\n",
      "Substitute: released, BertScore: 0.9697030782699585\n",
      "Substitute: succeeded, BertScore: 0.9687840342521667\n",
      "Substitute: appointed, BertScore: 0.9683074355125427\n",
      "Substitute: knighted, BertScore: 0.9637213945388794\n",
      "Substitute: created, BertScore: 0.9632508754730225\n",
      "Substitute: born, BertScore: 0.950808048248291\n",
      "top-10 substitutes based on bertscores in context: ['murdered', 'killed', 'deposed', 'slain', 'executed', 'ousted', 'toppled', 'exiled', 'beheaded', 'sacked']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: detonated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: exploded, BertScore: 0.9929599761962891\n",
      "Substitute: ignited, BertScore: 0.9905956983566284\n",
      "Substitute: dropped, BertScore: 0.9872921705245972\n",
      "Substitute: planted, BertScore: 0.985481858253479\n",
      "Substitute: struck, BertScore: 0.9851258993148804\n",
      "Substitute: hit, BertScore: 0.9838415384292603\n",
      "Substitute: activated, BertScore: 0.9836710691452026\n",
      "Substitute: launched, BertScore: 0.9820526838302612\n",
      "Substitute: destroyed, BertScore: 0.980694591999054\n",
      "Substitute: attacked, BertScore: 0.9798102378845215\n",
      "Substitute: bombed, BertScore: 0.9787872433662415\n",
      "Substitute: loaded, BertScore: 0.97797030210495\n",
      "Substitute: seized, BertScore: 0.9778587818145752\n",
      "Substitute: deployed, BertScore: 0.9773068428039551\n",
      "Substitute: crashed, BertScore: 0.9769577980041504\n",
      "Substitute: ambushed, BertScore: 0.9760220646858215\n",
      "Substitute: found, BertScore: 0.9753060936927795\n",
      "Substitute: installed, BertScore: 0.97435462474823\n",
      "Substitute: stopped, BertScore: 0.9741983413696289\n",
      "Substitute: identified, BertScore: 0.9740161299705505\n",
      "Substitute: located, BertScore: 0.9730908870697021\n",
      "Substitute: discovered, BertScore: 0.9730867743492126\n",
      "Substitute: parked, BertScore: 0.9720519185066223\n",
      "Substitute: killed, BertScore: 0.9701377153396606\n",
      "Substitute: released, BertScore: 0.9700847864151001\n",
      "Substitute: constructed, BertScore: 0.9691859483718872\n",
      "Substitute: arrested, BertScore: 0.9678658843040466\n",
      "Substitute: built, BertScore: 0.9672680497169495\n",
      "Substitute: unveiled, BertScore: 0.963174045085907\n",
      "top-10 substitutes based on bertscores in context: ['exploded', 'ignited', 'dropped', 'planted', 'struck', 'hit', 'activated', 'launched', 'destroyed', 'attacked']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: clamoring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: pressing, BertScore: 0.9528043270111084\n",
      "Substitute: eager, BertScore: 0.9494791626930237\n",
      "Substitute: pushing, BertScore: 0.9491658210754395\n",
      "Substitute: desperate, BertScore: 0.948596715927124\n",
      "Substitute: fighting, BertScore: 0.9484015107154846\n",
      "Substitute: battling, BertScore: 0.9476704001426697\n",
      "Substitute: calling, BertScore: 0.9474133253097534\n",
      "Substitute: yearning, BertScore: 0.9470449090003967\n",
      "Substitute: hunting, BertScore: 0.9468114972114563\n",
      "Substitute: praying, BertScore: 0.9463167786598206\n",
      "Substitute: campaigning, BertScore: 0.9461766481399536\n",
      "Substitute: craving, BertScore: 0.9461027979850769\n",
      "Substitute: lobbying, BertScore: 0.945318341255188\n",
      "Substitute: longing, BertScore: 0.9449588656425476\n",
      "Substitute: reaching, BertScore: 0.9438010454177856\n",
      "Substitute: looking, BertScore: 0.9436315894126892\n",
      "Substitute: waiting, BertScore: 0.9433926343917847\n",
      "Substitute: pleading, BertScore: 0.9430868625640869\n",
      "Substitute: asking, BertScore: 0.9427002668380737\n",
      "Substitute: settling, BertScore: 0.9421333074569702\n",
      "Substitute: seeking, BertScore: 0.9418449401855469\n",
      "Substitute: searching, BertScore: 0.9417536854743958\n",
      "Substitute: hoping, BertScore: 0.9402412176132202\n",
      "Substitute: advocating, BertScore: 0.9391663074493408\n",
      "Substitute: negotiating, BertScore: 0.9390118718147278\n",
      "Substitute: preparing, BertScore: 0.93797767162323\n",
      "Substitute: arguing, BertScore: 0.9371300935745239\n",
      "Substitute: bidding, BertScore: 0.9362526535987854\n",
      "Substitute: aiming, BertScore: 0.9359707832336426\n",
      "Substitute: ready, BertScore: 0.9296700358390808\n",
      "top-10 substitutes based on bertscores in context: ['pressing', 'eager', 'pushing', 'desperate', 'fighting', 'battling', 'calling', 'yearning', 'hunting', 'praying']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: credibility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: legitimacy, BertScore: 0.9970500469207764\n",
      "Substitute: prestige, BertScore: 0.9959486126899719\n",
      "Substitute: confidence, BertScore: 0.994770348072052\n",
      "Substitute: integrity, BertScore: 0.9946654438972473\n",
      "Substitute: authenticity, BertScore: 0.994635283946991\n",
      "Substitute: reputation, BertScore: 0.9938390851020813\n",
      "Substitute: stability, BertScore: 0.9938120245933533\n",
      "Substitute: loyalty, BertScore: 0.9936403632164001\n",
      "Substitute: credentials, BertScore: 0.9933624267578125\n",
      "Substitute: reliability, BertScore: 0.9933590292930603\n",
      "Substitute: momentum, BertScore: 0.9930180311203003\n",
      "Substitute: trust, BertScore: 0.9927762150764465\n",
      "Substitute: competence, BertScore: 0.9925317168235779\n",
      "Substitute: strength, BertScore: 0.9922787547111511\n",
      "Substitute: courage, BertScore: 0.9922565221786499\n",
      "Substitute: standing, BertScore: 0.992127537727356\n",
      "Substitute: support, BertScore: 0.9917007684707642\n",
      "Substitute: authority, BertScore: 0.9916791915893555\n",
      "Substitute: success, BertScore: 0.9916570782661438\n",
      "Substitute: faith, BertScore: 0.9915601015090942\n",
      "Substitute: leadership, BertScore: 0.9914529919624329\n",
      "Substitute: security, BertScore: 0.9911020994186401\n",
      "Substitute: capacity, BertScore: 0.9904676079750061\n",
      "Substitute: credible, BertScore: 0.9904252290725708\n",
      "Substitute: structure, BertScore: 0.9896547198295593\n",
      "Substitute: motivation, BertScore: 0.9891894459724426\n",
      "Substitute: foundation, BertScore: 0.9888784289360046\n",
      "Substitute: justification, BertScore: 0.9881228804588318\n",
      "Substitute: evidence, BertScore: 0.9879832863807678\n",
      "top-10 substitutes based on bertscores in context: ['legitimacy', 'prestige', 'confidence', 'integrity', 'authenticity', 'reputation', 'stability', 'loyalty', 'credentials', 'reliability']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: outskirts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: fringe, BertScore: 0.9932965636253357\n",
      "Substitute: edge, BertScore: 0.9924875497817993\n",
      "Substitute: periphery, BertScore: 0.990559458732605\n",
      "Substitute: edges, BertScore: 0.9880676865577698\n",
      "Substitute: outside, BertScore: 0.9874951839447021\n",
      "Substitute: doorstep, BertScore: 0.9850977659225464\n",
      "Substitute: inside, BertScore: 0.9850167036056519\n",
      "Substitute: perimeter, BertScore: 0.98479163646698\n",
      "Substitute: shores, BertScore: 0.9843162298202515\n",
      "Substitute: suburbs, BertScore: 0.9836082458496094\n",
      "Substitute: top, BertScore: 0.982708215713501\n",
      "Substitute: front, BertScore: 0.9825122356414795\n",
      "Substitute: hilltop, BertScore: 0.9815844297409058\n",
      "Substitute: streets, BertScore: 0.9814674854278564\n",
      "Substitute: corner, BertScore: 0.9804012775421143\n",
      "Substitute: floor, BertScore: 0.9802978038787842\n",
      "Substitute: entrance, BertScore: 0.9801052808761597\n",
      "Substitute: north, BertScore: 0.9790788888931274\n",
      "Substitute: premises, BertScore: 0.9788991212844849\n",
      "Substitute: rooftop, BertScore: 0.9787505865097046\n",
      "Substitute: center, BertScore: 0.9786711931228638\n",
      "Substitute: centre, BertScore: 0.9781448841094971\n",
      "Substitute: roof, BertScore: 0.9775649309158325\n",
      "Substitute: interior, BertScore: 0.9771832823753357\n",
      "Substitute: base, BertScore: 0.9769910573959351\n",
      "Substitute: side, BertScore: 0.9768102169036865\n",
      "Substitute: grounds, BertScore: 0.976476788520813\n",
      "Substitute: end, BertScore: 0.9757218956947327\n",
      "Substitute: site, BertScore: 0.9748316407203674\n",
      "top-10 substitutes based on bertscores in context: ['fringe', 'edge', 'periphery', 'edges', 'outside', 'doorstep', 'inside', 'perimeter', 'shores', 'suburbs']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: elite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: aristocracy, BertScore: 0.9918486475944519\n",
      "Substitute: class, BertScore: 0.986842155456543\n",
      "Substitute: establishment, BertScore: 0.9846068620681763\n",
      "Substitute: people, BertScore: 0.983660101890564\n",
      "Substitute: classes, BertScore: 0.982690691947937\n",
      "Substitute: body, BertScore: 0.9816432595252991\n",
      "Substitute: family, BertScore: 0.9793855547904968\n",
      "Substitute: leaders, BertScore: 0.9786352515220642\n",
      "Substitute: minority, BertScore: 0.9783446788787842\n",
      "Substitute: council, BertScore: 0.9781470894813538\n",
      "Substitute: assembly, BertScore: 0.9775089025497437\n",
      "Substitute: dynasty, BertScore: 0.977440357208252\n",
      "Substitute: bodies, BertScore: 0.9771909713745117\n",
      "Substitute: power, BertScore: 0.9764321446418762\n",
      "Substitute: junta, BertScore: 0.9761952757835388\n",
      "Substitute: rulers, BertScore: 0.9757753610610962\n",
      "Substitute: authority, BertScore: 0.975756049156189\n",
      "Substitute: regime, BertScore: 0.9756737947463989\n",
      "Substitute: party, BertScore: 0.9745137095451355\n",
      "Substitute: majority, BertScore: 0.9745090007781982\n",
      "Substitute: institutions, BertScore: 0.9742478132247925\n",
      "Substitute: parties, BertScore: 0.9741166830062866\n",
      "Substitute: monarchy, BertScore: 0.9739990830421448\n",
      "Substitute: group, BertScore: 0.9738954305648804\n",
      "Substitute: coalition, BertScore: 0.9736728668212891\n",
      "Substitute: judiciary, BertScore: 0.9729706645011902\n",
      "Substitute: minorities, BertScore: 0.971172034740448\n",
      "Substitute: scholars, BertScore: 0.9697045087814331\n",
      "top-10 substitutes based on bertscores in context: ['aristocracy', 'class', 'establishment', 'people', 'classes', 'body', 'family', 'leaders', 'minority', 'council']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: vulnerable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: susceptible, BertScore: 0.9960444569587708\n",
      "Substitute: vulnerability, BertScore: 0.9944128394126892\n",
      "Substitute: exposed, BertScore: 0.9920848608016968\n",
      "Substitute: sensitive, BertScore: 0.9915292859077454\n",
      "Substitute: prone, BertScore: 0.9912664890289307\n",
      "Substitute: resistant, BertScore: 0.9911866188049316\n",
      "Substitute: subject, BertScore: 0.9911338686943054\n",
      "Substitute: subjected, BertScore: 0.9902645945549011\n",
      "Substitute: immune, BertScore: 0.9901421070098877\n",
      "Substitute: responsive, BertScore: 0.9874549508094788\n",
      "Substitute: helpless, BertScore: 0.9873954653739929\n",
      "Substitute: hostile, BertScore: 0.9870927929878235\n",
      "Substitute: weak, BertScore: 0.9853501319885254\n",
      "Substitute: alert, BertScore: 0.985203742980957\n",
      "Substitute: dangerous, BertScore: 0.9849190711975098\n",
      "Substitute: open, BertScore: 0.9848659038543701\n",
      "Substitute: threatening, BertScore: 0.9847423434257507\n",
      "Substitute: threatened, BertScore: 0.9846352338790894\n",
      "Substitute: weakened, BertScore: 0.9843844771385193\n",
      "Substitute: committed, BertScore: 0.9836382269859314\n",
      "Substitute: engaged, BertScore: 0.9835584163665771\n",
      "Substitute: close, BertScore: 0.9833860397338867\n",
      "Substitute: inaccessible, BertScore: 0.9831030964851379\n",
      "Substitute: closed, BertScore: 0.9828565120697021\n",
      "Substitute: critical, BertScore: 0.982292115688324\n",
      "Substitute: linked, BertScore: 0.982110321521759\n",
      "Substitute: likely, BertScore: 0.9813584685325623\n",
      "Substitute: responding, BertScore: 0.9811795949935913\n",
      "Substitute: crucial, BertScore: 0.9808545112609863\n",
      "top-10 substitutes based on bertscores in context: ['susceptible', 'vulnerability', 'exposed', 'sensitive', 'prone', 'resistant', 'subject', 'subjected', 'immune', 'responsive']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: reaffirmed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: reiterated, BertScore: 0.96958327293396\n",
      "Substitute: affirmed, BertScore: 0.9680941700935364\n",
      "Substitute: confirmed, BertScore: 0.9666671752929688\n",
      "Substitute: clarified, BertScore: 0.9652365446090698\n",
      "Substitute: renewed, BertScore: 0.964877724647522\n",
      "Substitute: repeated, BertScore: 0.9646607637405396\n",
      "Substitute: acknowledged, BertScore: 0.9625627398490906\n",
      "Substitute: reinforced, BertScore: 0.9621655344963074\n",
      "Substitute: asserted, BertScore: 0.9616056680679321\n",
      "Substitute: emphasized, BertScore: 0.9609830975532532\n",
      "Substitute: continued, BertScore: 0.9608412384986877\n",
      "Substitute: stressed, BertScore: 0.9607807993888855\n",
      "Substitute: expressed, BertScore: 0.960663914680481\n",
      "Substitute: articulated, BertScore: 0.9603796005249023\n",
      "Substitute: echoed, BertScore: 0.9603288769721985\n",
      "Substitute: defended, BertScore: 0.9600397348403931\n",
      "Substitute: voiced, BertScore: 0.9598730802536011\n",
      "Substitute: upheld, BertScore: 0.9587463736534119\n",
      "Substitute: stated, BertScore: 0.9585089683532715\n",
      "Substitute: strengthened, BertScore: 0.9580848217010498\n",
      "Substitute: maintained, BertScore: 0.95594322681427\n",
      "Substitute: demonstrated, BertScore: 0.9543836116790771\n",
      "Substitute: respected, BertScore: 0.9533922672271729\n",
      "Substitute: proved, BertScore: 0.9526627063751221\n",
      "Substitute: backed, BertScore: 0.9521638751029968\n",
      "Substitute: explained, BertScore: 0.9519844055175781\n",
      "Substitute: supported, BertScore: 0.9514158964157104\n",
      "Substitute: challenged, BertScore: 0.9512104988098145\n",
      "Substitute: questioned, BertScore: 0.9493780136108398\n",
      "top-10 substitutes based on bertscores in context: ['reiterated', 'affirmed', 'confirmed', 'clarified', 'renewed', 'repeated', 'acknowledged', 'reinforced', 'asserted', 'emphasized']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: harassed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: assaulted, BertScore: 0.995556116104126\n",
      "Substitute: threatened, BertScore: 0.9946522116661072\n",
      "Substitute: targeted, BertScore: 0.9937354326248169\n",
      "Substitute: attacked, BertScore: 0.9936246871948242\n",
      "Substitute: pursued, BertScore: 0.9932852983474731\n",
      "Substitute: intimidated, BertScore: 0.9932575225830078\n",
      "Substitute: challenged, BertScore: 0.9930381774902344\n",
      "Substitute: abused, BertScore: 0.9929727911949158\n",
      "Substitute: tortured, BertScore: 0.9929445385932922\n",
      "Substitute: ambushed, BertScore: 0.9925255179405212\n",
      "Substitute: chased, BertScore: 0.992448091506958\n",
      "Substitute: humiliated, BertScore: 0.9923093914985657\n",
      "Substitute: confronted, BertScore: 0.99223393201828\n",
      "Substitute: teased, BertScore: 0.9919160604476929\n",
      "Substitute: beat, BertScore: 0.9918088316917419\n",
      "Substitute: detained, BertScore: 0.9916557669639587\n",
      "Substitute: insulted, BertScore: 0.991423487663269\n",
      "Substitute: abducted, BertScore: 0.9913350939750671\n",
      "Substitute: approached, BertScore: 0.9912210702896118\n",
      "Substitute: questioned, BertScore: 0.9911664724349976\n",
      "Substitute: intercepted, BertScore: 0.9911644458770752\n",
      "Substitute: kidnapped, BertScore: 0.9910663962364197\n",
      "Substitute: exploited, BertScore: 0.9906417727470398\n",
      "Substitute: captured, BertScore: 0.9892884492874146\n",
      "Substitute: arrested, BertScore: 0.989188015460968\n",
      "Substitute: defended, BertScore: 0.9889736175537109\n",
      "Substitute: killed, BertScore: 0.9888069033622742\n",
      "Substitute: expelled, BertScore: 0.9884116053581238\n",
      "Substitute: shot, BertScore: 0.9878168702125549\n",
      "top-10 substitutes based on bertscores in context: ['assaulted', 'threatened', 'targeted', 'attacked', 'pursued', 'intimidated', 'challenged', 'abused', 'tortured', 'ambushed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: safeguarding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: protecting, BertScore: 0.9867888689041138\n",
      "Substitute: securing, BertScore: 0.9841458797454834\n",
      "Substitute: defending, BertScore: 0.9827576875686646\n",
      "Substitute: ensuring, BertScore: 0.9819056987762451\n",
      "Substitute: preserving, BertScore: 0.9816354513168335\n",
      "Substitute: maintaining, BertScore: 0.9814216494560242\n",
      "Substitute: guarding, BertScore: 0.980602502822876\n",
      "Substitute: shielding, BertScore: 0.9788426756858826\n",
      "Substitute: protect, BertScore: 0.9788295030593872\n",
      "Substitute: strengthening, BertScore: 0.9774788618087769\n",
      "Substitute: supporting, BertScore: 0.97730553150177\n",
      "Substitute: enforcing, BertScore: 0.9764775037765503\n",
      "Substitute: monitoring, BertScore: 0.9763244986534119\n",
      "Substitute: policing, BertScore: 0.9760746955871582\n",
      "Substitute: secure, BertScore: 0.9750211834907532\n",
      "Substitute: defend, BertScore: 0.9746100902557373\n",
      "Substitute: advancing, BertScore: 0.974419116973877\n",
      "Substitute: respecting, BertScore: 0.973426878452301\n",
      "Substitute: promoting, BertScore: 0.9730713963508606\n",
      "Substitute: preventing, BertScore: 0.9723718166351318\n",
      "Substitute: patrolling, BertScore: 0.9711793065071106\n",
      "Substitute: providing, BertScore: 0.9704866409301758\n",
      "Substitute: retaining, BertScore: 0.9703165292739868\n",
      "Substitute: protection, BertScore: 0.9701333045959473\n",
      "Substitute: keeping, BertScore: 0.9694646000862122\n",
      "Substitute: holding, BertScore: 0.9655842185020447\n",
      "Substitute: protected, BertScore: 0.9622064828872681\n",
      "Substitute: security, BertScore: 0.9476356506347656\n",
      "Substitute: their, BertScore: 0.9315139651298523\n",
      "top-10 substitutes based on bertscores in context: ['protecting', 'securing', 'defending', 'ensuring', 'preserving', 'maintaining', 'guarding', 'shielding', 'protect', 'strengthening']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: subsidiaries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: employees, BertScore: 0.9857068061828613\n",
      "Substitute: operations, BertScore: 0.9846886992454529\n",
      "Substitute: assets, BertScore: 0.9830852150917053\n",
      "Substitute: offices, BertScore: 0.9820268154144287\n",
      "Substitute: branches, BertScore: 0.9818466901779175\n",
      "Substitute: stores, BertScore: 0.9817773103713989\n",
      "Substitute: factories, BertScore: 0.9815381765365601\n",
      "Substitute: affiliates, BertScore: 0.9798771142959595\n",
      "Substitute: businesses, BertScore: 0.9794138669967651\n",
      "Substitute: properties, BertScore: 0.9770186543464661\n",
      "Substitute: premises, BertScore: 0.9749996662139893\n",
      "Substitute: partners, BertScore: 0.9747030138969421\n",
      "Substitute: headquarters, BertScore: 0.9745978116989136\n",
      "Substitute: enterprises, BertScore: 0.9743369221687317\n",
      "Substitute: investments, BertScore: 0.9736424684524536\n",
      "Substitute: business, BertScore: 0.9734673500061035\n",
      "Substitute: locations, BertScore: 0.9730418920516968\n",
      "Substitute: holdings, BertScore: 0.9707694053649902\n",
      "Substitute: companies, BertScore: 0.9705564379692078\n",
      "Substitute: facilities, BertScore: 0.9696274399757385\n",
      "Substitute: clients, BertScore: 0.9668070673942566\n",
      "Substitute: associates, BertScore: 0.9660967588424683\n",
      "Substitute: bases, BertScore: 0.9657289981842041\n",
      "Substitute: ties, BertScore: 0.962523341178894\n",
      "Substitute: connections, BertScore: 0.9574576020240784\n",
      "Substitute: colonies, BertScore: 0.956667423248291\n",
      "Substitute: interests, BertScore: 0.9564695358276367\n",
      "Substitute: collections, BertScore: 0.9475690126419067\n",
      "top-10 substitutes based on bertscores in context: ['employees', 'operations', 'assets', 'offices', 'branches', 'stores', 'factories', 'affiliates', 'businesses', 'properties']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: imprecise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: unreliable, BertScore: 0.9544480443000793\n",
      "Substitute: crude, BertScore: 0.954241931438446\n",
      "Substitute: conservative, BertScore: 0.9535336494445801\n",
      "Substitute: precise, BertScore: 0.9521207809448242\n",
      "Substitute: compact, BertScore: 0.9517012238502502\n",
      "Substitute: limited, BertScore: 0.9511598348617554\n",
      "Substitute: bulky, BertScore: 0.951029896736145\n",
      "Substitute: robust, BertScore: 0.9504098296165466\n",
      "Substitute: narrow, BertScore: 0.950405478477478\n",
      "Substitute: accurate, BertScore: 0.9501449465751648\n",
      "Substitute: expensive, BertScore: 0.9494757652282715\n",
      "Substitute: simple, BertScore: 0.9492703676223755\n",
      "Substitute: slow, BertScore: 0.9490595459938049\n",
      "Substitute: sensitive, BertScore: 0.9489901661872864\n",
      "Substitute: rigid, BertScore: 0.9483380913734436\n",
      "Substitute: costly, BertScore: 0.9483234882354736\n",
      "Substitute: broad, BertScore: 0.9481373429298401\n",
      "Substitute: small, BertScore: 0.9481273293495178\n",
      "Substitute: efficient, BertScore: 0.9481027126312256\n",
      "Substitute: sharp, BertScore: 0.9480143189430237\n",
      "Substitute: short, BertScore: 0.9479069709777832\n",
      "Substitute: thin, BertScore: 0.947876513004303\n",
      "Substitute: dense, BertScore: 0.9478614330291748\n",
      "Substitute: quick, BertScore: 0.946334719657898\n",
      "Substitute: powerful, BertScore: 0.9458749890327454\n",
      "Substitute: heavy, BertScore: 0.9456594586372375\n",
      "Substitute: large, BertScore: 0.9454912543296814\n",
      "Substitute: fast, BertScore: 0.9454210996627808\n",
      "Substitute: advanced, BertScore: 0.9450423717498779\n",
      "Substitute: light, BertScore: 0.9442766904830933\n",
      "top-10 substitutes based on bertscores in context: ['unreliable', 'crude', 'conservative', 'precise', 'compact', 'limited', 'bulky', 'robust', 'narrow', 'accurate']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: surged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: swelled, BertScore: 0.9950989484786987\n",
      "Substitute: spiked, BertScore: 0.9931208491325378\n",
      "Substitute: rose, BertScore: 0.9928953647613525\n",
      "Substitute: flared, BertScore: 0.9926660060882568\n",
      "Substitute: escalated, BertScore: 0.991733968257904\n",
      "Substitute: accelerated, BertScore: 0.9915423393249512\n",
      "Substitute: advanced, BertScore: 0.9914426207542419\n",
      "Substitute: erupted, BertScore: 0.9909787178039551\n",
      "Substitute: exploded, BertScore: 0.990480899810791\n",
      "Substitute: intensified, BertScore: 0.9904776811599731\n",
      "Substitute: mounted, BertScore: 0.990435004234314\n",
      "Substitute: grew, BertScore: 0.9900925755500793\n",
      "Substitute: raged, BertScore: 0.9900246262550354\n",
      "Substitute: soared, BertScore: 0.9899721145629883\n",
      "Substitute: developed, BertScore: 0.989332914352417\n",
      "Substitute: fell, BertScore: 0.9893152713775635\n",
      "Substitute: raced, BertScore: 0.9889358282089233\n",
      "Substitute: increased, BertScore: 0.9885694980621338\n",
      "Substitute: ensued, BertScore: 0.9870731830596924\n",
      "Substitute: continued, BertScore: 0.9869006872177124\n",
      "Substitute: heightened, BertScore: 0.9862630367279053\n",
      "Substitute: peaked, BertScore: 0.9859501719474792\n",
      "Substitute: persisted, BertScore: 0.985630452632904\n",
      "Substitute: spread, BertScore: 0.9855850338935852\n",
      "Substitute: sparked, BertScore: 0.9846161603927612\n",
      "Substitute: occurred, BertScore: 0.9833675026893616\n",
      "Substitute: fought, BertScore: 0.982312798500061\n",
      "Substitute: demonstrated, BertScore: 0.980436384677887\n",
      "Substitute: continues, BertScore: 0.9750210046768188\n",
      "top-10 substitutes based on bertscores in context: ['swelled', 'spiked', 'rose', 'flared', 'escalated', 'accelerated', 'advanced', 'erupted', 'exploded', 'intensified']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: repealing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: removing, BertScore: 0.9836121201515198\n",
      "Substitute: eliminating, BertScore: 0.9832382202148438\n",
      "Substitute: ending, BertScore: 0.98231041431427\n",
      "Substitute: stopping, BertScore: 0.9811413288116455\n",
      "Substitute: introducing, BertScore: 0.9805923104286194\n",
      "Substitute: reducing, BertScore: 0.980025053024292\n",
      "Substitute: implementing, BertScore: 0.9800090193748474\n",
      "Substitute: adopting, BertScore: 0.9794176816940308\n",
      "Substitute: restoring, BertScore: 0.9792047739028931\n",
      "Substitute: expanding, BertScore: 0.9789586663246155\n",
      "Substitute: increasing, BertScore: 0.9789223670959473\n",
      "Substitute: abandoning, BertScore: 0.9784306883811951\n",
      "Substitute: passing, BertScore: 0.9778058528900146\n",
      "Substitute: terminating, BertScore: 0.9777979850769043\n",
      "Substitute: withdrawing, BertScore: 0.9775776267051697\n",
      "Substitute: closing, BertScore: 0.9774965047836304\n",
      "Substitute: cutting, BertScore: 0.9774919152259827\n",
      "Substitute: reforming, BertScore: 0.9774065017700195\n",
      "Substitute: changing, BertScore: 0.9767220616340637\n",
      "Substitute: extending, BertScore: 0.9762430191040039\n",
      "Substitute: improving, BertScore: 0.9752746820449829\n",
      "Substitute: altering, BertScore: 0.9752472639083862\n",
      "Substitute: continuing, BertScore: 0.9751721024513245\n",
      "Substitute: fixing, BertScore: 0.9750587344169617\n",
      "Substitute: replacing, BertScore: 0.9731705188751221\n",
      "Substitute: supporting, BertScore: 0.9687581062316895\n",
      "Substitute: using, BertScore: 0.9682537913322449\n",
      "Substitute: getting, BertScore: 0.9654567241668701\n",
      "Substitute: the, BertScore: 0.9576408267021179\n",
      "top-10 substitutes based on bertscores in context: ['removing', 'eliminating', 'ending', 'stopping', 'introducing', 'reducing', 'implementing', 'adopting', 'restoring', 'expanding']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: obvious\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: apparent, BertScore: 0.9930794835090637\n",
      "Substitute: clear, BertScore: 0.9901924133300781\n",
      "Substitute: definite, BertScore: 0.9889007806777954\n",
      "Substitute: visible, BertScore: 0.9887494444847107\n",
      "Substitute: immediate, BertScore: 0.9871219992637634\n",
      "Substitute: explicit, BertScore: 0.9865750670433044\n",
      "Substitute: direct, BertScore: 0.9862887859344482\n",
      "Substitute: significant, BertScore: 0.9858072996139526\n",
      "Substitute: real, BertScore: 0.9852190017700195\n",
      "Substitute: specific, BertScore: 0.9851491451263428\n",
      "Substitute: major, BertScore: 0.9850600361824036\n",
      "Substitute: detailed, BertScore: 0.9848259091377258\n",
      "Substitute: known, BertScore: 0.9844030737876892\n",
      "Substitute: logical, BertScore: 0.9842554926872253\n",
      "Substitute: possible, BertScore: 0.9837098717689514\n",
      "Substitute: formal, BertScore: 0.9831082820892334\n",
      "Substitute: plausible, BertScore: 0.9824032783508301\n",
      "Substitute: official, BertScore: 0.9822689890861511\n",
      "Substitute: particular, BertScore: 0.9821686744689941\n",
      "Substitute: actual, BertScore: 0.9818092584609985\n",
      "Substitute: identifiable, BertScore: 0.9806863069534302\n",
      "Substitute: physical, BertScore: 0.9782979488372803\n",
      "Substitute: familiar, BertScore: 0.978274405002594\n",
      "Substitute: causal, BertScore: 0.9780200719833374\n",
      "Substitute: indirect, BertScore: 0.9780179858207703\n",
      "Substitute: historical, BertScore: 0.977552056312561\n",
      "Substitute: other, BertScore: 0.9772192239761353\n",
      "Substitute: personal, BertScore: 0.9767141342163086\n",
      "Substitute: intimate, BertScore: 0.9765515327453613\n",
      "top-10 substitutes based on bertscores in context: ['apparent', 'clear', 'definite', 'visible', 'immediate', 'explicit', 'direct', 'significant', 'real', 'specific']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: resilience\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: stability, BertScore: 0.9697291254997253\n",
      "Substitute: strength, BertScore: 0.9679157733917236\n",
      "Substitute: readiness, BertScore: 0.9672139286994934\n",
      "Substitute: effectiveness, BertScore: 0.9670091867446899\n",
      "Substitute: vulnerability, BertScore: 0.9649449586868286\n",
      "Substitute: strengthening, BertScore: 0.9640341997146606\n",
      "Substitute: persistence, BertScore: 0.9639012813568115\n",
      "Substitute: success, BertScore: 0.9638450741767883\n",
      "Substitute: credibility, BertScore: 0.9634696841239929\n",
      "Substitute: continuity, BertScore: 0.963110625743866\n",
      "Substitute: legitimacy, BertScore: 0.9623630046844482\n",
      "Substitute: quality, BertScore: 0.9617436528205872\n",
      "Substitute: performance, BertScore: 0.9617404937744141\n",
      "Substitute: status, BertScore: 0.9612746238708496\n",
      "Substitute: intensity, BertScore: 0.9609131813049316\n",
      "Substitute: health, BertScore: 0.9604631662368774\n",
      "Substitute: progress, BertScore: 0.9602815508842468\n",
      "Substitute: seriousness, BertScore: 0.9601339101791382\n",
      "Substitute: dynamics, BertScore: 0.958956778049469\n",
      "Substitute: strain, BertScore: 0.9582715034484863\n",
      "Substitute: importance, BertScore: 0.957996129989624\n",
      "Substitute: morale, BertScore: 0.9577860832214355\n",
      "Substitute: urgency, BertScore: 0.9576210379600525\n",
      "Substitute: severity, BertScore: 0.9575327038764954\n",
      "Substitute: future, BertScore: 0.9562580585479736\n",
      "Substitute: state, BertScore: 0.9560464024543762\n",
      "Substitute: nature, BertScore: 0.955635666847229\n",
      "Substitute: continuation, BertScore: 0.9545163512229919\n",
      "Substitute: outcome, BertScore: 0.9534720182418823\n",
      "Substitute: impact, BertScore: 0.9529734253883362\n",
      "top-10 substitutes based on bertscores in context: ['stability', 'strength', 'readiness', 'effectiveness', 'vulnerability', 'strengthening', 'persistence', 'success', 'credibility', 'continuity']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: revert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: shift, BertScore: 0.9897466897964478\n",
      "Substitute: return, BertScore: 0.9897210001945496\n",
      "Substitute: transition, BertScore: 0.989683985710144\n",
      "Substitute: switch, BertScore: 0.9884573817253113\n",
      "Substitute: convert, BertScore: 0.9882082939147949\n",
      "Substitute: decline, BertScore: 0.9880121350288391\n",
      "Substitute: shrink, BertScore: 0.9874061942100525\n",
      "Substitute: turn, BertScore: 0.987173318862915\n",
      "Substitute: fade, BertScore: 0.9869939088821411\n",
      "Substitute: change, BertScore: 0.9869702458381653\n",
      "Substitute: expand, BertScore: 0.9859443306922913\n",
      "Substitute: default, BertScore: 0.9856653213500977\n",
      "Substitute: move, BertScore: 0.9852574467658997\n",
      "Substitute: evolve, BertScore: 0.9851990938186646\n",
      "Substitute: retreat, BertScore: 0.985183835029602\n",
      "Substitute: fall, BertScore: 0.9846234917640686\n",
      "Substitute: rev, BertScore: 0.9843840599060059\n",
      "Substitute: stick, BertScore: 0.9840957522392273\n",
      "Substitute: grow, BertScore: 0.9839417338371277\n",
      "Substitute: go, BertScore: 0.9837391376495361\n",
      "Substitute: tilt, BertScore: 0.9830247759819031\n",
      "Substitute: resort, BertScore: 0.9823338985443115\n",
      "Substitute: adjust, BertScore: 0.9818736910820007\n",
      "Substitute: surrender, BertScore: 0.9814794063568115\n",
      "Substitute: extend, BertScore: 0.9796965718269348\n",
      "Substitute: lose, BertScore: 0.978531002998352\n",
      "Substitute: refer, BertScore: 0.9778032302856445\n",
      "Substitute: end, BertScore: 0.977288007736206\n",
      "Substitute: conform, BertScore: 0.9766365885734558\n",
      "top-10 substitutes based on bertscores in context: ['shift', 'return', 'transition', 'switch', 'convert', 'decline', 'shrink', 'turn', 'fade', 'change']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: vicinity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: proximity, BertScore: 0.9883020520210266\n",
      "Substitute: area, BertScore: 0.9866881966590881\n",
      "Substitute: location, BertScore: 0.9822155237197876\n",
      "Substitute: region, BertScore: 0.9790968298912048\n",
      "Substitute: areas, BertScore: 0.9777301549911499\n",
      "Substitute: territory, BertScore: 0.9773653149604797\n",
      "Substitute: locality, BertScore: 0.9773147106170654\n",
      "Substitute: neighbourhood, BertScore: 0.9752562046051025\n",
      "Substitute: neighborhood, BertScore: 0.9738752841949463\n",
      "Substitute: surroundings, BertScore: 0.9733039140701294\n",
      "Substitute: localities, BertScore: 0.9726128578186035\n",
      "Substitute: territories, BertScore: 0.9717684984207153\n",
      "Substitute: regions, BertScore: 0.9701229929924011\n",
      "Substitute: direction, BertScore: 0.9699693322181702\n",
      "Substitute: backyard, BertScore: 0.968766450881958\n",
      "Substitute: place, BertScore: 0.9669184684753418\n",
      "Substitute: environment, BertScore: 0.9658569097518921\n",
      "Substitute: city, BertScore: 0.9640701413154602\n",
      "Substitute: home, BertScore: 0.9640616774559021\n",
      "Substitute: absence, BertScore: 0.9636346101760864\n",
      "Substitute: homeland, BertScore: 0.9613288640975952\n",
      "Substitute: situation, BertScore: 0.9601590633392334\n",
      "Substitute: country, BertScore: 0.9578422904014587\n",
      "Substitute: community, BertScore: 0.9564112424850464\n",
      "Substitute: state, BertScore: 0.9558075070381165\n",
      "Substitute: case, BertScore: 0.9551831483840942\n",
      "Substitute: society, BertScore: 0.9522415995597839\n",
      "Substitute: past, BertScore: 0.948596179485321\n",
      "Substitute: view, BertScore: 0.943296492099762\n",
      "top-10 substitutes based on bertscores in context: ['proximity', 'area', 'location', 'region', 'areas', 'territory', 'locality', 'neighbourhood', 'neighborhood', 'surroundings']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: riposte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: betrayal, BertScore: 0.9632782936096191\n",
      "Substitute: challenge, BertScore: 0.9614306688308716\n",
      "Substitute: concession, BertScore: 0.9582558870315552\n",
      "Substitute: warning, BertScore: 0.9577717781066895\n",
      "Substitute: message, BertScore: 0.9562240839004517\n",
      "Substitute: signal, BertScore: 0.9560285210609436\n",
      "Substitute: fabrication, BertScore: 0.9559041857719421\n",
      "Substitute: coup, BertScore: 0.955765962600708\n",
      "Substitute: reaction, BertScore: 0.9554010033607483\n",
      "Substitute: lie, BertScore: 0.9545808434486389\n",
      "Substitute: nod, BertScore: 0.9541166424751282\n",
      "Substitute: response, BertScore: 0.9538794755935669\n",
      "Substitute: credit, BertScore: 0.9538771510124207\n",
      "Substitute: threat, BertScore: 0.95294588804245\n",
      "Substitute: reference, BertScore: 0.9527797698974609\n",
      "Substitute: gift, BertScore: 0.9522309899330139\n",
      "Substitute: toast, BertScore: 0.9516353011131287\n",
      "Substitute: letter, BertScore: 0.9515537023544312\n",
      "Substitute: debt, BertScore: 0.9511680603027344\n",
      "Substitute: blow, BertScore: 0.9510111808776855\n",
      "Substitute: traitor, BertScore: 0.9508810639381409\n",
      "Substitute: shock, BertScore: 0.950468122959137\n",
      "Substitute: tribute, BertScore: 0.950444221496582\n",
      "Substitute: prelude, BertScore: 0.9500932693481445\n",
      "Substitute: second, BertScore: 0.948998212814331\n",
      "Substitute: surprise, BertScore: 0.9486493468284607\n",
      "Substitute: disappointment, BertScore: 0.9483644962310791\n",
      "Substitute: boon, BertScore: 0.9479055404663086\n",
      "Substitute: memorial, BertScore: 0.9477133750915527\n",
      "Substitute: precursor, BertScore: 0.9457705020904541\n",
      "top-10 substitutes based on bertscores in context: ['betrayal', 'challenge', 'concession', 'warning', 'message', 'signal', 'fabrication', 'coup', 'reaction', 'lie']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: accumulation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: accumulate, BertScore: 0.9894975423812866\n",
      "Substitute: aggregation, BertScore: 0.9835391640663147\n",
      "Substitute: deposit, BertScore: 0.9834288358688354\n",
      "Substitute: deposition, BertScore: 0.9832071661949158\n",
      "Substitute: collection, BertScore: 0.982883870601654\n",
      "Substitute: redistribution, BertScore: 0.979826033115387\n",
      "Substitute: formation, BertScore: 0.9790654182434082\n",
      "Substitute: destruction, BertScore: 0.9789886474609375\n",
      "Substitute: loss, BertScore: 0.9781850576400757\n",
      "Substitute: extraction, BertScore: 0.9779949188232422\n",
      "Substitute: reduction, BertScore: 0.9776557087898254\n",
      "Substitute: recovery, BertScore: 0.9769523739814758\n",
      "Substitute: precipitation, BertScore: 0.9768147468566895\n",
      "Substitute: production, BertScore: 0.9766615629196167\n",
      "Substitute: creation, BertScore: 0.9765209555625916\n",
      "Substitute: storage, BertScore: 0.9762535691261292\n",
      "Substitute: elimination, BertScore: 0.9756249785423279\n",
      "Substitute: disappearance, BertScore: 0.9755104184150696\n",
      "Substitute: removal, BertScore: 0.9745447635650635\n",
      "Substitute: concentration, BertScore: 0.9742063283920288\n",
      "Substitute: erosion, BertScore: 0.973976194858551\n",
      "Substitute: growth, BertScore: 0.9738996624946594\n",
      "Substitute: distribution, BertScore: 0.9738404750823975\n",
      "Substitute: decomposition, BertScore: 0.9737301468849182\n",
      "Substitute: melting, BertScore: 0.9723381400108337\n",
      "Substitute: absorption, BertScore: 0.971863865852356\n",
      "Substitute: decay, BertScore: 0.9701172709465027\n",
      "Substitute: diffusion, BertScore: 0.9697110652923584\n",
      "Substitute: oxidation, BertScore: 0.9651464223861694\n",
      "top-10 substitutes based on bertscores in context: ['accumulate', 'aggregation', 'deposit', 'deposition', 'collection', 'redistribution', 'formation', 'destruction', 'loss', 'extraction']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: sustained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: prolonged, BertScore: 0.9926878213882446\n",
      "Substitute: serious, BertScore: 0.9926165342330933\n",
      "Substitute: severe, BertScore: 0.9924651384353638\n",
      "Substitute: extensive, BertScore: 0.9917566776275635\n",
      "Substitute: repeated, BertScore: 0.991529107093811\n",
      "Substitute: intense, BertScore: 0.991174042224884\n",
      "Substitute: heavy, BertScore: 0.9907975196838379\n",
      "Substitute: aggravated, BertScore: 0.9905041456222534\n",
      "Substitute: continuous, BertScore: 0.9903831481933594\n",
      "Substitute: intermittent, BertScore: 0.9900506138801575\n",
      "Substitute: persistent, BertScore: 0.9896708726882935\n",
      "Substitute: suffered, BertScore: 0.989140510559082\n",
      "Substitute: continual, BertScore: 0.9889345169067383\n",
      "Substitute: strong, BertScore: 0.9889031052589417\n",
      "Substitute: sporadic, BertScore: 0.9888360500335693\n",
      "Substitute: widespread, BertScore: 0.9887533187866211\n",
      "Substitute: active, BertScore: 0.9884454607963562\n",
      "Substitute: frequent, BertScore: 0.9884030222892761\n",
      "Substitute: regular, BertScore: 0.9875695705413818\n",
      "Substitute: forced, BertScore: 0.9874451160430908\n",
      "Substitute: continued, BertScore: 0.9873559474945068\n",
      "Substitute: numerous, BertScore: 0.9871148467063904\n",
      "Substitute: constant, BertScore: 0.9870755672454834\n",
      "Substitute: multiple, BertScore: 0.9869067668914795\n",
      "Substitute: voluntary, BertScore: 0.9859801530838013\n",
      "Substitute: further, BertScore: 0.985953688621521\n",
      "Substitute: combat, BertScore: 0.9854832887649536\n",
      "Substitute: the, BertScore: 0.9790713787078857\n",
      "top-10 substitutes based on bertscores in context: ['prolonged', 'serious', 'severe', 'extensive', 'repeated', 'intense', 'heavy', 'aggravated', 'continuous', 'intermittent']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: vacationing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: staying, BertScore: 0.9869974851608276\n",
      "Substitute: camping, BertScore: 0.986299455165863\n",
      "Substitute: visiting, BertScore: 0.9849086403846741\n",
      "Substitute: lodging, BertScore: 0.9847460985183716\n",
      "Substitute: residing, BertScore: 0.9847199320793152\n",
      "Substitute: relaxing, BertScore: 0.9843933582305908\n",
      "Substitute: traveling, BertScore: 0.9842730164527893\n",
      "Substitute: living, BertScore: 0.9842286109924316\n",
      "Substitute: travelling, BertScore: 0.9827625751495361\n",
      "Substitute: sleeping, BertScore: 0.9823232889175415\n",
      "Substitute: skiing, BertScore: 0.9814457297325134\n",
      "Substitute: resting, BertScore: 0.980673611164093\n",
      "Substitute: touring, BertScore: 0.980466902256012\n",
      "Substitute: moving, BertScore: 0.9799559712409973\n",
      "Substitute: away, BertScore: 0.9785563945770264\n",
      "Substitute: working, BertScore: 0.9782540798187256\n",
      "Substitute: home, BertScore: 0.9782292246818542\n",
      "Substitute: returning, BertScore: 0.9780561327934265\n",
      "Substitute: stranded, BertScore: 0.9779497385025024\n",
      "Substitute: filming, BertScore: 0.977383553981781\n",
      "Substitute: going, BertScore: 0.9773469567298889\n",
      "Substitute: landing, BertScore: 0.9762909412384033\n",
      "Substitute: arriving, BertScore: 0.9748839139938354\n",
      "Substitute: flying, BertScore: 0.9737701416015625\n",
      "Substitute: playing, BertScore: 0.9726549386978149\n",
      "Substitute: there, BertScore: 0.9718684554100037\n",
      "Substitute: missing, BertScore: 0.9713519215583801\n",
      "Substitute: being, BertScore: 0.9705057740211487\n",
      "Substitute: still, BertScore: 0.9697710275650024\n",
      "top-10 substitutes based on bertscores in context: ['staying', 'camping', 'visiting', 'lodging', 'residing', 'relaxing', 'traveling', 'living', 'travelling', 'sleeping']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: allegations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: accusations, BertScore: 0.9986066222190857\n",
      "Substitute: charges, BertScore: 0.9955087900161743\n",
      "Substitute: claims, BertScore: 0.994222104549408\n",
      "Substitute: accusation, BertScore: 0.9936531186103821\n",
      "Substitute: revelations, BertScore: 0.9930276870727539\n",
      "Substitute: complaints, BertScore: 0.9926691651344299\n",
      "Substitute: reports, BertScore: 0.9922998547554016\n",
      "Substitute: suspicions, BertScore: 0.9920839071273804\n",
      "Substitute: suspicion, BertScore: 0.990961492061615\n",
      "Substitute: rumors, BertScore: 0.9901626110076904\n",
      "Substitute: rumours, BertScore: 0.9901092052459717\n",
      "Substitute: suggestions, BertScore: 0.9895434379577637\n",
      "Substitute: confessions, BertScore: 0.9891814589500427\n",
      "Substitute: instances, BertScore: 0.988935649394989\n",
      "Substitute: evidence, BertScore: 0.9888960719108582\n",
      "Substitute: cases, BertScore: 0.9888818860054016\n",
      "Substitute: accounts, BertScore: 0.9885552525520325\n",
      "Substitute: threats, BertScore: 0.9880142211914062\n",
      "Substitute: investigations, BertScore: 0.9877634644508362\n",
      "Substitute: criticisms, BertScore: 0.9871446490287781\n",
      "Substitute: concerns, BertScore: 0.986152708530426\n",
      "Substitute: fears, BertScore: 0.986064612865448\n",
      "Substitute: images, BertScore: 0.9845808148384094\n",
      "Substitute: attempts, BertScore: 0.9843043684959412\n",
      "Substitute: alleged, BertScore: 0.9824987649917603\n",
      "Substitute: promises, BertScore: 0.9821417927742004\n",
      "Substitute: charge, BertScore: 0.9807155728340149\n",
      "Substitute: methods, BertScore: 0.9780776500701904\n",
      "Substitute: accused, BertScore: 0.9750558733940125\n",
      "top-10 substitutes based on bertscores in context: ['accusations', 'charges', 'claims', 'accusation', 'revelations', 'complaints', 'reports', 'suspicions', 'suspicion', 'rumors']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: integral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: integrated, BertScore: 0.9881860613822937\n",
      "Substitute: independent, BertScore: 0.9850274920463562\n",
      "Substitute: exclusive, BertScore: 0.9844157695770264\n",
      "Substitute: essential, BertScore: 0.9837225675582886\n",
      "Substitute: incorporated, BertScore: 0.9828453063964844\n",
      "Substitute: extra, BertScore: 0.9808372259140015\n",
      "Substitute: important, BertScore: 0.9796753525733948\n",
      "Substitute: effective, BertScore: 0.97874915599823\n",
      "Substitute: expanded, BertScore: 0.9785478115081787\n",
      "Substitute: additional, BertScore: 0.9778614640235901\n",
      "Substitute: autonomous, BertScore: 0.9778298735618591\n",
      "Substitute: auxiliary, BertScore: 0.9763370752334595\n",
      "Substitute: extensive, BertScore: 0.9758453369140625\n",
      "Substitute: active, BertScore: 0.9752393364906311\n",
      "Substitute: extended, BertScore: 0.9749871492385864\n",
      "Substitute: insignificant, BertScore: 0.9740646481513977\n",
      "Substitute: a, BertScore: 0.9720067381858826\n",
      "Substitute: artificial, BertScore: 0.9719610810279846\n",
      "Substitute: industrial, BertScore: 0.9712105989456177\n",
      "Substitute: entire, BertScore: 0.9711421728134155\n",
      "Substitute: isolated, BertScore: 0.9710957407951355\n",
      "Substitute: outer, BertScore: 0.9703025221824646\n",
      "Substitute: iconic, BertScore: 0.9698755145072937\n",
      "Substitute: excellent, BertScore: 0.9688655734062195\n",
      "Substitute: interior, BertScore: 0.9683115482330322\n",
      "Substitute: indigenous, BertScore: 0.9677664637565613\n",
      "Substitute: endangered, BertScore: 0.9674336314201355\n",
      "Substitute: unincorporated, BertScore: 0.9632967710494995\n",
      "Substitute: extinct, BertScore: 0.9626594185829163\n",
      "top-10 substitutes based on bertscores in context: ['integrated', 'independent', 'exclusive', 'essential', 'incorporated', 'extra', 'important', 'effective', 'expanded', 'additional']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: monument\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: memorial, BertScore: 0.9905401468276978\n",
      "Substitute: statue, BertScore: 0.9859153032302856\n",
      "Substitute: shrine, BertScore: 0.9831588268280029\n",
      "Substitute: mausoleum, BertScore: 0.9821398854255676\n",
      "Substitute: dedication, BertScore: 0.9819040298461914\n",
      "Substitute: temple, BertScore: 0.9813107848167419\n",
      "Substitute: tomb, BertScore: 0.9807999730110168\n",
      "Substitute: plaque, BertScore: 0.9786214232444763\n",
      "Substitute: sculpture, BertScore: 0.9767146706581116\n",
      "Substitute: tombstone, BertScore: 0.9765464067459106\n",
      "Substitute: chapel, BertScore: 0.975017786026001\n",
      "Substitute: museum, BertScore: 0.9737775325775146\n",
      "Substitute: portal, BertScore: 0.9736621379852295\n",
      "Substitute: tribute, BertScore: 0.9721947908401489\n",
      "Substitute: church, BertScore: 0.9718414545059204\n",
      "Substitute: dedicated, BertScore: 0.9716987013816833\n",
      "Substitute: grave, BertScore: 0.9706477522850037\n",
      "Substitute: home, BertScore: 0.968359112739563\n",
      "Substitute: cemetery, BertScore: 0.9676830172538757\n",
      "Substitute: sign, BertScore: 0.9673542976379395\n",
      "Substitute: pendant, BertScore: 0.9659754037857056\n",
      "Substitute: service, BertScore: 0.9647171497344971\n",
      "Substitute: bridge, BertScore: 0.9643702507019043\n",
      "Substitute: gate, BertScore: 0.9636942148208618\n",
      "Substitute: site, BertScore: 0.9608246088027954\n",
      "Substitute: trail, BertScore: 0.9574412107467651\n",
      "Substitute: reference, BertScore: 0.9514412879943848\n",
      "Substitute: given, BertScore: 0.9435722827911377\n",
      "top-10 substitutes based on bertscores in context: ['memorial', 'statue', 'shrine', 'mausoleum', 'dedication', 'temple', 'tomb', 'plaque', 'sculpture', 'tombstone']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: homicides\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: murders, BertScore: 0.9707924127578735\n",
      "Substitute: killings, BertScore: 0.9636344909667969\n",
      "Substitute: murder, BertScore: 0.9631855487823486\n",
      "Substitute: deaths, BertScore: 0.9619475603103638\n",
      "Substitute: crimes, BertScore: 0.9606413841247559\n",
      "Substitute: fatalities, BertScore: 0.959800660610199\n",
      "Substitute: incidents, BertScore: 0.9528569579124451\n",
      "Substitute: offenses, BertScore: 0.9520370960235596\n",
      "Substitute: accidents, BertScore: 0.9517220258712769\n",
      "Substitute: occurrences, BertScore: 0.9515914916992188\n",
      "Substitute: crime, BertScore: 0.9497859477996826\n",
      "Substitute: cases, BertScore: 0.9491018056869507\n",
      "Substitute: massacre, BertScore: 0.9463968276977539\n",
      "Substitute: investigations, BertScore: 0.9435492753982544\n",
      "Substitute: incident, BertScore: 0.9429796934127808\n",
      "Substitute: worst, BertScore: 0.9428835511207581\n",
      "Substitute: felony, BertScore: 0.9409240484237671\n",
      "Substitute: ones, BertScore: 0.9408783912658691\n",
      "Substitute: reported, BertScore: 0.938798725605011\n",
      "Substitute: shooting, BertScore: 0.9364751577377319\n",
      "Substitute: all, BertScore: 0.9356069564819336\n",
      "Substitute: that, BertScore: 0.9355856776237488\n",
      "Substitute: ever, BertScore: 0.9333577752113342\n",
      "Substitute: one, BertScore: 0.9332798719406128\n",
      "Substitute: yet, BertScore: 0.9276463389396667\n",
      "Substitute: thing, BertScore: 0.9209944605827332\n",
      "Substitute: events, BertScore: 0.9191976189613342\n",
      "Substitute: than, BertScore: 0.9183102250099182\n",
      "top-10 substitutes based on bertscores in context: ['murders', 'killings', 'murder', 'deaths', 'crimes', 'fatalities', 'incidents', 'offenses', 'accidents', 'occurrences']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: fatalities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: casualties, BertScore: 0.9867613911628723\n",
      "Substitute: deaths, BertScore: 0.9822032451629639\n",
      "Substitute: victims, BertScore: 0.9756830930709839\n",
      "Substitute: dead, BertScore: 0.9737601280212402\n",
      "Substitute: arrests, BertScore: 0.9732313752174377\n",
      "Substitute: accidents, BertScore: 0.972608208656311\n",
      "Substitute: incidents, BertScore: 0.9725661277770996\n",
      "Substitute: perpetrators, BertScore: 0.9725624322891235\n",
      "Substitute: corpses, BertScore: 0.9718834161758423\n",
      "Substitute: killed, BertScore: 0.9710057377815247\n",
      "Substitute: injuries, BertScore: 0.9708747267723083\n",
      "Substitute: survivors, BertScore: 0.9706991910934448\n",
      "Substitute: murders, BertScore: 0.9696049094200134\n",
      "Substitute: bodies, BertScore: 0.9688927531242371\n",
      "Substitute: killers, BertScore: 0.9684350490570068\n",
      "Substitute: killings, BertScore: 0.9683699607849121\n",
      "Substitute: individuals, BertScore: 0.9636571407318115\n",
      "Substitute: persons, BertScore: 0.9622888565063477\n",
      "Substitute: members, BertScore: 0.9606223702430725\n",
      "Substitute: men, BertScore: 0.9601153135299683\n",
      "Substitute: people, BertScore: 0.9600841999053955\n",
      "Substitute: officers, BertScore: 0.9581611156463623\n",
      "Substitute: women, BertScore: 0.9561023116111755\n",
      "Substitute: others, BertScore: 0.9558770060539246\n",
      "Substitute: officials, BertScore: 0.955668032169342\n",
      "Substitute: cases, BertScore: 0.955466628074646\n",
      "Substitute: investigators, BertScore: 0.9520615935325623\n",
      "Substitute: families, BertScore: 0.9498440623283386\n",
      "Substitute: also, BertScore: 0.9496405124664307\n",
      "top-10 substitutes based on bertscores in context: ['casualties', 'deaths', 'victims', 'dead', 'arrests', 'accidents', 'incidents', 'perpetrators', 'corpses', 'killed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: underscores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: confirms, BertScore: 0.958895742893219\n",
      "Substitute: highlights, BertScore: 0.9583057165145874\n",
      "Substitute: indicates, BertScore: 0.9578492641448975\n",
      "Substitute: reflects, BertScore: 0.9578424096107483\n",
      "Substitute: highlighted, BertScore: 0.9572864770889282\n",
      "Substitute: illustrates, BertScore: 0.9567456245422363\n",
      "Substitute: demonstrates, BertScore: 0.9555369019508362\n",
      "Substitute: exposed, BertScore: 0.9552469849586487\n",
      "Substitute: ignores, BertScore: 0.9548524022102356\n",
      "Substitute: reveals, BertScore: 0.9546807408332825\n",
      "Substitute: outlines, BertScore: 0.9536677002906799\n",
      "Substitute: revealed, BertScore: 0.9535007476806641\n",
      "Substitute: addresses, BertScore: 0.9531505107879639\n",
      "Substitute: explains, BertScore: 0.9523545503616333\n",
      "Substitute: addressed, BertScore: 0.9516714811325073\n",
      "Substitute: depicts, BertScore: 0.9509909749031067\n",
      "Substitute: shows, BertScore: 0.9509578943252563\n",
      "Substitute: describes, BertScore: 0.9509515762329102\n",
      "Substitute: confronts, BertScore: 0.9505453109741211\n",
      "Substitute: tackles, BertScore: 0.9503979682922363\n",
      "Substitute: introduces, BertScore: 0.9503208994865417\n",
      "Substitute: raises, BertScore: 0.9501919746398926\n",
      "Substitute: presents, BertScore: 0.949975311756134\n",
      "Substitute: explores, BertScore: 0.9498984813690186\n",
      "Substitute: increases, BertScore: 0.9490530490875244\n",
      "Substitute: discusses, BertScore: 0.9489515423774719\n",
      "Substitute: creates, BertScore: 0.9458053112030029\n",
      "Substitute: details, BertScore: 0.9455844163894653\n",
      "Substitute: removes, BertScore: 0.9454843401908875\n",
      "Substitute: poses, BertScore: 0.9449024200439453\n",
      "top-10 substitutes based on bertscores in context: ['confirms', 'highlights', 'indicates', 'reflects', 'highlighted', 'illustrates', 'demonstrates', 'exposed', 'ignores', 'reveals']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: annul\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: void, BertScore: 0.983828604221344\n",
      "Substitute: cancel, BertScore: 0.9832757115364075\n",
      "Substitute: terminate, BertScore: 0.9831087589263916\n",
      "Substitute: suspend, BertScore: 0.9816833734512329\n",
      "Substitute: modify, BertScore: 0.9789918661117554\n",
      "Substitute: honor, BertScore: 0.9780007600784302\n",
      "Substitute: delay, BertScore: 0.9777781963348389\n",
      "Substitute: alter, BertScore: 0.9773117899894714\n",
      "Substitute: ignore, BertScore: 0.9770586490631104\n",
      "Substitute: amend, BertScore: 0.9764158129692078\n",
      "Substitute: disregard, BertScore: 0.9756346344947815\n",
      "Substitute: confirm, BertScore: 0.9754692316055298\n",
      "Substitute: approve, BertScore: 0.9754065275192261\n",
      "Substitute: review, BertScore: 0.9737396240234375\n",
      "Substitute: miss, BertScore: 0.9730270504951477\n",
      "Substitute: contest, BertScore: 0.972504734992981\n",
      "Substitute: declare, BertScore: 0.9717302322387695\n",
      "Substitute: announce, BertScore: 0.9714575409889221\n",
      "Substitute: forget, BertScore: 0.9704636931419373\n",
      "Substitute: publish, BertScore: 0.9704553484916687\n",
      "Substitute: control, BertScore: 0.9700926542282104\n",
      "Substitute: verify, BertScore: 0.9695952534675598\n",
      "Substitute: audit, BertScore: 0.9689244627952576\n",
      "Substitute: observe, BertScore: 0.9688053727149963\n",
      "Substitute: check, BertScore: 0.9686460494995117\n",
      "Substitute: report, BertScore: 0.9685124158859253\n",
      "Substitute: examine, BertScore: 0.9681215286254883\n",
      "Substitute: monitor, BertScore: 0.9677478671073914\n",
      "Substitute: broadcast, BertScore: 0.9676268100738525\n",
      "Substitute: write, BertScore: 0.9653366804122925\n",
      "top-10 substitutes based on bertscores in context: ['void', 'cancel', 'terminate', 'suspend', 'modify', 'honor', 'delay', 'alter', 'ignore', 'amend']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: deployed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: dispatched, BertScore: 0.9928059577941895\n",
      "Substitute: stationed, BertScore: 0.9920101165771484\n",
      "Substitute: posted, BertScore: 0.9911976456642151\n",
      "Substitute: sent, BertScore: 0.9886420369148254\n",
      "Substitute: mobilized, BertScore: 0.9876706600189209\n",
      "Substitute: employed, BertScore: 0.9847626090049744\n",
      "Substitute: transferred, BertScore: 0.9844081997871399\n",
      "Substitute: active, BertScore: 0.9837868213653564\n",
      "Substitute: installed, BertScore: 0.9835219383239746\n",
      "Substitute: assembled, BertScore: 0.983083963394165\n",
      "Substitute: present, BertScore: 0.9827836155891418\n",
      "Substitute: engaged, BertScore: 0.9823862314224243\n",
      "Substitute: placed, BertScore: 0.9820612668991089\n",
      "Substitute: based, BertScore: 0.9816563129425049\n",
      "Substitute: operating, BertScore: 0.981539785861969\n",
      "Substitute: arrived, BertScore: 0.981263279914856\n",
      "Substitute: recruited, BertScore: 0.9808899164199829\n",
      "Substitute: retained, BertScore: 0.9799885749816895\n",
      "Substitute: used, BertScore: 0.9790626764297485\n",
      "Substitute: withdrawn, BertScore: 0.9779069423675537\n",
      "Substitute: registered, BertScore: 0.9768521785736084\n",
      "Substitute: trained, BertScore: 0.9759798645973206\n",
      "Substitute: arriving, BertScore: 0.974808931350708\n",
      "Substitute: detained, BertScore: 0.9742660522460938\n",
      "Substitute: working, BertScore: 0.9734066128730774\n",
      "Substitute: held, BertScore: 0.9728947877883911\n",
      "Substitute: serving, BertScore: 0.9726896286010742\n",
      "Substitute: wounded, BertScore: 0.9622041583061218\n",
      "Substitute: killed, BertScore: 0.9617418050765991\n",
      "top-10 substitutes based on bertscores in context: ['dispatched', 'stationed', 'posted', 'sent', 'mobilized', 'employed', 'transferred', 'active', 'installed', 'assembled']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: revered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: respected, BertScore: 0.9957846403121948\n",
      "Substitute: celebrated, BertScore: 0.9954436421394348\n",
      "Substitute: sacred, BertScore: 0.9946582317352295\n",
      "Substitute: prized, BertScore: 0.9934065341949463\n",
      "Substitute: renowned, BertScore: 0.9933847784996033\n",
      "Substitute: beloved, BertScore: 0.9929123520851135\n",
      "Substitute: prominent, BertScore: 0.9922069311141968\n",
      "Substitute: coveted, BertScore: 0.9920874834060669\n",
      "Substitute: prestigious, BertScore: 0.9919258952140808\n",
      "Substitute: famous, BertScore: 0.9917491674423218\n",
      "Substitute: known, BertScore: 0.9907437562942505\n",
      "Substitute: popular, BertScore: 0.9905322194099426\n",
      "Substitute: holy, BertScore: 0.9903945922851562\n",
      "Substitute: high, BertScore: 0.9903823733329773\n",
      "Substitute: regular, BertScore: 0.9903393983840942\n",
      "Substitute: traditional, BertScore: 0.9901902079582214\n",
      "Substitute: favorite, BertScore: 0.9900119304656982\n",
      "Substitute: major, BertScore: 0.9899263978004456\n",
      "Substitute: landmark, BertScore: 0.9890861511230469\n",
      "Substitute: central, BertScore: 0.9890256524085999\n",
      "Substitute: great, BertScore: 0.9884179830551147\n",
      "Substitute: key, BertScore: 0.988379955291748\n",
      "Substitute: notorious, BertScore: 0.9881610870361328\n",
      "Substitute: special, BertScore: 0.988060712814331\n",
      "Substitute: religious, BertScore: 0.9879738688468933\n",
      "Substitute: common, BertScore: 0.9869577288627625\n",
      "Substitute: local, BertScore: 0.9857029318809509\n",
      "Substitute: rare, BertScore: 0.9850226640701294\n",
      "Substitute: pilgrimage, BertScore: 0.9844633340835571\n",
      "top-10 substitutes based on bertscores in context: ['respected', 'celebrated', 'sacred', 'prized', 'renowned', 'beloved', 'prominent', 'coveted', 'prestigious', 'famous']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: evade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: escape, BertScore: 0.9938967227935791\n",
      "Substitute: avoid, BertScore: 0.9922116994857788\n",
      "Substitute: resist, BertScore: 0.9899725914001465\n",
      "Substitute: dodge, BertScore: 0.9898015260696411\n",
      "Substitute: gain, BertScore: 0.9846354126930237\n",
      "Substitute: pursue, BertScore: 0.9823424220085144\n",
      "Substitute: prevent, BertScore: 0.9822039008140564\n",
      "Substitute: get, BertScore: 0.9821453094482422\n",
      "Substitute: obtain, BertScore: 0.981623113155365\n",
      "Substitute: attain, BertScore: 0.9812867641448975\n",
      "Substitute: seek, BertScore: 0.9812653660774231\n",
      "Substitute: hide, BertScore: 0.9806251525878906\n",
      "Substitute: force, BertScore: 0.9798592925071716\n",
      "Substitute: conceal, BertScore: 0.9797285199165344\n",
      "Substitute: achieve, BertScore: 0.9791760444641113\n",
      "Substitute: advance, BertScore: 0.9789589643478394\n",
      "Substitute: enforce, BertScore: 0.9785415530204773\n",
      "Substitute: ensure, BertScore: 0.9781824946403503\n",
      "Substitute: reach, BertScore: 0.9777615070343018\n",
      "Substitute: find, BertScore: 0.9770343899726868\n",
      "Substitute: block, BertScore: 0.9769025444984436\n",
      "Substitute: accomplish, BertScore: 0.9764377474784851\n",
      "Substitute: effect, BertScore: 0.9762608408927917\n",
      "Substitute: approximate, BertScore: 0.9754058718681335\n",
      "Substitute: detect, BertScore: 0.9746952056884766\n",
      "Substitute: manage, BertScore: 0.9737874269485474\n",
      "Substitute: retrieve, BertScore: 0.9724365472793579\n",
      "Substitute: verify, BertScore: 0.9712241291999817\n",
      "Substitute: determine, BertScore: 0.969084620475769\n",
      "top-10 substitutes based on bertscores in context: ['escape', 'avoid', 'resist', 'dodge', 'gain', 'pursue', 'prevent', 'get', 'obtain', 'attain']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: alleged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: suspected, BertScore: 0.9972242116928101\n",
      "Substitute: purported, BertScore: 0.9966782927513123\n",
      "Substitute: allegedly, BertScore: 0.9956377148628235\n",
      "Substitute: apparent, BertScore: 0.9948894381523132\n",
      "Substitute: reported, BertScore: 0.9936880469322205\n",
      "Substitute: attempted, BertScore: 0.9931820631027222\n",
      "Substitute: possible, BertScore: 0.992728054523468\n",
      "Substitute: suspect, BertScore: 0.992292046546936\n",
      "Substitute: potential, BertScore: 0.9916633367538452\n",
      "Substitute: deliberate, BertScore: 0.9907618761062622\n",
      "Substitute: ongoing, BertScore: 0.9904708862304688\n",
      "Substitute: illegal, BertScore: 0.9904213547706604\n",
      "Substitute: unlawful, BertScore: 0.9900795221328735\n",
      "Substitute: fraudulent, BertScore: 0.9898761510848999\n",
      "Substitute: disputed, BertScore: 0.989858090877533\n",
      "Substitute: rampant, BertScore: 0.9896470308303833\n",
      "Substitute: fake, BertScore: 0.9895970821380615\n",
      "Substitute: internal, BertScore: 0.9895901083946228\n",
      "Substitute: widespread, BertScore: 0.9893498420715332\n",
      "Substitute: false, BertScore: 0.9891636371612549\n",
      "Substitute: official, BertScore: 0.9890656471252441\n",
      "Substitute: massive, BertScore: 0.989056408405304\n",
      "Substitute: recent, BertScore: 0.9888961315155029\n",
      "Substitute: rigged, BertScore: 0.9887447953224182\n",
      "Substitute: federal, BertScore: 0.9887268543243408\n",
      "Substitute: state, BertScore: 0.9884472489356995\n",
      "Substitute: actual, BertScore: 0.9879723787307739\n",
      "Substitute: new, BertScore: 0.9874876737594604\n",
      "Substitute: the, BertScore: 0.9841201901435852\n",
      "top-10 substitutes based on bertscores in context: ['suspected', 'purported', 'allegedly', 'apparent', 'reported', 'attempted', 'possible', 'suspect', 'potential', 'deliberate']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: indignation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: frustration, BertScore: 0.9596289396286011\n",
      "Substitute: resentment, BertScore: 0.958927571773529\n",
      "Substitute: anger, BertScore: 0.9582949280738831\n",
      "Substitute: outrage, BertScore: 0.9582302570343018\n",
      "Substitute: dissatisfaction, BertScore: 0.9562568664550781\n",
      "Substitute: discontent, BertScore: 0.9551259279251099\n",
      "Substitute: hysteria, BertScore: 0.9541935324668884\n",
      "Substitute: protest, BertScore: 0.9538251161575317\n",
      "Substitute: condemnation, BertScore: 0.9531428217887878\n",
      "Substitute: unease, BertScore: 0.9522674679756165\n",
      "Substitute: agitation, BertScore: 0.9519824981689453\n",
      "Substitute: enthusiasm, BertScore: 0.9514979720115662\n",
      "Substitute: sympathy, BertScore: 0.9513862729072571\n",
      "Substitute: reaction, BertScore: 0.9495909810066223\n",
      "Substitute: panic, BertScore: 0.949474036693573\n",
      "Substitute: anxiety, BertScore: 0.9494126439094543\n",
      "Substitute: concern, BertScore: 0.9485725164413452\n",
      "Substitute: alarm, BertScore: 0.9479420185089111\n",
      "Substitute: fear, BertScore: 0.947314977645874\n",
      "Substitute: unrest, BertScore: 0.9466671943664551\n",
      "Substitute: tension, BertScore: 0.945580780506134\n",
      "Substitute: support, BertScore: 0.9450340270996094\n",
      "Substitute: sentiment, BertScore: 0.944376528263092\n",
      "Substitute: suspicion, BertScore: 0.9434447884559631\n",
      "Substitute: speculation, BertScore: 0.9427080750465393\n",
      "Substitute: awareness, BertScore: 0.942333996295929\n",
      "Substitute: pressure, BertScore: 0.9414944648742676\n",
      "Substitute: perception, BertScore: 0.940828800201416\n",
      "Substitute: confidence, BertScore: 0.9407274127006531\n",
      "Substitute: opinion, BertScore: 0.9405481815338135\n",
      "top-10 substitutes based on bertscores in context: ['frustration', 'resentment', 'anger', 'outrage', 'dissatisfaction', 'discontent', 'hysteria', 'protest', 'condemnation', 'unease']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: lingering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: continuing, BertScore: 0.9945206642150879\n",
      "Substitute: residual, BertScore: 0.9943978190422058\n",
      "Substitute: persistent, BertScore: 0.9936688542366028\n",
      "Substitute: lasting, BertScore: 0.9932959079742432\n",
      "Substitute: continued, BertScore: 0.99327552318573\n",
      "Substitute: renewed, BertScore: 0.992993175983429\n",
      "Substitute: lurking, BertScore: 0.9928038716316223\n",
      "Substitute: ongoing, BertScore: 0.9925985932350159\n",
      "Substitute: rising, BertScore: 0.992357611656189\n",
      "Substitute: recurring, BertScore: 0.9920414686203003\n",
      "Substitute: growing, BertScore: 0.9918581247329712\n",
      "Substitute: looming, BertScore: 0.9916127324104309\n",
      "Substitute: heightened, BertScore: 0.9913309812545776\n",
      "Substitute: fresh, BertScore: 0.9908351302146912\n",
      "Substitute: serious, BertScore: 0.9907487630844116\n",
      "Substitute: strong, BertScore: 0.9905151724815369\n",
      "Substitute: sharp, BertScore: 0.9901508688926697\n",
      "Substitute: deep, BertScore: 0.9899402856826782\n",
      "Substitute: recent, BertScore: 0.9896861910820007\n",
      "Substitute: distinct, BertScore: 0.9890695810317993\n",
      "Substitute: new, BertScore: 0.9889711141586304\n",
      "Substitute: deeper, BertScore: 0.9887866377830505\n",
      "Substitute: further, BertScore: 0.988659679889679\n",
      "Substitute: possible, BertScore: 0.9885076284408569\n",
      "Substitute: stronger, BertScore: 0.9883086085319519\n",
      "Substitute: clear, BertScore: 0.988307535648346\n",
      "Substitute: broader, BertScore: 0.9880966544151306\n",
      "Substitute: personal, BertScore: 0.9875059127807617\n",
      "Substitute: greater, BertScore: 0.9864789843559265\n",
      "top-10 substitutes based on bertscores in context: ['continuing', 'residual', 'persistent', 'lasting', 'continued', 'renewed', 'lurking', 'ongoing', 'rising', 'recurring']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: barren\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: arid, BertScore: 0.9910562038421631\n",
      "Substitute: flat, BertScore: 0.9908544421195984\n",
      "Substitute: stony, BertScore: 0.9908232688903809\n",
      "Substitute: lonely, BertScore: 0.9902437925338745\n",
      "Substitute: dry, BertScore: 0.9901868104934692\n",
      "Substitute: rocky, BertScore: 0.9899415373802185\n",
      "Substitute: empty, BertScore: 0.9895783066749573\n",
      "Substitute: sandy, BertScore: 0.9892683625221252\n",
      "Substitute: lifeless, BertScore: 0.9889605045318604\n",
      "Substitute: uninhabited, BertScore: 0.9888546466827393\n",
      "Substitute: desert, BertScore: 0.9885683655738831\n",
      "Substitute: pristine, BertScore: 0.9885293245315552\n",
      "Substitute: plain, BertScore: 0.9882773160934448\n",
      "Substitute: isolated, BertScore: 0.9880897998809814\n",
      "Substitute: fertile, BertScore: 0.9880843758583069\n",
      "Substitute: magnificent, BertScore: 0.9869405031204224\n",
      "Substitute: deep, BertScore: 0.986212968826294\n",
      "Substitute: scattered, BertScore: 0.9860228300094604\n",
      "Substitute: grey, BertScore: 0.9859349727630615\n",
      "Substitute: vast, BertScore: 0.9858659505844116\n",
      "Substitute: blank, BertScore: 0.9857395887374878\n",
      "Substitute: dune, BertScore: 0.9855930209159851\n",
      "Substitute: beautiful, BertScore: 0.9843322038650513\n",
      "Substitute: disputed, BertScore: 0.9830771684646606\n",
      "Substitute: distant, BertScore: 0.9820935726165771\n",
      "Substitute: coral, BertScore: 0.9811335206031799\n",
      "Substitute: surrounding, BertScore: 0.9797689914703369\n",
      "Substitute: two, BertScore: 0.9756087064743042\n",
      "Substitute: virgin, BertScore: 0.9744371771812439\n",
      "top-10 substitutes based on bertscores in context: ['arid', 'flat', 'stony', 'lonely', 'dry', 'rocky', 'empty', 'sandy', 'lifeless', 'uninhabited']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: falsifications\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: errors, BertScore: 0.9301047921180725\n",
      "Substitute: lies, BertScore: 0.925476610660553\n",
      "Substitute: irregularities, BertScore: 0.9242798089981079\n",
      "Substitute: violations, BertScore: 0.9231774210929871\n",
      "Substitute: leaks, BertScore: 0.9228806495666504\n",
      "Substitute: failures, BertScore: 0.9194813966751099\n",
      "Substitute: mistakes, BertScore: 0.9194501638412476\n",
      "Substitute: fraud, BertScore: 0.919161319732666\n",
      "Substitute: cheating, BertScore: 0.9185343980789185\n",
      "Substitute: flaws, BertScore: 0.9164895415306091\n",
      "Substitute: accusations, BertScore: 0.9139783978462219\n",
      "Substitute: allegations, BertScore: 0.9136638641357422\n",
      "Substitute: scandals, BertScore: 0.9132155776023865\n",
      "Substitute: attacks, BertScore: 0.9128687977790833\n",
      "Substitute: criticisms, BertScore: 0.9124321341514587\n",
      "Substitute: incidents, BertScore: 0.9107871055603027\n",
      "Substitute: problems, BertScore: 0.9104293584823608\n",
      "Substitute: advertisements, BertScore: 0.9087544083595276\n",
      "Substitute: controversies, BertScore: 0.9082607626914978\n",
      "Substitute: threats, BertScore: 0.9081885814666748\n",
      "Substitute: complaints, BertScore: 0.907505989074707\n",
      "Substitute: articles, BertScore: 0.9070913791656494\n",
      "Substitute: lawsuits, BertScore: 0.9069172143936157\n",
      "Substitute: insults, BertScore: 0.9068782329559326\n",
      "Substitute: additions, BertScore: 0.9064457416534424\n",
      "Substitute: changes, BertScore: 0.905969500541687\n",
      "Substitute: defamation, BertScore: 0.9054893255233765\n",
      "Substitute: sins, BertScore: 0.9026651382446289\n",
      "Substitute: cases, BertScore: 0.9023109078407288\n",
      "Substitute: issues, BertScore: 0.9004267454147339\n",
      "top-10 substitutes based on bertscores in context: ['errors', 'lies', 'irregularities', 'violations', 'leaks', 'failures', 'mistakes', 'fraud', 'cheating', 'flaws']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: incubated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: unleashed, BertScore: 0.946910560131073\n",
      "Substitute: activated, BertScore: 0.9450026154518127\n",
      "Substitute: triggered, BertScore: 0.9437904357910156\n",
      "Substitute: initiated, BertScore: 0.9433162212371826\n",
      "Substitute: contained, BertScore: 0.9429497718811035\n",
      "Substitute: prepared, BertScore: 0.9422293305397034\n",
      "Substitute: concentrated, BertScore: 0.9421254396438599\n",
      "Substitute: centered, BertScore: 0.9417051076889038\n",
      "Substitute: met, BertScore: 0.9416882395744324\n",
      "Substitute: staged, BertScore: 0.9413671493530273\n",
      "Substitute: launched, BertScore: 0.9409926533699036\n",
      "Substitute: dropped, BertScore: 0.9408146142959595\n",
      "Substitute: exposed, BertScore: 0.9406518340110779\n",
      "Substitute: announced, BertScore: 0.939751923084259\n",
      "Substitute: planned, BertScore: 0.9389899969100952\n",
      "Substitute: placed, BertScore: 0.9389501810073853\n",
      "Substitute: recorded, BertScore: 0.9387559294700623\n",
      "Substitute: held, BertScore: 0.9385234713554382\n",
      "Substitute: located, BertScore: 0.9383169412612915\n",
      "Substitute: conducted, BertScore: 0.9377672076225281\n",
      "Substitute: released, BertScore: 0.9371402859687805\n",
      "Substitute: reported, BertScore: 0.9351123571395874\n",
      "Substitute: ongoing, BertScore: 0.9349720478057861\n",
      "Substitute: committed, BertScore: 0.9349347352981567\n",
      "Substitute: detonated, BertScore: 0.9346248507499695\n",
      "Substitute: ended, BertScore: 0.9341682195663452\n",
      "Substitute: raging, BertScore: 0.9335302114486694\n",
      "Substitute: targeted, BertScore: 0.9331264495849609\n",
      "Substitute: occurring, BertScore: 0.9303684234619141\n",
      "Substitute: happening, BertScore: 0.9297983646392822\n",
      "top-10 substitutes based on bertscores in context: ['unleashed', 'activated', 'triggered', 'initiated', 'contained', 'prepared', 'concentrated', 'centered', 'met', 'staged']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: flashpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: moments, BertScore: 0.9678757786750793\n",
      "Substitute: points, BertScore: 0.967272162437439\n",
      "Substitute: ranges, BertScore: 0.9662874341011047\n",
      "Substitute: intervals, BertScore: 0.964847981929779\n",
      "Substitute: locations, BertScore: 0.9644718766212463\n",
      "Substitute: distances, BertScore: 0.9644381403923035\n",
      "Substitute: speeds, BertScore: 0.9618746042251587\n",
      "Substitute: sites, BertScore: 0.9618633389472961\n",
      "Substitute: places, BertScore: 0.9615536332130432\n",
      "Substitute: posts, BertScore: 0.9598618745803833\n",
      "Substitute: targets, BertScore: 0.9597444534301758\n",
      "Substitute: centres, BertScore: 0.9588013887405396\n",
      "Substitute: venues, BertScore: 0.9582608938217163\n",
      "Substitute: areas, BertScore: 0.9580467939376831\n",
      "Substitute: intersections, BertScore: 0.9573028087615967\n",
      "Substitute: stations, BertScore: 0.9572986960411072\n",
      "Substitute: camps, BertScore: 0.9565457105636597\n",
      "Substitute: homes, BertScore: 0.9565198421478271\n",
      "Substitute: roads, BertScore: 0.9558652639389038\n",
      "Substitute: houses, BertScore: 0.9558644890785217\n",
      "Substitute: cities, BertScore: 0.9557585716247559\n",
      "Substitute: times, BertScore: 0.9554429054260254\n",
      "Substitute: airports, BertScore: 0.9553635120391846\n",
      "Substitute: villages, BertScore: 0.954361081123352\n",
      "Substitute: buildings, BertScore: 0.9541529417037964\n",
      "Substitute: shops, BertScore: 0.9541094899177551\n",
      "Substitute: rallies, BertScore: 0.9539991617202759\n",
      "Substitute: schools, BertScore: 0.9538214802742004\n",
      "Substitute: events, BertScore: 0.9529079794883728\n",
      "top-10 substitutes based on bertscores in context: ['moments', 'points', 'ranges', 'intervals', 'locations', 'distances', 'speeds', 'sites', 'places', 'posts']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: prejudiced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: offended, BertScore: 0.9902248382568359\n",
      "Substitute: disadvantaged, BertScore: 0.9899588823318481\n",
      "Substitute: biased, BertScore: 0.9890927076339722\n",
      "Substitute: challenged, BertScore: 0.9885146021842957\n",
      "Substitute: upset, BertScore: 0.9882888793945312\n",
      "Substitute: confused, BertScore: 0.9881513714790344\n",
      "Substitute: bias, BertScore: 0.9880005717277527\n",
      "Substitute: ignorant, BertScore: 0.987806499004364\n",
      "Substitute: mistaken, BertScore: 0.9875632524490356\n",
      "Substitute: disappointed, BertScore: 0.986928403377533\n",
      "Substitute: exposed, BertScore: 0.9864619970321655\n",
      "Substitute: excluded, BertScore: 0.9864559173583984\n",
      "Substitute: wrong, BertScore: 0.9863625764846802\n",
      "Substitute: unfair, BertScore: 0.986353874206543\n",
      "Substitute: invalid, BertScore: 0.9863195419311523\n",
      "Substitute: unhappy, BertScore: 0.9862697720527649\n",
      "Substitute: judged, BertScore: 0.9860305190086365\n",
      "Substitute: neutral, BertScore: 0.9858857989311218\n",
      "Substitute: tested, BertScore: 0.9856319427490234\n",
      "Substitute: beaten, BertScore: 0.9854817390441895\n",
      "Substitute: racist, BertScore: 0.985438346862793\n",
      "Substitute: inferior, BertScore: 0.9853662848472595\n",
      "Substitute: protected, BertScore: 0.9851841330528259\n",
      "Substitute: favored, BertScore: 0.9847123622894287\n",
      "Substitute: favoured, BertScore: 0.9844909310340881\n",
      "Substitute: innocent, BertScore: 0.984097421169281\n",
      "Substitute: represented, BertScore: 0.9837807416915894\n",
      "Substitute: included, BertScore: 0.982700526714325\n",
      "Substitute: satisfied, BertScore: 0.9820898175239563\n",
      "top-10 substitutes based on bertscores in context: ['offended', 'disadvantaged', 'biased', 'challenged', 'upset', 'confused', 'bias', 'ignorant', 'mistaken', 'disappointed']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: conferred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: bestowed, BertScore: 0.9983842968940735\n",
      "Substitute: showered, BertScore: 0.993417501449585\n",
      "Substitute: granted, BertScore: 0.9928797483444214\n",
      "Substitute: awarded, BertScore: 0.9925664663314819\n",
      "Substitute: given, BertScore: 0.9904797673225403\n",
      "Substitute: imposed, BertScore: 0.9896974563598633\n",
      "Substitute: assigned, BertScore: 0.9893655776977539\n",
      "Substitute: offered, BertScore: 0.9891042709350586\n",
      "Substitute: placed, BertScore: 0.9887049198150635\n",
      "Substitute: earned, BertScore: 0.9885722994804382\n",
      "Substitute: afforded, BertScore: 0.9884564876556396\n",
      "Substitute: honored, BertScore: 0.9881006479263306\n",
      "Substitute: won, BertScore: 0.9880931973457336\n",
      "Substitute: administered, BertScore: 0.9878387451171875\n",
      "Substitute: inflicted, BertScore: 0.9877637624740601\n",
      "Substitute: received, BertScore: 0.9869263172149658\n",
      "Substitute: served, BertScore: 0.9867103695869446\n",
      "Substitute: exercised, BertScore: 0.986142635345459\n",
      "Substitute: blessed, BertScore: 0.9859181642532349\n",
      "Substitute: held, BertScore: 0.9855993390083313\n",
      "Substitute: applied, BertScore: 0.9852660298347473\n",
      "Substitute: passed, BertScore: 0.9852308034896851\n",
      "Substitute: gained, BertScore: 0.9847519397735596\n",
      "Substitute: reserved, BertScore: 0.9846776723861694\n",
      "Substitute: obtained, BertScore: 0.9842654466629028\n",
      "Substitute: landed, BertScore: 0.9841032028198242\n",
      "Substitute: provided, BertScore: 0.9839773178100586\n",
      "Substitute: displayed, BertScore: 0.9832648038864136\n",
      "Substitute: claimed, BertScore: 0.9813300371170044\n",
      "top-10 substitutes based on bertscores in context: ['bestowed', 'showered', 'granted', 'awarded', 'given', 'imposed', 'assigned', 'offered', 'placed', 'earned']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: alighting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: marching, BertScore: 0.9625602960586548\n",
      "Substitute: landing, BertScore: 0.9605790376663208\n",
      "Substitute: driving, BertScore: 0.9598836302757263\n",
      "Substitute: stopping, BertScore: 0.9596636891365051\n",
      "Substitute: departing, BertScore: 0.959606409072876\n",
      "Substitute: flying, BertScore: 0.9594880938529968\n",
      "Substitute: riding, BertScore: 0.9594124555587769\n",
      "Substitute: crossing, BertScore: 0.9587329626083374\n",
      "Substitute: appearing, BertScore: 0.9578850865364075\n",
      "Substitute: striking, BertScore: 0.9575853943824768\n",
      "Substitute: burning, BertScore: 0.956981360912323\n",
      "Substitute: patrolling, BertScore: 0.9569178819656372\n",
      "Substitute: firing, BertScore: 0.9564851522445679\n",
      "Substitute: travelling, BertScore: 0.9563347101211548\n",
      "Substitute: traveling, BertScore: 0.9558788537979126\n",
      "Substitute: arriving, BertScore: 0.9558756947517395\n",
      "Substitute: shooting, BertScore: 0.9553223848342896\n",
      "Substitute: staying, BertScore: 0.9544581770896912\n",
      "Substitute: returning, BertScore: 0.9541430473327637\n",
      "Substitute: practicing, BertScore: 0.9541178941726685\n",
      "Substitute: going, BertScore: 0.9531331658363342\n",
      "Substitute: proceeding, BertScore: 0.9531081318855286\n",
      "Substitute: coming, BertScore: 0.9522902369499207\n",
      "Substitute: turning, BertScore: 0.9520809054374695\n",
      "Substitute: leaving, BertScore: 0.951089084148407\n",
      "Substitute: being, BertScore: 0.950050413608551\n",
      "Substitute: continuing, BertScore: 0.9483605027198792\n",
      "Substitute: arrival, BertScore: 0.946800172328949\n",
      "Substitute: starting, BertScore: 0.9448196887969971\n",
      "top-10 substitutes based on bertscores in context: ['marching', 'landing', 'driving', 'stopping', 'departing', 'flying', 'riding', 'crossing', 'appearing', 'striking']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: illegitimate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: illicit, BertScore: 0.9943081140518188\n",
      "Substitute: illegal, BertScore: 0.9941896200180054\n",
      "Substitute: fraudulent, BertScore: 0.9939051866531372\n",
      "Substitute: unauthorized, BertScore: 0.9929953217506409\n",
      "Substitute: unlawful, BertScore: 0.9929516911506653\n",
      "Substitute: unwanted, BertScore: 0.9929381012916565\n",
      "Substitute: corrupt, BertScore: 0.9923609495162964\n",
      "Substitute: false, BertScore: 0.9922952055931091\n",
      "Substitute: corrupted, BertScore: 0.9921408891677856\n",
      "Substitute: tainted, BertScore: 0.9912353754043579\n",
      "Substitute: fake, BertScore: 0.9912275075912476\n",
      "Substitute: obsolete, BertScore: 0.9911936521530151\n",
      "Substitute: unconstitutional, BertScore: 0.9911044836044312\n",
      "Substitute: malicious, BertScore: 0.991064190864563\n",
      "Substitute: legitimate, BertScore: 0.9910314083099365\n",
      "Substitute: innocent, BertScore: 0.9905701875686646\n",
      "Substitute: fictitious, BertScore: 0.9904595613479614\n",
      "Substitute: evil, BertScore: 0.9900505542755127\n",
      "Substitute: unacceptable, BertScore: 0.9896833300590515\n",
      "Substitute: worthless, BertScore: 0.9893845319747925\n",
      "Substitute: stolen, BertScore: 0.9891073703765869\n",
      "Substitute: independent, BertScore: 0.9890134334564209\n",
      "Substitute: monstrous, BertScore: 0.9885934591293335\n",
      "Substitute: sovereign, BertScore: 0.987840473651886\n",
      "Substitute: important, BertScore: 0.9867912530899048\n",
      "Substitute: bloody, BertScore: 0.9865503311157227\n",
      "Substitute: confiscated, BertScore: 0.9857326149940491\n",
      "Substitute: new, BertScore: 0.9844615459442139\n",
      "Substitute: same, BertScore: 0.9799511432647705\n",
      "top-10 substitutes based on bertscores in context: ['illicit', 'illegal', 'fraudulent', 'unauthorized', 'unlawful', 'unwanted', 'corrupt', 'false', 'corrupted', 'tainted']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: extend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: offer, BertScore: 0.9837123155593872\n",
      "Substitute: spread, BertScore: 0.9835013151168823\n",
      "Substitute: grant, BertScore: 0.9831835627555847\n",
      "Substitute: expand, BertScore: 0.9809781312942505\n",
      "Substitute: give, BertScore: 0.9805780053138733\n",
      "Substitute: express, BertScore: 0.9804070591926575\n",
      "Substitute: transfer, BertScore: 0.9795438051223755\n",
      "Substitute: address, BertScore: 0.9785847663879395\n",
      "Substitute: present, BertScore: 0.9785246849060059\n",
      "Substitute: direct, BertScore: 0.97786545753479\n",
      "Substitute: speak, BertScore: 0.9771018028259277\n",
      "Substitute: send, BertScore: 0.977046012878418\n",
      "Substitute: convey, BertScore: 0.9767074584960938\n",
      "Substitute: pass, BertScore: 0.9766435623168945\n",
      "Substitute: relay, BertScore: 0.9758179187774658\n",
      "Substitute: open, BertScore: 0.9746516942977905\n",
      "Substitute: say, BertScore: 0.9741500020027161\n",
      "Substitute: relate, BertScore: 0.9738706350326538\n",
      "Substitute: show, BertScore: 0.9728877544403076\n",
      "Substitute: devote, BertScore: 0.9709188938140869\n",
      "Substitute: communicate, BertScore: 0.9708466529846191\n",
      "Substitute: bring, BertScore: 0.9706313610076904\n",
      "Substitute: return, BertScore: 0.9700316190719604\n",
      "Substitute: share, BertScore: 0.9693064093589783\n",
      "Substitute: continue, BertScore: 0.9688889384269714\n",
      "Substitute: release, BertScore: 0.9676828384399414\n",
      "Substitute: write, BertScore: 0.9653887152671814\n",
      "Substitute: reach, BertScore: 0.9619583487510681\n",
      "Substitute: leave, BertScore: 0.9534887671470642\n",
      "top-10 substitutes based on bertscores in context: ['offer', 'spread', 'grant', 'expand', 'give', 'express', 'transfer', 'address', 'present', 'direct']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: subsequently\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: later, BertScore: 0.9902447462081909\n",
      "Substitute: afterwards, BertScore: 0.9873453378677368\n",
      "Substitute: thereafter, BertScore: 0.9866931438446045\n",
      "Substitute: consequently, BertScore: 0.9849041104316711\n",
      "Substitute: eventually, BertScore: 0.9844641089439392\n",
      "Substitute: ultimately, BertScore: 0.9841437339782715\n",
      "Substitute: promptly, BertScore: 0.980938732624054\n",
      "Substitute: then, BertScore: 0.9799312949180603\n",
      "Substitute: further, BertScore: 0.9783987402915955\n",
      "Substitute: formally, BertScore: 0.9765706658363342\n",
      "Substitute: immediately, BertScore: 0.9743151664733887\n",
      "Substitute: additionally, BertScore: 0.9741237759590149\n",
      "Substitute: finally, BertScore: 0.973774790763855\n",
      "Substitute: therefore, BertScore: 0.9737231135368347\n",
      "Substitute: duly, BertScore: 0.9729291200637817\n",
      "Substitute: initially, BertScore: 0.9727668762207031\n",
      "Substitute: also, BertScore: 0.9718353152275085\n",
      "Substitute: was, BertScore: 0.9705245494842529\n",
      "Substitute: allegedly, BertScore: 0.9695113301277161\n",
      "Substitute: again, BertScore: 0.9675084352493286\n",
      "Substitute: originally, BertScore: 0.9651910662651062\n",
      "Substitute: been, BertScore: 0.9642676711082458\n",
      "Substitute: now, BertScore: 0.9634531736373901\n",
      "Substitute: first, BertScore: 0.9633817672729492\n",
      "Substitute: previously, BertScore: 0.9608709812164307\n",
      "Substitute: being, BertScore: 0.9552807807922363\n",
      "Substitute: is, BertScore: 0.9547867774963379\n",
      "Substitute: not, BertScore: 0.9540385007858276\n",
      "Substitute: were, BertScore: 0.9501840472221375\n",
      "top-10 substitutes based on bertscores in context: ['later', 'afterwards', 'thereafter', 'consequently', 'eventually', 'ultimately', 'promptly', 'then', 'further', 'formally']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: detained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: arrested, BertScore: 0.9961245656013489\n",
      "Substitute: jailed, BertScore: 0.9959364533424377\n",
      "Substitute: imprisoned, BertScore: 0.9959303140640259\n",
      "Substitute: incarcerated, BertScore: 0.9945511817932129\n",
      "Substitute: captured, BertScore: 0.9937793016433716\n",
      "Substitute: seized, BertScore: 0.9932931661605835\n",
      "Substitute: detention, BertScore: 0.992279052734375\n",
      "Substitute: caught, BertScore: 0.9921326637268066\n",
      "Substitute: deported, BertScore: 0.9921001195907593\n",
      "Substitute: tortured, BertScore: 0.9915470480918884\n",
      "Substitute: abducted, BertScore: 0.9914665222167969\n",
      "Substitute: held, BertScore: 0.991409182548523\n",
      "Substitute: expelled, BertScore: 0.9910420179367065\n",
      "Substitute: questioned, BertScore: 0.990755558013916\n",
      "Substitute: investigated, BertScore: 0.9906564950942993\n",
      "Substitute: suspended, BertScore: 0.9906463027000427\n",
      "Substitute: released, BertScore: 0.9906378984451294\n",
      "Substitute: stopped, BertScore: 0.9897906184196472\n",
      "Substitute: freed, BertScore: 0.989395797252655\n",
      "Substitute: charged, BertScore: 0.9891154766082764\n",
      "Substitute: identified, BertScore: 0.9884709119796753\n",
      "Substitute: banned, BertScore: 0.9883567690849304\n",
      "Substitute: kept, BertScore: 0.9882826209068298\n",
      "Substitute: wanted, BertScore: 0.9882205724716187\n",
      "Substitute: interviewed, BertScore: 0.9881482124328613\n",
      "Substitute: placed, BertScore: 0.9879220724105835\n",
      "Substitute: taken, BertScore: 0.9855014085769653\n",
      "Substitute: present, BertScore: 0.9848756194114685\n",
      "Substitute: selected, BertScore: 0.9822429418563843\n",
      "top-10 substitutes based on bertscores in context: ['arrested', 'jailed', 'imprisoned', 'incarcerated', 'captured', 'seized', 'detention', 'caught', 'deported', 'tortured']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: commenced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: began, BertScore: 0.9961802959442139\n",
      "Substitute: started, BertScore: 0.9941836595535278\n",
      "Substitute: begun, BertScore: 0.993599534034729\n",
      "Substitute: concluded, BertScore: 0.9920469522476196\n",
      "Substitute: completed, BertScore: 0.9916962385177612\n",
      "Substitute: undertook, BertScore: 0.9916343688964844\n",
      "Substitute: obtained, BertScore: 0.9907459616661072\n",
      "Substitute: pursued, BertScore: 0.9906825423240662\n",
      "Substitute: finished, BertScore: 0.9899685382843018\n",
      "Substitute: received, BertScore: 0.9887033700942993\n",
      "Substitute: did, BertScore: 0.988208532333374\n",
      "Substitute: continued, BertScore: 0.9880298376083374\n",
      "Substitute: entered, BertScore: 0.9879962801933289\n",
      "Substitute: attended, BertScore: 0.9871689081192017\n",
      "Substitute: opened, BertScore: 0.9867374300956726\n",
      "Substitute: conducted, BertScore: 0.9854509234428406\n",
      "Substitute: graduated, BertScore: 0.9854120016098022\n",
      "Substitute: beginning, BertScore: 0.9852650165557861\n",
      "Substitute: performed, BertScore: 0.9852170348167419\n",
      "Substitute: ended, BertScore: 0.9851428270339966\n",
      "Substitute: enrolled, BertScore: 0.9840670824050903\n",
      "Substitute: established, BertScore: 0.9839233160018921\n",
      "Substitute: resumed, BertScore: 0.9837903380393982\n",
      "Substitute: begins, BertScore: 0.9834197163581848\n",
      "Substitute: joined, BertScore: 0.9777342081069946\n",
      "Substitute: expanded, BertScore: 0.9776002168655396\n",
      "Substitute: ceased, BertScore: 0.9738384485244751\n",
      "Substitute: complete, BertScore: 0.9723682403564453\n",
      "Substitute: begin, BertScore: 0.9714140295982361\n",
      "top-10 substitutes based on bertscores in context: ['began', 'started', 'begun', 'concluded', 'completed', 'undertook', 'obtained', 'pursued', 'finished', 'received']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: intentions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: intent, BertScore: 0.9950166344642639\n",
      "Substitute: plans, BertScore: 0.9929658770561218\n",
      "Substitute: plan, BertScore: 0.9909694194793701\n",
      "Substitute: ambitions, BertScore: 0.9907968044281006\n",
      "Substitute: hopes, BertScore: 0.9889465570449829\n",
      "Substitute: aim, BertScore: 0.9880768060684204\n",
      "Substitute: thoughts, BertScore: 0.9868963360786438\n",
      "Substitute: goal, BertScore: 0.985660970211029\n",
      "Substitute: promise, BertScore: 0.9847859740257263\n",
      "Substitute: hope, BertScore: 0.984691321849823\n",
      "Substitute: goals, BertScore: 0.9844115972518921\n",
      "Substitute: ideas, BertScore: 0.9834365844726562\n",
      "Substitute: interest, BertScore: 0.9830588102340698\n",
      "Substitute: prospects, BertScore: 0.9817516207695007\n",
      "Substitute: idea, BertScore: 0.9815507531166077\n",
      "Substitute: options, BertScore: 0.9801741242408752\n",
      "Substitute: possibility, BertScore: 0.9796401858329773\n",
      "Substitute: interests, BertScore: 0.9795381426811218\n",
      "Substitute: option, BertScore: 0.9789818525314331\n",
      "Substitute: purpose, BertScore: 0.9788745641708374\n",
      "Substitute: agenda, BertScore: 0.9779883623123169\n",
      "Substitute: policy, BertScore: 0.9769798517227173\n",
      "Substitute: means, BertScore: 0.9752709865570068\n",
      "Substitute: chances, BertScore: 0.9741901159286499\n",
      "Substitute: concern, BertScore: 0.9728810787200928\n",
      "Substitute: fear, BertScore: 0.9720828533172607\n",
      "Substitute: concerns, BertScore: 0.9712646007537842\n",
      "Substitute: regrets, BertScore: 0.9643913507461548\n",
      "top-10 substitutes based on bertscores in context: ['intent', 'plans', 'plan', 'ambitions', 'hopes', 'aim', 'thoughts', 'goal', 'promise', 'hope']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: disruptive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: disturbing, BertScore: 0.9846034646034241\n",
      "Substitute: disrupt, BertScore: 0.9844142198562622\n",
      "Substitute: disruption, BertScore: 0.9835017323493958\n",
      "Substitute: damaging, BertScore: 0.9833083152770996\n",
      "Substitute: destructive, BertScore: 0.9830320477485657\n",
      "Substitute: harmful, BertScore: 0.9828853011131287\n",
      "Substitute: distracting, BertScore: 0.9828349947929382\n",
      "Substitute: critical, BertScore: 0.982546329498291\n",
      "Substitute: inappropriate, BertScore: 0.9823869466781616\n",
      "Substitute: hostile, BertScore: 0.9822486639022827\n",
      "Substitute: detrimental, BertScore: 0.982151985168457\n",
      "Substitute: dangerous, BertScore: 0.9821316599845886\n",
      "Substitute: offensive, BertScore: 0.9820758700370789\n",
      "Substitute: threatening, BertScore: 0.9820725321769714\n",
      "Substitute: repetitive, BertScore: 0.9819861650466919\n",
      "Substitute: creative, BertScore: 0.9819239377975464\n",
      "Substitute: unwanted, BertScore: 0.9818606376647949\n",
      "Substitute: negative, BertScore: 0.98175048828125\n",
      "Substitute: disturbance, BertScore: 0.9817121624946594\n",
      "Substitute: violent, BertScore: 0.981367826461792\n",
      "Substitute: illegal, BertScore: 0.9812642335891724\n",
      "Substitute: malicious, BertScore: 0.9812431335449219\n",
      "Substitute: positive, BertScore: 0.9807994365692139\n",
      "Substitute: interfering, BertScore: 0.9807976484298706\n",
      "Substitute: constructive, BertScore: 0.980792224407196\n",
      "Substitute: sexual, BertScore: 0.9798159599304199\n",
      "Substitute: harm, BertScore: 0.9790074825286865\n",
      "Substitute: provocative, BertScore: 0.9778438210487366\n",
      "Substitute: communication, BertScore: 0.9776397347450256\n",
      "Substitute: blocking, BertScore: 0.9734303951263428\n",
      "top-10 substitutes based on bertscores in context: ['disturbing', 'disrupt', 'disruption', 'damaging', 'destructive', 'harmful', 'distracting', 'critical', 'inappropriate', 'hostile']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: outskirts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: fringe, BertScore: 0.9947394132614136\n",
      "Substitute: edge, BertScore: 0.9935723543167114\n",
      "Substitute: edges, BertScore: 0.9923263192176819\n",
      "Substitute: periphery, BertScore: 0.9921474456787109\n",
      "Substitute: side, BertScore: 0.9906743764877319\n",
      "Substitute: suburbs, BertScore: 0.9904879927635193\n",
      "Substitute: verge, BertScore: 0.9904864430427551\n",
      "Substitute: doorstep, BertScore: 0.9897974729537964\n",
      "Substitute: perimeter, BertScore: 0.9891946911811829\n",
      "Substitute: sector, BertScore: 0.9885497093200684\n",
      "Substitute: corner, BertScore: 0.987677276134491\n",
      "Substitute: end, BertScore: 0.9876247644424438\n",
      "Substitute: flank, BertScore: 0.9871242642402649\n",
      "Substitute: tip, BertScore: 0.9870631694793701\n",
      "Substitute: bank, BertScore: 0.98670494556427\n",
      "Substitute: suburb, BertScore: 0.9864987134933472\n",
      "Substitute: face, BertScore: 0.9859700202941895\n",
      "Substitute: part, BertScore: 0.9858334064483643\n",
      "Substitute: floor, BertScore: 0.9857329726219177\n",
      "Substitute: streets, BertScore: 0.9856798648834229\n",
      "Substitute: corridor, BertScore: 0.9854143261909485\n",
      "Substitute: outside, BertScore: 0.9852952361106873\n",
      "Substitute: area, BertScore: 0.9852578639984131\n",
      "Substitute: quarter, BertScore: 0.9850358366966248\n",
      "Substitute: section, BertScore: 0.9840750694274902\n",
      "Substitute: entrance, BertScore: 0.983992874622345\n",
      "Substitute: square, BertScore: 0.9834603071212769\n",
      "Substitute: front, BertScore: 0.983027994632721\n",
      "Substitute: street, BertScore: 0.9812753200531006\n",
      "top-10 substitutes based on bertscores in context: ['fringe', 'edge', 'edges', 'periphery', 'side', 'suburbs', 'verge', 'doorstep', 'perimeter', 'sector']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: interred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: buried, BertScore: 0.9934215545654297\n",
      "Substitute: cremated, BertScore: 0.9754663109779358\n",
      "Substitute: resided, BertScore: 0.9743608236312866\n",
      "Substitute: seated, BertScore: 0.972854733467102\n",
      "Substitute: housed, BertScore: 0.970270037651062\n",
      "Substitute: located, BertScore: 0.9688427448272705\n",
      "Substitute: lived, BertScore: 0.9673078656196594\n",
      "Substitute: residing, BertScore: 0.9670845866203308\n",
      "Substitute: burial, BertScore: 0.9649373888969421\n",
      "Substitute: living, BertScore: 0.9649112224578857\n",
      "Substitute: settled, BertScore: 0.962594211101532\n",
      "Substitute: raised, BertScore: 0.9623068571090698\n",
      "Substitute: stored, BertScore: 0.9615213871002197\n",
      "Substitute: honored, BertScore: 0.9608794450759888\n",
      "Substitute: kept, BertScore: 0.9602661728858948\n",
      "Substitute: placed, BertScore: 0.9579219818115234\n",
      "Substitute: present, BertScore: 0.9572224020957947\n",
      "Substitute: married, BertScore: 0.9571933746337891\n",
      "Substitute: died, BertScore: 0.9567846059799194\n",
      "Substitute: listed, BertScore: 0.9566839337348938\n",
      "Substitute: interned, BertScore: 0.9551534652709961\n",
      "Substitute: found, BertScore: 0.9545065760612488\n",
      "Substitute: left, BertScore: 0.9538804888725281\n",
      "Substitute: enrolled, BertScore: 0.9529781341552734\n",
      "Substitute: born, BertScore: 0.9525421261787415\n",
      "Substitute: included, BertScore: 0.9502478837966919\n",
      "Substitute: killed, BertScore: 0.9485303163528442\n",
      "Substitute: sold, BertScore: 0.9458653926849365\n",
      "Substitute: discovered, BertScore: 0.9365644454956055\n",
      "top-10 substitutes based on bertscores in context: ['buried', 'cremated', 'resided', 'seated', 'housed', 'located', 'lived', 'residing', 'burial', 'living']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: epigrams\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: images, BertScore: 0.932165265083313\n",
      "Substitute: texts, BertScore: 0.9320149421691895\n",
      "Substitute: compositions, BertScore: 0.931027352809906\n",
      "Substitute: essays, BertScore: 0.9305769801139832\n",
      "Substitute: drawings, BertScore: 0.9295241236686707\n",
      "Substitute: expressions, BertScore: 0.9286835193634033\n",
      "Substitute: patterns, BertScore: 0.9281370043754578\n",
      "Substitute: narratives, BertScore: 0.9280167818069458\n",
      "Substitute: imagery, BertScore: 0.9278546571731567\n",
      "Substitute: prints, BertScore: 0.9273009300231934\n",
      "Substitute: stories, BertScore: 0.9271827936172485\n",
      "Substitute: structures, BertScore: 0.9266490340232849\n",
      "Substitute: prose, BertScore: 0.9265549778938293\n",
      "Substitute: works, BertScore: 0.9261167049407959\n",
      "Substitute: portraits, BertScore: 0.9258353114128113\n",
      "Substitute: forms, BertScore: 0.9251396656036377\n",
      "Substitute: artwork, BertScore: 0.9240384101867676\n",
      "Substitute: paintings, BertScore: 0.9239784479141235\n",
      "Substitute: installations, BertScore: 0.9234880805015564\n",
      "Substitute: writings, BertScore: 0.9232152700424194\n",
      "Substitute: work, BertScore: 0.9223905801773071\n",
      "Substitute: themes, BertScore: 0.9221724271774292\n",
      "Substitute: poetry, BertScore: 0.9214223027229309\n",
      "Substitute: writing, BertScore: 0.9214057326316833\n",
      "Substitute: murals, BertScore: 0.9208466410636902\n",
      "Substitute: art, BertScore: 0.9198431372642517\n",
      "Substitute: techniques, BertScore: 0.918235182762146\n",
      "Substitute: practices, BertScore: 0.917286217212677\n",
      "Substitute: graffiti, BertScore: 0.9162704348564148\n",
      "top-10 substitutes based on bertscores in context: ['images', 'texts', 'compositions', 'essays', 'drawings', 'expressions', 'patterns', 'narratives', 'imagery', 'prints']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: homicides\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: murders, BertScore: 0.9580742120742798\n",
      "Substitute: crimes, BertScore: 0.9530102610588074\n",
      "Substitute: killings, BertScore: 0.9502726793289185\n",
      "Substitute: deaths, BertScore: 0.9498600959777832\n",
      "Substitute: fatalities, BertScore: 0.9463061690330505\n",
      "Substitute: assaults, BertScore: 0.9456789493560791\n",
      "Substitute: cases, BertScore: 0.9456664323806763\n",
      "Substitute: arrests, BertScore: 0.9411919116973877\n",
      "Substitute: murder, BertScore: 0.9406946897506714\n",
      "Substitute: incidents, BertScore: 0.9402921199798584\n",
      "Substitute: kills, BertScore: 0.9399704337120056\n",
      "Substitute: executions, BertScore: 0.9387356638908386\n",
      "Substitute: accidents, BertScore: 0.9357519745826721\n",
      "Substitute: bombings, BertScore: 0.9341772198677063\n",
      "Substitute: attacks, BertScore: 0.9339936375617981\n",
      "Substitute: fires, BertScore: 0.9332586526870728\n",
      "Substitute: convictions, BertScore: 0.9326874613761902\n",
      "Substitute: investigations, BertScore: 0.9316856265068054\n",
      "Substitute: charges, BertScore: 0.9299522638320923\n",
      "Substitute: raids, BertScore: 0.9292330741882324\n",
      "Substitute: injuries, BertScore: 0.9287923574447632\n",
      "Substitute: explosions, BertScore: 0.9281183481216431\n",
      "Substitute: riots, BertScore: 0.9270728826522827\n",
      "Substitute: violations, BertScore: 0.9265472292900085\n",
      "Substitute: crashes, BertScore: 0.9222896099090576\n",
      "Substitute: counts, BertScore: 0.9182074666023254\n",
      "Substitute: events, BertScore: 0.9155063033103943\n",
      "Substitute: acts, BertScore: 0.8825908303260803\n",
      "top-10 substitutes based on bertscores in context: ['murders', 'crimes', 'killings', 'deaths', 'fatalities', 'assaults', 'cases', 'arrests', 'murder', 'incidents']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: seized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: captured, BertScore: 0.9914412498474121\n",
      "Substitute: recaptured, BertScore: 0.9844969511032104\n",
      "Substitute: conquered, BertScore: 0.983677864074707\n",
      "Substitute: occupied, BertScore: 0.9832524061203003\n",
      "Substitute: raided, BertScore: 0.9831172227859497\n",
      "Substitute: destroyed, BertScore: 0.9827523231506348\n",
      "Substitute: attacked, BertScore: 0.9814780950546265\n",
      "Substitute: invaded, BertScore: 0.9804256558418274\n",
      "Substitute: liberated, BertScore: 0.9801978468894958\n",
      "Substitute: sacked, BertScore: 0.9797492027282715\n",
      "Substitute: kidnapped, BertScore: 0.9786782264709473\n",
      "Substitute: besieged, BertScore: 0.9784672856330872\n",
      "Substitute: overrun, BertScore: 0.9775510430335999\n",
      "Substitute: bombed, BertScore: 0.9774876832962036\n",
      "Substitute: discovered, BertScore: 0.9768815636634827\n",
      "Substitute: ambushed, BertScore: 0.975969672203064\n",
      "Substitute: targeted, BertScore: 0.9756530523300171\n",
      "Substitute: arrested, BertScore: 0.9752808213233948\n",
      "Substitute: annexed, BertScore: 0.9752618074417114\n",
      "Substitute: toppled, BertScore: 0.9751964807510376\n",
      "Substitute: ousted, BertScore: 0.9746761322021484\n",
      "Substitute: defeated, BertScore: 0.9737593531608582\n",
      "Substitute: claimed, BertScore: 0.9733738303184509\n",
      "Substitute: held, BertScore: 0.9715784788131714\n",
      "Substitute: controlled, BertScore: 0.971560001373291\n",
      "Substitute: hit, BertScore: 0.9709433317184448\n",
      "Substitute: killed, BertScore: 0.9681898355484009\n",
      "Substitute: visited, BertScore: 0.9589143395423889\n",
      "Substitute: backed, BertScore: 0.9482425451278687\n",
      "top-10 substitutes based on bertscores in context: ['captured', 'recaptured', 'conquered', 'occupied', 'raided', 'destroyed', 'attacked', 'invaded', 'liberated', 'sacked']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Complex word: impugned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute: reinforced, BertScore: 0.9732668995857239\n",
      "Substitute: impaired, BertScore: 0.9695985317230225\n",
      "Substitute: diminished, BertScore: 0.9691740870475769\n",
      "Substitute: weakened, BertScore: 0.9690858125686646\n",
      "Substitute: shattered, BertScore: 0.96872478723526\n",
      "Substitute: betrayed, BertScore: 0.9687032699584961\n",
      "Substitute: destroyed, BertScore: 0.9686267375946045\n",
      "Substitute: compromised, BertScore: 0.9686120748519897\n",
      "Substitute: affected, BertScore: 0.9684553742408752\n",
      "Substitute: disrupted, BertScore: 0.9682807326316833\n",
      "Substitute: altered, BertScore: 0.9681162238121033\n",
      "Substitute: damaged, BertScore: 0.9679570198059082\n",
      "Substitute: challenged, BertScore: 0.9677156209945679\n",
      "Substitute: reflected, BertScore: 0.9675471186637878\n",
      "Substitute: clouded, BertScore: 0.9664851427078247\n",
      "Substitute: harmed, BertScore: 0.966336190700531\n",
      "Substitute: confirmed, BertScore: 0.9656509757041931\n",
      "Substitute: threatened, BertScore: 0.9652271866798401\n",
      "Substitute: ruined, BertScore: 0.9651889204978943\n",
      "Substitute: reduced, BertScore: 0.9650758504867554\n",
      "Substitute: increased, BertScore: 0.9649227857589722\n",
      "Substitute: endangered, BertScore: 0.964718222618103\n",
      "Substitute: hurt, BertScore: 0.963781476020813\n",
      "Substitute: broke, BertScore: 0.9634302258491516\n",
      "Substitute: lost, BertScore: 0.9617398381233215\n",
      "Substitute: restored, BertScore: 0.9614582061767578\n",
      "Substitute: violated, BertScore: 0.9612171053886414\n",
      "Substitute: disappointed, BertScore: 0.9611274003982544\n",
      "Substitute: changed, BertScore: 0.9610337615013123\n",
      "Substitute: denied, BertScore: 0.9594483375549316\n",
      "top-10 substitutes based on bertscores in context: ['reinforced', 'impaired', 'diminished', 'weakened', 'shattered', 'betrayed', 'destroyed', 'compromised', 'affected', 'disrupted']\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    #print(f\"Sentence: {sentence}\")\n",
    "    #print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, lm_tokenizer.mask_token) # this is different per model (this code line applies to Electra)\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    sentences_concat = f\"{sentence} {lm_tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline (removing elements without token_str key; as this gave errors in the ELECTRA models) .\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "    substitutes = [substitute[\"token_str\"] for substitute in result if \"token_str\" in substitute]\n",
    "    #print(f\"Substitute Generation step: initial substitute list: {substitutes}\\n\")\n",
    "\n",
    "\n",
    "    #2: Morphological Generation and Context Adaptation (Morphological Adaptation):  \n",
    "    ## a) remove noise in the substitutes, by ignoring generated substitutes that are empty or that have unwanted punctuation characters or that start with '##' (this returned errors with the ELECTRA model), and lowercase the substitutes (as some models don't lowercase by default)\n",
    "    ## and lowercase all substitutes. Use try/except statement to prevent other character-related problems to happen\n",
    "\n",
    "    punctuation_set = set(string.punctuation) - set('-') # retained hyphens in case tokenizers don't split on hyphenated compounds\n",
    "    punctuation_set.update({'',''})   # as these curly quotes appeared in the Electra (SG step) results but were not part of the string set\n",
    "\n",
    "    try:\n",
    "        substitutes = [substitute[\"token_str\"].lower() for substitute in result if not any(char in punctuation_set for char in substitute[\"token_str\"]) \n",
    "                       and not substitute[\"token_str\"].startswith('##') and substitute[\"token_str\"].strip() != \"\"]\n",
    "        # print(f\"Morphological Adaptation step a): substitute list without unwanted punctuation characters: {substitutes}\\n\")\n",
    "    except TypeError as error:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    ## b) remove duplicates within the substitute list from the substitute list (duplicates are likely for models that did not lowercase by default)\n",
    "    ## the last mentioned duplicate is removed on purpose, as this may probably be the (previously) uppercased variant of the lowercased substitute (lowercased subs are most likely higher ranked by the model)\n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl:\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    #print(f\"Morphological Adaptation step b): substitute list without duplicates of substitutes: {substitutes_no_dupl}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    ## c) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "\n",
    "    ## first Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## then, remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step c): substitute list without duplicates of the complex word nor inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "\n",
    "\n",
    "    ## d) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step d): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #3: Substitute Selection (SS) by calculating Bert scores: \n",
    "\n",
    "    ## create sentence with the complex word replaced by the substitutes\n",
    "    sentence_with_substitutes = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym]\n",
    "    #print(f\"List with sentences where complex word is substituted: {sentence_with_substitutes}\\n\")\n",
    "\n",
    "\n",
    "    ## calculate BERTScores, and rank the substitutes based on these scores\n",
    "    if len(sentence_with_substitutes) > 0: # to make sure the list with substitutes is always filled\n",
    "        logging.getLogger('transformers').setLevel(logging.ERROR)  # to prevent the same warnings from being printed x times \n",
    "        scores = bert_score.score([sentence]*len(sentence_with_substitutes), sentence_with_substitutes, lang=\"en\", model_type='bert-base-uncased', verbose=False)\n",
    "        logging.getLogger('transformers').setLevel(logging.WARNING) # to reset the logging level back to printing warnings\n",
    "        \n",
    "        # create a list of tuples, each tuple containing a substitute and its score\n",
    "        substitute_score_pairs = list(zip(substitutes_no_dupl_complex_word_no_antonym, scores[0].tolist()))\n",
    "\n",
    "        # sort the list of tuples by the scores (the second element of each tuple), in descending order\n",
    "        sorted_substitute_score_pairs = sorted(substitute_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # # print each substitute with its score\n",
    "        # for substitute, score in sorted_substitute_score_pairs:\n",
    "        #     print(f\"Substitute: {substitute}, BertScore: {score}\")\n",
    "\n",
    "        # extract the list of substitutes from the sorted pairs\n",
    "        bertscore_ranked_substitutes_only = [substitute for substitute, _ in sorted_substitute_score_pairs]\n",
    "        #print(f\"substitutes based on bertscores in context: {bertscore_ranked_substitutes_only}\\n\")\n",
    "\n",
    "        # limit the substitutes to the 10 first ones for evaluation\n",
    "        bertscore_top_10_substitutes = bertscore_ranked_substitutes_only[:10]\n",
    "        #print(f\"top-10 substitutes based on bertscores in context: {bertscore_top_10_substitutes}\\n\")\n",
    "\n",
    "    else:\n",
    "        bertscore_top_10_substitutes = []\n",
    "\n",
    "\n",
    "    ## add the results to the dataframe\n",
    "    # fill the dataframe with 10 elements even if there are less than 10 in the previous list\n",
    "    required_for_dataframe = 10\n",
    "\n",
    "    # pad the list with None until it has 10 elements\n",
    "    bertscore_top_10_substitutes += [None] * (required_for_dataframe - len(bertscore_top_10_substitutes))\n",
    "  \n",
    "\n",
    "\n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + bertscore_top_10_substitutes\n",
    "\n",
    "    #print('---------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "   \n",
    "    \n",
    "    \n",
    "# export the dataframe to a tsv file for evaluation\n",
    "substitutes_df.to_csv(\"./predictions/test/ElectraBase_SG_MA_SS_bsBERT.tsv\", sep=\"\\t\", index=False, header=False)\n",
    "print(\"ElectraBase_SG_MA_SS_bsBert exported to csv in path './predictions/test/ElectraBase_SG_MA_SS_bsBert.tsv'}\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c385aef2-04d1-4a94-a2cd-b0635a8fd616",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/ElectraBase_SG_MA_SS_bsBERT.tsv --output_file ./output/test/ElectraBase_SG_MA_SS_bsBERT.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "200eac4b-d783-4c11-a56e-61cbf22cc7c6",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/ElectraBase_SG_MA_SS_bsBERT.tsv\n",
    "OUTPUT file = ./output/test/ElectraBase_SG_MA_SS_bsBERT.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.5951\n",
    "\n",
    "MAP@3 = 0.4048\n",
    "MAP@5 = 0.297\n",
    "MAP@10 = 0.1801\n",
    "\n",
    "Potential@3 = 0.815\n",
    "Potential@5 = 0.8847\n",
    "Potential@10 = 0.9329\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.252\n",
    "Accuracy@2@top_gold_1 = 0.3941\n",
    "Accuracy@3@top_gold_1 = 0.4718"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967f0b63-a1f4-4d37-9d3e-6070ccb440c3",
   "metadata": {},
   "source": [
    "#### Bertscore based on Roberta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a35948f-3e35-49c8-9c6f-d42899b604cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    #print(f\"Sentence: {sentence}\")\n",
    "    #print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, lm_tokenizer.mask_token) # this is different per model (this code line applies to Electra)\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    sentences_concat = f\"{sentence} {lm_tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline (removing elements without token_str key; as this gave errors in the ELECTRA models) .\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "    substitutes = [substitute[\"token_str\"] for substitute in result if \"token_str\" in substitute]\n",
    "    #print(f\"Substitute Generation step: initial substitute list: {substitutes}\\n\")\n",
    "\n",
    "\n",
    "    #2: Morphological Generation and Context Adaptation (Morphological Adaptation):  \n",
    "    ## a) remove noise in the substitutes, by ignoring generated substitutes that are empty or that have unwanted punctuation characters or that start with '##' (this returned errors with the ELECTRA model), and lowercase the substitutes (as some models don't lowercase by default)\n",
    "    ## and lowercase all substitutes. Use try/except statement to prevent other character-related problems to happen\n",
    "\n",
    "    punctuation_set = set(string.punctuation) - set('-') # retained hyphens in case tokenizers don't split on hyphenated compounds\n",
    "    punctuation_set.update({'',''})   # as these curly quotes appeared in the Electra (SG step) results but were not part of the string set\n",
    "\n",
    "    try:\n",
    "        substitutes = [substitute[\"token_str\"].lower() for substitute in result if not any(char in punctuation_set for char in substitute[\"token_str\"]) \n",
    "                       and not substitute[\"token_str\"].startswith('##') and substitute[\"token_str\"].strip() != \"\"]\n",
    "        # print(f\"Morphological Adaptation step a): substitute list without unwanted punctuation characters: {substitutes}\\n\")\n",
    "    except TypeError as error:\n",
    "        continue\n",
    "\n",
    "\n",
    "\n",
    "    ## b) remove duplicates within the substitute list from the substitute list (duplicates are likely for models that did not lowercase by default)\n",
    "    ## the last mentioned duplicate is removed on purpose, as this may probably be the (previously) uppercased variant of the lowercased substitute (lowercased subs are most likely higher ranked by the model)\n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl:\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    #print(f\"Morphological Adaptation step b): substitute list without duplicates of substitutes: {substitutes_no_dupl}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "    ## c) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "\n",
    "    ## first Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## then, remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step c): substitute list without duplicates of the complex word nor inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "\n",
    "\n",
    "    ## d) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    #print(f\"Morphological Adaptation step d): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #3: Substitute Selection (SS) by calculating Bert scores: \n",
    "\n",
    "    ## create sentence with the complex word replaced by the substitutes\n",
    "    sentence_with_substitutes = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym]\n",
    "    #print(f\"List with sentences where complex word is substituted: {sentence_with_substitutes}\\n\")\n",
    "\n",
    "\n",
    "    ## calculate BERTScores, and rank the substitutes based on these scores\n",
    "    if len(sentence_with_substitutes) > 0: # to make sure the list with substitutes is always filled\n",
    "        logging.getLogger('transformers').setLevel(logging.ERROR)  # to prevent the same warnings from being printed x times \n",
    "        scores = bert_score.score([sentence]*len(sentence_with_substitutes), sentence_with_substitutes, lang=\"en\", model_type='roberta-base', verbose=False)\n",
    "        logging.getLogger('transformers').setLevel(logging.WARNING) # to reset the logging level back to printing warnings\n",
    "        \n",
    "        # create a list of tuples, each tuple containing a substitute and its score\n",
    "        substitute_score_pairs = list(zip(substitutes_no_dupl_complex_word_no_antonym, scores[0].tolist()))\n",
    "\n",
    "        # sort the list of tuples by the scores (the second element of each tuple), in descending order\n",
    "        sorted_substitute_score_pairs = sorted(substitute_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # # print each substitute with its score\n",
    "        # for substitute, score in sorted_substitute_score_pairs:\n",
    "        #     print(f\"Substitute: {substitute}, BertScore: {score}\")\n",
    "\n",
    "        # extract the list of substitutes from the sorted pairs\n",
    "        bertscore_ranked_substitutes_only = [substitute for substitute, _ in sorted_substitute_score_pairs]\n",
    "        #print(f\"substitutes based on bertscores in context: {bertscore_ranked_substitutes_only}\\n\")\n",
    "\n",
    "        # limit the substitutes to the 10 first ones for evaluation\n",
    "        bertscore_top_10_substitutes = bertscore_ranked_substitutes_only[:10]\n",
    "        #print(f\"top-10 substitutes based on bertscores in context: {bertscore_top_10_substitutes}\\n\")\n",
    "\n",
    "    else:\n",
    "        bertscore_top_10_substitutes = []\n",
    "\n",
    "\n",
    "    ## add the results to the dataframe\n",
    "    # fill the dataframe with 10 elements even if there are less than 10 in the previous list\n",
    "    required_for_dataframe = 10\n",
    "\n",
    "    # pad the list with None until it has 10 elements\n",
    "    bertscore_top_10_substitutes += [None] * (required_for_dataframe - len(bertscore_top_10_substitutes))\n",
    "  \n",
    "\n",
    "\n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + bertscore_top_10_substitutes\n",
    "\n",
    "    #print('---------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "   \n",
    "    \n",
    "    \n",
    "# export the dataframe to a tsv file for evaluation\n",
    "substitutes_df.to_csv(\"./predictions/test/ElectraBase_SG_MA_SS_bsRoberta.tsv\", sep=\"\\t\", index=False, header=False)\n",
    "print(\"ElectraBase_SG_MA_SS_bsRoberta exported to csv in path './predictions/test/ElectraBase_SG_MA_SS_bsRoberta.tsv'}\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aee89f8-c479-45eb-9a3e-d5cef6f3dec2",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/ElectraBase_SG_MA_SS_bsRoberta.tsv --output_file ./output/test/ElectraBase_SG_MA_SS_bsRoberta.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095eb2b6-11a7-4b00-87bd-adbe39149394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c506071-4e81-451a-b203-609abda5a06e",
   "metadata": {},
   "source": [
    "#### Conclusion (based on Map1):\n",
    "1. ElectraBase_SG_MA_SS_bsBERT (0.5951)\n",
    "2. ElectraBase_SG_MA (0.5469)\n",
    "3. ElectraBase_SG_MA_SS_bsElectra (0.5254)\n",
    "4. ElectraBase_SG_MA_SS_ce (0.3914)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6341a5d9-6363-40bd-851e-43801e6cdd1d",
   "metadata": {},
   "source": [
    "bs based on Roberta not yet executed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
