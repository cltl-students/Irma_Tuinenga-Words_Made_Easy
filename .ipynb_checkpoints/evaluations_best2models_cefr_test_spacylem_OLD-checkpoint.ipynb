{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22097079-bddc-4066-bcd6-981db0cde8bc",
   "metadata": {},
   "source": [
    "## TEST set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e47a95-bf30-4b15-9a9c-f5b075bb6dcc",
   "metadata": {},
   "source": [
    "## for CEFR-J dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53ed8a8-6947-400c-8070-148c5c7c36b7",
   "metadata": {},
   "source": [
    "### for model SG_MA_SS_bsRobertalarge_robertabase:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc9e169-bbd6-4a6d-93cc-6d582a4f82a8",
   "metadata": {},
   "source": [
    "### lemmatized:WITH SPACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85d4b4f6-302e-4e52-bdc6-b2134c33bff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_robertabase_SR_cefrj_lemSpacy exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefrj_lemSpacy.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load the English SpaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# read the cefr levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefrj/cefrj_all.tsv', sep='\\t', header=None, names=['word', 'cefr'])\n",
    "\n",
    "# define a mapping from cefr levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the cefr levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# lemmatize the words and then convert the cefr dataframe into a dictionary for efficient lookups\n",
    "cefr_df['word'] = cefr_df['word'].apply(lambda x: nlp(x)[0].lemma_)\n",
    "cefr_dict = cefr_df.set_index('word')['cefr'].to_dict()\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_robertabase.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its cefr level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, nlp(sub)[0].lemma_) for sub in substitutes]\n",
    "    \n",
    "    # map each lemmatized substitute to its cefr level, or to a high number if it doesn't have a cefr level\n",
    "    substitutes_cefr = [(original, cefr_dict.get(lemmatized, 7)) for original, lemmatized in substitutes_lemmatized]\n",
    "    # print(f\"substitutes with cefr levels mapped to numerical values: {substitutes_cefr}\\n\")\n",
    "\n",
    "    # sort the substitutes based on their cefr levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    # print(f\"ranked substitutes based on their cefr level mapped to numerical values: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrj_lemSpacy.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_robertabase_SR_cefrj_lemSpacy exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefrj_lemSpacy.tsv'\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c099b9cd-d498-488f-903f-60237d26a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrj_lemSpacy.tsv --output_file ./output/test/SS_bsRobertalarge_robertabase_SR_cefrj_lemSpacy.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6e4fed52-e1c9-45a0-9b50-48d6fb52f528",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefrj_lemSpacy.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_robertabase_SR_cefrj_lemSpacy.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.4784\n",
    "\n",
    "MAP@3 = 0.3288\n",
    "MAP@5 = 0.2569\n",
    "MAP@10 = 0.1786\n",
    "\n",
    "Potential@3 = 0.7634\n",
    "Potential@5 = 0.8897\n",
    "Potential@10 = 0.9677\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.2016\n",
    "Accuracy@2@top_gold_1 = 0.2956\n",
    "Accuracy@3@top_gold_1 = 0.422"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887ac195-0876-4bb1-8c76-ddfa2f3737e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4ea6076-4989-4bb3-a38a-fbb308e9c972",
   "metadata": {},
   "source": [
    "### for model SG_MA_SS_bsRobertalarge_electralarge:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266f19ae-a377-42d3-b7e9-980339c33320",
   "metadata": {},
   "source": [
    "lemmatized with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c842d45-9134-446b-b08a-e2915247c291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_electralarge_SR_cefrj_lemSpacy exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefrj_lemSpacy.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load the English SpaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# read the cefr levels file into a dataframe\n",
    "cefr_df = pd.read_csv('./cefrj/cefrj_all.tsv', sep='\\t', header=None, names=['word', 'cefr'])\n",
    "\n",
    "# define a mapping from cefr levels to numerical values\n",
    "cefr_level_mapping = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}\n",
    "\n",
    "# map the cefr levels in the dataframe to numerical values using the mapping\n",
    "cefr_df['cefr'] = cefr_df['cefr'].map(cefr_level_mapping)\n",
    "\n",
    "# lemmatize the words and then convert the cefr dataframe into a dictionary for efficient lookups\n",
    "cefr_df['word'] = cefr_df['word'].apply(lambda x: nlp(x)[0].lemma_)\n",
    "cefr_dict = cefr_df.set_index('word')['cefr'].to_dict()\n",
    "\n",
    "# read the predictions file into a dataframe\n",
    "pred_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_electralarge.tsv', sep='\\t', header=None)\n",
    "\n",
    "# for each row in the predictions dataframe, map each substitute to its cefr level, sort them, and save them into a new list\n",
    "new_lists = []\n",
    "for i, row in pred_df.iterrows():\n",
    "    sentence = row[0]\n",
    "    complex_word = row[1]\n",
    "    substitutes = row[2:12]\n",
    "\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, nlp(sub)[0].lemma_) for sub in substitutes]\n",
    "    \n",
    "    # map each lemmatized substitute to its cefr level, or to a high number if it doesn't have a cefr level\n",
    "    substitutes_cefr = [(original, cefr_dict.get(lemmatized, 7)) for original, lemmatized in substitutes_lemmatized]\n",
    "    # print(f\"substitutes with cefr levels mapped to numerical values: {substitutes_cefr}\\n\")\n",
    "\n",
    "    # sort the substitutes based on their cefr levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    # print(f\"ranked substitutes based on their cefr level mapped to numerical values: {ranked_cefr_subs}\\n\")\n",
    "\n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrj_lemSpacy.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_electralarge_SR_cefrj_lemSpacy exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefrj_lemSpacy.tsv'\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c8fe2-d3e1-4d85-bf14-d9903cf463c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrj_lemSpacy.tsv --output_file ./output/test/SS_bsRobertalarge_electralarge_SR_cefrj_lemSpacy.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5375de4-f974-46c5-90f2-c07b64c3c0bf",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefrj_lemSpacy.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_electralarge_SR_cefrj_lemSpacy.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.4489\n",
    "\n",
    "MAP@3 = 0.3057\n",
    "MAP@5 = 0.2437\n",
    "MAP@10 = 0.1701\n",
    "\n",
    "Potential@3 = 0.7768\n",
    "Potential@5 = 0.8897\n",
    "Potential@10 = 0.9462\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1801\n",
    "Accuracy@2@top_gold_1 = 0.3064\n",
    "Accuracy@3@top_gold_1 = 0.4059\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656259c9-8c8b-4c2c-88f7-6b4812ce9386",
   "metadata": {},
   "source": [
    "## for Uchida et al dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767e5b77-4bba-4dad-b5b5-0d25308b1eea",
   "metadata": {},
   "source": [
    "### for model SG_MA_SS_bsRobertalarge_robertabase:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5892df1-0c6b-4200-bc7e-ecb321ebc6f1",
   "metadata": {},
   "source": [
    "### lemmatized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fad3ce9f-903c-4dd7-a86c-5f36017867f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_robertabase_SR_cefruchida_lemSpacy exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lemSpacy.tsv'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load the English SpaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# read cefr file\n",
    "cefr_df = pd.read_csv('./cefr/uchida.tsv', sep='\\t', header=None, usecols=range(21))\n",
    "\n",
    "# read prediction file\n",
    "predictions_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_robertabase.tsv', sep='\\t', header=None)\n",
    "\n",
    "# convert CEFR levels to numerical values for ranking\n",
    "cefr_level_mapping = {\"A1\": 1, \"A2\": 2, \"B1\": 3, \"B2\": 4, \"C1\": 5, \"C2\": 6}\n",
    "\n",
    "# create a dictionary with substitute (lemmatized) as key and its corresponding CEFR level as value\n",
    "cefr_dict = {}\n",
    "for i in range(3, 21, 3):\n",
    "    for word, cefr_level, label in zip(cefr_df[i], cefr_df[i + 1], cefr_df[i + 2]):\n",
    "        if label == 1:  # only consider the substitute if the label is 1\n",
    "            lemmatized_word = nlp(word)[0].lemma_\n",
    "            cefr_dict[lemmatized_word] = cefr_level_mapping.get(cefr_level, 7)  # default to 7 if CEFR level is not found\n",
    "\n",
    "# create a new list to store the sorted substitutes with their sentence and complex word\n",
    "new_lists = []\n",
    "\n",
    "# map each substitute to its CEFR level and sort them\n",
    "for sentence, complex_word, *substitutes in predictions_df.values:\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, nlp(sub)[0].lemma_) for sub in substitutes]\n",
    "    \n",
    "    # map each lemmatized substitute to its cefr level, or to a high number if it doesn't have a cefr level\n",
    "    substitutes_cefr = [(original, cefr_dict.get(lemmatized, 7)) for original, lemmatized in substitutes_lemmatized]\n",
    "    \n",
    "    # sort the substitutes based on their cefr levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    # print(ranked_cefr_subs)\n",
    "    \n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "\n",
    "# create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lemSpacy.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_robertabase_SR_cefruchida_lemSpacy exported to csv in path './predictions/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lemSpacy.tsv'\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b90e72-cb03-440c-81b3-fe8d85f1f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lemSpacy.tsv --output_file ./output/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lemSpacy.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94955120-b2f7-43dc-9f64-682f4989074a",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lemSpacy.tsv\n",
    "OUTPUT file = ./output/test/SS_bsRobertalarge_robertabase_SR_cefruchida_lemSpacy.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.4919\n",
    "\n",
    "MAP@3 = 0.3793\n",
    "MAP@5 = 0.3018\n",
    "MAP@10 = 0.1923\n",
    "\n",
    "Potential@3 = 0.8225\n",
    "Potential@5 = 0.9193\n",
    "Potential@10 = 0.9677\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1451\n",
    "Accuracy@2@top_gold_1 = 0.3198\n",
    "Accuracy@3@top_gold_1 = 0.4543\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31cee8c-3a58-4228-a238-e9249e3ea800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f85e233f-8a9d-4991-8472-8e9ee6e518e2",
   "metadata": {},
   "source": [
    "### for model SG_MA_SS_bsRobertalarge_electralarge:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a221b9-6d41-4464-8cdf-40ad43e412e1",
   "metadata": {},
   "source": [
    "### lemmatized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8b0a6a1-16b5-4e02-866c-4e3e4d7c30e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS_bsRobertalarge_electralarge_SR_cefruchida_lemSpacy exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lemSpacy.tsv'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load the English SpaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# read cefr file\n",
    "cefr_df = pd.read_csv('./cefr/uchida.tsv', sep='\\t', header=None, usecols=range(21))\n",
    "\n",
    "# read prediction file\n",
    "predictions_df = pd.read_csv('./predictions/test/SG_MA_SS_bsRobertalarge_electralarge.tsv', sep='\\t', header=None)\n",
    "\n",
    "# convert CEFR levels to numerical values for ranking\n",
    "cefr_level_mapping = {\"A1\": 1, \"A2\": 2, \"B1\": 3, \"B2\": 4, \"C1\": 5, \"C2\": 6}\n",
    "\n",
    "# create a dictionary with substitute (lemmatized) as key and its corresponding CEFR level as value\n",
    "cefr_dict = {}\n",
    "for i in range(3, 21, 3):\n",
    "    for word, cefr_level, label in zip(cefr_df[i], cefr_df[i + 1], cefr_df[i + 2]):\n",
    "        if label == 1:  # only consider the substitute if the label is 1\n",
    "            lemmatized_word = nlp(word)[0].lemma_\n",
    "            cefr_dict[lemmatized_word] = cefr_level_mapping.get(cefr_level, 7)  # default to 7 if CEFR level is not found\n",
    "\n",
    "# create a new list to store the sorted substitutes with their sentence and complex word\n",
    "new_lists = []\n",
    "\n",
    "# map each substitute to its CEFR level and sort them\n",
    "for sentence, complex_word, *substitutes in predictions_df.values:\n",
    "    # lemmatize the substitutes but keep original form too\n",
    "    substitutes_lemmatized = [(sub, nlp(sub)[0].lemma_) for sub in substitutes]\n",
    "    \n",
    "    # map each lemmatized substitute to its cefr level, or to a high number if it doesn't have a cefr level\n",
    "    substitutes_cefr = [(original, cefr_dict.get(lemmatized, 7)) for original, lemmatized in substitutes_lemmatized]\n",
    "    \n",
    "    # sort the substitutes based on their cefr levels\n",
    "    ranked_cefr_subs = sorted(substitutes_cefr, key=lambda x: x[1])\n",
    "    # print(ranked_cefr_subs)\n",
    "    \n",
    "    # append the sorted list of substitutes to the new lists, keeping original form\n",
    "    new_lists.append([sentence, complex_word] + [sub for sub, _ in ranked_cefr_subs])\n",
    "    \n",
    "    \n",
    "# # create a new dataframe from the new lists and write it to a new tsv file\n",
    "new_df = pd.DataFrame(new_lists)\n",
    "new_df.to_csv('./predictions/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lemSpacy.tsv', sep='\\t', index=False, header=False)\n",
    "print(\"SS_bsRobertalarge_electralarge_SR_cefruchida_lemSpacy exported to csv in path './predictions/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lemSpacy.tsv'}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a63b48b-7f09-4ca6-ad11-0ebb4dd53397",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file ./data/test/tsar2022_en_test_gold_no_noise.tsv --predictions_file ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lemSpacy.tsv --output_file ./output/test/SSS_bsRobertalarge_electralarge_SR_cefruchida_lemSpacy.tsv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8f3689e-0b61-4ef2-a422-d3c71c4345af",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = ./data/test/tsar2022_en_test_gold_no_noise.tsv\n",
    "PREDICTION LABELS file = ./predictions/test/SS_bsRobertalarge_electralarge_SR_cefruchida_lemSpacy.tsv\n",
    "OUTPUT file = ./output/test/SSS_bsRobertalarge_electralarge_SR_cefruchida_lemSpacy.tsv\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.4327\n",
    "\n",
    "MAP@3 = 0.3472\n",
    "MAP@5 = 0.2834\n",
    "MAP@10 = 0.1827\n",
    "\n",
    "Potential@3 = 0.8037\n",
    "Potential@5 = 0.8951\n",
    "Potential@10 = 0.9462\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.1344\n",
    "Accuracy@2@top_gold_1 = 0.3225\n",
    "Accuracy@3@top_gold_1 = 0.4381\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
