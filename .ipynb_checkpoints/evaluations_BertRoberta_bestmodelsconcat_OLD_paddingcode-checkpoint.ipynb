{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b0ad47d-aef9-4d79-ac41-de890e0748ea",
   "metadata": {},
   "source": [
    "### All code below uses concatenated sentence pairs in the Substitute Generation step in order to generate similar substitutes (as opposed to generation of fitting substitutes only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f41c8337-c877-47d0-9b9d-2464ac9f76a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# read the tsv file\n",
    "filename = \"./data/trial/tsar2022_en_trial_none.tsv\"\n",
    "data = pd.read_csv(filename, sep='\\t', header=None, names=[\"sentence\", \"complex_word\"])\n",
    "\n",
    "# create an empty dataframe to store the substitutes for evaluation\n",
    "substitutes_df = pd.DataFrame(columns=[\"sentence\", \"complex_word\"] + [f\"substitute_{i+1}\" for i in range(10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524d32ce-ce1a-40d4-b13c-3baf9eb22187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8274756c-ed82-4720-aeb3-f4e789451069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb201754-5724-4594-bfaf-fe5b3194e5b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de2a8f51-26e4-4f17-a64c-aa3545a1450d",
   "metadata": {},
   "source": [
    "### Bert-base and Bert-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d9baa00-f810-4bb4-a3b9-a1affa7e6ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# initialize the models\n",
    "model_bertbase = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "model_bertlarge = AutoModelForMaskedLM.from_pretrained(\"bert-large-uncased\")\n",
    "\n",
    "# create a fill-mask pipeline for each model (tokenizer seems to be the same so i used the bert-large tokenizer)\n",
    "fill_mask_bertbase = pipeline(\"fill-mask\", model_bertbase, tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\"))\n",
    "fill_mask_bertlarge = pipeline(\"fill-mask\", model_bertlarge, tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d224f826-11e3-493f-9ecf-d2b550d2f2eb",
   "metadata": {},
   "source": [
    "### Roberta-base and Roberta-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57369206-696b-49c6-8ff1-01378e050e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the models\n",
    "model_robertabase = AutoModelForMaskedLM.from_pretrained(\"roberta-base\")\n",
    "model_robertalarge = AutoModelForMaskedLM.from_pretrained(\"roberta-large\")\n",
    "\n",
    "# create a fill-mask pipeline for each model (tokenizer seems to be the same so i used the roberta-large tokenizer)\n",
    "fill_mask_robertabase = pipeline(\"fill-mask\", model_robertabase, tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\"))\n",
    "fill_mask_robertalarge = pipeline(\"fill-mask\", model_robertalarge, tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8bbda6-1685-4044-b7e4-12271f49a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "### electrabase and electralarge #update names also in prediction code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f138e2e-b6de-40ab-bdc0-41f497c2d0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tokenizer and the model\n",
    "lm_model = AutoModelForMaskedLM.from_pretrained(\"google/electra-base-generator\")\n",
    "\n",
    "\n",
    "# Instantiate the fill-mask pipeline with the ELECTRA model\n",
    "fill_mask = pipeline(\"fill-mask\", lm_model, tokenizer =  AutoTokenizer.from_pretrained(\"google/electra-base-generator\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0570e48-5d56-45b2-936e-6607b0af23b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/electra-large-generator\")\n",
    "lm_model = AutoModelForMaskedLM.from_pretrained(\"google/electra-large-generator\")\n",
    "\n",
    "\n",
    "# Instantiate the fill-mask pipeline with the ELECTRA model\n",
    "fill_mask = pipeline(\"fill-mask\", lm_model, tokenizer =  AutoTokenizer.from_pretrained(\"google/electra-large-generator\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059bd933-564c-4ccf-9b11-dd31addbbefd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f466c47-3400-4f9f-8adc-5ecf4e0ea082",
   "metadata": {},
   "source": [
    "#### Substitute Generation with BERT-base and BERT-large, and Substitute Selection steps a-c, k =5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a443c2-1ef7-45ed-85bd-a1705380b637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc111e29-a588-427a-ae46-2da625465467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07352cfa-8ba5-447a-be18-84eda2b0f4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "\n",
      "SS step: c): Bertbase substitute list without antonyms of the complex word: ['mandatory', 'obligatory', 'optional', 'required', 'necessary', 'standard', 'voluntary', 'customary', 'impossible', 'easier', 'only', 'illegal', 'sufficient', 'unnecessary', 'easy', 'normal', 'permitted', 'mandated', 'difficult', 'simple', 'appropriate', 'expensive', 'possible', 'commonplace', 'essential', 'proper', 'available', 'enough', 'affordable']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertbase: ['mandatory', 'obligatory', 'optional', 'required', 'necessary', 'standard', 'voluntary', 'customary']\n",
      "\n",
      "SS step: c): Bertlarge substitute list without antonyms of the complex word: ['mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden', 'permitted', 'prescribed', 'illegal', 'available', 'beneficial', 'prohibited', 'scheduled', 'obliged', 'tertiary', 'secondary', 'statutory', 'legal', 'free', 'used', 'customary', 'primary', 'authorised', 'canonical', 'standard', 'lawful']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertlarge: ['mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden']\n",
      "\n",
      "duplicates_top5_bertbaselarge: ['mandatory', 'obligatory', 'optional', 'required', 'necessary', 'voluntary']\n",
      "\n",
      "nonduplicates_top5_bertbaselarge: ['standard', 'mandated', 'customary', 'forbidden']\n",
      "\n",
      "combined_top5_bertbaselarge with duplicates first: ['mandatory', 'obligatory', 'optional', 'required', 'necessary', 'voluntary', 'standard', 'mandated', 'customary', 'forbidden']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "\n",
      "SS step: c): Bertbase substitute list without antonyms of the complex word: ['strengthened', 'targeted', 'tested', 'provided', 'created', 'affected', 'addressed', 'attacked', 'punished', 'bred', 'rewarded', 'empowered', 'shocked', 'introduced', 'silenced', 'improved', 'set', 'defeated', 'treated', 'reinforced', 'prepared', 'hit', 'surprised', 'hardened', 'infused', 'challenged', 'released', 'secured', 'delivered', 'established']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertbase: ['strengthened', 'targeted', 'tested', 'provided', 'created', 'affected', 'addressed', 'attacked']\n",
      "\n",
      "SS step: c): Bertlarge substitute list without antonyms of the complex word: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed', 'impressed', 'fed', 'gifted', 'struck', 'furnished', 'inspired', 'fitted', 'equipped', 'raised', 'given', 'seeded', 'created', 'rewarded', 'hit', 'treated', 'introduced', 'encouraged', 'infected', 'tested', 'shaken', 'offered', 'filled']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertlarge: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed']\n",
      "\n",
      "duplicates_top5_bertbaselarge: ['provided']\n",
      "\n",
      "nonduplicates_top5_bertbaselarge: ['strengthened', 'targeted', 'injected', 'tested', 'infused', 'presented', 'created', 'left', 'affected', 'supplied', 'addressed', 'delivered', 'attacked', 'endowed']\n",
      "\n",
      "combined_top5_bertbaselarge with duplicates first: ['provided', 'strengthened', 'targeted', 'injected', 'tested', 'infused', 'presented', 'created', 'left', 'affected', 'supplied', 'addressed', 'delivered', 'attacked', 'endowed']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "\n",
      "SS step: c): Bertbase substitute list without antonyms of the complex word: ['criminals', 'crimes', 'machines', 'rats', 'pigs', 'heroes', 'demons', 'robots', 'machine', 'games', 'doctors', 'dogs', 'priests', 'bandits', 'lords', 'monsters', 'soldiers', 'leaders', 'freaks', 'ants', 'saints', 'people', 'workers', 'terror', 'zombies', 'fighters', 'elephants']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertbase: ['criminals', 'crimes', 'machines', 'rats', 'pigs', 'heroes', 'demons', 'robots']\n",
      "\n",
      "SS step: c): Bertlarge substitute list without antonyms of the complex word: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria', 'demons', 'gods', 'insects', 'sims', 'crimes', 'pigs', 'dogs', 'victims', 'organs', 'heroes', 'fans', 'fantasies', 'dolls', 'leaders', 'puppets', 'followers', 'vampires', 'theorists', 'giants', 'children', 'lovers']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertlarge: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria']\n",
      "\n",
      "duplicates_top5_bertbaselarge: ['criminals', 'machines']\n",
      "\n",
      "nonduplicates_top5_bertbaselarge: ['crimes', 'mania', 'rats', 'killers', 'pigs', 'monsters', 'heroes', 'zombies', 'demons', 'freaks', 'robots', 'hysteria']\n",
      "\n",
      "combined_top5_bertbaselarge with duplicates first: ['criminals', 'machines', 'crimes', 'mania', 'rats', 'killers', 'pigs', 'monsters', 'heroes', 'zombies', 'demons', 'freaks', 'robots', 'hysteria']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "\n",
      "SS step: c): Bertbase substitute list without antonyms of the complex word: ['witnesses', 'participants', 'casualties', 'refugees', 'visitors', 'monitors', 'victims', 'delegates', 'travelers', 'experts', 'troops', 'inspectors', 'allies', 'diplomats', 'inspections', 'soldiers', 'fatalities', 'workers', 'pilgrims', 'people', 'officials', 'deaths', 'tourists', 'survivors', 'volunteers', 'citizens', 'civilians', 'combatants']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertbase: ['witnesses', 'participants', 'casualties', 'refugees', 'visitors', 'monitors', 'victims', 'delegates']\n",
      "\n",
      "SS step: c): Bertlarge substitute list without antonyms of the complex word: ['monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters', 'observation', 'experts', 'activists', 'casualties', 'volunteers', 'civilians', 'observing', 'people', 'citizens', 'combatants', 'observe', 'individuals', 'indicators', 'monitoring', 'troops', 'soldiers', 'victims', 'refugees', 'instruments']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertlarge: ['monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters']\n",
      "\n",
      "duplicates_top5_bertbaselarge: ['witnesses', 'participants', 'monitors']\n",
      "\n",
      "nonduplicates_top5_bertbaselarge: ['casualties', 'refugees', 'analysts', 'visitors', 'spectators', 'observations', 'victims', 'journalists', 'delegates', 'fighters']\n",
      "\n",
      "combined_top5_bertbaselarge with duplicates first: ['witnesses', 'participants', 'monitors', 'casualties', 'refugees', 'analysts', 'visitors', 'spectators', 'observations', 'victims', 'journalists', 'delegates', 'fighters']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "\n",
      "SS step: c): Bertbase substitute list without antonyms of the complex word: ['stab', 'gunshot', 'bullet', 'knife', 'multiple', 'severe', 'arrow', 'several', 'minor', 'stabbing', 'laser', 'open', 'two', 'rifle', 'serious', 'blunt', 'similar', 'blast', 'numerous', 'penetrating', 'three', 'sword', 'some', 'slash', 'shooting', 'the', 'painful', 'fatal', 'deep', 'horrible']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertbase: ['stab', 'gunshot', 'bullet', 'knife', 'multiple', 'severe', 'arrow', 'several']\n",
      "\n",
      "SS step: c): Bertlarge substitute list without antonyms of the complex word: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor', 'blast', 'battle', 'three', 'splinter', 'shot', 'serious', 'exit', 'entry', 'shotgun', 'several', 'two', 'severe', 'shell', 'open', 'burn', 'bomb', 'penetrating', 'the', 'inflicted', 'stabbing', 'internal', 'fatal']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertlarge: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor']\n",
      "\n",
      "duplicates_top5_bertbaselarge: ['stab', 'gunshot', 'bullet', 'knife', 'multiple', 'arrow']\n",
      "\n",
      "nonduplicates_top5_bertbaselarge: ['flesh', 'severe', 'several', 'minor']\n",
      "\n",
      "combined_top5_bertbaselarge with duplicates first: ['stab', 'gunshot', 'bullet', 'knife', 'multiple', 'arrow', 'flesh', 'severe', 'several', 'minor']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "\n",
      "SS step: c): Bertbase substitute list without antonyms of the complex word: ['dressed', 'clad', 'masked', 'clothed', 'dressing', 'disguise', 'concealed', 'cloak', 'posing', 'appeared', 'dress', 'posed', 'guise', 'costume', 'attire', 'appearing', 'dresses', 'hiding', 'hooded', 'covered', 'draped', 'costumes', 'hidden', 'wrapped', 'undercover', 'lured', 'present', 'adorned']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertbase: ['dressed', 'clad', 'masked', 'clothed', 'dressing', 'disguise', 'concealed', 'cloak']\n",
      "\n",
      "SS step: c): Bertlarge substitute list without antonyms of the complex word: ['dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad', 'guise', 'hiding', 'draped', 'posing', 'appearing', 'hidden', 'acting', 'dress', 'painted', 'seated', 'fitted', 'identified', 'covered', 'armed', 'appeared', 'cloak', 'armored', 'undercover', 'portrayed', 'depicted']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertlarge: ['dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad']\n",
      "\n",
      "duplicates_top5_bertbaselarge: ['dressed', 'clad', 'masked', 'clothed', 'dressing', 'disguise', 'concealed']\n",
      "\n",
      "nonduplicates_top5_bertbaselarge: ['armoured', 'cloak']\n",
      "\n",
      "combined_top5_bertbaselarge with duplicates first: ['dressed', 'clad', 'masked', 'clothed', 'dressing', 'disguise', 'concealed', 'armoured', 'cloak']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "\n",
      "SS step: c): Bertbase substitute list without antonyms of the complex word: ['affiliate', 'extension', 'arm', 'adaptation', 'incarnation', 'ally', 'opponent', 'attack', 'expansion', 'outpost', 'associate', 'advocate', 'enemy', 'aspect', 'origin', 'branch', 'adversary', 'independent', 'alliance', 'ancestor', 'iteration', 'evolution', 'independently', 'antagonist', 'offspring', 'overthrow', 'imitation', 'implementation', 'organization', 'example']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertbase: ['affiliate', 'extension', 'arm', 'adaptation', 'incarnation', 'ally', 'opponent', 'attack']\n",
      "\n",
      "SS step: c): Bertlarge substitute list without antonyms of the complex word: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy', 'aspect', 'enclave', 'heir', 'isolate', 'offspring', 'expression', 'orthodox', 'evolution', 'exception', 'example', 'sect', 'embrace', 'echo', 'approximation', 'adherence', 'adhere', 'adaptation', 'associate', 'issue', 'inhibitor', 'imitation', 'extreme']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertlarge: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy']\n",
      "\n",
      "duplicates_top5_bertbaselarge: ['affiliate', 'extension', 'arm', 'ally', 'opponent']\n",
      "\n",
      "nonduplicates_top5_bertbaselarge: ['adaptation', 'incarnation', 'outpost', 'element', 'attack', 'enemy']\n",
      "\n",
      "combined_top5_bertbaselarge with duplicates first: ['affiliate', 'extension', 'arm', 'ally', 'opponent', 'adaptation', 'incarnation', 'outpost', 'element', 'attack', 'enemy']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "\n",
      "SS step: c): Bertbase substitute list without antonyms of the complex word: ['orchestral', 'symphony', 'musical', 'classical', 'operatic', 'philharmonic', 'melodic', 'choral', 'music', 'orchestra', 'instrumental', 'concert', 'historical', 'popular', 'concerto', 'harmonic', 'symphonies', 'technical', 'trombone', 'romantic', 'lyric', 'liturgical', 'dramatic', 'thematic', 'traditional', 'composers', 'vocal', 'dynamic', 'general']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertbase: ['orchestral', 'symphony', 'musical', 'classical', 'operatic', 'philharmonic', 'melodic', 'choral']\n",
      "\n",
      "SS step: c): Bertlarge substitute list without antonyms of the complex word: ['orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata', 'operatic', 'piano', 'concert', 'chamber', 'music', 'orchestra', 'modern', 'lyrical', 'thematic', 'instrumental', 'continental', 'orchestrated', 'scholarly', 'dramatic', 'goldberg', 'romantic', 'standard', 'choral', 'poetic', 'comparative', 'written']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertlarge: ['orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata']\n",
      "\n",
      "duplicates_top5_bertbaselarge: ['orchestral', 'symphony', 'musical', 'classical', 'philharmonic']\n",
      "\n",
      "nonduplicates_top5_bertbaselarge: ['operatic', 'symphonies', 'melodic', 'concerto', 'choral', 'sonata']\n",
      "\n",
      "combined_top5_bertbaselarge with duplicates first: ['orchestral', 'symphony', 'musical', 'classical', 'philharmonic', 'operatic', 'symphonies', 'melodic', 'concerto', 'choral', 'sonata']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "\n",
      "SS step: c): Bertbase substitute list without antonyms of the complex word: ['withdraw', 'activate', 'deployment', 'send', 'maintain', 'dispatch', 'use', 'acquire', 'reserve', 'retain', 'move', 'utilize', 'request', 'return', 'include', 'add', 'launch', 'designate', 'fire', 'operate', 'provide', 'establish', 'employ', 'outfit', 'purchase', 'expand', 'retire', 'build']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertbase: ['withdraw', 'activate', 'deployment', 'send', 'maintain', 'dispatch', 'use', 'acquire']\n",
      "\n",
      "SS step: c): Bertlarge substitute list without antonyms of the complex word: ['activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw', 'utilize', 'operate', 'employ', 'acquire', 'maintain', 'reinforce', 'exercise', 'install', 'build', 'move', 'drill', 'fire', 'construct', 'alert', 'dock', 'establish', 'release', 'outfit', 'station', 'ready']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertlarge: ['activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw']\n",
      "\n",
      "duplicates_top5_bertbaselarge: ['withdraw', 'activate', 'deployment', 'send', 'dispatch', 'use']\n",
      "\n",
      "nonduplicates_top5_bertbaselarge: ['assemble', 'maintain', 'launch', 'acquire']\n",
      "\n",
      "combined_top5_bertbaselarge with duplicates first: ['withdraw', 'activate', 'deployment', 'send', 'dispatch', 'use', 'assemble', 'maintain', 'launch', 'acquire']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "\n",
      "SS step: c): Bertbase substitute list without antonyms of the complex word: ['officials', 'police', 'citizens', 'forces', 'government', 'officers', 'people', 'governments', 'residents', 'troops', 'courts', 'individuals', 'persons', 'organisations', 'policemen', 'civilians', 'nationals', 'protesters', 'institutions', 'interests', 'agencies', 'subjects', 'bodies', 'activists', 'personnel', 'magistrates', 'politicians']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertbase: ['officials', 'police', 'citizens', 'forces', 'government', 'officers', 'people', 'governments']\n",
      "\n",
      "SS step: c): Bertlarge substitute list without antonyms of the complex word: ['police', 'officials', 'magistrates', 'officers', 'forces', 'courts', 'people', 'government', 'investigators', 'governments', 'victims', 'ministers', 'operators', 'bodies', 'judges', 'agencies', 'policemen', 'rulers', 'organisations', 'prosecutors', 'elements', 'offences', 'journalists', 'persons', 'subjects', 'residents', 'prisoners']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertlarge: ['police', 'officials', 'magistrates', 'officers', 'forces', 'courts', 'people', 'government']\n",
      "\n",
      "duplicates_top5_bertbaselarge: ['officials', 'police', 'forces', 'government', 'officers', 'people']\n",
      "\n",
      "nonduplicates_top5_bertbaselarge: ['citizens', 'magistrates', 'courts', 'governments']\n",
      "\n",
      "combined_top5_bertbaselarge with duplicates first: ['officials', 'police', 'forces', 'government', 'officers', 'people', 'citizens', 'magistrates', 'courts', 'governments']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "    \n",
    "    # for Bert-base:\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\\n\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"[MASK]\")\n",
    "\n",
    "    ## fill the mask with substitute words, and concatenate the original sentence and the masked sentence\n",
    "    tokenizer_bertbase = fill_mask_bertbase.tokenizer\n",
    "    sentences_concat_bertbase = f\"{sentence} {tokenizer_bertbase.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result_bertbase = fill_mask_bertbase(sentences_concat_bertbase, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes_bertbase = [substitute[\"token_str\"].lower() for substitute in result_bertbase]\n",
    "    #print(f\"SG step: Bertbase generated substitutes: {substitutes_bertbase}\\n\")\n",
    "    \n",
    "   # 2. Substitute Selection (SS):   \n",
    "\n",
    "    # create a punctuation set without hyphen, in order to retain hyphens in compound substitutes\n",
    "    punctuation_without_hyphen = set(string.punctuation) - set('-')\n",
    "    \n",
    "    # a) remove duplicates and unwanted punctuation within the substitute list from the substitute list\n",
    "    substitutes_no_dupl_bertbase = []\n",
    "    for sub in substitutes_bertbase:\n",
    "        if sub not in substitutes_no_dupl_bertbase and not any(char in punctuation_without_hyphen for char in sub):\n",
    "            substitutes_no_dupl_bertbase.append(sub)\n",
    "    #print(f\"SS step: a) Bertbase substitute list without duplicates and undesired punctuation: {substitutes_no_dupl_bertbase}\\n\")\n",
    "    \n",
    "\n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word_bertbase = []\n",
    "    for substitute in substitutes_no_dupl_bertbase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word_bertbase.append(substitute)\n",
    "    #print(f\"SS step: b) Bertbase substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word_bertbase}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym_bertbase = []\n",
    "    for substitute in substitutes_no_dupl_complex_word_bertbase:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym_bertbase.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym_bertbase.append(substitute)\n",
    "    #print(f\"SS step: c): Bertbase substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym_bertbase}\\n\")\n",
    "    \n",
    "     \n",
    "    \n",
    "    # limit the substitutes to the 5 first ones for concatenation with the top-5 of other models\n",
    "    top_5_substitutes_bertbase = substitutes_no_dupl_complex_word_no_antonym_bertbase[:5]\n",
    "    print(f\"SS step: d): top_5_substitutes_bertbase: {top_5_substitutes_bertbase}\\n\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # for Bert-large:\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    # ## print the sentence and the complex word\n",
    "    # sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    # print(f\"Sentence: {sentence}\")\n",
    "    # print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "#     ## in the sentence, replace the complex word with a masked word\n",
    "#     sentence_masked_word = sentence.replace(complex_word, \"[MASK]\")\n",
    "\n",
    "    ## fill the mask with substitute words, and concatenate the original sentence and the masked sentence\n",
    "    tokenizer_bertlarge = fill_mask_bertlarge.tokenizer\n",
    "    sentences_concat_bertlarge = f\"{sentence} {tokenizer_bertlarge.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result_bertlarge = fill_mask_bertlarge(sentences_concat_bertlarge, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes_bertlarge = [substitute[\"token_str\"].lower() for substitute in result_bertlarge]\n",
    "    #print(f\"SG step: Bertlarge generated substitutes: {substitutes_bertlarge}\\n\")\n",
    "    \n",
    "   # 2. Substitute Selection (SS):   \n",
    "\n",
    "    # create a punctuation set without hyphen, in order to retain hyphens in compound substitutes\n",
    "    punctuation_without_hyphen = set(string.punctuation) - set('-')\n",
    "    \n",
    "    # a) remove duplicates and unwanted punctuation (this happened with BERT) within the substitute list from the substitute list\n",
    "    substitutes_no_dupl_bertlarge = []\n",
    "    for sub in substitutes_bertlarge:\n",
    "        if sub not in substitutes_no_dupl_bertlarge and not any(char in punctuation_without_hyphen for char in sub):\n",
    "            substitutes_no_dupl_bertlarge.append(sub)\n",
    "    #print(f\"SS step: a) Bertlarge substitute list without duplicates and undesired punctuation: {substitutes_no_dupl_bertlarge}\\n\")\n",
    "    \n",
    "\n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word_bertlarge = []\n",
    "    for substitute in substitutes_no_dupl_bertlarge:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word_bertlarge.append(substitute)\n",
    "    #print(f\"SS step: b) Bertlarge substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word_bertlarge}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym_bertlarge = []\n",
    "    for substitute in substitutes_no_dupl_complex_word_bertlarge:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym_bertlarge.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym_bertlarge.append(substitute)\n",
    "    #print(f\"SS step: c): Bertlarge substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym_bertlarge}\\n\")\n",
    "     \n",
    "    \n",
    "    # limit the substitutes to the 5 first ones for concatenation with the top-5 of other models\n",
    "    top_5_substitutes_bertlarge = substitutes_no_dupl_complex_word_no_antonym_bertlarge[:5]\n",
    "    print(f\"SS step: d): top_5_substitutes_bertlarge: {top_5_substitutes_bertlarge}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # find duplicates between top_5_substitutes_bertbase and top_5_substitutes_bertlarge\n",
    "    duplicates = set(top_5_substitutes_bertbase) & set(top_5_substitutes_bertlarge)\n",
    "\n",
    "    # create a list with duplicates, preserving the original order as much as possible\n",
    "    duplicates_top5_bertbaselarge = []\n",
    "    for sub in top_5_substitutes_bertbase + top_5_substitutes_bertlarge:\n",
    "        if sub in duplicates and sub not in duplicates_top5_bertbaselarge:\n",
    "            duplicates_top5_bertbaselarge.append(sub)\n",
    "\n",
    "    print(f\"duplicates_top5_bertbaselarge: {duplicates_top5_bertbaselarge}\\n\")\n",
    "\n",
    "    # create a list with non-duplicates, using the interleaving order\n",
    "    nonduplicates_top5_bertbaselarge = []\n",
    "    dup_used = set(duplicates_top5_bertbaselarge)\n",
    "\n",
    "    for bert_base, bert_large in zip(top_5_substitutes_bertbase, top_5_substitutes_bertlarge):\n",
    "        if bert_base not in dup_used:\n",
    "            nonduplicates_top5_bertbaselarge.append(bert_base)\n",
    "        if bert_large not in dup_used:\n",
    "            nonduplicates_top5_bertbaselarge.append(bert_large)\n",
    "\n",
    "    print(f\"nonduplicates_top5_bertbaselarge: {nonduplicates_top5_bertbaselarge}\\n\")\n",
    "    \n",
    "    \n",
    "    # concatenate all lists, the duplicate list first\n",
    "    combined_top5_bertbaselarge_duplicates_first = duplicates_top5_bertbaselarge + nonduplicates_top5_bertbaselarge\n",
    "    print(f\"combined_top5_bertbaselarge with duplicates first: {combined_top5_bertbaselarge_duplicates_first}\\n\")\n",
    "    \n",
    "    print('-------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "    \n",
    "    # check if the number of substitutes is greater than the current number of substitute columns\n",
    "    num_substitutes = len(combined_top5_bertbaselarge_duplicates_first)\n",
    "    num_columns = len(substitutes_df.columns)\n",
    "\n",
    "    if num_substitutes + 2 > num_columns:\n",
    "        # Add the required number of new columns\n",
    "        for i in range(num_columns - 2, num_substitutes):\n",
    "            substitutes_df[f\"substitute_{i+1}\"] = ''\n",
    "\n",
    "    # pad the list with empty strings to match the number of columns in the DataFrame\n",
    "    padding = [''] * (num_columns - 2 - len(combined_top5_bertbaselarge_duplicates_first))\n",
    "    row_data = [sentence, complex_word] + combined_top5_bertbaselarge_duplicates_first + padding\n",
    "\n",
    "    # Add the row to the DataFrame\n",
    "    substitutes_df.loc[index] = row_data\n",
    "    \n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the DataFrame\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "\n",
    "      \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/BertBaseLarge_top_5_SG_SS_abc.tsv\", sep=\"\\t\", index=False, header=False)\n",
    "    \n",
    "    \n",
    " \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f93f0d-0ff3-48d3-80f2-8ca6797525ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file .\\predictions\\trial\\BertBaseLarge_top_5_SG_SS_abc.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ae3f266-96a1-4d00-a268-22b29addcd12",
   "metadata": {},
   "source": [
    "top 5:\n",
    "\n",
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = .\\predictions\\trial\\BertBaseLarge_top_5_SG_SS_abc.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.5\n",
    "\n",
    "MAP@3 = 0.2777\n",
    "MAP@5 = 0.1956\n",
    "MAP@10 = 0.1243\n",
    "\n",
    "Potential@3 = 0.6\n",
    "Potential@5 = 0.7\n",
    "Potential@10 = 0.8\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.3\n",
    "Accuracy@2@top_gold_1 = 0.3\n",
    "Accuracy@3@top_gold_1 = 0.4"
   ]
  },
  {
   "cell_type": "raw",
   "id": "795157b8-23b0-403d-aa2b-b4a6bc8b69fe",
   "metadata": {},
   "source": [
    "top 7 (only changed the code, not the name of the file):\n",
    "\n",
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = .\\predictions\\trial\\BertBaseLarge_top_5_SG_SS_abc.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.5\n",
    "\n",
    "MAP@3 = 0.3111\n",
    "MAP@5 = 0.2406\n",
    "MAP@10 = 0.144\n",
    "\n",
    "Potential@3 = 0.7\n",
    "Potential@5 = 0.7\n",
    "Potential@10 = 0.8\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.3\n",
    "Accuracy@2@top_gold_1 = 0.3\n",
    "Accuracy@3@top_gold_1 = 0.6"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47a7f3fd-b1ad-47cb-ade5-1a30e5f2e062",
   "metadata": {},
   "source": [
    "top 8   (only changed the code, not the name of the file):\n",
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = .\\predictions\\trial\\BertBaseLarge_top_5_SG_SS_abc.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.5\n",
    "\n",
    "MAP@3 = 0.2888\n",
    "MAP@5 = 0.2403\n",
    "MAP@10 = 0.1415\n",
    "\n",
    "Potential@3 = 0.6\n",
    "Potential@5 = 0.7\n",
    "Potential@10 = 0.8\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.3\n",
    "Accuracy@2@top_gold_1 = 0.3\n",
    "Accuracy@3@top_gold_1 = 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6ec834-7252-478b-ab47-7531b52b6d0b",
   "metadata": {},
   "source": [
    "result: top 7 of both bertbase and bertlarge seem to give the best (slightly though) results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea44aa17-edf7-456a-95e5-783e187f302b",
   "metadata": {},
   "source": [
    " to do: the same for Roberta! see code above.\n",
    " then, export it to a tsv as before and check results. See if <10 results gives problems, if so, repeat the first word n times until 10 is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f96aaa5-bef4-4f8a-a8c9-e433f6895410",
   "metadata": {},
   "source": [
    "### Roberta-base and Roberta-large:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65641c8f-41d9-4b61-9e63-b0802a36fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the models\n",
    "model_robertabase = AutoModelForMaskedLM.from_pretrained(\"roberta-base\")\n",
    "model_robertalarge = AutoModelForMaskedLM.from_pretrained(\"roberta-large\")\n",
    "\n",
    "# create a fill-mask pipeline for each model (tokenizer seems to be the same so i used the roberta-large tokenizer)\n",
    "fill_mask_robertabase = pipeline(\"fill-mask\", model_robertabase, tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\"))\n",
    "fill_mask_robertalarge = pipeline(\"fill-mask\", model_robertalarge, tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5111ee97-b783-4391-bdd6-c501915f435c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "\n",
      "SG step: Robertabase generated substitutes: ['compulsory', 'mandatory', 'obligatory', 'voluntary', 'required', 'optional', 'obliged', 'uniform', 'necessary', 'available', 'mandated', 'sufficient', 'routine', 'forced', 'customary', 'prerequisite', 'feasible', 'indispensable', 'forthcoming', 'universal', 'requirement', 'involuntary', 'obligated', 'compelled', 'conditional', 'enforced', 'contingent', 'possible', 'compulsion', 'mandatory']\n",
      "\n",
      "SS step: c): Robertabase substitute list without antonyms of the complex word: ['mandatory', 'obligatory', 'voluntary', 'required', 'optional', 'obliged', 'uniform', 'necessary', 'available', 'mandated', 'sufficient', 'routine', 'forced', 'customary', 'prerequisite', 'feasible', 'indispensable', 'forthcoming', 'universal', 'requirement', 'involuntary', 'obligated', 'compelled', 'conditional', 'enforced', 'contingent', 'possible', 'compulsion']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertabase: ['mandatory', 'obligatory', 'voluntary', 'required', 'optional', 'obliged']\n",
      "\n",
      "SG step: Robertalarge generated substitutes: ['compulsory', 'mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n",
      "SS step: c): Robertalarge substitute list without antonyms of the complex word: ['mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine', 'relevant', 'required', 'vital', 'clandestine', 'obliged', 'bureaucratic', 'ministerial', 'mandate', 'necessary', 'lifelong', 'strict', 'gradual', 'demanded', 'lax', 'continuous', 'practicable', 'indispensable', 'forced', 'habitual', 'plain', 'preferable']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertalarge: ['mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant']\n",
      "\n",
      "duplicates_top5_robertabaselarge: ['mandatory', 'obligatory', 'voluntary']\n",
      "\n",
      "nonduplicates_top5_robertabaselarge: ['mandated', 'required', 'optional', 'statutory', 'obliged', 'redundant']\n",
      "\n",
      "combined_top5_robertabaselarge with duplicates first: ['mandatory', 'obligatory', 'voluntary', 'mandated', 'required', 'optional', 'statutory', 'obliged', 'redundant']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "\n",
      "SG step: Robertabase generated substitutes: ['infused', 'injected', 'endowed', 'illed', 'inst', 'furnished', 'supplied', 'bolstered', 'implanted', 'impressed', 'reinforced', 'invested', 'provided', 'filled', 'reassured', 'undermined', 'filled', 'pumped', 'struck', 'augmented', 'enriched', 'stirred', 'vested', 'imb', 'intoxicated', 'seeded', 'misled', 'stunned', 'inspired', 'inflated']\n",
      "\n",
      "SS step: c): Robertabase substitute list without antonyms of the complex word: ['infused', 'injected', 'endowed', 'illed', 'inst', 'furnished', 'supplied', 'bolstered', 'implanted', 'impressed', 'reinforced', 'invested', 'provided', 'filled', 'reassured', 'undermined', 'pumped', 'struck', 'augmented', 'enriched', 'stirred', 'vested', 'imb', 'intoxicated', 'seeded', 'misled', 'stunned', 'inspired', 'inflated']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertabase: ['infused', 'injected', 'endowed', 'illed', 'inst', 'furnished']\n",
      "\n",
      "SG step: Robertalarge generated substitutes: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n",
      "SS step: c): Robertalarge substitute list without antonyms of the complex word: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected', 'revived', 'endowed', 'gifted', 'reassured', 'implanted', 'infiltrated', 'pumped', 'inject', 'flooded', 'sprinkled', 'installed', 'vested', 'thrilled', 'assured', 'penetrated', 'hit', 'provided', 'insulated', 'vaccinated', 'stocked', 'stoked', 'elevated']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertalarge: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed']\n",
      "\n",
      "duplicates_top5_robertabaselarge: ['infused', 'injected', 'illed', 'inst']\n",
      "\n",
      "nonduplicates_top5_robertabaselarge: ['endowed', 'filled', 'invested', 'furnished']\n",
      "\n",
      "combined_top5_robertabaselarge with duplicates first: ['infused', 'injected', 'illed', 'inst', 'endowed', 'filled', 'invested', 'furnished']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "\n",
      "SG step: Robertabase generated substitutes: ['maniac', 'criminals', 'riors', 'hawks', 'heads', 'killers', 'gangs', 'lords', 'thugs', 'devils', 'drums', 'murderers', 'fighters', 'monsters', 'fools', 'villains', 'idiots', 'machines', 'demons', 'doctors', 'planes', 'igans', 'bosses', 'nazis', 'beasts', 'fascists', 'children', 'nerds', 'extremists', 'parasites']\n",
      "\n",
      "SS step: c): Robertabase substitute list without antonyms of the complex word: ['criminals', 'riors', 'hawks', 'heads', 'killers', 'gangs', 'lords', 'thugs', 'devils', 'drums', 'murderers', 'fighters', 'monsters', 'fools', 'villains', 'idiots', 'machines', 'demons', 'doctors', 'planes', 'igans', 'bosses', 'nazis', 'beasts', 'fascists', 'children', 'nerds', 'extremists', 'parasites']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertabase: ['criminals', 'riors', 'hawks', 'heads', 'killers', 'gangs']\n",
      "\n",
      "SG step: Robertalarge generated substitutes: ['maniac', 'criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'fighters', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'killers', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n",
      "SS step: c): Robertalarge substitute list without antonyms of the complex word: ['criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants', 'factions', 'commanders', 'lords', 'jihadists', 'gangs', 'fascists', 'helmets', 'assassins', 'crimes', 'squads', 'hunters', 'gunmen', 'partisans', 'detainees', 'killings', 'troops', 'monsters', 'chiefs', 'perpetrators']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertalarge: ['criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries']\n",
      "\n",
      "duplicates_top5_robertabaselarge: ['criminals', 'killers']\n",
      "\n",
      "nonduplicates_top5_robertabaselarge: ['riors', 'hawks', 'thugs', 'heads', 'fighters', 'murderers', 'gangs', 'mercenaries']\n",
      "\n",
      "combined_top5_robertabaselarge with duplicates first: ['criminals', 'killers', 'riors', 'hawks', 'thugs', 'heads', 'fighters', 'murderers', 'gangs', 'mercenaries']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "\n",
      "SG step: Robertabase generated substitutes: ['observers', 'monitors', 'spectators', 'witnesses', 'observer', 'observes', 'visitors', 'viewers', 'reporters', 'inspectors', 'commentators', 'investigators', 'participants', 'analysts', 'cameras', 'outsiders', 'demonstrators', 'activists', 'journalists', 'experts', 'authorities', 'observations', 'eyes', 'supporters', 'observing', 'residents', 'protesters', 'responders', 'parties', 'followers']\n",
      "\n",
      "SS step: c): Robertabase substitute list without antonyms of the complex word: ['monitors', 'spectators', 'witnesses', 'observes', 'visitors', 'viewers', 'reporters', 'inspectors', 'commentators', 'investigators', 'participants', 'analysts', 'cameras', 'outsiders', 'demonstrators', 'activists', 'journalists', 'experts', 'authorities', 'observations', 'eyes', 'supporters', 'observing', 'residents', 'protesters', 'responders', 'parties', 'followers']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertabase: ['monitors', 'spectators', 'witnesses', 'observes', 'visitors', 'viewers']\n",
      "\n",
      "SG step: Robertalarge generated substitutes: ['observers', 'monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'observer', 'supervisors', 'analysts', 'operators', 'responders', 'observer', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n",
      "SS step: c): Robertalarge substitute list without antonyms of the complex word: ['monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'supervisors', 'analysts', 'operators', 'responders', 'reporters', 'witnesses', 'observations', 'inspectors', 'observes', 'investigators', 'dissidents', 'bystanders', 'visitors', 'officials', 'educators', 'airstrikes', 'organizers', 'followers', 'observed', 'outsiders', 'reinforcements']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertalarge: ['monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts']\n",
      "\n",
      "duplicates_top5_robertabaselarge: ['monitors']\n",
      "\n",
      "nonduplicates_top5_robertabaselarge: ['spectators', 'demonstrators', 'witnesses', 'participants', 'observes', 'opponents', 'visitors', 'advisors', 'viewers', 'experts']\n",
      "\n",
      "combined_top5_robertabaselarge with duplicates first: ['monitors', 'spectators', 'demonstrators', 'witnesses', 'participants', 'observes', 'opponents', 'visitors', 'advisors', 'viewers', 'experts']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "\n",
      "SG step: Robertabase generated substitutes: ['rapnel', 'bullet', 'gunshot', 'stab', 'radiation', 'projectile', 'crippling', 'shotgun', 'mortar', 'stun', 'explosive', 'stray', 'shell', 'bomb', 'microscopic', 'fragmentation', 'cartridge', 'grenade', 'rocket', 'torpedo', 'piercing', 'unidentified', 'ammunition', 'insurgent', 'similar', 'blast', 'bullets', 'slug', 'terrorist', 'pillow']\n",
      "\n",
      "SS step: c): Robertabase substitute list without antonyms of the complex word: ['rapnel', 'bullet', 'gunshot', 'stab', 'radiation', 'projectile', 'crippling', 'shotgun', 'mortar', 'stun', 'explosive', 'stray', 'shell', 'bomb', 'microscopic', 'fragmentation', 'cartridge', 'grenade', 'rocket', 'torpedo', 'piercing', 'unidentified', 'ammunition', 'insurgent', 'similar', 'blast', 'bullets', 'slug', 'terrorist', 'pillow']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertabase: ['rapnel', 'bullet', 'gunshot', 'stab', 'radiation', 'projectile']\n",
      "\n",
      "SG step: Robertalarge generated substitutes: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n",
      "SS step: c): Robertalarge substitute list without antonyms of the complex word: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar', 'sh', 'shell', 'sniper', 'projectile', 'stab', 'multiple', 'shot', 'gunshots', 'several', 'blast', 'arrow', 'a', 'shotgun', 'spear', 'shock', 'dagger', 'blaster', 'the', 'stray', 'explosive', 'unspecified', 'knife']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertalarge: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun']\n",
      "\n",
      "duplicates_top5_robertabaselarge: ['rapnel', 'bullet', 'gunshot']\n",
      "\n",
      "nonduplicates_top5_robertabaselarge: ['stab', 'gunfire', 'radiation', 'grenade', 'projectile', 'gun']\n",
      "\n",
      "combined_top5_robertabaselarge with duplicates first: ['rapnel', 'bullet', 'gunshot', 'stab', 'gunfire', 'radiation', 'grenade', 'projectile', 'gun']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "\n",
      "SG step: Robertabase generated substitutes: ['disguised', 'dressed', 'veiled', 'masked', 'concealed', 'hidden', 'disguise', 'clothed', 'clad', 'posed', 'covered', 'cloaked', 'shrouded', 'wrapped', 'posing', 'hiding', 'trained', 'camoufl', 'presented', 'known', 'smuggled', 'staged', 'draped', 'described', 'decorated', 'armed', 'buried', 'camouflage', 'marked', 'hid']\n",
      "\n",
      "SS step: c): Robertabase substitute list without antonyms of the complex word: ['dressed', 'veiled', 'masked', 'concealed', 'hidden', 'disguise', 'clothed', 'clad', 'posed', 'covered', 'cloaked', 'shrouded', 'wrapped', 'posing', 'hiding', 'trained', 'camoufl', 'presented', 'known', 'smuggled', 'staged', 'draped', 'described', 'decorated', 'armed', 'buried', 'camouflage', 'marked', 'hid']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertabase: ['dressed', 'veiled', 'masked', 'concealed', 'hidden', 'disguise']\n",
      "\n",
      "SG step: Robertalarge generated substitutes: ['disguised', 'cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n",
      "SS step: c): Robertalarge substitute list without antonyms of the complex word: ['cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised', 'portrayed', 'shrouded', 'styled', 'wrapped', 'packaged', 'posed', 'adorned', 'imprisoned', 'dispersed', 'united', 'disgu', 'displayed', 'veiled', 'fitted', 'framed', 'armoured', 'frightened', 'formed', 'revealed', 'organised', 'branded']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertalarge: ['cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise']\n",
      "\n",
      "duplicates_top5_robertabaselarge: ['dressed', 'masked', 'concealed', 'disguise']\n",
      "\n",
      "nonduplicates_top5_robertabaselarge: ['cloaked', 'veiled', 'hidden', 'clothed']\n",
      "\n",
      "combined_top5_robertabaselarge with duplicates first: ['dressed', 'masked', 'concealed', 'disguise', 'cloaked', 'veiled', 'hidden', 'clothed']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "\n",
      "SG step: Robertabase generated substitutes: ['off', 'extension', 'opposite', 'outpost', 'off', 'out', 'affiliate', 'offspring', 'overthrow', 'element', 'outside', 'echo', 'expansion', 'imprint', 'arm', 'ideology', 'overhaul', 'branch', 'opposition', 'evolution', 'indication', 'upset', 'archetype', 'extend', 'independent', 'alternative', 'example', 'instance', 'embrace', 'adjunct']\n",
      "\n",
      "SS step: c): Robertabase substitute list without antonyms of the complex word: ['off', 'extension', 'opposite', 'outpost', 'out', 'affiliate', 'offspring', 'overthrow', 'element', 'outside', 'echo', 'expansion', 'imprint', 'arm', 'ideology', 'overhaul', 'branch', 'opposition', 'evolution', 'indication', 'upset', 'archetype', 'extend', 'independent', 'alternative', 'example', 'instance', 'embrace', 'adjunct']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertabase: ['off', 'extension', 'opposite', 'outpost', 'out', 'affiliate']\n",
      "\n",
      "SG step: Robertalarge generated substitutes: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n",
      "SS step: c): Robertalarge substitute list without antonyms of the complex word: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation', 'off', 'adjunct', 'iteration', 'incarnation', 'enclave', 'arm', 'embryo', 'branch', 'affiliation', 'example', 'acronym', 'outreach', 'extremist', 'outline', 'insurgency', 'affiliated', 'embrace', 'orthodoxy', 'undercut', 'outlet', 'subset']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertalarge: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring']\n",
      "\n",
      "duplicates_top5_robertabaselarge: ['extension', 'outpost', 'affiliate']\n",
      "\n",
      "nonduplicates_top5_robertabaselarge: ['off', 'shoot', 'opposite', 'out', 'adherent', 'offspring']\n",
      "\n",
      "combined_top5_robertabaselarge with duplicates first: ['extension', 'outpost', 'affiliate', 'off', 'shoot', 'opposite', 'out', 'adherent', 'offspring']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "\n",
      "SG step: Robertabase generated substitutes: ['classical', 'harmonic', 'musical', 'sym', 'music', 'instrumental', 'piano', 'lyric', 'jazz', 'modern', 'dramatic', 'major', 'vocal', 'composing', 'concert', 'opera', 'sonic', 'formal', 'popular', 'early', 'composition', 'english', 'singing', 'standard', 'trumpet', 'keyboard', 'contemporary', 'orchestra', 'technical', 'onic']\n",
      "\n",
      "SS step: c): Robertabase substitute list without antonyms of the complex word: ['classical', 'harmonic', 'musical', 'sym', 'music', 'instrumental', 'piano', 'lyric', 'jazz', 'modern', 'dramatic', 'major', 'vocal', 'composing', 'concert', 'opera', 'sonic', 'formal', 'popular', 'early', 'composition', 'english', 'singing', 'standard', 'trumpet', 'keyboard', 'contemporary', 'orchestra', 'technical', 'onic']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertabase: ['classical', 'harmonic', 'musical', 'sym', 'music', 'instrumental']\n",
      "\n",
      "SG step: Robertalarge generated substitutes: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', ',', 'theoretical', 'or', 'and', 'traditional', '</s>', 'concert', 'romantic', 'vocal', 'in', 'musical', 'contemporary', 'formal', 'analytic']\n",
      "\n",
      "SS step: c): Robertalarge substitute list without antonyms of the complex word: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical', 'instrumental', 'piano', 'the', 'of', 'historical', 'dramatic', 'general', 'modern', 'theoretical', 'or', 'and', 'traditional', 'concert', 'romantic', 'vocal', 'in', 'contemporary', 'formal', 'analytic']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertalarge: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic']\n",
      "\n",
      "duplicates_top5_robertabaselarge: ['classical', 'harmonic', 'musical', 'music']\n",
      "\n",
      "nonduplicates_top5_robertabaselarge: ['sym', 'popular', 'instrumental', 'onic']\n",
      "\n",
      "combined_top5_robertabaselarge with duplicates first: ['classical', 'harmonic', 'musical', 'music', 'sym', 'popular', 'instrumental', 'onic']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "\n",
      "SG step: Robertabase generated substitutes: ['deploy', 'deployed', 'deployment', 'utilize', 'mobilize', 'employ', 'deploying', 'dispatch', 'equip', 'deploy', 'ploy', 'use', 'activate', 'recruit', 'transport', 'operate', 'withdraw', 'install', 'locate', 'commit', 'construct', 'summon', 'expend', 'send', 'reserve', 'possess', 'cultivate', 'adopt', 'engage', 'unleash']\n",
      "\n",
      "SS step: c): Robertabase substitute list without antonyms of the complex word: ['deployment', 'utilize', 'mobilize', 'employ', 'dispatch', 'equip', 'ploy', 'use', 'activate', 'recruit', 'transport', 'operate', 'withdraw', 'install', 'locate', 'commit', 'construct', 'summon', 'expend', 'send', 'reserve', 'possess', 'cultivate', 'adopt', 'engage', 'unleash']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertabase: ['deployment', 'utilize', 'mobilize', 'employ', 'dispatch', 'equip']\n",
      "\n",
      "SG step: Robertalarge generated substitutes: ['deploy', 'deployed', 'deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'deploying', 'deploy', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n",
      "SS step: c): Robertalarge substitute list without antonyms of the complex word: ['deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'maneuver', 'disperse', 'send', 'launch', 'recruit', 'contract', 'use', 'move', 'tether', 'expend', 'monitor', 'deliver', 'secure', 'operate', 'construct', 'wield', 'patrol', 'combat', 'command', 'withdraw', 'transport']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertalarge: ['deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'maneuver']\n",
      "\n",
      "duplicates_top5_robertabaselarge: ['deployment', 'mobilize', 'employ', 'dispatch']\n",
      "\n",
      "nonduplicates_top5_robertabaselarge: ['utilize', 'ploy', 'equip', 'maneuver']\n",
      "\n",
      "combined_top5_robertabaselarge with duplicates first: ['deployment', 'mobilize', 'employ', 'dispatch', 'utilize', 'ploy', 'equip', 'maneuver']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "\n",
      "SG step: Robertabase generated substitutes: ['authorities', 'officials', 'authorities', 'authority', 'investigators', 'counterparts', 'police', 'agencies', 'administrators', 'forces', 'prosecutors', 'officers', 'authorities', 'entities', 'intelligence', 'jurisdictions', 'individuals', 'detainees', 'institutions', 'affairs', 'demonstrators', 'superiors', 'victims', 'regulators', 'concerns', 'ministers', 'figures', 'suspects', 'sources', 'assistance']\n",
      "\n",
      "SS step: c): Robertabase substitute list without antonyms of the complex word: ['officials', 'investigators', 'counterparts', 'police', 'agencies', 'administrators', 'forces', 'prosecutors', 'officers', 'entities', 'intelligence', 'jurisdictions', 'individuals', 'detainees', 'institutions', 'affairs', 'demonstrators', 'superiors', 'victims', 'regulators', 'concerns', 'ministers', 'figures', 'suspects', 'sources', 'assistance']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertabase: ['officials', 'investigators', 'counterparts', 'police', 'agencies', 'administrators']\n",
      "\n",
      "SG step: Robertalarge generated substitutes: ['authorities', 'police', 'officials', 'authorities', 'authority', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'authorities', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n",
      "SS step: c): Robertalarge substitute list without antonyms of the complex word: ['police', 'officials', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors', 'officers', 'employees', 'courts', 'residents', 'prosecutors', 'detainees', 'authors', 'paramedics', 'policemen', 'applications', 'forces', 'institutions', 'representatives', 'neighbours', 'bodies', 'regimes', 'individuals', 'requirements']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertalarge: ['police', 'officials', 'regulators', 'governments', 'arrests', 'investigators']\n",
      "\n",
      "duplicates_top5_robertabaselarge: ['officials', 'investigators', 'police']\n",
      "\n",
      "nonduplicates_top5_robertabaselarge: ['counterparts', 'regulators', 'governments', 'agencies', 'arrests', 'administrators']\n",
      "\n",
      "combined_top5_robertabaselarge with duplicates first: ['officials', 'investigators', 'police', 'counterparts', 'regulators', 'governments', 'agencies', 'arrests', 'administrators']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "    \n",
    "    # for Roberta-base:\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\\n\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word,\"<mask>\")   # RoBERTa uses <mask> instead of [MASK]\n",
    "\n",
    "    ## fill the mask with substitute words, and concatenate the original sentence and the masked sentence\n",
    "    tokenizer_robertabase = fill_mask_robertabase.tokenizer\n",
    "    sentences_concat_robertabase = f\"{sentence} {tokenizer_robertabase.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result_robertabase = fill_mask_robertabase(sentences_concat_robertabase, top_k=top_k)\n",
    "   \n",
    "        \n",
    "    ## lowercase, remove the leading space in each substitute (roberta only) and print the top-k substitutes\n",
    "    substitutes_robertabase = [substitute[\"token_str\"].lower().lstrip() for substitute in result_robertabase]   # and use .lstrip to remove the leading space (for ROBERTA only), as Roberta tokenizes by default with a space in front of the word\n",
    "    #print(f\"SG step: Robertabase generated substitutes: {substitutes_robertabase}\\n\")\n",
    "    \n",
    "   # 2. Substitute Selection (SS):   \n",
    "\n",
    "    # create a punctuation set without hyphen, in order to retain hyphens in compound substitutes\n",
    "    punctuation_without_hyphen = set(string.punctuation) - set('-')\n",
    "    \n",
    "    # a) remove duplicates and unwanted punctuation (this happened with BERT) within the substitute list from the substitute list\n",
    "    substitutes_no_dupl_robertabase = []\n",
    "    for sub in substitutes_robertabase:\n",
    "        if sub not in substitutes_no_dupl_robertabase and not any(char in punctuation_without_hyphen for char in sub):\n",
    "            substitutes_no_dupl_robertabase.append(sub)\n",
    "    #print(f\"SS step: a) Robertabase substitute list without duplicates and undesired punctuation: {substitutes_no_dupl_robertabase}\\n\")\n",
    "    \n",
    "\n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word_robertabase = []\n",
    "    for substitute in substitutes_no_dupl_robertabase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word_robertabase.append(substitute)\n",
    "    #print(f\"SS step: b) Robertabase substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word_robertabase}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym_robertabase = []\n",
    "    for substitute in substitutes_no_dupl_complex_word_robertabase:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym_robertabase.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym_robertabase.append(substitute)\n",
    "    #print(f\"SS step: c): Robertabase substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym_robertabase}\\n\")\n",
    "    \n",
    "     \n",
    "    \n",
    "    # limit the substitutes to the 5 first ones for concatenation with the top-5 of other models\n",
    "    top_5_substitutes_robertabase = substitutes_no_dupl_complex_word_no_antonym_robertabase[:5]\n",
    "    print(f\"SS step: d): top_5_substitutes_robertabase: {top_5_substitutes_robertabase}\\n\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # for Roberta-large:\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    # ## print the sentence and the complex word\n",
    "    # sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    # print(f\"Sentence: {sentence}\")\n",
    "    # print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "#     ## in the sentence, replace the complex word with a masked word\n",
    "#     sentence_masked_word = sentence.replace(complex_word, \"<mask>\")  # RoBERTa uses <mask> instead of [MASK]\n",
    "\n",
    "    ## fill the mask with substitute words, and concatenate the original sentence and the masked sentence\n",
    "    tokenizer_robertalarge = fill_mask_robertalarge.tokenizer\n",
    "    sentences_concat_robertalarge = f\"{sentence} {tokenizer_robertalarge.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result_robertalarge = fill_mask_robertalarge(sentences_concat_robertalarge, top_k=top_k)\n",
    "   \n",
    "     ## lowercase, remove the leading space in each substitute (roberta only) and print the top-k substitutes\n",
    "    substitutes_robertalarge = [substitute[\"token_str\"].lower().lstrip() for substitute in result_robertalarge]   # and use .lstrip to remove the leading space (for ROBERTA only), as Roberta tokenizes by default with a space in front of the word\n",
    "    #print(f\"SG step: Robertalarge generated substitutes: {substitutes_robertalarge}\\n\")\n",
    "    \n",
    "   # 2. Substitute Selection (SS):   \n",
    "\n",
    "    # create a punctuation set without hyphen, in order to retain hyphens in compound substitutes\n",
    "    punctuation_without_hyphen = set(string.punctuation) - set('-')\n",
    "    \n",
    "    # a) remove duplicates and unwanted punctuation within the substitute list from the substitute list\n",
    "    substitutes_no_dupl_robertalarge = []\n",
    "    for sub in substitutes_robertalarge:\n",
    "        if sub not in substitutes_no_dupl_robertalarge and not any(char in punctuation_without_hyphen for char in sub):\n",
    "            substitutes_no_dupl_robertalarge.append(sub)\n",
    "    #print(f\"SS step: a) Robertalarge substitute list without duplicates and undesired punctuation: {substitutes_no_dupl_robertalarge}\\n\")\n",
    "    \n",
    "\n",
    "   \n",
    "    # # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    # ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    # doc_complex_word = nlp(complex_word)\n",
    "    # complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    # #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word_robertalarge = []\n",
    "    for substitute in substitutes_no_dupl_robertalarge:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word_robertalarge.append(substitute)\n",
    "    #print(f\"SS step: b) Robertalarge substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word_robertalarge}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym_robertalarge = []\n",
    "    for substitute in substitutes_no_dupl_complex_word_robertalarge:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym_robertalarge.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym_robertalarge.append(substitute)\n",
    "    #print(f\"SS step: c): Robertalarge substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym_robertalarge}\\n\")\n",
    "     \n",
    "    \n",
    "    # limit the substitutes to the 5 first ones for concatenation with the top-5 of other models\n",
    "    top_5_substitutes_robertalarge = substitutes_no_dupl_complex_word_no_antonym_robertalarge[:5]\n",
    "    print(f\"SS step: d): top_5_substitutes_robertalarge: {top_5_substitutes_robertalarge}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # find duplicates between top_5_substitutes_robertabase and top_5_substitutes_robertalarge\n",
    "    duplicates = set(top_5_substitutes_robertabase) & set(top_5_substitutes_robertalarge)\n",
    "\n",
    "    # create a list with duplicates, preserving the original order as much as possible\n",
    "    duplicates_top5_robertabaselarge = []\n",
    "    for sub in top_5_substitutes_robertabase + top_5_substitutes_robertalarge:\n",
    "        if sub in duplicates and sub not in duplicates_top5_robertabaselarge:\n",
    "            duplicates_top5_robertabaselarge.append(sub)\n",
    "\n",
    "    print(f\"duplicates_top5_robertabaselarge: {duplicates_top5_robertabaselarge}\\n\")\n",
    "\n",
    "    # create a list with non-duplicates, using the interleaving order\n",
    "    nonduplicates_top5_robertabaselarge = []\n",
    "    dup_used = set(duplicates_top5_robertabaselarge)\n",
    "\n",
    "    for roberta_base, roberta_large in zip(top_5_substitutes_robertabase, top_5_substitutes_robertalarge):\n",
    "        if roberta_base not in dup_used:\n",
    "            nonduplicates_top5_robertabaselarge.append(roberta_base)\n",
    "        if roberta_large not in dup_used:\n",
    "            nonduplicates_top5_robertabaselarge.append(roberta_large)\n",
    "\n",
    "    print(f\"nonduplicates_top5_robertabaselarge: {nonduplicates_top5_robertabaselarge}\\n\")\n",
    "    \n",
    "    \n",
    "    # concatenate all lists, the duplicate list first\n",
    "    combined_top5_robertabaselarge_duplicates_first = duplicates_top5_robertabaselarge + nonduplicates_top5_robertabaselarge\n",
    "    print(f\"combined_top5_robertabaselarge with duplicates first: {combined_top5_robertabaselarge_duplicates_first}\\n\")\n",
    "    \n",
    "    print('-------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "    \n",
    "    # check if the number of substitutes is greater than the current number of substitute columns\n",
    "    num_substitutes = len(combined_top5_robertabaselarge_duplicates_first)\n",
    "    num_columns = len(substitutes_df.columns)\n",
    "\n",
    "    if num_substitutes + 2 > num_columns:\n",
    "        # Add the required number of new columns\n",
    "        for i in range(num_columns - 2, num_substitutes):\n",
    "            substitutes_df[f\"substitute_{i+1}\"] = ''\n",
    "\n",
    "    # pad the list with empty strings to match the number of columns in the DataFrame\n",
    "    padding = [''] * (num_columns - 2 - len(combined_top5_robertabaselarge_duplicates_first))\n",
    "    row_data = [sentence, complex_word] + combined_top5_robertabaselarge_duplicates_first + padding\n",
    "\n",
    "    # Add the row to the DataFrame\n",
    "    substitutes_df.loc[index] = row_data\n",
    "    \n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the DataFrame\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "\n",
    "      \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/RobertaBaseLarge_top_5_SG_SS_abc.tsv\", sep=\"\\t\", index=False, header=False)\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a54364d-386a-4a0c-9c93-7a0b4b774f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file .\\predictions\\trial\\RobertaBaseLarge_top_5_SG_SS_abc.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7960f3f-dd2c-4caf-9dab-edc56df7b672",
   "metadata": {},
   "source": [
    "top 5:\n",
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = .\\predictions\\trial\\RobertaBaseLarge_top_5_SG_SS_abc.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.4\n",
    "\n",
    "MAP@3 = 0.35\n",
    "MAP@5 = 0.25\n",
    "MAP@10 = 0.1316\n",
    "\n",
    "Potential@3 = 0.8\n",
    "Potential@5 = 1.0\n",
    "Potential@10 = 1.0\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.4\n",
    "Accuracy@2@top_gold_1 = 0.5\n",
    "Accuracy@3@top_gold_1 = 0.6\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da95c4a9-9174-43b4-b136-414afd5b5c76",
   "metadata": {},
   "source": [
    "top 7 (only changed the code, not the name of the file):\n",
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = .\\predictions\\trial\\RobertaBaseLarge_top_5_SG_SS_abc.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.4\n",
    "\n",
    "MAP@3 = 0.3388\n",
    "MAP@5 = 0.2303\n",
    "MAP@10 = 0.1311\n",
    "\n",
    "Potential@3 = 0.8\n",
    "Potential@5 = 0.9\n",
    "Potential@10 = 1.0\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.4\n",
    "Accuracy@2@top_gold_1 = 0.5\n",
    "Accuracy@3@top_gold_1 = 0.6\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf42bc20-fbc4-419a-9f6e-2620022aa95b",
   "metadata": {},
   "source": [
    "top 7 is slighlty worse than top 5, so trying top 6 now:\n",
    "top 6 (only changed the code, not the name of the file):\n",
    "\n",
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = .\\predictions\\trial\\RobertaBaseLarge_top_5_SG_SS_abc.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.4\n",
    "\n",
    "MAP@3 = 0.3388\n",
    "MAP@5 = 0.2343\n",
    "MAP@10 = 0.1292\n",
    "\n",
    "Potential@3 = 0.8\n",
    "Potential@5 = 1.0\n",
    "Potential@10 = 1.0\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.4\n",
    "Accuracy@2@top_gold_1 = 0.5\n",
    "Accuracy@3@top_gold_1 = 0.6   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be039c2-39b1-42e1-8d2f-09064de746fb",
   "metadata": {},
   "source": [
    "### Combine all 4 models (bert and roberta, base and large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9366200a-73be-4cae-b3d6-1bea2c3d7f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "\n",
      "SS step: d): top_5_substitutes_bertbase: ['mandatory', 'obligatory', 'optional', 'required', 'necessary', 'standard', 'voluntary', 'customary']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertlarge: ['mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertabase: ['mandatory', 'obligatory', 'voluntary', 'required', 'optional', 'obliged', 'uniform', 'necessary']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertalarge: ['mandatory', 'mandated', 'voluntary', 'obligatory', 'statutory', 'redundant', 'enforced', 'routine']\n",
      "\n",
      "duplicates_top5_bertrobertabaselarge: ['mandatory', 'obligatory', 'voluntary']\n",
      "\n",
      "nonduplicates_top5_bertrobertabaselarge: ['mandated', 'optional', 'required', 'necessary', 'statutory', 'standard', 'obliged', 'redundant', 'uniform', 'enforced', 'customary', 'forbidden', 'routine']\n",
      "\n",
      "combined_top5_bertrobertabaselarge_duplicates_first: ['mandatory', 'obligatory', 'voluntary', 'mandated', 'optional', 'required', 'necessary', 'statutory', 'standard', 'obliged', 'redundant', 'uniform', 'enforced', 'customary', 'forbidden', 'routine']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "\n",
      "SS step: d): top_5_substitutes_bertbase: ['strengthened', 'targeted', 'tested', 'provided', 'created', 'affected', 'addressed', 'attacked']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertlarge: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertabase: ['infused', 'injected', 'endowed', 'illed', 'inst', 'furnished', 'supplied', 'bolstered']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertalarge: ['infused', 'injected', 'filled', 'inst', 'invested', 'illed', 'impressed', 'infected']\n",
      "\n",
      "duplicates_top5_bertrobertabaselarge: []\n",
      "\n",
      "nonduplicates_top5_bertrobertabaselarge: ['strengthened', 'provided', 'infused', 'targeted', 'injected', 'tested', 'endowed', 'filled', 'presented', 'illed', 'inst', 'created', 'left', 'invested', 'affected', 'supplied', 'furnished', 'addressed', 'delivered', 'impressed', 'attacked', 'bolstered', 'infected']\n",
      "\n",
      "combined_top5_bertrobertabaselarge_duplicates_first: ['strengthened', 'provided', 'infused', 'targeted', 'injected', 'tested', 'endowed', 'filled', 'presented', 'illed', 'inst', 'created', 'left', 'invested', 'affected', 'supplied', 'furnished', 'addressed', 'delivered', 'impressed', 'attacked', 'bolstered', 'infected']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "\n",
      "SS step: d): top_5_substitutes_bertbase: ['criminals', 'crimes', 'machines', 'rats', 'pigs', 'heroes', 'demons', 'robots']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertlarge: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertabase: ['criminals', 'riors', 'hawks', 'heads', 'killers', 'gangs', 'lords', 'thugs']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertalarge: ['criminals', 'killers', 'thugs', 'fighters', 'murderers', 'mercenaries', 'militias', 'combatants']\n",
      "\n",
      "duplicates_top5_bertrobertabaselarge: ['criminals']\n",
      "\n",
      "nonduplicates_top5_bertrobertabaselarge: ['machines', 'crimes', 'mania', 'riors', 'killers', 'hawks', 'thugs', 'rats', 'heads', 'fighters', 'pigs', 'monsters', 'murderers', 'heroes', 'zombies', 'gangs', 'mercenaries', 'demons', 'freaks', 'lords', 'militias', 'robots', 'hysteria', 'combatants']\n",
      "\n",
      "combined_top5_bertrobertabaselarge_duplicates_first: ['criminals', 'machines', 'crimes', 'mania', 'riors', 'killers', 'hawks', 'thugs', 'rats', 'heads', 'fighters', 'pigs', 'monsters', 'murderers', 'heroes', 'zombies', 'gangs', 'mercenaries', 'demons', 'freaks', 'lords', 'militias', 'robots', 'hysteria', 'combatants']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "\n",
      "SS step: d): top_5_substitutes_bertbase: ['witnesses', 'participants', 'casualties', 'refugees', 'visitors', 'monitors', 'victims', 'delegates']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertlarge: ['monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertabase: ['monitors', 'spectators', 'witnesses', 'observes', 'visitors', 'viewers', 'reporters', 'inspectors']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertalarge: ['monitors', 'demonstrators', 'participants', 'opponents', 'advisors', 'experts', 'supervisors', 'analysts']\n",
      "\n",
      "duplicates_top5_bertrobertabaselarge: ['monitors']\n",
      "\n",
      "nonduplicates_top5_bertrobertabaselarge: ['witnesses', 'participants', 'spectators', 'demonstrators', 'casualties', 'refugees', 'analysts', 'observes', 'opponents', 'visitors', 'advisors', 'observations', 'viewers', 'experts', 'victims', 'journalists', 'reporters', 'supervisors', 'delegates', 'fighters', 'inspectors']\n",
      "\n",
      "combined_top5_bertrobertabaselarge_duplicates_first: ['monitors', 'witnesses', 'participants', 'spectators', 'demonstrators', 'casualties', 'refugees', 'analysts', 'observes', 'opponents', 'visitors', 'advisors', 'observations', 'viewers', 'experts', 'victims', 'journalists', 'reporters', 'supervisors', 'delegates', 'fighters', 'inspectors']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "\n",
      "SS step: d): top_5_substitutes_bertbase: ['stab', 'gunshot', 'bullet', 'knife', 'multiple', 'severe', 'arrow', 'several']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertlarge: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertabase: ['rapnel', 'bullet', 'gunshot', 'stab', 'radiation', 'projectile', 'crippling', 'shotgun']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertalarge: ['gunshot', 'rapnel', 'bullet', 'gunfire', 'grenade', 'gun', 'rifle', 'mortar']\n",
      "\n",
      "duplicates_top5_bertrobertabaselarge: ['gunshot', 'bullet']\n",
      "\n",
      "nonduplicates_top5_bertrobertabaselarge: ['stab', 'rapnel', 'knife', 'gunfire', 'multiple', 'flesh', 'radiation', 'grenade', 'severe', 'arrow', 'projectile', 'gun', 'crippling', 'rifle', 'several', 'minor', 'shotgun', 'mortar']\n",
      "\n",
      "combined_top5_bertrobertabaselarge_duplicates_first: ['gunshot', 'bullet', 'stab', 'rapnel', 'knife', 'gunfire', 'multiple', 'flesh', 'radiation', 'grenade', 'severe', 'arrow', 'projectile', 'gun', 'crippling', 'rifle', 'several', 'minor', 'shotgun', 'mortar']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "\n",
      "SS step: d): top_5_substitutes_bertbase: ['dressed', 'clad', 'masked', 'clothed', 'dressing', 'disguise', 'concealed', 'cloak']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertlarge: ['dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertabase: ['dressed', 'veiled', 'masked', 'concealed', 'hidden', 'disguise', 'clothed', 'clad']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertalarge: ['cloaked', 'masked', 'dressed', 'concealed', 'clothed', 'disguise', 'clad', 'recognised']\n",
      "\n",
      "duplicates_top5_bertrobertabaselarge: ['dressed', 'clad', 'masked', 'clothed', 'disguise', 'concealed']\n",
      "\n",
      "nonduplicates_top5_bertrobertabaselarge: ['cloaked', 'veiled', 'dressing', 'armoured', 'hidden', 'cloak', 'recognised']\n",
      "\n",
      "combined_top5_bertrobertabaselarge_duplicates_first: ['dressed', 'clad', 'masked', 'clothed', 'disguise', 'concealed', 'cloaked', 'veiled', 'dressing', 'armoured', 'hidden', 'cloak', 'recognised']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "\n",
      "SS step: d): top_5_substitutes_bertbase: ['affiliate', 'extension', 'arm', 'adaptation', 'incarnation', 'ally', 'opponent', 'attack']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertlarge: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertabase: ['off', 'extension', 'opposite', 'outpost', 'out', 'affiliate', 'offspring', 'overthrow']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertalarge: ['shoot', 'affiliate', 'extension', 'outpost', 'adherent', 'offspring', 'ally', 'adaptation']\n",
      "\n",
      "duplicates_top5_bertrobertabaselarge: ['affiliate', 'extension']\n",
      "\n",
      "nonduplicates_top5_bertrobertabaselarge: ['off', 'shoot', 'arm', 'ally', 'opposite', 'adaptation', 'outpost', 'incarnation', 'out', 'adherent', 'element', 'offspring', 'opponent', 'attack', 'enemy', 'overthrow']\n",
      "\n",
      "combined_top5_bertrobertabaselarge_duplicates_first: ['affiliate', 'extension', 'off', 'shoot', 'arm', 'ally', 'opposite', 'adaptation', 'outpost', 'incarnation', 'out', 'adherent', 'element', 'offspring', 'opponent', 'attack', 'enemy', 'overthrow']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "\n",
      "SS step: d): top_5_substitutes_bertbase: ['orchestral', 'symphony', 'musical', 'classical', 'operatic', 'philharmonic', 'melodic', 'choral']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertlarge: ['orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertabase: ['classical', 'harmonic', 'musical', 'sym', 'music', 'instrumental', 'piano', 'lyric']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertalarge: ['musical', 'classical', 'harmonic', 'music', 'popular', 'onic', 'sym', 'canonical']\n",
      "\n",
      "duplicates_top5_bertrobertabaselarge: ['musical', 'classical']\n",
      "\n",
      "nonduplicates_top5_bertrobertabaselarge: ['orchestral', 'symphony', 'harmonic', 'philharmonic', 'sym', 'music', 'operatic', 'symphonies', 'popular', 'instrumental', 'onic', 'melodic', 'concerto', 'piano', 'choral', 'sonata', 'lyric', 'canonical']\n",
      "\n",
      "combined_top5_bertrobertabaselarge_duplicates_first: ['musical', 'classical', 'orchestral', 'symphony', 'harmonic', 'philharmonic', 'sym', 'music', 'operatic', 'symphonies', 'popular', 'instrumental', 'onic', 'melodic', 'concerto', 'piano', 'choral', 'sonata', 'lyric', 'canonical']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "\n",
      "SS step: d): top_5_substitutes_bertbase: ['withdraw', 'activate', 'deployment', 'send', 'maintain', 'dispatch', 'use', 'acquire']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertlarge: ['activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertabase: ['deployment', 'utilize', 'mobilize', 'employ', 'dispatch', 'equip', 'ploy', 'use']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertalarge: ['deployment', 'mobilize', 'dispatch', 'ploy', 'employ', 'maneuver', 'disperse', 'send']\n",
      "\n",
      "duplicates_top5_bertrobertabaselarge: ['deployment', 'dispatch']\n",
      "\n",
      "nonduplicates_top5_bertrobertabaselarge: ['withdraw', 'activate', 'utilize', 'mobilize', 'send', 'assemble', 'employ', 'ploy', 'maintain', 'launch', 'equip', 'maneuver', 'use', 'disperse', 'acquire']\n",
      "\n",
      "combined_top5_bertrobertabaselarge_duplicates_first: ['deployment', 'dispatch', 'withdraw', 'activate', 'utilize', 'mobilize', 'send', 'assemble', 'employ', 'ploy', 'maintain', 'launch', 'equip', 'maneuver', 'use', 'disperse', 'acquire']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "\n",
      "SS step: d): top_5_substitutes_bertbase: ['officials', 'police', 'citizens', 'forces', 'government', 'officers', 'people', 'governments']\n",
      "\n",
      "SS step: d): top_5_substitutes_bertlarge: ['police', 'officials', 'magistrates', 'officers', 'forces', 'courts', 'people', 'government']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertabase: ['officials', 'investigators', 'counterparts', 'police', 'agencies', 'administrators', 'forces', 'prosecutors']\n",
      "\n",
      "SS step: d): top_5_substitutes_robertalarge: ['police', 'officials', 'regulators', 'governments', 'arrests', 'investigators', 'colleagues', 'superiors']\n",
      "\n",
      "duplicates_top5_bertrobertabaselarge: ['officials', 'police']\n",
      "\n",
      "nonduplicates_top5_bertrobertabaselarge: ['investigators', 'citizens', 'magistrates', 'counterparts', 'regulators', 'forces', 'officers', 'governments', 'government', 'agencies', 'arrests', 'courts', 'administrators', 'people', 'colleagues', 'prosecutors', 'superiors']\n",
      "\n",
      "combined_top5_bertrobertabaselarge_duplicates_first: ['officials', 'police', 'investigators', 'citizens', 'magistrates', 'counterparts', 'regulators', 'forces', 'officers', 'governments', 'government', 'agencies', 'arrests', 'courts', 'administrators', 'people', 'colleagues', 'prosecutors', 'superiors']\n",
      "\n",
      "-------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "    \n",
    "    # for Bert-base:\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\\n\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"[MASK]\")\n",
    "\n",
    "    ## fill the mask with substitute words, and concatenate the original sentence and the masked sentence\n",
    "    tokenizer_bertbase = fill_mask_bertbase.tokenizer\n",
    "    sentences_concat_bertbase = f\"{sentence} {tokenizer_bertbase.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result_bertbase = fill_mask_bertbase(sentences_concat_bertbase, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes_bertbase = [substitute[\"token_str\"].lower() for substitute in result_bertbase]\n",
    "    #print(f\"SG step: Bertbase generated substitutes: {substitutes_bertbase}\\n\")\n",
    "    \n",
    "   # 2. Substitute Selection (SS):   \n",
    "\n",
    "    # create a punctuation set without hyphen, in order to retain hyphens in compound substitutes\n",
    "    punctuation_without_hyphen = set(string.punctuation) - set('-')\n",
    "    \n",
    "    # a) remove duplicates and unwanted punctuation within the substitute list from the substitute list\n",
    "    substitutes_no_dupl_bertbase = []\n",
    "    for sub in substitutes_bertbase:\n",
    "        if sub not in substitutes_no_dupl_bertbase and not any(char in punctuation_without_hyphen for char in sub):\n",
    "            substitutes_no_dupl_bertbase.append(sub)\n",
    "    #print(f\"SS step: a) Bertbase substitute list without duplicates and undesired punctuation: {substitutes_no_dupl_bertbase}\\n\")\n",
    "    \n",
    "\n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word_bertbase = []\n",
    "    for substitute in substitutes_no_dupl_bertbase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word_bertbase.append(substitute)\n",
    "    #print(f\"SS step: b) Bertbase substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word_bertbase}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym_bertbase = []\n",
    "    for substitute in substitutes_no_dupl_complex_word_bertbase:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym_bertbase.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym_bertbase.append(substitute)\n",
    "    #print(f\"SS step: c): Bertbase substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym_bertbase}\\n\")\n",
    "    \n",
    "     \n",
    "    \n",
    "    # limit the substitutes to the 5 first ones for concatenation with the top-5 of other models\n",
    "    top_5_substitutes_bertbase = substitutes_no_dupl_complex_word_no_antonym_bertbase[:5]\n",
    "    print(f\"SS step: d): top_5_substitutes_bertbase: {top_5_substitutes_bertbase}\\n\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # for Bert-large:\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    # ## print the sentence and the complex word\n",
    "    # sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    # print(f\"Sentence: {sentence}\")\n",
    "    # print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "#     ## in the sentence, replace the complex word with a masked word\n",
    "#     sentence_masked_word = sentence.replace(complex_word, \"[MASK]\")\n",
    "\n",
    "    ## fill the mask with substitute words, and concatenate the original sentence and the masked sentence\n",
    "    tokenizer_bertlarge = fill_mask_bertlarge.tokenizer\n",
    "    sentences_concat_bertlarge = f\"{sentence} {tokenizer_bertlarge.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result_bertlarge = fill_mask_bertlarge(sentences_concat_bertlarge, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes_bertlarge = [substitute[\"token_str\"].lower() for substitute in result_bertlarge]\n",
    "    #print(f\"SG step: Bertlarge generated substitutes: {substitutes_bertlarge}\\n\")\n",
    "    \n",
    "   # 2. Substitute Selection (SS):   \n",
    "\n",
    "    # create a punctuation set without hyphen, in order to retain hyphens in compound substitutes\n",
    "    punctuation_without_hyphen = set(string.punctuation) - set('-')\n",
    "    \n",
    "    # a) remove duplicates and unwanted punctuation (this happened with BERT) within the substitute list from the substitute list\n",
    "    substitutes_no_dupl_bertlarge = []\n",
    "    for sub in substitutes_bertlarge:\n",
    "        if sub not in substitutes_no_dupl_bertlarge and not any(char in punctuation_without_hyphen for char in sub):\n",
    "            substitutes_no_dupl_bertlarge.append(sub)\n",
    "    #print(f\"SS step: a) Bertlarge substitute list without duplicates and undesired punctuation: {substitutes_no_dupl_bertlarge}\\n\")\n",
    "    \n",
    "\n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word_bertlarge = []\n",
    "    for substitute in substitutes_no_dupl_bertlarge:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word_bertlarge.append(substitute)\n",
    "    #print(f\"SS step: b) Bertlarge substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word_bertlarge}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym_bertlarge = []\n",
    "    for substitute in substitutes_no_dupl_complex_word_bertlarge:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym_bertlarge.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym_bertlarge.append(substitute)\n",
    "    #print(f\"SS step: c): Bertlarge substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym_bertlarge}\\n\")\n",
    "     \n",
    "    \n",
    "    # limit the substitutes to the 5 first ones for concatenation with the top-5 of other models\n",
    "    top_5_substitutes_bertlarge = substitutes_no_dupl_complex_word_no_antonym_bertlarge[:5]\n",
    "    print(f\"SS step: d): top_5_substitutes_bertlarge: {top_5_substitutes_bertlarge}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "     # for Roberta-base:\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    # sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    # print(f\"Sentence: {sentence}\")\n",
    "    # print(f\"Complex word: {complex_word}\\n\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word,\"<mask>\")   # RoBERTa uses <mask> instead of [MASK]\n",
    "\n",
    "    ## fill the mask with substitute words, and concatenate the original sentence and the masked sentence\n",
    "    tokenizer_robertabase = fill_mask_robertabase.tokenizer\n",
    "    sentences_concat_robertabase = f\"{sentence} {tokenizer_robertabase.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result_robertabase = fill_mask_robertabase(sentences_concat_robertabase, top_k=top_k)\n",
    "   \n",
    "        \n",
    "    ## lowercase, remove the leading space in each substitute (roberta only) and print the top-k substitutes\n",
    "    substitutes_robertabase = [substitute[\"token_str\"].lower().lstrip() for substitute in result_robertabase]   # and use .lstrip to remove the leading space (for ROBERTA only), as Roberta tokenizes by default with a space in front of the word\n",
    "    #print(f\"SG step: Robertabase generated substitutes: {substitutes_robertabase}\\n\")\n",
    "    \n",
    "   # 2. Substitute Selection (SS):   \n",
    "\n",
    "    # create a punctuation set without hyphen, in order to retain hyphens in compound substitutes\n",
    "    punctuation_without_hyphen = set(string.punctuation) - set('-')\n",
    "    \n",
    "    # a) remove duplicates and unwanted punctuation (this happened with BERT) within the substitute list from the substitute list\n",
    "    substitutes_no_dupl_robertabase = []\n",
    "    for sub in substitutes_robertabase:\n",
    "        if sub not in substitutes_no_dupl_robertabase and not any(char in punctuation_without_hyphen for char in sub):\n",
    "            substitutes_no_dupl_robertabase.append(sub)\n",
    "    #print(f\"SS step: a) Robertabase substitute list without duplicates and undesired punctuation: {substitutes_no_dupl_robertabase}\\n\")\n",
    "    \n",
    "\n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word_robertabase = []\n",
    "    for substitute in substitutes_no_dupl_robertabase:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word_robertabase.append(substitute)\n",
    "    #print(f\"SS step: b) Robertabase substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word_robertabase}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym_robertabase = []\n",
    "    for substitute in substitutes_no_dupl_complex_word_robertabase:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym_robertabase.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym_robertabase.append(substitute)\n",
    "    #print(f\"SS step: c): Robertabase substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym_robertabase}\\n\")\n",
    "    \n",
    "     \n",
    "    \n",
    "    # limit the substitutes to the 5 first ones for concatenation with the top-5 of other models\n",
    "    top_5_substitutes_robertabase = substitutes_no_dupl_complex_word_no_antonym_robertabase[:5]\n",
    "    print(f\"SS step: d): top_5_substitutes_robertabase: {top_5_substitutes_robertabase}\\n\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # for Roberta-large:\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    # ## print the sentence and the complex word\n",
    "    # sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    # print(f\"Sentence: {sentence}\")\n",
    "    # print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    # ## in the sentence, replace the complex word with a masked word\n",
    "    # sentence_masked_word = sentence.replace(complex_word, \"<mask>\")  # RoBERTa uses <mask> instead of [MASK]\n",
    "\n",
    "    ## fill the mask with substitute words, and concatenate the original sentence and the masked sentence\n",
    "    tokenizer_robertalarge = fill_mask_robertalarge.tokenizer\n",
    "    sentences_concat_robertalarge = f\"{sentence} {tokenizer_robertalarge.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result_robertalarge = fill_mask_robertalarge(sentences_concat_robertalarge, top_k=top_k)\n",
    "   \n",
    "     ## lowercase, remove the leading space in each substitute (roberta only) and print the top-k substitutes\n",
    "    substitutes_robertalarge = [substitute[\"token_str\"].lower().lstrip() for substitute in result_robertalarge]   # and use .lstrip to remove the leading space (for ROBERTA only), as Roberta tokenizes by default with a space in front of the word\n",
    "    #print(f\"SG step: Robertalarge generated substitutes: {substitutes_robertalarge}\\n\")\n",
    "    \n",
    "   # 2. Substitute Selection (SS):   \n",
    "\n",
    "    # create a punctuation set without hyphen, in order to retain hyphens in compound substitutes\n",
    "    punctuation_without_hyphen = set(string.punctuation) - set('-')\n",
    "    \n",
    "    # a) remove duplicates and unwanted punctuation within the substitute list from the substitute list\n",
    "    substitutes_no_dupl_robertalarge = []\n",
    "    for sub in substitutes_robertalarge:\n",
    "        if sub not in substitutes_no_dupl_robertalarge and not any(char in punctuation_without_hyphen for char in sub):\n",
    "            substitutes_no_dupl_robertalarge.append(sub)\n",
    "    #print(f\"SS step: a) Robertalarge substitute list without duplicates and undesired punctuation: {substitutes_no_dupl_robertalarge}\\n\")\n",
    "    \n",
    "\n",
    "   \n",
    "    # # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    # ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    # doc_complex_word = nlp(complex_word)\n",
    "    # complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    # #print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word_robertalarge = []\n",
    "    for substitute in substitutes_no_dupl_robertalarge:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word_robertalarge.append(substitute)\n",
    "    #print(f\"SS step: b) Robertalarge substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word_robertalarge}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym_robertalarge = []\n",
    "    for substitute in substitutes_no_dupl_complex_word_robertalarge:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym_robertalarge.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym_robertalarge.append(substitute)\n",
    "    #print(f\"SS step: c): Robertalarge substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym_robertalarge}\\n\")\n",
    "     \n",
    "    \n",
    "    # limit the substitutes to the 5 first ones for concatenation with the top-5 of other models\n",
    "    top_5_substitutes_robertalarge = substitutes_no_dupl_complex_word_no_antonym_robertalarge[:5]\n",
    "    print(f\"SS step: d): top_5_substitutes_robertalarge: {top_5_substitutes_robertalarge}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # concatenating the top-x outputs of all 4 models  \n",
    "    \n",
    "    \n",
    "   # find duplicates between top_5_substitutes of all 4 models\n",
    "    duplicates = set(top_5_substitutes_bertbase) & set(top_5_substitutes_bertlarge) & set(top_5_substitutes_robertabase) & set(top_5_substitutes_robertalarge)\n",
    "\n",
    "    # create a list with duplicates, preserving the original order as much as possible\n",
    "    duplicates_top5_bertrobertabaselarge = []\n",
    "    for sub in top_5_substitutes_bertbase + top_5_substitutes_bertlarge + top_5_substitutes_robertabase + top_5_substitutes_robertalarge:\n",
    "        if sub in duplicates and sub not in duplicates_top5_bertrobertabaselarge:\n",
    "            duplicates_top5_bertrobertabaselarge.append(sub)\n",
    "\n",
    "    print(f\"duplicates_top5_bertrobertabaselarge: {duplicates_top5_bertrobertabaselarge}\\n\")\n",
    "\n",
    "    # create a list with non-duplicates, using the interleaving order\n",
    "    nonduplicates_top5_bertrobertabaselarge = []\n",
    "    dup_used = set(duplicates_top5_bertrobertabaselarge)\n",
    "    already_added = set()\n",
    "\n",
    "    for bert_base, bert_large, roberta_base, roberta_large in zip(top_5_substitutes_bertbase, top_5_substitutes_bertlarge,top_5_substitutes_robertabase,top_5_substitutes_robertalarge):\n",
    "        if bert_base not in dup_used and bert_base not in already_added:\n",
    "            nonduplicates_top5_bertrobertabaselarge.append(bert_base)\n",
    "            already_added.add(bert_base)\n",
    "        if bert_large not in dup_used and bert_large not in already_added:\n",
    "            nonduplicates_top5_bertrobertabaselarge.append(bert_large)\n",
    "            already_added.add(bert_large)\n",
    "        if roberta_base not in dup_used and roberta_base not in already_added:\n",
    "            nonduplicates_top5_bertrobertabaselarge.append(roberta_base)\n",
    "            already_added.add(roberta_base)\n",
    "        if roberta_large not in dup_used and roberta_large not in already_added:\n",
    "            nonduplicates_top5_bertrobertabaselarge.append(roberta_large)\n",
    "            already_added.add(roberta_large)\n",
    "\n",
    "    print(f\"nonduplicates_top5_bertrobertabaselarge: {nonduplicates_top5_bertrobertabaselarge}\\n\")\n",
    " \n",
    "    \n",
    "       \n",
    "    \n",
    "    # old code, remove if above code works\n",
    "       \n",
    "\n",
    "#     # create a list with non-duplicates, using the interleaving order\n",
    "#     nonduplicates_top5_bertrobertabaselarge = []\n",
    "#     dup_used = set(duplicates_top5_bertrobertabaselarge)\n",
    "\n",
    "#     for bert_base, bert_large, roberta_base, roberta_large in zip(top_5_substitutes_bertbase, top_5_substitutes_bertlarge,top_5_substitutes_robertabase,top_5_substitutes_robertalarge):\n",
    "#         if bert_base not in dup_used:\n",
    "#             nonduplicates_top5_bertrobertabaselarge.append(bert_base)\n",
    "#         if bert_large not in dup_used:\n",
    "#             nonduplicates_top5_bertrobertabaselarge.append(bert_large)\n",
    "#         if roberta_base not in dup_used:\n",
    "#             nonduplicates_top5_bertrobertabaselarge.append(roberta_base)\n",
    "#         if roberta_large not in dup_used:\n",
    "#             nonduplicates_top5_bertrobertabaselarge.append(roberta_large)\n",
    "            \n",
    "#     print(f\"nonduplicates_top5_bertrobertabaselarge: {nonduplicates_top5_bertrobertabaselarge}\\n\")\n",
    "    \n",
    "    \n",
    "    # concatenate all lists, the duplicate list first\n",
    "    combined_top5_bertrobertabaselarge_duplicates_first = duplicates_top5_bertrobertabaselarge + nonduplicates_top5_bertrobertabaselarge\n",
    "    print(f\"combined_top5_bertrobertabaselarge_duplicates_first: {combined_top5_bertrobertabaselarge_duplicates_first}\\n\")\n",
    "    \n",
    "    print('-------------------------------------------------------------------------------------------------')\n",
    "    \n",
    "    \n",
    "    # check if the number of substitutes is greater than the current number of substitute columns\n",
    "    num_substitutes = len(combined_top5_bertrobertabaselarge_duplicates_first)\n",
    "    num_columns = len(substitutes_df.columns)\n",
    "\n",
    "    if num_substitutes + 2 > num_columns:\n",
    "        # Add the required number of new columns\n",
    "        for i in range(num_columns - 2, num_substitutes):\n",
    "            substitutes_df[f\"substitute_{i+1}\"] = ''\n",
    "\n",
    "    # pad the list with empty strings to match the number of columns in the DataFrame\n",
    "    padding = [''] * (num_columns - 2 - len(combined_top5_bertrobertabaselarge_duplicates_first))\n",
    "    row_data = [sentence, complex_word] + combined_top5_bertrobertabaselarge_duplicates_first + padding\n",
    "\n",
    "    # Add the row to the DataFrame\n",
    "    substitutes_df.loc[index] = row_data\n",
    "    \n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the DataFrame\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "\n",
    "      \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/BertRobertaBaseLarge_top_5_SG_SS_abc.tsv\", sep=\"\\t\", index=False, header=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44f542a-8b96-493a-bc2f-21c860126848",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file .\\predictions\\trial\\BertRobertaBaseLarge_top_5_SG_SS_abc.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b895062-52c8-4b3b-9b17-0e76d33bed18",
   "metadata": {},
   "source": [
    "top 5:\n",
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = .\\predictions\\trial\\BertRobertaBaseLarge_top_5_SG_SS_abc.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.4\n",
    "\n",
    "MAP@3 = 0.2999\n",
    "MAP@5 = 0.219\n",
    "MAP@10 = 0.1294\n",
    "\n",
    "Potential@3 = 0.7\n",
    "Potential@5 = 0.8\n",
    "Potential@10 = 1.0\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.3\n",
    "Accuracy@2@top_gold_1 = 0.4\n",
    "Accuracy@3@top_gold_1 = 0.6\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "c05aa376-692b-4cb1-a6f9-2fce4ed91c3f",
   "metadata": {},
   "source": [
    "top 8 (only code changed, not file name):\n",
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = .\\predictions\\trial\\BertRobertaBaseLarge_top_5_SG_SS_abc.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.4\n",
    "\n",
    "MAP@3 = 0.2888\n",
    "MAP@5 = 0.2003\n",
    "MAP@10 = 0.1267\n",
    "\n",
    "Potential@3 = 0.7\n",
    "Potential@5 = 0.8\n",
    "Potential@10 = 1.0\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.4\n",
    "Accuracy@2@top_gold_1 = 0.5\n",
    "Accuracy@3@top_gold_1 = 0.6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93353092-ba1c-4b09-abd7-3fe447bd08c1",
   "metadata": {},
   "source": [
    "Results: so far, concatenation of the top-x of all 4 lists is not an improvement of BertBase_SG_SS_abc, BertLarge_SG_SS_abc, Robertabase_SG_SS_abc, Robertalarge_SG_SS_abc. Sometimes even worse. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff27fa7-609c-4132-94f8-a54486f6cb95",
   "metadata": {},
   "source": [
    "To Do later:\n",
    "\n",
    "1. see if padding in case of <10 subs is the right way. Maybe better to pad with the first item (which is the most sem. fitting item) in the combined subs list?\n",
    "2. remove unsimilar substitutes, to account for removing e.g., voluntary from the list for 'compulsory' (maybe with equivalence scores or something word embedding scores?.\n",
    "2. explore wordnet co-hyponyms, and add/prioritize in list, together with synsets code (see old code). Think about how to prioritize, above or after the duplicates from all 4 models.\n",
    "3. remove substitutes like 'disguise' and 'dressing' (complex word = disguised); 'deployment' (complex word = deploy). Maybe by removing words that have the first 4 or 5 leftstrings the same as the complex word (that will remove words like disguise and deployment. but not dressing (can be a noun and a verb), as this only appears in the subst list together with dressed which is a good substitute). maybe see with Fitbert what it does? \n",
    "4. update the code with embeddings and BERTScore (applied to the combined list of all 4 systems), and see which of these work best. \n",
    "5. Explore equivalence scores (MANTIS).\n",
    "5. automate the code in a way that it selects all 4 models (bert-base, bert-large, roberta-base, roberta-large) automatically, one by one, and that all the separate variables _bertbase, bertlarge, robertabase, robertalarge are not needed.\n",
    "6. automate to test scores with different top-x for the concatenated list of all 4 models\n",
    "7. Automate to get the best top-x, based on the output scores for the task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2627c4a4-8bbd-425e-9404-84ba8bf44488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
