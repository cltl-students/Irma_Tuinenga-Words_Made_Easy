{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b0ad47d-aef9-4d79-ac41-de890e0748ea",
   "metadata": {},
   "source": [
    "### All code below uses concatenated sentence pairs in the Substitute Generation step in order to generate similar substitutes (as opposed to generation of fitting substitutes only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c8337-c877-47d0-9b9d-2464ac9f76a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from fitbert import FitBert\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# read the tsv file\n",
    "filename = \"./data/trial/tsar2022_en_trial_none.tsv\"\n",
    "data = pd.read_csv(filename, sep='\\t', header=None, names=[\"sentence\", \"complex_word\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "127d1567-694c-4580-9706-dd94125b98d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe to store the substitutes for evaluation\n",
    "substitutes_df = pd.DataFrame(columns=[\"sentence\", \"complex_word\"] + [f\"substitute_{i+1}\" for i in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a8f51-26e4-4f17-a64c-aa3545a1450d",
   "metadata": {},
   "source": [
    "### Bert-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d9baa00-f810-4bb4-a3b9-a1affa7e6ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# initialize the tokenizer and the models\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "lm_model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# create a fill-mask pipeline\n",
    "fill_mask = pipeline(\"fill-mask\", lm_model, tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2245941-e389-4ff0-b88e-e43dc3da5a21",
   "metadata": {},
   "source": [
    "#### Only Substitute Generation with BERT-base (k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ae349b7-d595-4172-a002-19437478b341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "SG step: generated substitutes: ['compulsory', 'mandatory', 'obligatory', 'optional', 'required', 'necessary', 'standard', 'voluntary', 'customary', 'impossible']\n",
      "\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "SG step: generated substitutes: ['strengthened', 'targeted', 'tested', 'provided', 'created', 'affected', 'addressed', 'attacked', 'punished', 'bred']\n",
      "\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "SG step: generated substitutes: ['criminals', 'crimes', 'machines', '\"', 'rats', 'pigs', 'heroes', 'demons', 'robots', 'machine']\n",
      "\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "SG step: generated substitutes: ['observers', 'witnesses', 'participants', 'casualties', 'refugees', 'observer', 'visitors', 'monitors', 'victims', 'delegates']\n",
      "\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "SG step: generated substitutes: ['stab', 'gunshot', 'bullet', 'knife', 'multiple', 'severe', 'arrow', 'several', 'minor', 'stabbing']\n",
      "\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "SG step: generated substitutes: ['disguised', 'dressed', 'clad', 'masked', 'clothed', 'dressing', 'disguise', 'concealed', 'cloak', 'posing']\n",
      "\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "SG step: generated substitutes: ['affiliate', 'extension', 'arm', 'adaptation', 'incarnation', 'ally', 'opponent', 'attack', 'expansion', 'outpost']\n",
      "\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "SG step: generated substitutes: ['symphonic', 'orchestral', 'symphony', 'musical', 'classical', 'operatic', 'philharmonic', 'melodic', 'choral', 'music']\n",
      "\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "SG step: generated substitutes: ['deploy', 'deployed', 'withdraw', 'activate', 'deployment', 'send', 'maintain', 'dispatch', 'use', 'acquire']\n",
      "\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "SG step: generated substitutes: ['authorities', 'officials', 'police', '##s', 'citizens', 'forces', 'government', 'officers', 'people', 'governments']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"[MASK]\")\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    tokenizer = fill_mask.tokenizer\n",
    "    sentences_concat = f\"{sentence} {tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 10\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes = [substitute[\"token_str\"].lower() for substitute in result]\n",
    "    print(f\"SG step: generated substitutes: {substitutes}\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + substitutes\n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the dataframe\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/BertBase_SG.tsv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd559222-97c0-4b52-a67f-7b7665321ba4",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file ./predictions/trial/BertBase_SG.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "108d96b7-6db7-41d9-9188-2bb90a4fffae",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/BertBase_SG.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.5\n",
    "\n",
    "MAP@3 = 0.2888\n",
    "MAP@5 = 0.2123\n",
    "MAP@10 = 0.1279\n",
    "\n",
    "Potential@3 = 0.6\n",
    "Potential@5 = 0.8\n",
    "Potential@10 = 0.8\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.3\n",
    "Accuracy@2@top_gold_1 = 0.3\n",
    "Accuracy@3@top_gold_1 = 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f466c47-3400-4f9f-8adc-5ecf4e0ea082",
   "metadata": {},
   "source": [
    "#### Substitute Generation with BERT-base, and Substitute Selection steps a-c (k=30, limited to 10 after step 2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65a443c2-1ef7-45ed-85bd-a1705380b637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dda89f9-3c5e-4847-a4f8-26780c300210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07352cfa-8ba5-447a-be18-84eda2b0f4de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# in each row, for each complex word: \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m      3\u001b[0m        \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# 1. Substitute Generation (SG): perform masking and generate substitutes:\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m## print the sentence and the complex word\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     sentence, complex_word \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplex_word\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msentence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"[MASK]\")\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    tokenizer = fill_mask.tokenizer\n",
    "    sentences_concat = f\"{sentence} {tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes = [substitute[\"token_str\"].lower() for substitute in result]\n",
    "    print(f\"SG step: generated substitutes: {substitutes}\\n\")\n",
    "    \n",
    "   # 2. Substitute Selection (SS):   \n",
    "    \n",
    "     # create a punctuation set without hyphen, in order to retain hyphens in compound substitutes\n",
    "    punctuation_without_hyphen = set(string.punctuation) - set('-')\n",
    "    \n",
    "    # a) remove duplicates and unwanted punctuation within the substitute list from the substitute list\n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl and not any(char in punctuation_without_hyphen for char in sub):\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    print(f\"SS step: a) substitute list without duplicates and undesired punctuation: {substitutes_no_dupl}\\n\")\n",
    "    \n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    print(f\"SS step: b) substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    print(f\"SS step: c): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "    \n",
    "     \n",
    "    \n",
    "    # limit the substitutes to the 10 first ones for evaluation\n",
    "    top_10_substitutes = substitutes_no_dupl_complex_word_no_antonym[:10]\n",
    "    \n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + top_10_substitutes\n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the dataframe\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/BertBase_SG_SS_abc.tsv\", sep=\"\\t\", index=False, header=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d989d45d-b4e6-4181-b0b7-ee6e8bfceff1",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file ./predictions/trial/BertBase_SG_SS_abc.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a38adca4-18e5-4936-9016-d61603f20634",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/BertBase_SG_SS_abc.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.5\n",
    "\n",
    "MAP@3 = 0.2888\n",
    "MAP@5 = 0.2133\n",
    "MAP@10 = 0.1288\n",
    "\n",
    "Potential@3 = 0.6\n",
    "Potential@5 = 0.8\n",
    "Potential@10 = 0.8\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.3\n",
    "Accuracy@2@top_gold_1 = 0.3\n",
    "Accuracy@3@top_gold_1 = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e562583-b633-4c44-8025-9184040d1f4d",
   "metadata": {},
   "source": [
    "Result: steps 2 a-c only contributed to MAP@10, and only very slightly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0d1e28-ddfa-430a-8fd0-63eb12f8eda9",
   "metadata": {},
   "source": [
    "#### Substitute Generation with BERT-base, and Substitute Selection steps a-c, and the resulting list with FitBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e56180e-f0b4-4d35-aab9-8098a3021cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FitBERT mainly seems to look at syntactic fit\n",
    "import fitbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92ad8f9b-0be0-48d0-bbe7-5fed5a2f582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "using custom model: ['BertForMaskedLM']\n",
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "SG step: generated substitutes: ['compulsory', 'mandatory', 'obligatory', 'optional', 'required', 'necessary', 'standard', 'voluntary', 'customary', 'impossible', 'easier', 'only', 'illegal', 'sufficient', 'unnecessary', 'easy', 'normal', 'permitted', 'mandated', 'difficult', 'simple', 'appropriate', 'expensive', 'possible', 'commonplace', 'essential', 'proper', 'available', 'enough', 'affordable']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['compulsory', 'mandatory', 'obligatory', 'optional', 'required', 'necessary', 'standard', 'voluntary', 'customary', 'impossible', 'easier', 'only', 'illegal', 'sufficient', 'unnecessary', 'easy', 'normal', 'permitted', 'mandated', 'difficult', 'simple', 'appropriate', 'expensive', 'possible', 'commonplace', 'essential', 'proper', 'available', 'enough', 'affordable']\n",
      "\n",
      "complex_word_lemma for complex word 'compulsory': compulsory\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['mandatory', 'obligatory', 'optional', 'required', 'necessary', 'standard', 'voluntary', 'customary', 'impossible', 'easier', 'only', 'illegal', 'sufficient', 'unnecessary', 'easy', 'normal', 'permitted', 'mandated', 'difficult', 'simple', 'appropriate', 'expensive', 'possible', 'commonplace', 'essential', 'proper', 'available', 'enough', 'affordable']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['mandatory', 'obligatory', 'optional', 'required', 'necessary', 'standard', 'voluntary', 'customary', 'impossible', 'easier', 'only', 'illegal', 'sufficient', 'unnecessary', 'easy', 'normal', 'permitted', 'mandated', 'difficult', 'simple', 'appropriate', 'expensive', 'possible', 'commonplace', 'essential', 'proper', 'available', 'enough', 'affordable']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['mandatory', 'obligatory', 'optional', 'required', 'necessary', 'standard', 'voluntary', 'customary', 'impossible', 'easier', 'only', 'illegal', 'sufficient', 'unnecessary', 'easy', 'normal', 'permitted', 'mandated', 'difficult', 'simple', 'appropriate', 'expensive', 'possible', 'commonplace', 'essential', 'proper', 'available', 'enough', 'affordable']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "SG step: generated substitutes: ['strengthened', 'targeted', 'tested', 'provided', 'created', 'affected', 'addressed', 'attacked', 'punished', 'bred', 'rewarded', 'empowered', 'shocked', 'introduced', 'silenced', 'improved', 'set', 'defeated', 'treated', 'reinforced', 'prepared', 'hit', 'surprised', 'hardened', 'infused', 'challenged', 'released', 'secured', 'delivered', 'established']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['strengthened', 'targeted', 'tested', 'provided', 'created', 'affected', 'addressed', 'attacked', 'punished', 'bred', 'rewarded', 'empowered', 'shocked', 'introduced', 'silenced', 'improved', 'set', 'defeated', 'treated', 'reinforced', 'prepared', 'hit', 'surprised', 'hardened', 'infused', 'challenged', 'released', 'secured', 'delivered', 'established']\n",
      "\n",
      "complex_word_lemma for complex word 'instilled': instill\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['strengthened', 'targeted', 'tested', 'provided', 'created', 'affected', 'addressed', 'attacked', 'punished', 'bred', 'rewarded', 'empowered', 'shocked', 'introduced', 'silenced', 'improved', 'set', 'defeated', 'treated', 'reinforced', 'prepared', 'hit', 'surprised', 'hardened', 'infused', 'challenged', 'released', 'secured', 'delivered', 'established']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['strengthened', 'targeted', 'tested', 'provided', 'created', 'affected', 'addressed', 'attacked', 'punished', 'bred', 'rewarded', 'empowered', 'shocked', 'introduced', 'silenced', 'improved', 'set', 'defeated', 'treated', 'reinforced', 'prepared', 'hit', 'surprised', 'hardened', 'infused', 'challenged', 'released', 'secured', 'delivered', 'established']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['strengthened', 'targeted', 'tested', 'provided', 'created', 'affected', 'addressed', 'attacked', 'punished', 'bred', 'rewarded', 'empowered', 'shocked', 'introduced', 'silenced', 'improved', 'set', 'defeated', 'treated', 'reinforced', 'prepared', 'hit', 'surprised', 'hardened', 'infused', 'challenged', 'released', 'secured', 'delivered', 'established']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "SG step: generated substitutes: ['criminals', 'crimes', 'machines', '\"', 'rats', 'pigs', 'heroes', 'demons', 'robots', 'machine', 'games', 'doctors', 'dogs', 'priests', 'bandits', 'lords', 'monsters', 'soldiers', '##games', 'leaders', 'freaks', 'ants', 'saints', 'people', '##ists', 'workers', 'terror', 'zombies', 'fighters', 'elephants']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['criminals', 'crimes', 'machines', '\"', 'rats', 'pigs', 'heroes', 'demons', 'robots', 'machine', 'games', 'doctors', 'dogs', 'priests', 'bandits', 'lords', 'monsters', 'soldiers', '##games', 'leaders', 'freaks', 'ants', 'saints', 'people', '##ists', 'workers', 'terror', 'zombies', 'fighters', 'elephants']\n",
      "\n",
      "complex_word_lemma for complex word 'maniacs': maniac\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['criminals', 'crimes', 'machines', '\"', 'rats', 'pigs', 'heroes', 'demons', 'robots', 'machine', 'games', 'doctors', 'dogs', 'priests', 'bandits', 'lords', 'monsters', 'soldiers', '##games', 'leaders', 'freaks', 'ants', 'saints', 'people', '##ists', 'workers', 'terror', 'zombies', 'fighters', 'elephants']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['criminals', 'crimes', 'machines', '\"', 'rats', 'pigs', 'heroes', 'demons', 'robots', 'machine', 'games', 'doctors', 'dogs', 'priests', 'bandits', 'lords', 'monsters', 'soldiers', '##games', 'leaders', 'freaks', 'ants', 'saints', 'people', '##ists', 'workers', 'terror', 'zombies', 'fighters', 'elephants']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['criminals', 'crimes', 'machines', '\"', 'rats', 'pigs', 'heroes', 'demons', 'robots', 'machine', 'games', 'doctors', 'dogs', 'priests', 'bandits', 'lords', 'monsters', 'soldiers', 'leaders', 'freaks', 'ants', 'saints', 'people', 'workers', 'terror', 'zombies', 'fighters', 'elephants', '##games', '##ists']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "SG step: generated substitutes: ['observers', 'witnesses', 'participants', 'casualties', 'refugees', 'observer', 'visitors', 'monitors', 'victims', 'delegates', 'travelers', 'experts', 'troops', 'inspectors', 'allies', 'diplomats', 'inspections', 'soldiers', 'fatalities', 'workers', 'pilgrims', 'people', 'officials', 'deaths', 'tourists', 'survivors', 'volunteers', 'citizens', 'civilians', 'combatants']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['observers', 'witnesses', 'participants', 'casualties', 'refugees', 'observer', 'visitors', 'monitors', 'victims', 'delegates', 'travelers', 'experts', 'troops', 'inspectors', 'allies', 'diplomats', 'inspections', 'soldiers', 'fatalities', 'workers', 'pilgrims', 'people', 'officials', 'deaths', 'tourists', 'survivors', 'volunteers', 'citizens', 'civilians', 'combatants']\n",
      "\n",
      "complex_word_lemma for complex word 'observers': observer\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['witnesses', 'participants', 'casualties', 'refugees', 'visitors', 'monitors', 'victims', 'delegates', 'travelers', 'experts', 'troops', 'inspectors', 'allies', 'diplomats', 'inspections', 'soldiers', 'fatalities', 'workers', 'pilgrims', 'people', 'officials', 'deaths', 'tourists', 'survivors', 'volunteers', 'citizens', 'civilians', 'combatants']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['witnesses', 'participants', 'casualties', 'refugees', 'visitors', 'monitors', 'victims', 'delegates', 'travelers', 'experts', 'troops', 'inspectors', 'allies', 'diplomats', 'inspections', 'soldiers', 'fatalities', 'workers', 'pilgrims', 'people', 'officials', 'deaths', 'tourists', 'survivors', 'volunteers', 'citizens', 'civilians', 'combatants']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['witnesses', 'participants', 'casualties', 'refugees', 'visitors', 'monitors', 'victims', 'delegates', 'travelers', 'experts', 'troops', 'inspectors', 'allies', 'diplomats', 'inspections', 'soldiers', 'fatalities', 'workers', 'pilgrims', 'people', 'officials', 'deaths', 'tourists', 'survivors', 'volunteers', 'citizens', 'civilians', 'combatants']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "SG step: generated substitutes: ['stab', 'gunshot', 'bullet', 'knife', 'multiple', 'severe', 'arrow', 'several', 'minor', 'stabbing', 'laser', 'open', 'two', 'rifle', 'serious', 'blunt', 'similar', 'blast', 'numerous', 'penetrating', 'three', 'sword', 'some', 'slash', 'shooting', 'the', 'painful', 'fatal', 'deep', 'horrible']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['stab', 'gunshot', 'bullet', 'knife', 'multiple', 'severe', 'arrow', 'several', 'minor', 'stabbing', 'laser', 'open', 'two', 'rifle', 'serious', 'blunt', 'similar', 'blast', 'numerous', 'penetrating', 'three', 'sword', 'some', 'slash', 'shooting', 'the', 'painful', 'fatal', 'deep', 'horrible']\n",
      "\n",
      "complex_word_lemma for complex word 'shrapnel': shrapnel\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['stab', 'gunshot', 'bullet', 'knife', 'multiple', 'severe', 'arrow', 'several', 'minor', 'stabbing', 'laser', 'open', 'two', 'rifle', 'serious', 'blunt', 'similar', 'blast', 'numerous', 'penetrating', 'three', 'sword', 'some', 'slash', 'shooting', 'the', 'painful', 'fatal', 'deep', 'horrible']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['stab', 'gunshot', 'bullet', 'knife', 'multiple', 'severe', 'arrow', 'several', 'minor', 'stabbing', 'laser', 'open', 'two', 'rifle', 'serious', 'blunt', 'similar', 'blast', 'numerous', 'penetrating', 'three', 'sword', 'some', 'slash', 'shooting', 'the', 'painful', 'fatal', 'deep', 'horrible']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['stab', 'gunshot', 'bullet', 'knife', 'multiple', 'severe', 'arrow', 'several', 'minor', 'stabbing', 'laser', 'open', 'two', 'rifle', 'serious', 'blunt', 'similar', 'blast', 'numerous', 'penetrating', 'three', 'sword', 'some', 'slash', 'shooting', 'the', 'painful', 'fatal', 'deep', 'horrible']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "SG step: generated substitutes: ['disguised', 'dressed', 'clad', 'masked', 'clothed', 'dressing', 'disguise', 'concealed', 'cloak', 'posing', 'appeared', 'dress', 'posed', 'guise', 'costume', 'attire', 'appearing', 'dresses', 'hiding', 'hooded', 'covered', 'draped', 'costumes', ',', 'hidden', 'wrapped', 'undercover', 'lured', 'present', 'adorned']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['disguised', 'dressed', 'clad', 'masked', 'clothed', 'dressing', 'disguise', 'concealed', 'cloak', 'posing', 'appeared', 'dress', 'posed', 'guise', 'costume', 'attire', 'appearing', 'dresses', 'hiding', 'hooded', 'covered', 'draped', 'costumes', ',', 'hidden', 'wrapped', 'undercover', 'lured', 'present', 'adorned']\n",
      "\n",
      "complex_word_lemma for complex word 'disguised': disguised\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['dressed', 'clad', 'masked', 'clothed', 'dressing', 'disguise', 'concealed', 'cloak', 'posing', 'appeared', 'dress', 'posed', 'guise', 'costume', 'attire', 'appearing', 'dresses', 'hiding', 'hooded', 'covered', 'draped', 'costumes', ',', 'hidden', 'wrapped', 'undercover', 'lured', 'present', 'adorned']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['dressed', 'clad', 'masked', 'clothed', 'dressing', 'disguise', 'concealed', 'cloak', 'posing', 'appeared', 'dress', 'posed', 'guise', 'costume', 'attire', 'appearing', 'dresses', 'hiding', 'hooded', 'covered', 'draped', 'costumes', ',', 'hidden', 'wrapped', 'undercover', 'lured', 'present', 'adorned']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['dressed', 'clad', 'masked', 'clothed', 'dressing', 'disguise', 'concealed', 'cloak', 'posing', 'appeared', 'dress', 'posed', 'guise', 'costume', 'attire', 'appearing', 'dresses', 'hiding', 'hooded', 'covered', 'draped', 'costumes', ',', 'hidden', 'wrapped', 'undercover', 'lured', 'present', 'adorned']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "SG step: generated substitutes: ['affiliate', 'extension', 'arm', 'adaptation', 'incarnation', 'ally', 'opponent', 'attack', 'expansion', 'outpost', 'associate', 'advocate', 'enemy', 'aspect', 'origin', 'branch', 'adversary', 'independent', 'alliance', 'ancestor', 'iteration', 'evolution', 'independently', 'antagonist', 'offspring', 'overthrow', 'imitation', 'implementation', 'organization', 'example']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['affiliate', 'extension', 'arm', 'adaptation', 'incarnation', 'ally', 'opponent', 'attack', 'expansion', 'outpost', 'associate', 'advocate', 'enemy', 'aspect', 'origin', 'branch', 'adversary', 'independent', 'alliance', 'ancestor', 'iteration', 'evolution', 'independently', 'antagonist', 'offspring', 'overthrow', 'imitation', 'implementation', 'organization', 'example']\n",
      "\n",
      "complex_word_lemma for complex word 'offshoot': offshoot\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['affiliate', 'extension', 'arm', 'adaptation', 'incarnation', 'ally', 'opponent', 'attack', 'expansion', 'outpost', 'associate', 'advocate', 'enemy', 'aspect', 'origin', 'branch', 'adversary', 'independent', 'alliance', 'ancestor', 'iteration', 'evolution', 'independently', 'antagonist', 'offspring', 'overthrow', 'imitation', 'implementation', 'organization', 'example']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['affiliate', 'extension', 'arm', 'adaptation', 'incarnation', 'ally', 'opponent', 'attack', 'expansion', 'outpost', 'associate', 'advocate', 'enemy', 'aspect', 'origin', 'branch', 'adversary', 'independent', 'alliance', 'ancestor', 'iteration', 'evolution', 'independently', 'antagonist', 'offspring', 'overthrow', 'imitation', 'implementation', 'organization', 'example']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['affiliate', 'extension', 'arm', 'adaptation', 'incarnation', 'ally', 'opponent', 'attack', 'expansion', 'outpost', 'associate', 'advocate', 'enemy', 'aspect', 'origin', 'branch', 'adversary', 'independent', 'alliance', 'ancestor', 'iteration', 'evolution', 'independently', 'antagonist', 'offspring', 'overthrow', 'imitation', 'implementation', 'organization', 'example']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "SG step: generated substitutes: ['symphonic', 'orchestral', 'symphony', 'musical', 'classical', 'operatic', 'philharmonic', 'melodic', 'choral', 'music', 'orchestra', 'instrumental', 'concert', 'historical', 'popular', 'concerto', 'harmonic', 'symphonies', 'technical', 'trombone', 'romantic', 'lyric', 'liturgical', 'dramatic', 'thematic', 'traditional', 'composers', 'vocal', 'dynamic', 'general']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['symphonic', 'orchestral', 'symphony', 'musical', 'classical', 'operatic', 'philharmonic', 'melodic', 'choral', 'music', 'orchestra', 'instrumental', 'concert', 'historical', 'popular', 'concerto', 'harmonic', 'symphonies', 'technical', 'trombone', 'romantic', 'lyric', 'liturgical', 'dramatic', 'thematic', 'traditional', 'composers', 'vocal', 'dynamic', 'general']\n",
      "\n",
      "complex_word_lemma for complex word 'symphonic': symphonic\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['orchestral', 'symphony', 'musical', 'classical', 'operatic', 'philharmonic', 'melodic', 'choral', 'music', 'orchestra', 'instrumental', 'concert', 'historical', 'popular', 'concerto', 'harmonic', 'symphonies', 'technical', 'trombone', 'romantic', 'lyric', 'liturgical', 'dramatic', 'thematic', 'traditional', 'composers', 'vocal', 'dynamic', 'general']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['orchestral', 'symphony', 'musical', 'classical', 'operatic', 'philharmonic', 'melodic', 'choral', 'music', 'orchestra', 'instrumental', 'concert', 'historical', 'popular', 'concerto', 'harmonic', 'symphonies', 'technical', 'trombone', 'romantic', 'lyric', 'liturgical', 'dramatic', 'thematic', 'traditional', 'composers', 'vocal', 'dynamic', 'general']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['orchestral', 'symphony', 'musical', 'classical', 'operatic', 'philharmonic', 'melodic', 'choral', 'music', 'orchestra', 'instrumental', 'concert', 'historical', 'popular', 'concerto', 'harmonic', 'symphonies', 'technical', 'trombone', 'romantic', 'lyric', 'liturgical', 'dramatic', 'thematic', 'traditional', 'composers', 'vocal', 'dynamic', 'general']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "SG step: generated substitutes: ['deploy', 'deployed', 'withdraw', 'activate', 'deployment', 'send', 'maintain', 'dispatch', 'use', 'acquire', 'reserve', 'retain', 'move', 'utilize', 'request', 'return', 'include', 'add', 'launch', 'designate', 'fire', 'operate', 'provide', 'establish', 'employ', 'outfit', 'purchase', 'expand', 'retire', 'build']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['deploy', 'deployed', 'withdraw', 'activate', 'deployment', 'send', 'maintain', 'dispatch', 'use', 'acquire', 'reserve', 'retain', 'move', 'utilize', 'request', 'return', 'include', 'add', 'launch', 'designate', 'fire', 'operate', 'provide', 'establish', 'employ', 'outfit', 'purchase', 'expand', 'retire', 'build']\n",
      "\n",
      "complex_word_lemma for complex word 'deploy': deploy\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['withdraw', 'activate', 'deployment', 'send', 'maintain', 'dispatch', 'use', 'acquire', 'reserve', 'retain', 'move', 'utilize', 'request', 'return', 'include', 'add', 'launch', 'designate', 'fire', 'operate', 'provide', 'establish', 'employ', 'outfit', 'purchase', 'expand', 'retire', 'build']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['withdraw', 'activate', 'deployment', 'send', 'maintain', 'dispatch', 'use', 'acquire', 'reserve', 'retain', 'move', 'utilize', 'request', 'return', 'include', 'add', 'launch', 'designate', 'fire', 'operate', 'provide', 'establish', 'employ', 'outfit', 'purchase', 'expand', 'retire', 'build']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['withdraw', 'activate', 'deployment', 'send', 'maintain', 'dispatch', 'use', 'acquire', 'reserve', 'retain', 'move', 'utilize', 'request', 'return', 'include', 'add', 'launch', 'designate', 'fire', 'operate', 'provide', 'establish', 'employ', 'outfit', 'purchase', 'expand', 'retire', 'build']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "SG step: generated substitutes: ['authorities', 'officials', 'police', '##s', 'citizens', 'forces', 'government', 'officers', 'people', 'governments', 'residents', 'troops', 'authority', 'courts', 'individuals', 'persons', 'organisations', 'policemen', 'civilians', 'nationals', 'protesters', 'institutions', 'interests', 'agencies', 'subjects', 'bodies', 'activists', 'personnel', 'magistrates', 'politicians']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['authorities', 'officials', 'police', '##s', 'citizens', 'forces', 'government', 'officers', 'people', 'governments', 'residents', 'troops', 'authority', 'courts', 'individuals', 'persons', 'organisations', 'policemen', 'civilians', 'nationals', 'protesters', 'institutions', 'interests', 'agencies', 'subjects', 'bodies', 'activists', 'personnel', 'magistrates', 'politicians']\n",
      "\n",
      "complex_word_lemma for complex word 'authorities': authority\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['officials', 'police', '##s', 'citizens', 'forces', 'government', 'officers', 'people', 'governments', 'residents', 'troops', 'courts', 'individuals', 'persons', 'organisations', 'policemen', 'civilians', 'nationals', 'protesters', 'institutions', 'interests', 'agencies', 'subjects', 'bodies', 'activists', 'personnel', 'magistrates', 'politicians']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['officials', 'police', '##s', 'citizens', 'forces', 'government', 'officers', 'people', 'governments', 'residents', 'troops', 'courts', 'individuals', 'persons', 'organisations', 'policemen', 'civilians', 'nationals', 'protesters', 'institutions', 'interests', 'agencies', 'subjects', 'bodies', 'activists', 'personnel', 'magistrates', 'politicians']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['officials', 'police', 'citizens', 'forces', 'government', 'officers', 'people', 'governments', 'residents', 'troops', 'courts', 'individuals', 'persons', 'organisations', 'policemen', 'civilians', 'nationals', 'protesters', 'institutions', 'interests', 'agencies', 'subjects', 'bodies', 'activists', 'personnel', 'magistrates', 'politicians', '##s']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# instantiate a FitBert model\n",
    "fb_model = FitBert(lm_model)\n",
    "\n",
    "\n",
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"[MASK]\")\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    tokenizer = fill_mask.tokenizer\n",
    "    sentences_concat = f\"{sentence} {tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes = [substitute[\"token_str\"].lower() for substitute in result]\n",
    "    print(f\"SG step: generated substitutes: {substitutes}\\n\")\n",
    "    \n",
    "    # 2. Substitute Selection (SS):   \n",
    "    \n",
    "    # create a punctuation set without hyphen, in order to retain hyphens in compound substitutes\n",
    "    punctuation_without_hyphen = set(string.punctuation) - set('-')\n",
    "    \n",
    "    # a) remove duplicates and unwanted punctuation within the substitute list from the substitute list\n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl and not any(char in punctuation_without_hyphen for char in sub):\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    print(f\"SS step: a) substitute list without duplicates and undesired punctuation: {substitutes_no_dupl}\\n\")\n",
    "    \n",
    "\n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    print(f\"SS step: b) substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    print(f\"SS step: c): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "    \n",
    "     # d) apply FITBERT to the list of substitutes\n",
    "    sentence_fitbert_masked = sentence_masked_word.replace(\"[MASK]\", \"***mask***\")   # fitbert uses ***mask*** instead of [MASK] or <mask> \n",
    "    sentences_concat_fitbert = f\"{sentence} {tokenizer.sep_token} {sentence_fitbert_masked}\"\n",
    "    \n",
    "    ranked_substitutes = fb_model.rank(sentences_concat_fitbert, substitutes_no_dupl_complex_word_no_antonym)\n",
    "    print(f\"SS step: d) ranked substitutes using FitBert: {ranked_substitutes}\\n\")\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------------------')\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    # limit the substitutes to the 10 first ones for evaluation\n",
    "    top_10_substitutes = ranked_substitutes[:10]\n",
    "    \n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + top_10_substitutes\n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the dataframe\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/BertBase_SG_SS_abc_fb.tsv\", sep=\"\\t\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029c8f79-d63c-46a8-9bad-68abcfedc153",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file ./predictions/trial/BertBase_SG_SS_abc_fb.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "90548025-2477-4863-8e28-1f9874089151",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/BertBase_SG_SS_abc_fb.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.5\n",
    "\n",
    "MAP@3 = 0.2888\n",
    "MAP@5 = 0.2253\n",
    "MAP@10 = 0.1307\n",
    "\n",
    "Potential@3 = 0.6\n",
    "Potential@5 = 0.8\n",
    "Potential@10 = 0.8\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.3\n",
    "Accuracy@2@top_gold_1 = 0.3\n",
    "Accuracy@3@top_gold_1 = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aec21e3-4306-4b18-857c-332e59e2ed4d",
   "metadata": {},
   "source": [
    "Result: only Map@5 and Map@10 improved slightly, probably due to ranking subs starting with ## at the end of the list, which seems to be the only thing that FitBERT did. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dbf939-28ef-4f7a-91a3-7c8a1ec648dc",
   "metadata": {},
   "source": [
    "#### Substitute Generation with BERT-base, and Substitute Selection steps a-c, and the resulting list with contextualized embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25885e02-9df3-437d-9ae0-29b610d28016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00dc9a0b-b74c-4b19-a7cf-ceda9e7cfe86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "SG step: generated substitutes: ['compulsory', 'mandatory', 'obligatory', 'optional', 'required', 'necessary', 'standard', 'voluntary', 'customary', 'impossible', 'easier', 'only', 'illegal', 'sufficient', 'unnecessary', 'easy', 'normal', 'permitted', 'mandated', 'difficult', 'simple', 'appropriate', 'expensive', 'possible', 'commonplace', 'essential', 'proper', 'available', 'enough', 'affordable']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['compulsory', 'mandatory', 'obligatory', 'optional', 'required', 'necessary', 'standard', 'voluntary', 'customary', 'impossible', 'easier', 'only', 'illegal', 'sufficient', 'unnecessary', 'easy', 'normal', 'permitted', 'mandated', 'difficult', 'simple', 'appropriate', 'expensive', 'possible', 'commonplace', 'essential', 'proper', 'available', 'enough', 'affordable']\n",
      "\n",
      "complex_word_lemma for complex word 'compulsory': compulsory\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['mandatory', 'obligatory', 'optional', 'required', 'necessary', 'standard', 'voluntary', 'customary', 'impossible', 'easier', 'only', 'illegal', 'sufficient', 'unnecessary', 'easy', 'normal', 'permitted', 'mandated', 'difficult', 'simple', 'appropriate', 'expensive', 'possible', 'commonplace', 'essential', 'proper', 'available', 'enough', 'affordable']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['mandatory', 'obligatory', 'optional', 'required', 'necessary', 'standard', 'voluntary', 'customary', 'impossible', 'easier', 'only', 'illegal', 'sufficient', 'unnecessary', 'easy', 'normal', 'permitted', 'mandated', 'difficult', 'simple', 'appropriate', 'expensive', 'possible', 'commonplace', 'essential', 'proper', 'available', 'enough', 'affordable']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step d) Ranked substitutes, based on cosine similarity scores in context: ['mandatory', 'obligatory', 'voluntary', 'permitted', 'mandated', 'illegal', 'required', 'optional', 'unnecessary', 'proper', 'customary', 'expensive', 'possible', 'necessary', 'standard', 'impossible', 'normal', 'easier', 'essential', 'difficult', 'only', 'appropriate', 'easy', 'sufficient', 'simple', 'enough', 'commonplace', 'affordable', 'available']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "SG step: generated substitutes: ['strengthened', 'targeted', 'tested', 'provided', 'created', 'affected', 'addressed', 'attacked', 'punished', 'bred', 'rewarded', 'empowered', 'shocked', 'introduced', 'silenced', 'improved', 'set', 'defeated', 'treated', 'reinforced', 'prepared', 'hit', 'surprised', 'hardened', 'infused', 'challenged', 'released', 'secured', 'delivered', 'established']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['strengthened', 'targeted', 'tested', 'provided', 'created', 'affected', 'addressed', 'attacked', 'punished', 'bred', 'rewarded', 'empowered', 'shocked', 'introduced', 'silenced', 'improved', 'set', 'defeated', 'treated', 'reinforced', 'prepared', 'hit', 'surprised', 'hardened', 'infused', 'challenged', 'released', 'secured', 'delivered', 'established']\n",
      "\n",
      "complex_word_lemma for complex word 'instilled': instill\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['strengthened', 'targeted', 'tested', 'provided', 'created', 'affected', 'addressed', 'attacked', 'punished', 'bred', 'rewarded', 'empowered', 'shocked', 'introduced', 'silenced', 'improved', 'set', 'defeated', 'treated', 'reinforced', 'prepared', 'hit', 'surprised', 'hardened', 'infused', 'challenged', 'released', 'secured', 'delivered', 'established']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['strengthened', 'targeted', 'tested', 'provided', 'created', 'affected', 'addressed', 'attacked', 'punished', 'bred', 'rewarded', 'empowered', 'shocked', 'introduced', 'silenced', 'improved', 'set', 'defeated', 'treated', 'reinforced', 'prepared', 'hit', 'surprised', 'hardened', 'infused', 'challenged', 'released', 'secured', 'delivered', 'established']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step d) Ranked substitutes, based on cosine similarity scores in context: ['infused', 'prepared', 'hardened', 'silenced', 'reinforced', 'shocked', 'established', 'set', 'secured', 'created', 'delivered', 'rewarded', 'surprised', 'treated', 'bred', 'empowered', 'hit', 'tested', 'addressed', 'attacked', 'introduced', 'released', 'targeted', 'strengthened', 'provided', 'defeated', 'challenged', 'affected', 'punished', 'improved']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "SG step: generated substitutes: ['criminals', 'crimes', 'machines', '\"', 'rats', 'pigs', 'heroes', 'demons', 'robots', 'machine', 'games', 'doctors', 'dogs', 'priests', 'bandits', 'lords', 'monsters', 'soldiers', '##games', 'leaders', 'freaks', 'ants', 'saints', 'people', '##ists', 'workers', 'terror', 'zombies', 'fighters', 'elephants']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['criminals', 'crimes', 'machines', '\"', 'rats', 'pigs', 'heroes', 'demons', 'robots', 'machine', 'games', 'doctors', 'dogs', 'priests', 'bandits', 'lords', 'monsters', 'soldiers', '##games', 'leaders', 'freaks', 'ants', 'saints', 'people', '##ists', 'workers', 'terror', 'zombies', 'fighters', 'elephants']\n",
      "\n",
      "complex_word_lemma for complex word 'maniacs': maniac\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['criminals', 'crimes', 'machines', '\"', 'rats', 'pigs', 'heroes', 'demons', 'robots', 'machine', 'games', 'doctors', 'dogs', 'priests', 'bandits', 'lords', 'monsters', 'soldiers', '##games', 'leaders', 'freaks', 'ants', 'saints', 'people', '##ists', 'workers', 'terror', 'zombies', 'fighters', 'elephants']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['criminals', 'crimes', 'machines', '\"', 'rats', 'pigs', 'heroes', 'demons', 'robots', 'machine', 'games', 'doctors', 'dogs', 'priests', 'bandits', 'lords', 'monsters', 'soldiers', '##games', 'leaders', 'freaks', 'ants', 'saints', 'people', '##ists', 'workers', 'terror', 'zombies', 'fighters', 'elephants']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step d) Ranked substitutes, based on cosine similarity scores in context: ['rats', 'monsters', 'lords', 'demons', 'freaks', 'zombies', 'robots', 'bandits', 'doctors', 'ants', 'pigs', 'priests', 'criminals', 'saints', 'dogs', 'terror', 'leaders', 'people', 'heroes', 'machines', 'soldiers', 'workers', 'elephants', 'fighters', 'machine', 'games', 'crimes', '##games', '##ists', '\"']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "SG step: generated substitutes: ['observers', 'witnesses', 'participants', 'casualties', 'refugees', 'observer', 'visitors', 'monitors', 'victims', 'delegates', 'travelers', 'experts', 'troops', 'inspectors', 'allies', 'diplomats', 'inspections', 'soldiers', 'fatalities', 'workers', 'pilgrims', 'people', 'officials', 'deaths', 'tourists', 'survivors', 'volunteers', 'citizens', 'civilians', 'combatants']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['observers', 'witnesses', 'participants', 'casualties', 'refugees', 'observer', 'visitors', 'monitors', 'victims', 'delegates', 'travelers', 'experts', 'troops', 'inspectors', 'allies', 'diplomats', 'inspections', 'soldiers', 'fatalities', 'workers', 'pilgrims', 'people', 'officials', 'deaths', 'tourists', 'survivors', 'volunteers', 'citizens', 'civilians', 'combatants']\n",
      "\n",
      "complex_word_lemma for complex word 'observers': observer\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['witnesses', 'participants', 'casualties', 'refugees', 'visitors', 'monitors', 'victims', 'delegates', 'travelers', 'experts', 'troops', 'inspectors', 'allies', 'diplomats', 'inspections', 'soldiers', 'fatalities', 'workers', 'pilgrims', 'people', 'officials', 'deaths', 'tourists', 'survivors', 'volunteers', 'citizens', 'civilians', 'combatants']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['witnesses', 'participants', 'casualties', 'refugees', 'visitors', 'monitors', 'victims', 'delegates', 'travelers', 'experts', 'troops', 'inspectors', 'allies', 'diplomats', 'inspections', 'soldiers', 'fatalities', 'workers', 'pilgrims', 'people', 'officials', 'deaths', 'tourists', 'survivors', 'volunteers', 'citizens', 'civilians', 'combatants']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step d) Ranked substitutes, based on cosine similarity scores in context: ['monitors', 'officials', 'casualties', 'travelers', 'people', 'tourists', 'citizens', 'troops', 'diplomats', 'witnesses', 'victims', 'civilians', 'survivors', 'experts', 'soldiers', 'deaths', 'refugees', 'fatalities', 'visitors', 'inspections', 'volunteers', 'participants', 'pilgrims', 'combatants', 'workers', 'inspectors', 'delegates', 'allies']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "SG step: generated substitutes: ['stab', 'gunshot', 'bullet', 'knife', 'multiple', 'severe', 'arrow', 'several', 'minor', 'stabbing', 'laser', 'open', 'two', 'rifle', 'serious', 'blunt', 'similar', 'blast', 'numerous', 'penetrating', 'three', 'sword', 'some', 'slash', 'shooting', 'the', 'painful', 'fatal', 'deep', 'horrible']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['stab', 'gunshot', 'bullet', 'knife', 'multiple', 'severe', 'arrow', 'several', 'minor', 'stabbing', 'laser', 'open', 'two', 'rifle', 'serious', 'blunt', 'similar', 'blast', 'numerous', 'penetrating', 'three', 'sword', 'some', 'slash', 'shooting', 'the', 'painful', 'fatal', 'deep', 'horrible']\n",
      "\n",
      "complex_word_lemma for complex word 'shrapnel': shrapnel\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['stab', 'gunshot', 'bullet', 'knife', 'multiple', 'severe', 'arrow', 'several', 'minor', 'stabbing', 'laser', 'open', 'two', 'rifle', 'serious', 'blunt', 'similar', 'blast', 'numerous', 'penetrating', 'three', 'sword', 'some', 'slash', 'shooting', 'the', 'painful', 'fatal', 'deep', 'horrible']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['stab', 'gunshot', 'bullet', 'knife', 'multiple', 'severe', 'arrow', 'several', 'minor', 'stabbing', 'laser', 'open', 'two', 'rifle', 'serious', 'blunt', 'similar', 'blast', 'numerous', 'penetrating', 'three', 'sword', 'some', 'slash', 'shooting', 'the', 'painful', 'fatal', 'deep', 'horrible']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step d) Ranked substitutes, based on cosine similarity scores in context: ['arrow', 'bullet', 'blast', 'multiple', 'penetrating', 'three', 'several', 'numerous', 'severe', 'minor', 'two', 'deep', 'serious', 'gunshot', 'blunt', 'stab', 'slash', 'fatal', 'rifle', 'some', 'open', 'shooting', 'painful', 'knife', 'sword', 'the', 'stabbing', 'laser', 'horrible', 'similar']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "SG step: generated substitutes: ['disguised', 'dressed', 'clad', 'masked', 'clothed', 'dressing', 'disguise', 'concealed', 'cloak', 'posing', 'appeared', 'dress', 'posed', 'guise', 'costume', 'attire', 'appearing', 'dresses', 'hiding', 'hooded', 'covered', 'draped', 'costumes', ',', 'hidden', 'wrapped', 'undercover', 'lured', 'present', 'adorned']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['disguised', 'dressed', 'clad', 'masked', 'clothed', 'dressing', 'disguise', 'concealed', 'cloak', 'posing', 'appeared', 'dress', 'posed', 'guise', 'costume', 'attire', 'appearing', 'dresses', 'hiding', 'hooded', 'covered', 'draped', 'costumes', ',', 'hidden', 'wrapped', 'undercover', 'lured', 'present', 'adorned']\n",
      "\n",
      "complex_word_lemma for complex word 'disguised': disguised\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['dressed', 'clad', 'masked', 'clothed', 'dressing', 'disguise', 'concealed', 'cloak', 'posing', 'appeared', 'dress', 'posed', 'guise', 'costume', 'attire', 'appearing', 'dresses', 'hiding', 'hooded', 'covered', 'draped', 'costumes', ',', 'hidden', 'wrapped', 'undercover', 'lured', 'present', 'adorned']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['dressed', 'clad', 'masked', 'clothed', 'dressing', 'disguise', 'concealed', 'cloak', 'posing', 'appeared', 'dress', 'posed', 'guise', 'costume', 'attire', 'appearing', 'dresses', 'hiding', 'hooded', 'covered', 'draped', 'costumes', ',', 'hidden', 'wrapped', 'undercover', 'lured', 'present', 'adorned']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step d) Ranked substitutes, based on cosine similarity scores in context: ['masked', 'hooded', 'clad', 'clothed', 'dressed', 'adorned', 'covered', 'concealed', 'posing', 'dressing', 'draped', 'wrapped', 'hidden', 'hiding', ',', 'posed', 'disguise', 'appearing', 'undercover', 'lured', 'appeared', 'present', 'guise', 'cloak', 'costumes', 'costume', 'attire', 'dress', 'dresses']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "SG step: generated substitutes: ['affiliate', 'extension', 'arm', 'adaptation', 'incarnation', 'ally', 'opponent', 'attack', 'expansion', 'outpost', 'associate', 'advocate', 'enemy', 'aspect', 'origin', 'branch', 'adversary', 'independent', 'alliance', 'ancestor', 'iteration', 'evolution', 'independently', 'antagonist', 'offspring', 'overthrow', 'imitation', 'implementation', 'organization', 'example']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['affiliate', 'extension', 'arm', 'adaptation', 'incarnation', 'ally', 'opponent', 'attack', 'expansion', 'outpost', 'associate', 'advocate', 'enemy', 'aspect', 'origin', 'branch', 'adversary', 'independent', 'alliance', 'ancestor', 'iteration', 'evolution', 'independently', 'antagonist', 'offspring', 'overthrow', 'imitation', 'implementation', 'organization', 'example']\n",
      "\n",
      "complex_word_lemma for complex word 'offshoot': offshoot\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['affiliate', 'extension', 'arm', 'adaptation', 'incarnation', 'ally', 'opponent', 'attack', 'expansion', 'outpost', 'associate', 'advocate', 'enemy', 'aspect', 'origin', 'branch', 'adversary', 'independent', 'alliance', 'ancestor', 'iteration', 'evolution', 'independently', 'antagonist', 'offspring', 'overthrow', 'imitation', 'implementation', 'organization', 'example']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['affiliate', 'extension', 'arm', 'adaptation', 'incarnation', 'ally', 'opponent', 'attack', 'expansion', 'outpost', 'associate', 'advocate', 'enemy', 'aspect', 'origin', 'branch', 'adversary', 'independent', 'alliance', 'ancestor', 'iteration', 'evolution', 'independently', 'antagonist', 'offspring', 'overthrow', 'imitation', 'implementation', 'organization', 'example']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step d) Ranked substitutes, based on cosine similarity scores in context: ['branch', 'arm', 'affiliate', 'extension', 'associate', 'offspring', 'adversary', 'organization', 'outpost', 'aspect', 'independent', 'iteration', 'advocate', 'incarnation', 'opponent', 'antagonist', 'independently', 'evolution', 'implementation', 'adaptation', 'alliance', 'expansion', 'ancestor', 'origin', 'ally', 'enemy', 'imitation', 'overthrow', 'example', 'attack']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "SG step: generated substitutes: ['symphonic', 'orchestral', 'symphony', 'musical', 'classical', 'operatic', 'philharmonic', 'melodic', 'choral', 'music', 'orchestra', 'instrumental', 'concert', 'historical', 'popular', 'concerto', 'harmonic', 'symphonies', 'technical', 'trombone', 'romantic', 'lyric', 'liturgical', 'dramatic', 'thematic', 'traditional', 'composers', 'vocal', 'dynamic', 'general']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['symphonic', 'orchestral', 'symphony', 'musical', 'classical', 'operatic', 'philharmonic', 'melodic', 'choral', 'music', 'orchestra', 'instrumental', 'concert', 'historical', 'popular', 'concerto', 'harmonic', 'symphonies', 'technical', 'trombone', 'romantic', 'lyric', 'liturgical', 'dramatic', 'thematic', 'traditional', 'composers', 'vocal', 'dynamic', 'general']\n",
      "\n",
      "complex_word_lemma for complex word 'symphonic': symphonic\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['orchestral', 'symphony', 'musical', 'classical', 'operatic', 'philharmonic', 'melodic', 'choral', 'music', 'orchestra', 'instrumental', 'concert', 'historical', 'popular', 'concerto', 'harmonic', 'symphonies', 'technical', 'trombone', 'romantic', 'lyric', 'liturgical', 'dramatic', 'thematic', 'traditional', 'composers', 'vocal', 'dynamic', 'general']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['orchestral', 'symphony', 'musical', 'classical', 'operatic', 'philharmonic', 'melodic', 'choral', 'music', 'orchestra', 'instrumental', 'concert', 'historical', 'popular', 'concerto', 'harmonic', 'symphonies', 'technical', 'trombone', 'romantic', 'lyric', 'liturgical', 'dramatic', 'thematic', 'traditional', 'composers', 'vocal', 'dynamic', 'general']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step d) Ranked substitutes, based on cosine similarity scores in context: ['orchestral', 'harmonic', 'composers', 'vocal', 'concert', 'popular', 'melodic', 'technical', 'orchestra', 'symphony', 'classical', 'philharmonic', 'traditional', 'musical', 'general', 'thematic', 'instrumental', 'dynamic', 'dramatic', 'historical', 'choral', 'symphonies', 'lyric', 'music', 'operatic', 'concerto', 'liturgical', 'trombone', 'romantic']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "SG step: generated substitutes: ['deploy', 'deployed', 'withdraw', 'activate', 'deployment', 'send', 'maintain', 'dispatch', 'use', 'acquire', 'reserve', 'retain', 'move', 'utilize', 'request', 'return', 'include', 'add', 'launch', 'designate', 'fire', 'operate', 'provide', 'establish', 'employ', 'outfit', 'purchase', 'expand', 'retire', 'build']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['deploy', 'deployed', 'withdraw', 'activate', 'deployment', 'send', 'maintain', 'dispatch', 'use', 'acquire', 'reserve', 'retain', 'move', 'utilize', 'request', 'return', 'include', 'add', 'launch', 'designate', 'fire', 'operate', 'provide', 'establish', 'employ', 'outfit', 'purchase', 'expand', 'retire', 'build']\n",
      "\n",
      "complex_word_lemma for complex word 'deploy': deploy\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['withdraw', 'activate', 'deployment', 'send', 'maintain', 'dispatch', 'use', 'acquire', 'reserve', 'retain', 'move', 'utilize', 'request', 'return', 'include', 'add', 'launch', 'designate', 'fire', 'operate', 'provide', 'establish', 'employ', 'outfit', 'purchase', 'expand', 'retire', 'build']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['withdraw', 'activate', 'deployment', 'send', 'maintain', 'dispatch', 'use', 'acquire', 'reserve', 'retain', 'move', 'utilize', 'request', 'return', 'include', 'add', 'launch', 'designate', 'fire', 'operate', 'provide', 'establish', 'employ', 'outfit', 'purchase', 'expand', 'retire', 'build']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step d) Ranked substitutes, based on cosine similarity scores in context: ['deployment', 'activate', 'utilize', 'dispatch', 'operate', 'expand', 'include', 'maintain', 'add', 'employ', 'launch', 'use', 'return', 'move', 'provide', 'acquire', 'retain', 'outfit', 'send', 'request', 'build', 'purchase', 'establish', 'reserve', 'retire', 'fire', 'withdraw', 'designate']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "SG step: generated substitutes: ['authorities', 'officials', 'police', '##s', 'citizens', 'forces', 'government', 'officers', 'people', 'governments', 'residents', 'troops', 'authority', 'courts', 'individuals', 'persons', 'organisations', 'policemen', 'civilians', 'nationals', 'protesters', 'institutions', 'interests', 'agencies', 'subjects', 'bodies', 'activists', 'personnel', 'magistrates', 'politicians']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['authorities', 'officials', 'police', '##s', 'citizens', 'forces', 'government', 'officers', 'people', 'governments', 'residents', 'troops', 'authority', 'courts', 'individuals', 'persons', 'organisations', 'policemen', 'civilians', 'nationals', 'protesters', 'institutions', 'interests', 'agencies', 'subjects', 'bodies', 'activists', 'personnel', 'magistrates', 'politicians']\n",
      "\n",
      "complex_word_lemma for complex word 'authorities': authority\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['officials', 'police', '##s', 'citizens', 'forces', 'government', 'officers', 'people', 'governments', 'residents', 'troops', 'courts', 'individuals', 'persons', 'organisations', 'policemen', 'civilians', 'nationals', 'protesters', 'institutions', 'interests', 'agencies', 'subjects', 'bodies', 'activists', 'personnel', 'magistrates', 'politicians']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['officials', 'police', '##s', 'citizens', 'forces', 'government', 'officers', 'people', 'governments', 'residents', 'troops', 'courts', 'individuals', 'persons', 'organisations', 'policemen', 'civilians', 'nationals', 'protesters', 'institutions', 'interests', 'agencies', 'subjects', 'bodies', 'activists', 'personnel', 'magistrates', 'politicians']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step d) Ranked substitutes, based on cosine similarity scores in context: ['officials', 'personnel', 'citizens', 'agencies', 'nationals', 'individuals', 'police', 'persons', 'bodies', 'residents', 'officers', 'courts', 'civilians', 'people', 'interests', 'organisations', 'government', 'institutions', 'governments', 'subjects', 'policemen', 'forces', 'magistrates', 'troops', 'politicians', 'activists', 'protesters', '##s']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculates similarity between the original sentence and the sentences with candidate substitutes that were retrieved in the SG step \n",
    "# creates a list with sentences with substitute words filled in (commented out for oversight purposes)\n",
    "\n",
    "\n",
    "def calculate_similarity_scores(sentence, sentence_with_substitutes):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    tf_model = TFAutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    def embed_text(text):\n",
    "        tokens = tokenizer(text, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "        outputs = tf_model(**tokens)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        embeddings = tf.nn.l2_normalize(embeddings, axis=1)\n",
    "        return embeddings\n",
    "\n",
    "    original_sentence_embedding = embed_text(sentence)\n",
    "    substitute_sentence_embeddings = embed_text(sentence_with_substitutes)\n",
    "\n",
    "    cosine_similarity = np.inner(original_sentence_embedding, substitute_sentence_embeddings)\n",
    "    similarity_scores = cosine_similarity[0]\n",
    "\n",
    "    return similarity_scores\n",
    "\n",
    "\n",
    "\n",
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"[MASK]\")\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    tokenizer = fill_mask.tokenizer\n",
    "    sentences_concat = f\"{sentence} {tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes = [substitute[\"token_str\"].lower() for substitute in result]\n",
    "    print(f\"SG step: generated substitutes: {substitutes}\\n\")\n",
    "    \n",
    "    # 2. Substitute Selection (SS):   \n",
    "    \n",
    "    # create a punctuation set without hyphen, in order to retain hyphens in compound substitutes\n",
    "    punctuation_without_hyphen = set(string.punctuation) - set('-')\n",
    "    \n",
    "    # a) remove duplicates and unwanted punctuation within the substitute list from the substitute list\n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl and not any(char in punctuation_without_hyphen for char in sub):\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    print(f\"SS step: a) substitute list without duplicates and undesired punctuation: {substitutes_no_dupl}\\n\")\n",
    "    \n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    print(f\"SS step: b) substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    print(f\"SS step: c): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "    \n",
    "    \n",
    "    # create sentence with the complex word replaced by the substitutes\n",
    "    sentence_with_substitutes = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym]\n",
    "    #print(f\"List with sentences where complex word is substituted: {sentence_with_substitutes}\\n\")\n",
    "    \n",
    "    \n",
    "    # d) calculate cosine similarity scores, and rank the substitutes based on their similarity score\n",
    "    similarity_scores = calculate_similarity_scores(sentence, sentence_with_substitutes)\n",
    "    #print(f\"Similarity scores: {similarity_scores}\\n\")\n",
    "    ranked_substitutes_withscores = sorted(zip(substitutes_no_dupl_complex_word_no_antonym, similarity_scores), key=lambda x: x[1], reverse=True)\n",
    "    #print(f\"SS step d) Ranked substitutes, including similarity scores in context: {ranked_substitutes}\\n\")\n",
    "    ranked_substitutes = [substitute for substitute, score in ranked_substitutes_withscores]\n",
    "    print(f\"SS step d) Ranked substitutes, based on cosine similarity scores in context: {ranked_substitutes}\\n\")\n",
    "        \n",
    "    print('-----------------------------------------------------------------------------------------')\n",
    "    print()\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    # limit the substitutes to the 10 first ones for evaluation\n",
    "    top_10_substitutes = ranked_substitutes[:10]\n",
    "    \n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + top_10_substitutes\n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the dataframe\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/BertBase_SG_SS_abc_ce.tsv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb70be81-a48c-4ec5-964a-b34b42674768",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file ./predictions/trial/BertBase_SG_SS_abc_ce.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ac2d866-2924-44f9-81be-d816cade47da",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/BertBase_SG_SS_abc_ce.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.6\n",
    "\n",
    "MAP@3 = 0.2833\n",
    "MAP@5 = 0.182\n",
    "MAP@10 = 0.1192\n",
    "\n",
    "Potential@3 = 0.7\n",
    "Potential@5 = 0.8\n",
    "Potential@10 = 1.0\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.4\n",
    "Accuracy@2@top_gold_1 = 0.5\n",
    "Accuracy@3@top_gold_1 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "779d98e6-c618-48cb-ac73-300b8de99cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best output so far on MAP@1., and on Potential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd8288c-88ab-4b3b-95c2-91604a0c3cde",
   "metadata": {},
   "source": [
    "#### Substitute Generation with BERT-base, and Substitute Selection steps a-c, and the resulting list with BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "728b2211-1fa8-44f5-930d-98435d489da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert_score\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0fe36c4-e4fd-4f3f-9746-6e8cb6f71616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "using custom model: ['BertForMaskedLM']\n",
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "SG step: generated substitutes: ['compulsory', 'mandatory', 'obligatory', 'optional', 'required', 'necessary', 'standard', 'voluntary', 'customary', 'impossible', 'easier', 'only', 'illegal', 'sufficient', 'unnecessary', 'easy', 'normal', 'permitted', 'mandated', 'difficult', 'simple', 'appropriate', 'expensive', 'possible', 'commonplace', 'essential', 'proper', 'available', 'enough', 'affordable']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['compulsory', 'mandatory', 'obligatory', 'optional', 'required', 'necessary', 'standard', 'voluntary', 'customary', 'impossible', 'easier', 'only', 'illegal', 'sufficient', 'unnecessary', 'easy', 'normal', 'permitted', 'mandated', 'difficult', 'simple', 'appropriate', 'expensive', 'possible', 'commonplace', 'essential', 'proper', 'available', 'enough', 'affordable']\n",
      "\n",
      "complex_word_lemma for complex word 'compulsory': compulsory\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['mandatory', 'obligatory', 'optional', 'required', 'necessary', 'standard', 'voluntary', 'customary', 'impossible', 'easier', 'only', 'illegal', 'sufficient', 'unnecessary', 'easy', 'normal', 'permitted', 'mandated', 'difficult', 'simple', 'appropriate', 'expensive', 'possible', 'commonplace', 'essential', 'proper', 'available', 'enough', 'affordable']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['mandatory', 'obligatory', 'optional', 'required', 'necessary', 'standard', 'voluntary', 'customary', 'impossible', 'easier', 'only', 'illegal', 'sufficient', 'unnecessary', 'easy', 'normal', 'permitted', 'mandated', 'difficult', 'simple', 'appropriate', 'expensive', 'possible', 'commonplace', 'essential', 'proper', 'available', 'enough', 'affordable']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['mandatory', 'required', 'mandated', 'necessary', 'essential', 'voluntary', 'optional', 'permitted', 'appropriate', 'illegal', 'standard', 'unnecessary', 'simple', 'obligatory', 'easier', 'normal', 'expensive', 'sufficient', 'easy', 'affordable', 'possible', 'only', 'enough', 'available', 'commonplace', 'impossible', 'customary', 'difficult', 'proper']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "SG step: generated substitutes: ['strengthened', 'targeted', 'tested', 'provided', 'created', 'affected', 'addressed', 'attacked', 'punished', 'bred', 'rewarded', 'empowered', 'shocked', 'introduced', 'silenced', 'improved', 'set', 'defeated', 'treated', 'reinforced', 'prepared', 'hit', 'surprised', 'hardened', 'infused', 'challenged', 'released', 'secured', 'delivered', 'established']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['strengthened', 'targeted', 'tested', 'provided', 'created', 'affected', 'addressed', 'attacked', 'punished', 'bred', 'rewarded', 'empowered', 'shocked', 'introduced', 'silenced', 'improved', 'set', 'defeated', 'treated', 'reinforced', 'prepared', 'hit', 'surprised', 'hardened', 'infused', 'challenged', 'released', 'secured', 'delivered', 'established']\n",
      "\n",
      "complex_word_lemma for complex word 'instilled': instill\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['strengthened', 'targeted', 'tested', 'provided', 'created', 'affected', 'addressed', 'attacked', 'punished', 'bred', 'rewarded', 'empowered', 'shocked', 'introduced', 'silenced', 'improved', 'set', 'defeated', 'treated', 'reinforced', 'prepared', 'hit', 'surprised', 'hardened', 'infused', 'challenged', 'released', 'secured', 'delivered', 'established']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['strengthened', 'targeted', 'tested', 'provided', 'created', 'affected', 'addressed', 'attacked', 'punished', 'bred', 'rewarded', 'empowered', 'shocked', 'introduced', 'silenced', 'improved', 'set', 'defeated', 'treated', 'reinforced', 'prepared', 'hit', 'surprised', 'hardened', 'infused', 'challenged', 'released', 'secured', 'delivered', 'established']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['infused', 'provided', 'empowered', 'treated', 'hit', 'strengthened', 'rewarded', 'reinforced', 'affected', 'challenged', 'set', 'tested', 'surprised', 'created', 'attacked', 'shocked', 'prepared', 'established', 'delivered', 'improved', 'secured', 'targeted', 'silenced', 'punished', 'addressed', 'introduced', 'released', 'hardened', 'defeated', 'bred']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "SG step: generated substitutes: ['criminals', 'crimes', 'machines', '\"', 'rats', 'pigs', 'heroes', 'demons', 'robots', 'machine', 'games', 'doctors', 'dogs', 'priests', 'bandits', 'lords', 'monsters', 'soldiers', '##games', 'leaders', 'freaks', 'ants', 'saints', 'people', '##ists', 'workers', 'terror', 'zombies', 'fighters', 'elephants']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['criminals', 'crimes', 'machines', '\"', 'rats', 'pigs', 'heroes', 'demons', 'robots', 'machine', 'games', 'doctors', 'dogs', 'priests', 'bandits', 'lords', 'monsters', 'soldiers', '##games', 'leaders', 'freaks', 'ants', 'saints', 'people', '##ists', 'workers', 'terror', 'zombies', 'fighters', 'elephants']\n",
      "\n",
      "complex_word_lemma for complex word 'maniacs': maniac\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['criminals', 'crimes', 'machines', '\"', 'rats', 'pigs', 'heroes', 'demons', 'robots', 'machine', 'games', 'doctors', 'dogs', 'priests', 'bandits', 'lords', 'monsters', 'soldiers', '##games', 'leaders', 'freaks', 'ants', 'saints', 'people', '##ists', 'workers', 'terror', 'zombies', 'fighters', 'elephants']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['criminals', 'crimes', 'machines', '\"', 'rats', 'pigs', 'heroes', 'demons', 'robots', 'machine', 'games', 'doctors', 'dogs', 'priests', 'bandits', 'lords', 'monsters', 'soldiers', '##games', 'leaders', 'freaks', 'ants', 'saints', 'people', '##ists', 'workers', 'terror', 'zombies', 'fighters', 'elephants']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['freaks', 'criminals', 'lords', 'machines', 'soldiers', 'dogs', 'heroes', 'machine', 'fighters', 'games', 'crimes', 'workers', 'leaders', 'demons', 'terror', 'monsters', '##ists', 'elephants', 'rats', 'doctors', 'people', 'ants', 'bandits', 'robots', 'saints', 'priests', 'zombies', 'pigs', '##games', '\"']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "SG step: generated substitutes: ['observers', 'witnesses', 'participants', 'casualties', 'refugees', 'observer', 'visitors', 'monitors', 'victims', 'delegates', 'travelers', 'experts', 'troops', 'inspectors', 'allies', 'diplomats', 'inspections', 'soldiers', 'fatalities', 'workers', 'pilgrims', 'people', 'officials', 'deaths', 'tourists', 'survivors', 'volunteers', 'citizens', 'civilians', 'combatants']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['observers', 'witnesses', 'participants', 'casualties', 'refugees', 'observer', 'visitors', 'monitors', 'victims', 'delegates', 'travelers', 'experts', 'troops', 'inspectors', 'allies', 'diplomats', 'inspections', 'soldiers', 'fatalities', 'workers', 'pilgrims', 'people', 'officials', 'deaths', 'tourists', 'survivors', 'volunteers', 'citizens', 'civilians', 'combatants']\n",
      "\n",
      "complex_word_lemma for complex word 'observers': observer\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['witnesses', 'participants', 'casualties', 'refugees', 'visitors', 'monitors', 'victims', 'delegates', 'travelers', 'experts', 'troops', 'inspectors', 'allies', 'diplomats', 'inspections', 'soldiers', 'fatalities', 'workers', 'pilgrims', 'people', 'officials', 'deaths', 'tourists', 'survivors', 'volunteers', 'citizens', 'civilians', 'combatants']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['witnesses', 'participants', 'casualties', 'refugees', 'visitors', 'monitors', 'victims', 'delegates', 'travelers', 'experts', 'troops', 'inspectors', 'allies', 'diplomats', 'inspections', 'soldiers', 'fatalities', 'workers', 'pilgrims', 'people', 'officials', 'deaths', 'tourists', 'survivors', 'volunteers', 'citizens', 'civilians', 'combatants']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['monitors', 'inspectors', 'diplomats', 'experts', 'inspections', 'witnesses', 'allies', 'officials', 'delegates', 'workers', 'volunteers', 'participants', 'visitors', 'tourists', 'pilgrims', 'travelers', 'troops', 'soldiers', 'survivors', 'combatants', 'citizens', 'refugees', 'civilians', 'people', 'casualties', 'victims', 'fatalities', 'deaths']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "SG step: generated substitutes: ['stab', 'gunshot', 'bullet', 'knife', 'multiple', 'severe', 'arrow', 'several', 'minor', 'stabbing', 'laser', 'open', 'two', 'rifle', 'serious', 'blunt', 'similar', 'blast', 'numerous', 'penetrating', 'three', 'sword', 'some', 'slash', 'shooting', 'the', 'painful', 'fatal', 'deep', 'horrible']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['stab', 'gunshot', 'bullet', 'knife', 'multiple', 'severe', 'arrow', 'several', 'minor', 'stabbing', 'laser', 'open', 'two', 'rifle', 'serious', 'blunt', 'similar', 'blast', 'numerous', 'penetrating', 'three', 'sword', 'some', 'slash', 'shooting', 'the', 'painful', 'fatal', 'deep', 'horrible']\n",
      "\n",
      "complex_word_lemma for complex word 'shrapnel': shrapnel\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['stab', 'gunshot', 'bullet', 'knife', 'multiple', 'severe', 'arrow', 'several', 'minor', 'stabbing', 'laser', 'open', 'two', 'rifle', 'serious', 'blunt', 'similar', 'blast', 'numerous', 'penetrating', 'three', 'sword', 'some', 'slash', 'shooting', 'the', 'painful', 'fatal', 'deep', 'horrible']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['stab', 'gunshot', 'bullet', 'knife', 'multiple', 'severe', 'arrow', 'several', 'minor', 'stabbing', 'laser', 'open', 'two', 'rifle', 'serious', 'blunt', 'similar', 'blast', 'numerous', 'penetrating', 'three', 'sword', 'some', 'slash', 'shooting', 'the', 'painful', 'fatal', 'deep', 'horrible']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['bullet', 'stab', 'gunshot', 'shooting', 'knife', 'multiple', 'stabbing', 'blunt', 'severe', 'deep', 'blast', 'several', 'numerous', 'minor', 'serious', 'two', 'open', 'three', 'slash', 'penetrating', 'some', 'rifle', 'fatal', 'arrow', 'painful', 'sword', 'horrible', 'similar', 'the', 'laser']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "SG step: generated substitutes: ['disguised', 'dressed', 'clad', 'masked', 'clothed', 'dressing', 'disguise', 'concealed', 'cloak', 'posing', 'appeared', 'dress', 'posed', 'guise', 'costume', 'attire', 'appearing', 'dresses', 'hiding', 'hooded', 'covered', 'draped', 'costumes', ',', 'hidden', 'wrapped', 'undercover', 'lured', 'present', 'adorned']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['disguised', 'dressed', 'clad', 'masked', 'clothed', 'dressing', 'disguise', 'concealed', 'cloak', 'posing', 'appeared', 'dress', 'posed', 'guise', 'costume', 'attire', 'appearing', 'dresses', 'hiding', 'hooded', 'covered', 'draped', 'costumes', ',', 'hidden', 'wrapped', 'undercover', 'lured', 'present', 'adorned']\n",
      "\n",
      "complex_word_lemma for complex word 'disguised': disguised\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['dressed', 'clad', 'masked', 'clothed', 'dressing', 'disguise', 'concealed', 'cloak', 'posing', 'appeared', 'dress', 'posed', 'guise', 'costume', 'attire', 'appearing', 'dresses', 'hiding', 'hooded', 'covered', 'draped', 'costumes', ',', 'hidden', 'wrapped', 'undercover', 'lured', 'present', 'adorned']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['dressed', 'clad', 'masked', 'clothed', 'dressing', 'disguise', 'concealed', 'cloak', 'posing', 'appeared', 'dress', 'posed', 'guise', 'costume', 'attire', 'appearing', 'dresses', 'hiding', 'hooded', 'covered', 'draped', 'costumes', ',', 'hidden', 'wrapped', 'undercover', 'lured', 'present', 'adorned']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['masked', 'concealed', 'clothed', 'posing', 'dressed', 'clad', 'adorned', 'wrapped', 'hidden', 'covered', 'dressing', 'hiding', 'draped', 'hooded', 'appearing', 'posed', 'present', 'dress', 'appeared', 'lured', 'disguise', 'undercover', 'dresses', 'cloak', ',', 'costumes', 'costume', 'guise', 'attire']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "SG step: generated substitutes: ['affiliate', 'extension', 'arm', 'adaptation', 'incarnation', 'ally', 'opponent', 'attack', 'expansion', 'outpost', 'associate', 'advocate', 'enemy', 'aspect', 'origin', 'branch', 'adversary', 'independent', 'alliance', 'ancestor', 'iteration', 'evolution', 'independently', 'antagonist', 'offspring', 'overthrow', 'imitation', 'implementation', 'organization', 'example']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['affiliate', 'extension', 'arm', 'adaptation', 'incarnation', 'ally', 'opponent', 'attack', 'expansion', 'outpost', 'associate', 'advocate', 'enemy', 'aspect', 'origin', 'branch', 'adversary', 'independent', 'alliance', 'ancestor', 'iteration', 'evolution', 'independently', 'antagonist', 'offspring', 'overthrow', 'imitation', 'implementation', 'organization', 'example']\n",
      "\n",
      "complex_word_lemma for complex word 'offshoot': offshoot\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['affiliate', 'extension', 'arm', 'adaptation', 'incarnation', 'ally', 'opponent', 'attack', 'expansion', 'outpost', 'associate', 'advocate', 'enemy', 'aspect', 'origin', 'branch', 'adversary', 'independent', 'alliance', 'ancestor', 'iteration', 'evolution', 'independently', 'antagonist', 'offspring', 'overthrow', 'imitation', 'implementation', 'organization', 'example']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['affiliate', 'extension', 'arm', 'adaptation', 'incarnation', 'ally', 'opponent', 'attack', 'expansion', 'outpost', 'associate', 'advocate', 'enemy', 'aspect', 'origin', 'branch', 'adversary', 'independent', 'alliance', 'ancestor', 'iteration', 'evolution', 'independently', 'antagonist', 'offspring', 'overthrow', 'imitation', 'implementation', 'organization', 'example']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['extension', 'affiliate', 'arm', 'offspring', 'iteration', 'incarnation', 'outpost', 'adaptation', 'evolution', 'ally', 'aspect', 'branch', 'ancestor', 'imitation', 'expansion', 'adversary', 'opponent', 'origin', 'associate', 'antagonist', 'enemy', 'example', 'independent', 'alliance', 'advocate', 'implementation', 'organization', 'independently', 'attack', 'overthrow']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "SG step: generated substitutes: ['symphonic', 'orchestral', 'symphony', 'musical', 'classical', 'operatic', 'philharmonic', 'melodic', 'choral', 'music', 'orchestra', 'instrumental', 'concert', 'historical', 'popular', 'concerto', 'harmonic', 'symphonies', 'technical', 'trombone', 'romantic', 'lyric', 'liturgical', 'dramatic', 'thematic', 'traditional', 'composers', 'vocal', 'dynamic', 'general']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['symphonic', 'orchestral', 'symphony', 'musical', 'classical', 'operatic', 'philharmonic', 'melodic', 'choral', 'music', 'orchestra', 'instrumental', 'concert', 'historical', 'popular', 'concerto', 'harmonic', 'symphonies', 'technical', 'trombone', 'romantic', 'lyric', 'liturgical', 'dramatic', 'thematic', 'traditional', 'composers', 'vocal', 'dynamic', 'general']\n",
      "\n",
      "complex_word_lemma for complex word 'symphonic': symphonic\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['orchestral', 'symphony', 'musical', 'classical', 'operatic', 'philharmonic', 'melodic', 'choral', 'music', 'orchestra', 'instrumental', 'concert', 'historical', 'popular', 'concerto', 'harmonic', 'symphonies', 'technical', 'trombone', 'romantic', 'lyric', 'liturgical', 'dramatic', 'thematic', 'traditional', 'composers', 'vocal', 'dynamic', 'general']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['orchestral', 'symphony', 'musical', 'classical', 'operatic', 'philharmonic', 'melodic', 'choral', 'music', 'orchestra', 'instrumental', 'concert', 'historical', 'popular', 'concerto', 'harmonic', 'symphonies', 'technical', 'trombone', 'romantic', 'lyric', 'liturgical', 'dramatic', 'thematic', 'traditional', 'composers', 'vocal', 'dynamic', 'general']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['philharmonic', 'symphony', 'orchestral', 'melodic', 'operatic', 'concerto', 'thematic', 'symphonies', 'classical', 'musical', 'dramatic', 'choral', 'harmonic', 'dynamic', 'concert', 'liturgical', 'instrumental', 'music', 'general', 'popular', 'traditional', 'historical', 'lyric', 'romantic', 'orchestra', 'trombone', 'composers', 'technical', 'vocal']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "SG step: generated substitutes: ['deploy', 'deployed', 'withdraw', 'activate', 'deployment', 'send', 'maintain', 'dispatch', 'use', 'acquire', 'reserve', 'retain', 'move', 'utilize', 'request', 'return', 'include', 'add', 'launch', 'designate', 'fire', 'operate', 'provide', 'establish', 'employ', 'outfit', 'purchase', 'expand', 'retire', 'build']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['deploy', 'deployed', 'withdraw', 'activate', 'deployment', 'send', 'maintain', 'dispatch', 'use', 'acquire', 'reserve', 'retain', 'move', 'utilize', 'request', 'return', 'include', 'add', 'launch', 'designate', 'fire', 'operate', 'provide', 'establish', 'employ', 'outfit', 'purchase', 'expand', 'retire', 'build']\n",
      "\n",
      "complex_word_lemma for complex word 'deploy': deploy\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['withdraw', 'activate', 'deployment', 'send', 'maintain', 'dispatch', 'use', 'acquire', 'reserve', 'retain', 'move', 'utilize', 'request', 'return', 'include', 'add', 'launch', 'designate', 'fire', 'operate', 'provide', 'establish', 'employ', 'outfit', 'purchase', 'expand', 'retire', 'build']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['withdraw', 'activate', 'deployment', 'send', 'maintain', 'dispatch', 'use', 'acquire', 'reserve', 'retain', 'move', 'utilize', 'request', 'return', 'include', 'add', 'launch', 'designate', 'fire', 'operate', 'provide', 'establish', 'employ', 'outfit', 'purchase', 'expand', 'retire', 'build']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['dispatch', 'activate', 'utilize', 'employ', 'use', 'launch', 'operate', 'send', 'outfit', 'reserve', 'expand', 'add', 'establish', 'purchase', 'maintain', 'provide', 'acquire', 'fire', 'build', 'request', 'retain', 'move', 'designate', 'retire', 'include', 'withdraw', 'deployment', 'return']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "SG step: generated substitutes: ['authorities', 'officials', 'police', '##s', 'citizens', 'forces', 'government', 'officers', 'people', 'governments', 'residents', 'troops', 'authority', 'courts', 'individuals', 'persons', 'organisations', 'policemen', 'civilians', 'nationals', 'protesters', 'institutions', 'interests', 'agencies', 'subjects', 'bodies', 'activists', 'personnel', 'magistrates', 'politicians']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['authorities', 'officials', 'police', '##s', 'citizens', 'forces', 'government', 'officers', 'people', 'governments', 'residents', 'troops', 'authority', 'courts', 'individuals', 'persons', 'organisations', 'policemen', 'civilians', 'nationals', 'protesters', 'institutions', 'interests', 'agencies', 'subjects', 'bodies', 'activists', 'personnel', 'magistrates', 'politicians']\n",
      "\n",
      "complex_word_lemma for complex word 'authorities': authority\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['officials', 'police', '##s', 'citizens', 'forces', 'government', 'officers', 'people', 'governments', 'residents', 'troops', 'courts', 'individuals', 'persons', 'organisations', 'policemen', 'civilians', 'nationals', 'protesters', 'institutions', 'interests', 'agencies', 'subjects', 'bodies', 'activists', 'personnel', 'magistrates', 'politicians']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['officials', 'police', '##s', 'citizens', 'forces', 'government', 'officers', 'people', 'governments', 'residents', 'troops', 'courts', 'individuals', 'persons', 'organisations', 'policemen', 'civilians', 'nationals', 'protesters', 'institutions', 'interests', 'agencies', 'subjects', 'bodies', 'activists', 'personnel', 'magistrates', 'politicians']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['police', 'officials', 'government', 'magistrates', 'policemen', 'courts', 'civilians', 'troops', 'citizens', 'residents', 'nationals', 'forces', 'activists', 'governments', 'politicians', 'personnel', 'officers', 'institutions', 'protesters', 'agencies', 'people', 'organisations', 'individuals', 'subjects', 'bodies', 'persons', 'interests', '##s']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"[MASK]\")\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    tokenizer = fill_mask.tokenizer\n",
    "    sentences_concat = f\"{sentence} {tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes = [substitute[\"token_str\"].lower() for substitute in result]\n",
    "    print(f\"SG step: generated substitutes: {substitutes}\\n\")\n",
    "    \n",
    "    # 2. Substitute Selection (SS):   \n",
    "    \n",
    "     # create a punctuation set without hyphen, in order to retain hyphens in compound substitutes\n",
    "    punctuation_without_hyphen = set(string.punctuation) - set('-')\n",
    "    \n",
    "    # a) remove duplicates and unwanted punctuation within the substitute list from the substitute list\n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl and not any(char in punctuation_without_hyphen for char in sub):\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    print(f\"SS step: a) substitute list without duplicates and undesired punctuation: {substitutes_no_dupl}\\n\")\n",
    "    \n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    print(f\"SS step: b) substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    print(f\"SS step: c): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "    \n",
    "    \n",
    "    # create sentences with the complex word replaced by the substitutes\n",
    "    sentences_with_substitutes = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym]\n",
    "    #print(f\"SG step: sentences with substitutes: {sentences_with_substitutes}\\n\")\n",
    "    \n",
    "          \n",
    "    # d) use BERTScore for sorting\n",
    "    scores = bert_score.score([sentence]*len(sentences_with_substitutes), sentences_with_substitutes, lang=\"en\", model_type='bert-base-uncased', verbose=False)\n",
    "    ranked_substitutes = [substitute for _, substitute in sorted(zip(scores[0].tolist(), substitutes_no_dupl_complex_word_no_antonym), reverse=True)]\n",
    "    print(f\"SS step: d) substitute list sorted by descending BERTScore: {ranked_substitutes}\\n\")\n",
    "\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------------------')\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    # limit the substitutes to the 10 first ones for evaluation\n",
    "    top_10_substitutes = ranked_substitutes[:10]\n",
    "    \n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + top_10_substitutes\n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the dataframe\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/BertBase_SG_SS_abc_bs.tsv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67feed8b-b2bf-4539-95f8-7085cfe1d90f",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file ./predictions/trial/BertBase_SG_SS_abc_bs.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec19060e-baa9-4a1f-abb9-abcbfc55a0a2",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/BertBase_SG_SS_abc_bs.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.6\n",
    "\n",
    "MAP@3 = 0.3444\n",
    "MAP@5 = 0.2726\n",
    "MAP@10 = 0.1624\n",
    "\n",
    "Potential@3 = 0.7\n",
    "Potential@5 = 0.8\n",
    "Potential@10 = 0.9\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.3\n",
    "Accuracy@2@top_gold_1 = 0.5\n",
    "Accuracy@3@top_gold_1 = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1789dd-0c85-4c8d-9ea9-4f3732e18199",
   "metadata": {},
   "source": [
    "Comparable with context. embeddings model based on regular Bert. MAP is better (only MAP1 is the same), potential and accuracy differ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ef875a-5d61-4501-9b47-f3f5635c2382",
   "metadata": {},
   "source": [
    "### Bert-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "044ee468-d1d1-43d0-9f52-0c81a436815a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# # initialize the tokenizer and the models\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "lm_model = AutoModelForMaskedLM.from_pretrained(\"bert-large-uncased\")\n",
    "\n",
    "# create a fill-mask pipeline \n",
    "fill_mask = pipeline(\"fill-mask\", lm_model, tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee1f666-df46-41e9-bf46-86f811c4581d",
   "metadata": {},
   "source": [
    "#### Only Substitute Generation with BERT-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba263a4a-ecca-434b-b8a2-9aa20d1be64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "SG step: generated substitutes: ['compulsory', 'mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden', 'permitted']\n",
      "\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "SG step: generated substitutes: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed', 'impressed', 'fed']\n",
      "\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "SG step: generated substitutes: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria', 'demons', 'gods']\n",
      "\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "SG step: generated substitutes: ['observers', 'observer', 'monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters']\n",
      "\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "SG step: generated substitutes: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor', 'blast', 'battle']\n",
      "\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "SG step: generated substitutes: ['disguised', 'dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad', 'guise']\n",
      "\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "SG step: generated substitutes: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy', 'aspect', 'enclave']\n",
      "\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "SG step: generated substitutes: ['symphonic', 'orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata', 'operatic']\n",
      "\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "SG step: generated substitutes: ['deploy', 'deployed', 'activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw']\n",
      "\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "SG step: generated substitutes: ['authorities', 'police', 'officials', '##s', 'magistrates', 'officers', 'forces', 'courts', 'authority', 'people']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"[MASK]\")\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    tokenizer = fill_mask.tokenizer\n",
    "    sentences_concat = f\"{sentence} {tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 10\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes = [substitute[\"token_str\"].lower() for substitute in result]\n",
    "    print(f\"SG step: generated substitutes: {substitutes}\\n\")\n",
    "    \n",
    "    \n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + substitutes\n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the dataframe\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/BertLarge_SG.tsv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8746b67a-186a-473f-b001-c20c4bf74ef0",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file ./predictions/trial/BertLarge_SG.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "734f15ff-9d9a-4971-a5f5-556f56718fe0",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/BertLarge_SG.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.4\n",
    "\n",
    "MAP@3 = 0.3055\n",
    "MAP@5 = 0.1953\n",
    "MAP@10 = 0.1262\n",
    "\n",
    "Potential@3 = 0.7\n",
    "Potential@5 = 0.7\n",
    "Potential@10 = 0.9\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.2\n",
    "Accuracy@2@top_gold_1 = 0.4\n",
    "Accuracy@3@top_gold_1 = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70418a5d-5078-4352-adc1-20bb49f08eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surprisingly, bert-base performs better on the MAP@1 metric than bert-large!  on the other metrics, the results vary. Find out what this means and adapt approach accordingly!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06c1ddc-4d5b-4f11-a300-378b93c477f6",
   "metadata": {},
   "source": [
    "#### Substitute Generation with BERT-large, and Substitute Selection steps a-c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "142aceeb-93ee-40c0-88b8-e636a3c3c254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "SG step: generated substitutes: ['compulsory', 'mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden', 'permitted', 'prescribed', '##rricular', 'illegal', 'available', 'beneficial', 'prohibited', 'scheduled', 'obliged', 'tertiary', 'secondary', 'statutory', 'legal', 'free', 'used', 'customary', 'primary', 'authorised', 'canonical', 'standard', 'lawful']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['compulsory', 'mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden', 'permitted', 'prescribed', '##rricular', 'illegal', 'available', 'beneficial', 'prohibited', 'scheduled', 'obliged', 'tertiary', 'secondary', 'statutory', 'legal', 'free', 'used', 'customary', 'primary', 'authorised', 'canonical', 'standard', 'lawful']\n",
      "\n",
      "complex_word_lemma for complex word 'compulsory': compulsory\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden', 'permitted', 'prescribed', '##rricular', 'illegal', 'available', 'beneficial', 'prohibited', 'scheduled', 'obliged', 'tertiary', 'secondary', 'statutory', 'legal', 'free', 'used', 'customary', 'primary', 'authorised', 'canonical', 'standard', 'lawful']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden', 'permitted', 'prescribed', '##rricular', 'illegal', 'available', 'beneficial', 'prohibited', 'scheduled', 'obliged', 'tertiary', 'secondary', 'statutory', 'legal', 'free', 'used', 'customary', 'primary', 'authorised', 'canonical', 'standard', 'lawful']\n",
      "\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "SG step: generated substitutes: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed', 'impressed', 'fed', 'gifted', 'struck', 'furnished', 'inspired', 'fitted', 'equipped', 'raised', 'given', 'seeded', 'created', 'rewarded', 'hit', 'treated', 'introduced', 'encouraged', 'infected', 'tested', 'shaken', 'offered', 'filled']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed', 'impressed', 'fed', 'gifted', 'struck', 'furnished', 'inspired', 'fitted', 'equipped', 'raised', 'given', 'seeded', 'created', 'rewarded', 'hit', 'treated', 'introduced', 'encouraged', 'infected', 'tested', 'shaken', 'offered', 'filled']\n",
      "\n",
      "complex_word_lemma for complex word 'instilled': instill\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed', 'impressed', 'fed', 'gifted', 'struck', 'furnished', 'inspired', 'fitted', 'equipped', 'raised', 'given', 'seeded', 'created', 'rewarded', 'hit', 'treated', 'introduced', 'encouraged', 'infected', 'tested', 'shaken', 'offered', 'filled']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed', 'impressed', 'fed', 'gifted', 'struck', 'furnished', 'inspired', 'fitted', 'equipped', 'raised', 'given', 'seeded', 'created', 'rewarded', 'hit', 'treated', 'introduced', 'encouraged', 'infected', 'tested', 'shaken', 'offered', 'filled']\n",
      "\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "SG step: generated substitutes: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria', 'demons', 'gods', 'insects', 'sims', 'crimes', 'pigs', 'dogs', 'victims', 'organs', 'heroes', 'fans', 'fantasies', 'dolls', 'leaders', 'puppets', 'followers', '##atics', 'vampires', 'theorists', 'giants', 'children', 'lovers']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria', 'demons', 'gods', 'insects', 'sims', 'crimes', 'pigs', 'dogs', 'victims', 'organs', 'heroes', 'fans', 'fantasies', 'dolls', 'leaders', 'puppets', 'followers', '##atics', 'vampires', 'theorists', 'giants', 'children', 'lovers']\n",
      "\n",
      "complex_word_lemma for complex word 'maniacs': maniac\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria', 'demons', 'gods', 'insects', 'sims', 'crimes', 'pigs', 'dogs', 'victims', 'organs', 'heroes', 'fans', 'fantasies', 'dolls', 'leaders', 'puppets', 'followers', '##atics', 'vampires', 'theorists', 'giants', 'children', 'lovers']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria', 'demons', 'gods', 'insects', 'sims', 'crimes', 'pigs', 'dogs', 'victims', 'organs', 'heroes', 'fans', 'fantasies', 'dolls', 'leaders', 'puppets', 'followers', '##atics', 'vampires', 'theorists', 'giants', 'children', 'lovers']\n",
      "\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "SG step: generated substitutes: ['observers', 'observer', 'monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters', 'observation', '##keepers', 'experts', 'activists', 'casualties', 'volunteers', 'civilians', 'observing', 'people', 'citizens', 'combatants', 'observe', 'individuals', 'indicators', 'monitoring', 'troops', 'soldiers', 'victims', 'refugees', 'instruments']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['observers', 'observer', 'monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters', 'observation', '##keepers', 'experts', 'activists', 'casualties', 'volunteers', 'civilians', 'observing', 'people', 'citizens', 'combatants', 'observe', 'individuals', 'indicators', 'monitoring', 'troops', 'soldiers', 'victims', 'refugees', 'instruments']\n",
      "\n",
      "complex_word_lemma for complex word 'observers': observer\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters', 'observation', '##keepers', 'experts', 'activists', 'casualties', 'volunteers', 'civilians', 'observing', 'people', 'citizens', 'combatants', 'observe', 'individuals', 'indicators', 'monitoring', 'troops', 'soldiers', 'victims', 'refugees', 'instruments']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters', 'observation', '##keepers', 'experts', 'activists', 'casualties', 'volunteers', 'civilians', 'observing', 'people', 'citizens', 'combatants', 'observe', 'individuals', 'indicators', 'monitoring', 'troops', 'soldiers', 'victims', 'refugees', 'instruments']\n",
      "\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "SG step: generated substitutes: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor', 'blast', 'battle', 'three', 'splinter', 'shot', 'serious', 'exit', 'entry', 'shotgun', 'several', 'two', 'severe', 'shell', 'open', 'burn', 'bomb', 'penetrating', 'the', 'inflicted', 'stabbing', 'internal', 'fatal']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor', 'blast', 'battle', 'three', 'splinter', 'shot', 'serious', 'exit', 'entry', 'shotgun', 'several', 'two', 'severe', 'shell', 'open', 'burn', 'bomb', 'penetrating', 'the', 'inflicted', 'stabbing', 'internal', 'fatal']\n",
      "\n",
      "complex_word_lemma for complex word 'shrapnel': shrapnel\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor', 'blast', 'battle', 'three', 'splinter', 'shot', 'serious', 'exit', 'entry', 'shotgun', 'several', 'two', 'severe', 'shell', 'open', 'burn', 'bomb', 'penetrating', 'the', 'inflicted', 'stabbing', 'internal', 'fatal']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor', 'blast', 'battle', 'three', 'splinter', 'shot', 'serious', 'exit', 'entry', 'shotgun', 'several', 'two', 'severe', 'shell', 'open', 'burn', 'bomb', 'penetrating', 'the', 'inflicted', 'stabbing', 'internal', 'fatal']\n",
      "\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "SG step: generated substitutes: ['disguised', 'dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad', 'guise', 'hiding', 'draped', 'posing', 'appearing', ',', 'hidden', 'acting', 'dress', 'painted', 'seated', 'fitted', 'identified', 'covered', 'armed', 'appeared', 'cloak', 'armored', 'undercover', 'portrayed', 'depicted']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['disguised', 'dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad', 'guise', 'hiding', 'draped', 'posing', 'appearing', ',', 'hidden', 'acting', 'dress', 'painted', 'seated', 'fitted', 'identified', 'covered', 'armed', 'appeared', 'cloak', 'armored', 'undercover', 'portrayed', 'depicted']\n",
      "\n",
      "complex_word_lemma for complex word 'disguised': disguised\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad', 'guise', 'hiding', 'draped', 'posing', 'appearing', ',', 'hidden', 'acting', 'dress', 'painted', 'seated', 'fitted', 'identified', 'covered', 'armed', 'appeared', 'cloak', 'armored', 'undercover', 'portrayed', 'depicted']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad', 'guise', 'hiding', 'draped', 'posing', 'appearing', ',', 'hidden', 'acting', 'dress', 'painted', 'seated', 'fitted', 'identified', 'covered', 'armed', 'appeared', 'cloak', 'armored', 'undercover', 'portrayed', 'depicted']\n",
      "\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "SG step: generated substitutes: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy', 'aspect', 'enclave', 'heir', 'isolate', 'offspring', 'expression', 'orthodox', 'evolution', 'exception', 'example', 'sect', 'embrace', 'echo', 'approximation', 'adherence', 'adhere', 'adaptation', 'associate', 'issue', 'inhibitor', 'imitation', 'extreme']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy', 'aspect', 'enclave', 'heir', 'isolate', 'offspring', 'expression', 'orthodox', 'evolution', 'exception', 'example', 'sect', 'embrace', 'echo', 'approximation', 'adherence', 'adhere', 'adaptation', 'associate', 'issue', 'inhibitor', 'imitation', 'extreme']\n",
      "\n",
      "complex_word_lemma for complex word 'offshoot': offshoot\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy', 'aspect', 'enclave', 'heir', 'isolate', 'offspring', 'expression', 'orthodox', 'evolution', 'exception', 'example', 'sect', 'embrace', 'echo', 'approximation', 'adherence', 'adhere', 'adaptation', 'associate', 'issue', 'inhibitor', 'imitation', 'extreme']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy', 'aspect', 'enclave', 'heir', 'isolate', 'offspring', 'expression', 'orthodox', 'evolution', 'exception', 'example', 'sect', 'embrace', 'echo', 'approximation', 'adherence', 'adhere', 'adaptation', 'associate', 'issue', 'inhibitor', 'imitation', 'extreme']\n",
      "\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "SG step: generated substitutes: ['symphonic', 'orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata', 'operatic', 'piano', 'concert', 'chamber', 'music', 'orchestra', 'modern', 'lyrical', 'thematic', 'instrumental', 'continental', 'orchestrated', 'scholarly', 'dramatic', 'goldberg', 'romantic', 'standard', 'choral', 'poetic', 'comparative', 'written']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['symphonic', 'orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata', 'operatic', 'piano', 'concert', 'chamber', 'music', 'orchestra', 'modern', 'lyrical', 'thematic', 'instrumental', 'continental', 'orchestrated', 'scholarly', 'dramatic', 'goldberg', 'romantic', 'standard', 'choral', 'poetic', 'comparative', 'written']\n",
      "\n",
      "complex_word_lemma for complex word 'symphonic': symphonic\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata', 'operatic', 'piano', 'concert', 'chamber', 'music', 'orchestra', 'modern', 'lyrical', 'thematic', 'instrumental', 'continental', 'orchestrated', 'scholarly', 'dramatic', 'goldberg', 'romantic', 'standard', 'choral', 'poetic', 'comparative', 'written']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata', 'operatic', 'piano', 'concert', 'chamber', 'music', 'orchestra', 'modern', 'lyrical', 'thematic', 'instrumental', 'continental', 'orchestrated', 'scholarly', 'dramatic', 'goldberg', 'romantic', 'standard', 'choral', 'poetic', 'comparative', 'written']\n",
      "\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "SG step: generated substitutes: ['deploy', 'deployed', 'activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw', 'utilize', 'operate', 'employ', 'acquire', 'maintain', 'reinforce', 'exercise', 'install', 'build', 'move', 'drill', 'fire', 'construct', 'alert', 'dock', 'establish', 'release', 'outfit', 'station', 'ready']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['deploy', 'deployed', 'activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw', 'utilize', 'operate', 'employ', 'acquire', 'maintain', 'reinforce', 'exercise', 'install', 'build', 'move', 'drill', 'fire', 'construct', 'alert', 'dock', 'establish', 'release', 'outfit', 'station', 'ready']\n",
      "\n",
      "complex_word_lemma for complex word 'deploy': deploy\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw', 'utilize', 'operate', 'employ', 'acquire', 'maintain', 'reinforce', 'exercise', 'install', 'build', 'move', 'drill', 'fire', 'construct', 'alert', 'dock', 'establish', 'release', 'outfit', 'station', 'ready']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw', 'utilize', 'operate', 'employ', 'acquire', 'maintain', 'reinforce', 'exercise', 'install', 'build', 'move', 'drill', 'fire', 'construct', 'alert', 'dock', 'establish', 'release', 'outfit', 'station', 'ready']\n",
      "\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "SG step: generated substitutes: ['authorities', 'police', 'officials', '##s', 'magistrates', 'officers', 'forces', 'courts', 'authority', 'people', 'government', 'investigators', 'governments', 'victims', 'ministers', 'operators', 'bodies', 'judges', 'agencies', 'policemen', 'rulers', 'organisations', 'prosecutors', 'elements', 'offences', 'journalists', 'persons', 'subjects', 'residents', 'prisoners']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['authorities', 'police', 'officials', '##s', 'magistrates', 'officers', 'forces', 'courts', 'authority', 'people', 'government', 'investigators', 'governments', 'victims', 'ministers', 'operators', 'bodies', 'judges', 'agencies', 'policemen', 'rulers', 'organisations', 'prosecutors', 'elements', 'offences', 'journalists', 'persons', 'subjects', 'residents', 'prisoners']\n",
      "\n",
      "complex_word_lemma for complex word 'authorities': authority\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['police', 'officials', '##s', 'magistrates', 'officers', 'forces', 'courts', 'people', 'government', 'investigators', 'governments', 'victims', 'ministers', 'operators', 'bodies', 'judges', 'agencies', 'policemen', 'rulers', 'organisations', 'prosecutors', 'elements', 'offences', 'journalists', 'persons', 'subjects', 'residents', 'prisoners']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['police', 'officials', '##s', 'magistrates', 'officers', 'forces', 'courts', 'people', 'government', 'investigators', 'governments', 'victims', 'ministers', 'operators', 'bodies', 'judges', 'agencies', 'policemen', 'rulers', 'organisations', 'prosecutors', 'elements', 'offences', 'journalists', 'persons', 'subjects', 'residents', 'prisoners']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"[MASK]\")\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    tokenizer = fill_mask.tokenizer\n",
    "    sentences_concat = f\"{sentence} {tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes = [substitute[\"token_str\"].lower() for substitute in result]\n",
    "    print(f\"SG step: generated substitutes: {substitutes}\\n\")\n",
    "    \n",
    "    # 2. Substitute Selection (SS):   \n",
    "    \n",
    "    # a) remove duplicates within the substitute list from the substitute list \n",
    "    \n",
    "    # create a punctuation set without hyphen, in order to retain hyphens in compound substitutes\n",
    "    punctuation_without_hyphen = set(string.punctuation) - set('-')\n",
    "    \n",
    "    # a) remove duplicates and unwanted punctuation within the substitute list from the substitute list\n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl and not any(char in punctuation_without_hyphen for char in sub):\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    print(f\"SS step: a) substitute list without duplicates and undesired punctuation: {substitutes_no_dupl}\\n\")\n",
    "    \n",
    "\n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    print(f\"SS step: b) substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    print(f\"SS step: c): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "    \n",
    "     \n",
    "    \n",
    "    # limit the substitutes to the 10 first ones for evaluation\n",
    "    top_10_substitutes = substitutes_no_dupl_complex_word_no_antonym[:10]\n",
    "    \n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + top_10_substitutes\n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the dataframe\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/BertLarge_SG_SS_abc.tsv\", sep=\"\\t\", index=False, header=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f63df5-9984-486d-acde-c4577ef905a9",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file ./predictions/trial/BertLarge_SG_SS_abc.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c5430a3-a50e-4b3a-a1cf-7acc5dceb13a",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/BertLarge_SG_SS_abc.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.4\n",
    "\n",
    "MAP@3 = 0.3111\n",
    "MAP@5 = 0.2106\n",
    "MAP@10 = 0.1343\n",
    "\n",
    "Potential@3 = 0.7\n",
    "Potential@5 = 0.8\n",
    "Potential@10 = 0.9\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.2\n",
    "Accuracy@2@top_gold_1 = 0.4\n",
    "Accuracy@3@top_gold_1 = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163e817e-33d4-4f44-aa1f-d7f417845789",
   "metadata": {},
   "source": [
    "Slightly better results on all Map metrics, except for Map@1 (the same).  and on Potential @5. rest is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e2839f-8d4a-47c4-a77c-ce5b25900722",
   "metadata": {},
   "source": [
    "#### Substitute Generation with BERT-large, and Substitute Selection steps a-c, and the resulting list with FitBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc8cb0a4-d6b7-4286-90d2-b1db81bc722f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "using custom model: ['BertForMaskedLM']\n",
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "SG step: generated substitutes: ['compulsory', 'mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden', 'permitted', 'prescribed', '##rricular', 'illegal', 'available', 'beneficial', 'prohibited', 'scheduled', 'obliged', 'tertiary', 'secondary', 'statutory', 'legal', 'free', 'used', 'customary', 'primary', 'authorised', 'canonical', 'standard', 'lawful']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['compulsory', 'mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden', 'permitted', 'prescribed', '##rricular', 'illegal', 'available', 'beneficial', 'prohibited', 'scheduled', 'obliged', 'tertiary', 'secondary', 'statutory', 'legal', 'free', 'used', 'customary', 'primary', 'authorised', 'canonical', 'standard', 'lawful']\n",
      "\n",
      "complex_word_lemma for complex word 'compulsory': compulsory\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden', 'permitted', 'prescribed', '##rricular', 'illegal', 'available', 'beneficial', 'prohibited', 'scheduled', 'obliged', 'tertiary', 'secondary', 'statutory', 'legal', 'free', 'used', 'customary', 'primary', 'authorised', 'canonical', 'standard', 'lawful']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden', 'permitted', 'prescribed', '##rricular', 'illegal', 'available', 'beneficial', 'prohibited', 'scheduled', 'obliged', 'tertiary', 'secondary', 'statutory', 'legal', 'free', 'used', 'customary', 'primary', 'authorised', 'canonical', 'standard', 'lawful']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden', 'permitted', 'prescribed', 'illegal', 'available', 'beneficial', 'prohibited', 'scheduled', 'obliged', 'tertiary', 'secondary', 'statutory', 'legal', 'free', 'used', 'customary', 'primary', 'authorised', 'canonical', 'standard', 'lawful', '##rricular']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "SG step: generated substitutes: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed', 'impressed', 'fed', 'gifted', 'struck', 'furnished', 'inspired', 'fitted', 'equipped', 'raised', 'given', 'seeded', 'created', 'rewarded', 'hit', 'treated', 'introduced', 'encouraged', 'infected', 'tested', 'shaken', 'offered', 'filled']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed', 'impressed', 'fed', 'gifted', 'struck', 'furnished', 'inspired', 'fitted', 'equipped', 'raised', 'given', 'seeded', 'created', 'rewarded', 'hit', 'treated', 'introduced', 'encouraged', 'infected', 'tested', 'shaken', 'offered', 'filled']\n",
      "\n",
      "complex_word_lemma for complex word 'instilled': instill\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed', 'impressed', 'fed', 'gifted', 'struck', 'furnished', 'inspired', 'fitted', 'equipped', 'raised', 'given', 'seeded', 'created', 'rewarded', 'hit', 'treated', 'introduced', 'encouraged', 'infected', 'tested', 'shaken', 'offered', 'filled']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed', 'impressed', 'fed', 'gifted', 'struck', 'furnished', 'inspired', 'fitted', 'equipped', 'raised', 'given', 'seeded', 'created', 'rewarded', 'hit', 'treated', 'introduced', 'encouraged', 'infected', 'tested', 'shaken', 'offered', 'filled']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed', 'impressed', 'fed', 'gifted', 'struck', 'furnished', 'inspired', 'fitted', 'equipped', 'raised', 'given', 'seeded', 'created', 'rewarded', 'hit', 'treated', 'introduced', 'encouraged', 'infected', 'tested', 'shaken', 'offered', 'filled']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "SG step: generated substitutes: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria', 'demons', 'gods', 'insects', 'sims', 'crimes', 'pigs', 'dogs', 'victims', 'organs', 'heroes', 'fans', 'fantasies', 'dolls', 'leaders', 'puppets', 'followers', '##atics', 'vampires', 'theorists', 'giants', 'children', 'lovers']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria', 'demons', 'gods', 'insects', 'sims', 'crimes', 'pigs', 'dogs', 'victims', 'organs', 'heroes', 'fans', 'fantasies', 'dolls', 'leaders', 'puppets', 'followers', '##atics', 'vampires', 'theorists', 'giants', 'children', 'lovers']\n",
      "\n",
      "complex_word_lemma for complex word 'maniacs': maniac\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria', 'demons', 'gods', 'insects', 'sims', 'crimes', 'pigs', 'dogs', 'victims', 'organs', 'heroes', 'fans', 'fantasies', 'dolls', 'leaders', 'puppets', 'followers', '##atics', 'vampires', 'theorists', 'giants', 'children', 'lovers']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria', 'demons', 'gods', 'insects', 'sims', 'crimes', 'pigs', 'dogs', 'victims', 'organs', 'heroes', 'fans', 'fantasies', 'dolls', 'leaders', 'puppets', 'followers', '##atics', 'vampires', 'theorists', 'giants', 'children', 'lovers']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria', 'demons', 'gods', 'insects', 'sims', 'crimes', 'pigs', 'dogs', 'victims', 'organs', 'heroes', 'fans', 'fantasies', 'dolls', 'leaders', 'puppets', 'followers', 'vampires', 'theorists', 'giants', 'children', 'lovers', '##atics']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "SG step: generated substitutes: ['observers', 'observer', 'monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters', 'observation', '##keepers', 'experts', 'activists', 'casualties', 'volunteers', 'civilians', 'observing', 'people', 'citizens', 'combatants', 'observe', 'individuals', 'indicators', 'monitoring', 'troops', 'soldiers', 'victims', 'refugees', 'instruments']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['observers', 'observer', 'monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters', 'observation', '##keepers', 'experts', 'activists', 'casualties', 'volunteers', 'civilians', 'observing', 'people', 'citizens', 'combatants', 'observe', 'individuals', 'indicators', 'monitoring', 'troops', 'soldiers', 'victims', 'refugees', 'instruments']\n",
      "\n",
      "complex_word_lemma for complex word 'observers': observer\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters', 'observation', '##keepers', 'experts', 'activists', 'casualties', 'volunteers', 'civilians', 'observing', 'people', 'citizens', 'combatants', 'observe', 'individuals', 'indicators', 'monitoring', 'troops', 'soldiers', 'victims', 'refugees', 'instruments']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters', 'observation', '##keepers', 'experts', 'activists', 'casualties', 'volunteers', 'civilians', 'observing', 'people', 'citizens', 'combatants', 'observe', 'individuals', 'indicators', 'monitoring', 'troops', 'soldiers', 'victims', 'refugees', 'instruments']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters', 'observation', 'experts', 'activists', 'casualties', 'volunteers', 'civilians', 'observing', 'people', 'citizens', 'combatants', 'observe', 'individuals', 'indicators', 'monitoring', 'troops', 'soldiers', 'victims', 'refugees', 'instruments', '##keepers']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "SG step: generated substitutes: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor', 'blast', 'battle', 'three', 'splinter', 'shot', 'serious', 'exit', 'entry', 'shotgun', 'several', 'two', 'severe', 'shell', 'open', 'burn', 'bomb', 'penetrating', 'the', 'inflicted', 'stabbing', 'internal', 'fatal']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor', 'blast', 'battle', 'three', 'splinter', 'shot', 'serious', 'exit', 'entry', 'shotgun', 'several', 'two', 'severe', 'shell', 'open', 'burn', 'bomb', 'penetrating', 'the', 'inflicted', 'stabbing', 'internal', 'fatal']\n",
      "\n",
      "complex_word_lemma for complex word 'shrapnel': shrapnel\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor', 'blast', 'battle', 'three', 'splinter', 'shot', 'serious', 'exit', 'entry', 'shotgun', 'several', 'two', 'severe', 'shell', 'open', 'burn', 'bomb', 'penetrating', 'the', 'inflicted', 'stabbing', 'internal', 'fatal']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor', 'blast', 'battle', 'three', 'splinter', 'shot', 'serious', 'exit', 'entry', 'shotgun', 'several', 'two', 'severe', 'shell', 'open', 'burn', 'bomb', 'penetrating', 'the', 'inflicted', 'stabbing', 'internal', 'fatal']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor', 'blast', 'battle', 'three', 'splinter', 'shot', 'serious', 'exit', 'entry', 'shotgun', 'several', 'two', 'severe', 'shell', 'open', 'burn', 'bomb', 'penetrating', 'the', 'inflicted', 'stabbing', 'internal', 'fatal']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "SG step: generated substitutes: ['disguised', 'dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad', 'guise', 'hiding', 'draped', 'posing', 'appearing', ',', 'hidden', 'acting', 'dress', 'painted', 'seated', 'fitted', 'identified', 'covered', 'armed', 'appeared', 'cloak', 'armored', 'undercover', 'portrayed', 'depicted']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['disguised', 'dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad', 'guise', 'hiding', 'draped', 'posing', 'appearing', ',', 'hidden', 'acting', 'dress', 'painted', 'seated', 'fitted', 'identified', 'covered', 'armed', 'appeared', 'cloak', 'armored', 'undercover', 'portrayed', 'depicted']\n",
      "\n",
      "complex_word_lemma for complex word 'disguised': disguised\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad', 'guise', 'hiding', 'draped', 'posing', 'appearing', ',', 'hidden', 'acting', 'dress', 'painted', 'seated', 'fitted', 'identified', 'covered', 'armed', 'appeared', 'cloak', 'armored', 'undercover', 'portrayed', 'depicted']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad', 'guise', 'hiding', 'draped', 'posing', 'appearing', ',', 'hidden', 'acting', 'dress', 'painted', 'seated', 'fitted', 'identified', 'covered', 'armed', 'appeared', 'cloak', 'armored', 'undercover', 'portrayed', 'depicted']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad', 'guise', 'hiding', 'draped', 'posing', 'appearing', ',', 'hidden', 'acting', 'dress', 'painted', 'seated', 'fitted', 'identified', 'covered', 'armed', 'appeared', 'cloak', 'armored', 'undercover', 'portrayed', 'depicted']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "SG step: generated substitutes: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy', 'aspect', 'enclave', 'heir', 'isolate', 'offspring', 'expression', 'orthodox', 'evolution', 'exception', 'example', 'sect', 'embrace', 'echo', 'approximation', 'adherence', 'adhere', 'adaptation', 'associate', 'issue', 'inhibitor', 'imitation', 'extreme']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy', 'aspect', 'enclave', 'heir', 'isolate', 'offspring', 'expression', 'orthodox', 'evolution', 'exception', 'example', 'sect', 'embrace', 'echo', 'approximation', 'adherence', 'adhere', 'adaptation', 'associate', 'issue', 'inhibitor', 'imitation', 'extreme']\n",
      "\n",
      "complex_word_lemma for complex word 'offshoot': offshoot\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy', 'aspect', 'enclave', 'heir', 'isolate', 'offspring', 'expression', 'orthodox', 'evolution', 'exception', 'example', 'sect', 'embrace', 'echo', 'approximation', 'adherence', 'adhere', 'adaptation', 'associate', 'issue', 'inhibitor', 'imitation', 'extreme']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy', 'aspect', 'enclave', 'heir', 'isolate', 'offspring', 'expression', 'orthodox', 'evolution', 'exception', 'example', 'sect', 'embrace', 'echo', 'approximation', 'adherence', 'adhere', 'adaptation', 'associate', 'issue', 'inhibitor', 'imitation', 'extreme']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy', 'aspect', 'enclave', 'heir', 'isolate', 'offspring', 'expression', 'orthodox', 'evolution', 'exception', 'example', 'sect', 'embrace', 'echo', 'approximation', 'adherence', 'adhere', 'adaptation', 'associate', 'issue', 'inhibitor', 'imitation', 'extreme']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "SG step: generated substitutes: ['symphonic', 'orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata', 'operatic', 'piano', 'concert', 'chamber', 'music', 'orchestra', 'modern', 'lyrical', 'thematic', 'instrumental', 'continental', 'orchestrated', 'scholarly', 'dramatic', 'goldberg', 'romantic', 'standard', 'choral', 'poetic', 'comparative', 'written']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['symphonic', 'orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata', 'operatic', 'piano', 'concert', 'chamber', 'music', 'orchestra', 'modern', 'lyrical', 'thematic', 'instrumental', 'continental', 'orchestrated', 'scholarly', 'dramatic', 'goldberg', 'romantic', 'standard', 'choral', 'poetic', 'comparative', 'written']\n",
      "\n",
      "complex_word_lemma for complex word 'symphonic': symphonic\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata', 'operatic', 'piano', 'concert', 'chamber', 'music', 'orchestra', 'modern', 'lyrical', 'thematic', 'instrumental', 'continental', 'orchestrated', 'scholarly', 'dramatic', 'goldberg', 'romantic', 'standard', 'choral', 'poetic', 'comparative', 'written']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata', 'operatic', 'piano', 'concert', 'chamber', 'music', 'orchestra', 'modern', 'lyrical', 'thematic', 'instrumental', 'continental', 'orchestrated', 'scholarly', 'dramatic', 'goldberg', 'romantic', 'standard', 'choral', 'poetic', 'comparative', 'written']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata', 'operatic', 'piano', 'concert', 'chamber', 'music', 'orchestra', 'modern', 'lyrical', 'thematic', 'instrumental', 'continental', 'orchestrated', 'scholarly', 'dramatic', 'goldberg', 'romantic', 'standard', 'choral', 'poetic', 'comparative', 'written']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "SG step: generated substitutes: ['deploy', 'deployed', 'activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw', 'utilize', 'operate', 'employ', 'acquire', 'maintain', 'reinforce', 'exercise', 'install', 'build', 'move', 'drill', 'fire', 'construct', 'alert', 'dock', 'establish', 'release', 'outfit', 'station', 'ready']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['deploy', 'deployed', 'activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw', 'utilize', 'operate', 'employ', 'acquire', 'maintain', 'reinforce', 'exercise', 'install', 'build', 'move', 'drill', 'fire', 'construct', 'alert', 'dock', 'establish', 'release', 'outfit', 'station', 'ready']\n",
      "\n",
      "complex_word_lemma for complex word 'deploy': deploy\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw', 'utilize', 'operate', 'employ', 'acquire', 'maintain', 'reinforce', 'exercise', 'install', 'build', 'move', 'drill', 'fire', 'construct', 'alert', 'dock', 'establish', 'release', 'outfit', 'station', 'ready']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw', 'utilize', 'operate', 'employ', 'acquire', 'maintain', 'reinforce', 'exercise', 'install', 'build', 'move', 'drill', 'fire', 'construct', 'alert', 'dock', 'establish', 'release', 'outfit', 'station', 'ready']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw', 'utilize', 'operate', 'employ', 'acquire', 'maintain', 'reinforce', 'exercise', 'install', 'build', 'move', 'drill', 'fire', 'construct', 'alert', 'dock', 'establish', 'release', 'outfit', 'station', 'ready']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "SG step: generated substitutes: ['authorities', 'police', 'officials', '##s', 'magistrates', 'officers', 'forces', 'courts', 'authority', 'people', 'government', 'investigators', 'governments', 'victims', 'ministers', 'operators', 'bodies', 'judges', 'agencies', 'policemen', 'rulers', 'organisations', 'prosecutors', 'elements', 'offences', 'journalists', 'persons', 'subjects', 'residents', 'prisoners']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['authorities', 'police', 'officials', '##s', 'magistrates', 'officers', 'forces', 'courts', 'authority', 'people', 'government', 'investigators', 'governments', 'victims', 'ministers', 'operators', 'bodies', 'judges', 'agencies', 'policemen', 'rulers', 'organisations', 'prosecutors', 'elements', 'offences', 'journalists', 'persons', 'subjects', 'residents', 'prisoners']\n",
      "\n",
      "complex_word_lemma for complex word 'authorities': authority\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['police', 'officials', '##s', 'magistrates', 'officers', 'forces', 'courts', 'people', 'government', 'investigators', 'governments', 'victims', 'ministers', 'operators', 'bodies', 'judges', 'agencies', 'policemen', 'rulers', 'organisations', 'prosecutors', 'elements', 'offences', 'journalists', 'persons', 'subjects', 'residents', 'prisoners']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['police', 'officials', '##s', 'magistrates', 'officers', 'forces', 'courts', 'people', 'government', 'investigators', 'governments', 'victims', 'ministers', 'operators', 'bodies', 'judges', 'agencies', 'policemen', 'rulers', 'organisations', 'prosecutors', 'elements', 'offences', 'journalists', 'persons', 'subjects', 'residents', 'prisoners']\n",
      "\n",
      "SS step: d) ranked substitutes using FitBert: ['police', 'officials', 'magistrates', 'officers', 'forces', 'courts', 'people', 'government', 'investigators', 'governments', 'victims', 'ministers', 'operators', 'bodies', 'judges', 'agencies', 'policemen', 'rulers', 'organisations', 'prosecutors', 'elements', 'offences', 'journalists', 'persons', 'subjects', 'residents', 'prisoners', '##s']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# instantiate a FitBert model\n",
    "fb_model = FitBert(lm_model)\n",
    "\n",
    "\n",
    "\n",
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"[MASK]\")\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    tokenizer = fill_mask.tokenizer\n",
    "    sentences_concat = f\"{sentence} {tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes = [substitute[\"token_str\"].lower() for substitute in result]\n",
    "    print(f\"SG step: generated substitutes: {substitutes}\\n\")\n",
    "    \n",
    "    # 2. Substitute Selection (SS):   \n",
    "    \n",
    "     # create a punctuation set without hyphen, in order to retain hyphens in compound substitutes\n",
    "    punctuation_without_hyphen = set(string.punctuation) - set('-')\n",
    "    \n",
    "    # a) remove duplicates and unwanted punctuation within the substitute list from the substitute list\n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl and not any(char in punctuation_without_hyphen for char in sub):\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    print(f\"SS step: a) substitute list without duplicates and undesired punctuation: {substitutes_no_dupl}\\n\")\n",
    "    \n",
    "\n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    print(f\"SS step: b) substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    print(f\"SS step: c): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "    \n",
    "    \n",
    "    # d) apply FITBERT to the list of substitutes\n",
    "    sentence_fitbert_masked = sentence_masked_word.replace(\"[MASK]\", \"***mask***\")\n",
    "    sentences_concat_fitbert = f\"{sentence} {tokenizer.sep_token} {sentence_fitbert_masked}\"\n",
    "    \n",
    "    ranked_substitutes = fb_model.rank(sentences_concat_fitbert, substitutes_no_dupl_complex_word_no_antonym)\n",
    "    print(f\"SS step: d) ranked substitutes using FitBert: {ranked_substitutes}\\n\")\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------------------')\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # limit the substitutes to the 10 first ones for evaluation\n",
    "    top_10_substitutes = ranked_substitutes[:10]\n",
    "    \n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + top_10_substitutes\n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the dataframe\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/BertLarge_SG_SS_abc_fb.tsv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b640062b-1358-4081-af87-c2fa6c4af3ba",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file ./predictions/trial/BertLarge_SG_SS_abc_fb.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4464f32-8d9a-40c9-ac81-9c5eae9ea7c8",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/BertLarge_SG_SS_abc_fb.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.4\n",
    "\n",
    "MAP@3 = 0.3111\n",
    "MAP@5 = 0.2136\n",
    "MAP@10 = 0.1364\n",
    "\n",
    "Potential@3 = 0.7\n",
    "Potential@5 = 0.8\n",
    "Potential@10 = 0.9\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.2\n",
    "Accuracy@2@top_gold_1 = 0.4\n",
    "Accuracy@3@top_gold_1 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f3a61d8-2cfc-437a-a7de-e44f0d5586cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardly changed, only a very tiny bit better on map@5 and map@10 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fe0e88-bb89-4a27-b668-72036c4abd28",
   "metadata": {},
   "source": [
    "#### Substitute Generation with BERT-large, and Substitute Selection steps a-c, and the resulting list with contextualized embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69a0ff52-f8d3-43b4-b482-be631d39c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bba05efd-80b0-4e42-9b27-5742b22bc4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "SG step: generated substitutes: ['compulsory', 'mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden', 'permitted', 'prescribed', '##rricular', 'illegal', 'available', 'beneficial', 'prohibited', 'scheduled', 'obliged', 'tertiary', 'secondary', 'statutory', 'legal', 'free', 'used', 'customary', 'primary', 'authorised', 'canonical', 'standard', 'lawful']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['compulsory', 'mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden', 'permitted', 'prescribed', '##rricular', 'illegal', 'available', 'beneficial', 'prohibited', 'scheduled', 'obliged', 'tertiary', 'secondary', 'statutory', 'legal', 'free', 'used', 'customary', 'primary', 'authorised', 'canonical', 'standard', 'lawful']\n",
      "\n",
      "complex_word_lemma for complex word 'compulsory': compulsory\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden', 'permitted', 'prescribed', '##rricular', 'illegal', 'available', 'beneficial', 'prohibited', 'scheduled', 'obliged', 'tertiary', 'secondary', 'statutory', 'legal', 'free', 'used', 'customary', 'primary', 'authorised', 'canonical', 'standard', 'lawful']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden', 'permitted', 'prescribed', '##rricular', 'illegal', 'available', 'beneficial', 'prohibited', 'scheduled', 'obliged', 'tertiary', 'secondary', 'statutory', 'legal', 'free', 'used', 'customary', 'primary', 'authorised', 'canonical', 'standard', 'lawful']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step d) Ranked substitutes, based on cosine similarity scores in context: ['obligatory', 'forbidden', 'voluntary', 'legal', 'secondary', 'statutory', 'primary', 'mandatory', 'authorised', 'necessary', 'illegal', 'free', 'available', 'scheduled', 'lawful', 'obliged', 'standard', 'prescribed', 'used', 'beneficial', 'prohibited', 'mandated', 'permitted', 'required', 'optional', 'customary', 'tertiary', 'canonical', '##rricular']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "SG step: generated substitutes: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed', 'impressed', 'fed', 'gifted', 'struck', 'furnished', 'inspired', 'fitted', 'equipped', 'raised', 'given', 'seeded', 'created', 'rewarded', 'hit', 'treated', 'introduced', 'encouraged', 'infected', 'tested', 'shaken', 'offered', 'filled']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed', 'impressed', 'fed', 'gifted', 'struck', 'furnished', 'inspired', 'fitted', 'equipped', 'raised', 'given', 'seeded', 'created', 'rewarded', 'hit', 'treated', 'introduced', 'encouraged', 'infected', 'tested', 'shaken', 'offered', 'filled']\n",
      "\n",
      "complex_word_lemma for complex word 'instilled': instill\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed', 'impressed', 'fed', 'gifted', 'struck', 'furnished', 'inspired', 'fitted', 'equipped', 'raised', 'given', 'seeded', 'created', 'rewarded', 'hit', 'treated', 'introduced', 'encouraged', 'infected', 'tested', 'shaken', 'offered', 'filled']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed', 'impressed', 'fed', 'gifted', 'struck', 'furnished', 'inspired', 'fitted', 'equipped', 'raised', 'given', 'seeded', 'created', 'rewarded', 'hit', 'treated', 'introduced', 'encouraged', 'infected', 'tested', 'shaken', 'offered', 'filled']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step d) Ranked substitutes, based on cosine similarity scores in context: ['infused', 'filled', 'injected', 'fitted', 'delivered', 'seeded', 'equipped', 'infected', 'left', 'created', 'fed', 'tested', 'gifted', 'encouraged', 'given', 'inspired', 'raised', 'impressed', 'shaken', 'endowed', 'introduced', 'hit', 'supplied', 'treated', 'offered', 'struck', 'provided', 'rewarded', 'furnished', 'presented']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "SG step: generated substitutes: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria', 'demons', 'gods', 'insects', 'sims', 'crimes', 'pigs', 'dogs', 'victims', 'organs', 'heroes', 'fans', 'fantasies', 'dolls', 'leaders', 'puppets', 'followers', '##atics', 'vampires', 'theorists', 'giants', 'children', 'lovers']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria', 'demons', 'gods', 'insects', 'sims', 'crimes', 'pigs', 'dogs', 'victims', 'organs', 'heroes', 'fans', 'fantasies', 'dolls', 'leaders', 'puppets', 'followers', '##atics', 'vampires', 'theorists', 'giants', 'children', 'lovers']\n",
      "\n",
      "complex_word_lemma for complex word 'maniacs': maniac\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria', 'demons', 'gods', 'insects', 'sims', 'crimes', 'pigs', 'dogs', 'victims', 'organs', 'heroes', 'fans', 'fantasies', 'dolls', 'leaders', 'puppets', 'followers', '##atics', 'vampires', 'theorists', 'giants', 'children', 'lovers']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria', 'demons', 'gods', 'insects', 'sims', 'crimes', 'pigs', 'dogs', 'victims', 'organs', 'heroes', 'fans', 'fantasies', 'dolls', 'leaders', 'puppets', 'followers', '##atics', 'vampires', 'theorists', 'giants', 'children', 'lovers']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step d) Ranked substitutes, based on cosine similarity scores in context: ['monsters', 'demons', 'insects', 'vampires', 'zombies', 'freaks', 'dogs', 'pigs', 'gods', 'lovers', 'fantasies', 'dolls', 'mania', 'giants', 'sims', 'leaders', 'machines', 'fans', 'hysteria', 'followers', 'children', 'puppets', 'organs', 'heroes', 'victims', 'killers', 'theorists', 'criminals', 'crimes', '##atics']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "SG step: generated substitutes: ['observers', 'observer', 'monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters', 'observation', '##keepers', 'experts', 'activists', 'casualties', 'volunteers', 'civilians', 'observing', 'people', 'citizens', 'combatants', 'observe', 'individuals', 'indicators', 'monitoring', 'troops', 'soldiers', 'victims', 'refugees', 'instruments']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['observers', 'observer', 'monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters', 'observation', '##keepers', 'experts', 'activists', 'casualties', 'volunteers', 'civilians', 'observing', 'people', 'citizens', 'combatants', 'observe', 'individuals', 'indicators', 'monitoring', 'troops', 'soldiers', 'victims', 'refugees', 'instruments']\n",
      "\n",
      "complex_word_lemma for complex word 'observers': observer\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters', 'observation', '##keepers', 'experts', 'activists', 'casualties', 'volunteers', 'civilians', 'observing', 'people', 'citizens', 'combatants', 'observe', 'individuals', 'indicators', 'monitoring', 'troops', 'soldiers', 'victims', 'refugees', 'instruments']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters', 'observation', '##keepers', 'experts', 'activists', 'casualties', 'volunteers', 'civilians', 'observing', 'people', 'citizens', 'combatants', 'observe', 'individuals', 'indicators', 'monitoring', 'troops', 'soldiers', 'victims', 'refugees', 'instruments']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step d) Ranked substitutes, based on cosine similarity scores in context: ['monitoring', 'observation', 'troops', 'monitors', 'soldiers', 'analysts', 'experts', 'victims', 'casualties', 'observations', 'refugees', 'fighters', 'observing', 'civilians', 'volunteers', 'individuals', 'observe', 'indicators', 'participants', 'journalists', 'people', 'combatants', 'citizens', 'witnesses', 'instruments', 'activists', '##keepers', 'spectators']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "SG step: generated substitutes: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor', 'blast', 'battle', 'three', 'splinter', 'shot', 'serious', 'exit', 'entry', 'shotgun', 'several', 'two', 'severe', 'shell', 'open', 'burn', 'bomb', 'penetrating', 'the', 'inflicted', 'stabbing', 'internal', 'fatal']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor', 'blast', 'battle', 'three', 'splinter', 'shot', 'serious', 'exit', 'entry', 'shotgun', 'several', 'two', 'severe', 'shell', 'open', 'burn', 'bomb', 'penetrating', 'the', 'inflicted', 'stabbing', 'internal', 'fatal']\n",
      "\n",
      "complex_word_lemma for complex word 'shrapnel': shrapnel\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor', 'blast', 'battle', 'three', 'splinter', 'shot', 'serious', 'exit', 'entry', 'shotgun', 'several', 'two', 'severe', 'shell', 'open', 'burn', 'bomb', 'penetrating', 'the', 'inflicted', 'stabbing', 'internal', 'fatal']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor', 'blast', 'battle', 'three', 'splinter', 'shot', 'serious', 'exit', 'entry', 'shotgun', 'several', 'two', 'severe', 'shell', 'open', 'burn', 'bomb', 'penetrating', 'the', 'inflicted', 'stabbing', 'internal', 'fatal']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step d) Ranked substitutes, based on cosine similarity scores in context: ['bullet', 'blast', 'arrow', 'serious', 'fatal', 'severe', 'penetrating', 'multiple', 'splinter', 'flesh', 'shotgun', 'gunshot', 'two', 'stabbing', 'several', 'battle', 'inflicted', 'three', 'minor', 'entry', 'exit', 'shot', 'burn', 'open', 'internal', 'knife', 'the', 'stab', 'shell', 'bomb']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "SG step: generated substitutes: ['disguised', 'dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad', 'guise', 'hiding', 'draped', 'posing', 'appearing', ',', 'hidden', 'acting', 'dress', 'painted', 'seated', 'fitted', 'identified', 'covered', 'armed', 'appeared', 'cloak', 'armored', 'undercover', 'portrayed', 'depicted']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['disguised', 'dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad', 'guise', 'hiding', 'draped', 'posing', 'appearing', ',', 'hidden', 'acting', 'dress', 'painted', 'seated', 'fitted', 'identified', 'covered', 'armed', 'appeared', 'cloak', 'armored', 'undercover', 'portrayed', 'depicted']\n",
      "\n",
      "complex_word_lemma for complex word 'disguised': disguised\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad', 'guise', 'hiding', 'draped', 'posing', 'appearing', ',', 'hidden', 'acting', 'dress', 'painted', 'seated', 'fitted', 'identified', 'covered', 'armed', 'appeared', 'cloak', 'armored', 'undercover', 'portrayed', 'depicted']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad', 'guise', 'hiding', 'draped', 'posing', 'appearing', ',', 'hidden', 'acting', 'dress', 'painted', 'seated', 'fitted', 'identified', 'covered', 'armed', 'appeared', 'cloak', 'armored', 'undercover', 'portrayed', 'depicted']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step d) Ranked substitutes, based on cosine similarity scores in context: ['masked', 'dressed', 'clad', 'covered', 'armed', 'hiding', 'draped', 'posing', 'dressing', 'concealed', 'hidden', 'acting', 'clothed', 'armored', 'undercover', 'seated', 'armoured', ',', 'portrayed', 'appearing', 'disguise', 'depicted', 'cloak', 'painted', 'fitted', 'dress', 'appeared', 'guise', 'identified']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "SG step: generated substitutes: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy', 'aspect', 'enclave', 'heir', 'isolate', 'offspring', 'expression', 'orthodox', 'evolution', 'exception', 'example', 'sect', 'embrace', 'echo', 'approximation', 'adherence', 'adhere', 'adaptation', 'associate', 'issue', 'inhibitor', 'imitation', 'extreme']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy', 'aspect', 'enclave', 'heir', 'isolate', 'offspring', 'expression', 'orthodox', 'evolution', 'exception', 'example', 'sect', 'embrace', 'echo', 'approximation', 'adherence', 'adhere', 'adaptation', 'associate', 'issue', 'inhibitor', 'imitation', 'extreme']\n",
      "\n",
      "complex_word_lemma for complex word 'offshoot': offshoot\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy', 'aspect', 'enclave', 'heir', 'isolate', 'offspring', 'expression', 'orthodox', 'evolution', 'exception', 'example', 'sect', 'embrace', 'echo', 'approximation', 'adherence', 'adhere', 'adaptation', 'associate', 'issue', 'inhibitor', 'imitation', 'extreme']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy', 'aspect', 'enclave', 'heir', 'isolate', 'offspring', 'expression', 'orthodox', 'evolution', 'exception', 'example', 'sect', 'embrace', 'echo', 'approximation', 'adherence', 'adhere', 'adaptation', 'associate', 'issue', 'inhibitor', 'imitation', 'extreme']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step d) Ranked substitutes, based on cosine similarity scores in context: ['extension', 'echo', 'arm', 'aspect', 'adhere', 'outpost', 'affiliate', 'heir', 'extreme', 'isolate', 'expression', 'imitation', 'adaptation', 'associate', 'evolution', 'offspring', 'approximation', 'element', 'adherence', 'inhibitor', 'ally', 'opponent', 'orthodox', 'enemy', 'enclave', 'embrace', 'sect', 'example', 'issue', 'exception']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "SG step: generated substitutes: ['symphonic', 'orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata', 'operatic', 'piano', 'concert', 'chamber', 'music', 'orchestra', 'modern', 'lyrical', 'thematic', 'instrumental', 'continental', 'orchestrated', 'scholarly', 'dramatic', 'goldberg', 'romantic', 'standard', 'choral', 'poetic', 'comparative', 'written']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['symphonic', 'orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata', 'operatic', 'piano', 'concert', 'chamber', 'music', 'orchestra', 'modern', 'lyrical', 'thematic', 'instrumental', 'continental', 'orchestrated', 'scholarly', 'dramatic', 'goldberg', 'romantic', 'standard', 'choral', 'poetic', 'comparative', 'written']\n",
      "\n",
      "complex_word_lemma for complex word 'symphonic': symphonic\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata', 'operatic', 'piano', 'concert', 'chamber', 'music', 'orchestra', 'modern', 'lyrical', 'thematic', 'instrumental', 'continental', 'orchestrated', 'scholarly', 'dramatic', 'goldberg', 'romantic', 'standard', 'choral', 'poetic', 'comparative', 'written']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata', 'operatic', 'piano', 'concert', 'chamber', 'music', 'orchestra', 'modern', 'lyrical', 'thematic', 'instrumental', 'continental', 'orchestrated', 'scholarly', 'dramatic', 'goldberg', 'romantic', 'standard', 'choral', 'poetic', 'comparative', 'written']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step d) Ranked substitutes, based on cosine similarity scores in context: ['orchestrated', 'chamber', 'symphonies', 'piano', 'romantic', 'sonata', 'concerto', 'symphony', 'orchestral', 'goldberg', 'philharmonic', 'music', 'orchestra', 'instrumental', 'classical', 'scholarly', 'modern', 'concert', 'musical', 'dramatic', 'standard', 'written', 'operatic', 'comparative', 'thematic', 'choral', 'continental', 'poetic', 'lyrical']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "SG step: generated substitutes: ['deploy', 'deployed', 'activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw', 'utilize', 'operate', 'employ', 'acquire', 'maintain', 'reinforce', 'exercise', 'install', 'build', 'move', 'drill', 'fire', 'construct', 'alert', 'dock', 'establish', 'release', 'outfit', 'station', 'ready']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['deploy', 'deployed', 'activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw', 'utilize', 'operate', 'employ', 'acquire', 'maintain', 'reinforce', 'exercise', 'install', 'build', 'move', 'drill', 'fire', 'construct', 'alert', 'dock', 'establish', 'release', 'outfit', 'station', 'ready']\n",
      "\n",
      "complex_word_lemma for complex word 'deploy': deploy\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw', 'utilize', 'operate', 'employ', 'acquire', 'maintain', 'reinforce', 'exercise', 'install', 'build', 'move', 'drill', 'fire', 'construct', 'alert', 'dock', 'establish', 'release', 'outfit', 'station', 'ready']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw', 'utilize', 'operate', 'employ', 'acquire', 'maintain', 'reinforce', 'exercise', 'install', 'build', 'move', 'drill', 'fire', 'construct', 'alert', 'dock', 'establish', 'release', 'outfit', 'station', 'ready']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step d) Ranked substitutes, based on cosine similarity scores in context: ['deployment', 'activate', 'employ', 'utilize', 'ready', 'operate', 'dock', 'dispatch', 'reinforce', 'exercise', 'outfit', 'acquire', 'launch', 'send', 'install', 'assemble', 'use', 'establish', 'move', 'maintain', 'construct', 'station', 'drill', 'build', 'withdraw', 'release', 'fire', 'alert']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "SG step: generated substitutes: ['authorities', 'police', 'officials', '##s', 'magistrates', 'officers', 'forces', 'courts', 'authority', 'people', 'government', 'investigators', 'governments', 'victims', 'ministers', 'operators', 'bodies', 'judges', 'agencies', 'policemen', 'rulers', 'organisations', 'prosecutors', 'elements', 'offences', 'journalists', 'persons', 'subjects', 'residents', 'prisoners']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['authorities', 'police', 'officials', '##s', 'magistrates', 'officers', 'forces', 'courts', 'authority', 'people', 'government', 'investigators', 'governments', 'victims', 'ministers', 'operators', 'bodies', 'judges', 'agencies', 'policemen', 'rulers', 'organisations', 'prosecutors', 'elements', 'offences', 'journalists', 'persons', 'subjects', 'residents', 'prisoners']\n",
      "\n",
      "complex_word_lemma for complex word 'authorities': authority\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['police', 'officials', '##s', 'magistrates', 'officers', 'forces', 'courts', 'people', 'government', 'investigators', 'governments', 'victims', 'ministers', 'operators', 'bodies', 'judges', 'agencies', 'policemen', 'rulers', 'organisations', 'prosecutors', 'elements', 'offences', 'journalists', 'persons', 'subjects', 'residents', 'prisoners']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['police', 'officials', '##s', 'magistrates', 'officers', 'forces', 'courts', 'people', 'government', 'investigators', 'governments', 'victims', 'ministers', 'operators', 'bodies', 'judges', 'agencies', 'policemen', 'rulers', 'organisations', 'prosecutors', 'elements', 'offences', 'journalists', 'persons', 'subjects', 'residents', 'prisoners']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step d) Ranked substitutes, based on cosine similarity scores in context: ['agencies', 'officials', 'police', 'government', 'policemen', 'prosecutors', 'officers', 'ministers', 'persons', 'courts', 'bodies', 'governments', 'people', 'residents', 'organisations', 'forces', 'magistrates', 'subjects', 'investigators', 'judges', 'offences', 'rulers', 'prisoners', 'victims', 'journalists', 'elements', 'operators', '##s']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculates similarity between the original sentence and the sentences with candidate substitutes that were retrieved in the SG step \n",
    "# creates a list with sentences with substitute words filled in (commented out for oversight purposes)\n",
    "\n",
    "\n",
    "def calculate_similarity_scores(sentence, sentence_with_substitutes):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "    tf_model = TFAutoModel.from_pretrained(\"bert-large-uncased\")\n",
    "\n",
    "    def embed_text(text):\n",
    "        tokens = tokenizer(text, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "        outputs = tf_model(**tokens)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        embeddings = tf.nn.l2_normalize(embeddings, axis=1)\n",
    "        return embeddings\n",
    "\n",
    "    original_sentence_embedding = embed_text(sentence)\n",
    "    substitute_sentence_embeddings = embed_text(sentence_with_substitutes)\n",
    "\n",
    "    cosine_similarity = np.inner(original_sentence_embedding, substitute_sentence_embeddings)\n",
    "    similarity_scores = cosine_similarity[0]\n",
    "\n",
    "    return similarity_scores\n",
    "\n",
    "\n",
    "\n",
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"[MASK]\")\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    tokenizer = fill_mask.tokenizer\n",
    "    sentences_concat = f\"{sentence} {tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes = [substitute[\"token_str\"].lower() for substitute in result]\n",
    "    print(f\"SG step: generated substitutes: {substitutes}\\n\")\n",
    "    \n",
    "    # 2. Substitute Selection (SS):   \n",
    "    \n",
    "     # create a punctuation set without hyphen, in order to retain hyphens in compound substitutes\n",
    "    punctuation_without_hyphen = set(string.punctuation) - set('-')\n",
    "    \n",
    "    # a) remove duplicates and unwanted punctuation within the substitute list from the substitute list\n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl and not any(char in punctuation_without_hyphen for char in sub):\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    print(f\"SS step: a) substitute list without duplicates and undesired punctuation: {substitutes_no_dupl}\\n\")\n",
    "    \n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    print(f\"SS step: b) substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    print(f\"SS step: c): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "    \n",
    "    \n",
    "    # create sentence with the complex word replaced by the substitutes\n",
    "    sentence_with_substitutes = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym]\n",
    "    #print(f\"List with sentences where complex word is substituted: {sentence_with_substitutes}\\n\")\n",
    "    \n",
    "    \n",
    "    # d) calculate cosine similarity scores, and rank the substitutes based on their similarity score\n",
    "    similarity_scores = calculate_similarity_scores(sentence, sentence_with_substitutes)\n",
    "    #print(f\"Similarity scores: {similarity_scores}\\n\")\n",
    "    ranked_substitutes_withscores = sorted(zip(substitutes_no_dupl_complex_word_no_antonym, similarity_scores), key=lambda x: x[1], reverse=True)\n",
    "    #print(f\"SS step d) Ranked substitutes, including similarity scores in context: {ranked_substitutes}\\n\")\n",
    "    ranked_substitutes = [substitute for substitute, score in ranked_substitutes_withscores]\n",
    "    print(f\"SS step d) Ranked substitutes, based on cosine similarity scores in context: {ranked_substitutes}\\n\")\n",
    "        \n",
    "    print('-----------------------------------------------------------------------------------------')\n",
    "    print()\n",
    "    \n",
    "       \n",
    "    \n",
    "    \n",
    "    # limit the substitutes to the 10 first ones for evaluation\n",
    "    top_10_substitutes = ranked_substitutes[:10]\n",
    "    \n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + top_10_substitutes\n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the dataframe\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/BertLarge_SG_SS_abc_ce.tsv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947801bc-3246-49f9-9195-e14ee9e966c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file ./predictions/trial/BertLarge_SG_SS_abc_ce.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b32b478a-9e78-4ecd-9c68-66b549e10a5c",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/BertLarge_SG_SS_abc_ce.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.4\n",
    "\n",
    "MAP@3 = 0.25\n",
    "MAP@5 = 0.18\n",
    "MAP@10 = 0.1109\n",
    "\n",
    "Potential@3 = 0.6\n",
    "Potential@5 = 0.6\n",
    "Potential@10 = 0.8\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.2\n",
    "Accuracy@2@top_gold_1 = 0.4\n",
    "Accuracy@3@top_gold_1 = 0.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c6dfa0-a2ea-4c23-92e1-7c15ea78aa4b",
   "metadata": {},
   "source": [
    "results a lot worse than bert-base!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c7d765-3a62-45dc-87ab-e13a4b58e542",
   "metadata": {},
   "source": [
    "#### Substitute Generation with BERT-Large, and Substitute Selection steps a-c, and the resulting list with BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c552c17e-e34f-4278-852c-a3fa4b941f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert_score\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28958809-5f5e-450d-a0c1-f40e735048f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "using custom model: ['BertForMaskedLM']\n",
      "Sentence: A Spanish government source, however, later said that banks able to cover by themselves losses on their toxic property assets will not be forced to remove them from their books while it will be compulsory for those receiving public help.\n",
      "Complex word: compulsory\n",
      "SG step: generated substitutes: ['compulsory', 'mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden', 'permitted', 'prescribed', '##rricular', 'illegal', 'available', 'beneficial', 'prohibited', 'scheduled', 'obliged', 'tertiary', 'secondary', 'statutory', 'legal', 'free', 'used', 'customary', 'primary', 'authorised', 'canonical', 'standard', 'lawful']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['compulsory', 'mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden', 'permitted', 'prescribed', '##rricular', 'illegal', 'available', 'beneficial', 'prohibited', 'scheduled', 'obliged', 'tertiary', 'secondary', 'statutory', 'legal', 'free', 'used', 'customary', 'primary', 'authorised', 'canonical', 'standard', 'lawful']\n",
      "\n",
      "complex_word_lemma for complex word 'compulsory': compulsory\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden', 'permitted', 'prescribed', '##rricular', 'illegal', 'available', 'beneficial', 'prohibited', 'scheduled', 'obliged', 'tertiary', 'secondary', 'statutory', 'legal', 'free', 'used', 'customary', 'primary', 'authorised', 'canonical', 'standard', 'lawful']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['mandatory', 'obligatory', 'required', 'voluntary', 'optional', 'mandated', 'necessary', 'forbidden', 'permitted', 'prescribed', '##rricular', 'illegal', 'available', 'beneficial', 'prohibited', 'scheduled', 'obliged', 'tertiary', 'secondary', 'statutory', 'legal', 'free', 'used', 'customary', 'primary', 'authorised', 'canonical', 'standard', 'lawful']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['mandatory', 'required', 'mandated', 'necessary', 'voluntary', 'optional', 'permitted', 'legal', 'prohibited', 'free', 'lawful', 'illegal', 'standard', 'obligatory', 'forbidden', 'tertiary', 'available', 'beneficial', 'authorised', 'customary', 'obliged', 'used', 'prescribed', 'secondary', 'scheduled', 'statutory', 'primary', '##rricular', 'canonical']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Rajoy's conservative government had instilled markets with a brief dose of confidence by stepping into Bankia, performing a U-turn on its refusal to spend public money to rescue banks.\n",
      "Complex word: instilled\n",
      "SG step: generated substitutes: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed', 'impressed', 'fed', 'gifted', 'struck', 'furnished', 'inspired', 'fitted', 'equipped', 'raised', 'given', 'seeded', 'created', 'rewarded', 'hit', 'treated', 'introduced', 'encouraged', 'infected', 'tested', 'shaken', 'offered', 'filled']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed', 'impressed', 'fed', 'gifted', 'struck', 'furnished', 'inspired', 'fitted', 'equipped', 'raised', 'given', 'seeded', 'created', 'rewarded', 'hit', 'treated', 'introduced', 'encouraged', 'infected', 'tested', 'shaken', 'offered', 'filled']\n",
      "\n",
      "complex_word_lemma for complex word 'instilled': instill\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed', 'impressed', 'fed', 'gifted', 'struck', 'furnished', 'inspired', 'fitted', 'equipped', 'raised', 'given', 'seeded', 'created', 'rewarded', 'hit', 'treated', 'introduced', 'encouraged', 'infected', 'tested', 'shaken', 'offered', 'filled']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['provided', 'injected', 'infused', 'presented', 'left', 'supplied', 'delivered', 'endowed', 'impressed', 'fed', 'gifted', 'struck', 'furnished', 'inspired', 'fitted', 'equipped', 'raised', 'given', 'seeded', 'created', 'rewarded', 'hit', 'treated', 'introduced', 'encouraged', 'infected', 'tested', 'shaken', 'offered', 'filled']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['infused', 'filled', 'injected', 'fed', 'inspired', 'provided', 'seeded', 'encouraged', 'gifted', 'endowed', 'infected', 'equipped', 'presented', 'shaken', 'treated', 'impressed', 'hit', 'struck', 'furnished', 'left', 'supplied', 'rewarded', 'raised', 'tested', 'created', 'delivered', 'offered', 'given', 'introduced', 'fitted']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #34-3 \"War maniacs of the South Korean puppet military made another grave provocation to the DPRK in the central western sector of the front on Thursday afternoon.\n",
      "Complex word: maniacs\n",
      "SG step: generated substitutes: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria', 'demons', 'gods', 'insects', 'sims', 'crimes', 'pigs', 'dogs', 'victims', 'organs', 'heroes', 'fans', 'fantasies', 'dolls', 'leaders', 'puppets', 'followers', '##atics', 'vampires', 'theorists', 'giants', 'children', 'lovers']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria', 'demons', 'gods', 'insects', 'sims', 'crimes', 'pigs', 'dogs', 'victims', 'organs', 'heroes', 'fans', 'fantasies', 'dolls', 'leaders', 'puppets', 'followers', '##atics', 'vampires', 'theorists', 'giants', 'children', 'lovers']\n",
      "\n",
      "complex_word_lemma for complex word 'maniacs': maniac\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria', 'demons', 'gods', 'insects', 'sims', 'crimes', 'pigs', 'dogs', 'victims', 'organs', 'heroes', 'fans', 'fantasies', 'dolls', 'leaders', 'puppets', 'followers', '##atics', 'vampires', 'theorists', 'giants', 'children', 'lovers']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['machines', 'mania', 'criminals', 'killers', 'monsters', 'zombies', 'freaks', 'hysteria', 'demons', 'gods', 'insects', 'sims', 'crimes', 'pigs', 'dogs', 'victims', 'organs', 'heroes', 'fans', 'fantasies', 'dolls', 'leaders', 'puppets', 'followers', '##atics', 'vampires', 'theorists', 'giants', 'children', 'lovers']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['freaks', 'criminals', 'puppets', 'mania', 'machines', 'dogs', 'heroes', 'killers', 'crimes', 'leaders', 'lovers', 'children', 'fans', 'victims', 'followers', 'sims', 'organs', 'demons', 'hysteria', 'monsters', 'gods', 'dolls', 'theorists', 'giants', '##atics', 'fantasies', 'zombies', 'pigs', 'insects', 'vampires']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: The daily death toll in Syria has declined as the number of observers has risen, but few experts expect the U.N. plan to succeed in its entirety.\n",
      "Complex word: observers\n",
      "SG step: generated substitutes: ['observers', 'observer', 'monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters', 'observation', '##keepers', 'experts', 'activists', 'casualties', 'volunteers', 'civilians', 'observing', 'people', 'citizens', 'combatants', 'observe', 'individuals', 'indicators', 'monitoring', 'troops', 'soldiers', 'victims', 'refugees', 'instruments']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['observers', 'observer', 'monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters', 'observation', '##keepers', 'experts', 'activists', 'casualties', 'volunteers', 'civilians', 'observing', 'people', 'citizens', 'combatants', 'observe', 'individuals', 'indicators', 'monitoring', 'troops', 'soldiers', 'victims', 'refugees', 'instruments']\n",
      "\n",
      "complex_word_lemma for complex word 'observers': observer\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters', 'observation', '##keepers', 'experts', 'activists', 'casualties', 'volunteers', 'civilians', 'observing', 'people', 'citizens', 'combatants', 'observe', 'individuals', 'indicators', 'monitoring', 'troops', 'soldiers', 'victims', 'refugees', 'instruments']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['monitors', 'witnesses', 'participants', 'analysts', 'spectators', 'observations', 'journalists', 'fighters', 'observation', '##keepers', 'experts', 'activists', 'casualties', 'volunteers', 'civilians', 'observing', 'people', 'citizens', 'combatants', 'observe', 'individuals', 'indicators', 'monitoring', 'troops', 'soldiers', 'victims', 'refugees', 'instruments']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['monitors', 'experts', 'observations', 'witnesses', 'volunteers', '##keepers', 'analysts', 'activists', 'participants', 'journalists', 'monitoring', 'spectators', 'troops', 'soldiers', 'combatants', 'indicators', 'citizens', 'fighters', 'refugees', 'instruments', 'individuals', 'civilians', 'observation', 'people', 'casualties', 'victims', 'observing', 'observe']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: An amateur video showed a young girl who apparently suffered shrapnel wounds in her thigh undergoing treatment in a makeshift Rastan hospital while screaming in pain.\n",
      "Complex word: shrapnel\n",
      "SG step: generated substitutes: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor', 'blast', 'battle', 'three', 'splinter', 'shot', 'serious', 'exit', 'entry', 'shotgun', 'several', 'two', 'severe', 'shell', 'open', 'burn', 'bomb', 'penetrating', 'the', 'inflicted', 'stabbing', 'internal', 'fatal']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor', 'blast', 'battle', 'three', 'splinter', 'shot', 'serious', 'exit', 'entry', 'shotgun', 'several', 'two', 'severe', 'shell', 'open', 'burn', 'bomb', 'penetrating', 'the', 'inflicted', 'stabbing', 'internal', 'fatal']\n",
      "\n",
      "complex_word_lemma for complex word 'shrapnel': shrapnel\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor', 'blast', 'battle', 'three', 'splinter', 'shot', 'serious', 'exit', 'entry', 'shotgun', 'several', 'two', 'severe', 'shell', 'open', 'burn', 'bomb', 'penetrating', 'the', 'inflicted', 'stabbing', 'internal', 'fatal']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['gunshot', 'bullet', 'stab', 'knife', 'flesh', 'arrow', 'multiple', 'minor', 'blast', 'battle', 'three', 'splinter', 'shot', 'serious', 'exit', 'entry', 'shotgun', 'several', 'two', 'severe', 'shell', 'open', 'burn', 'bomb', 'penetrating', 'the', 'inflicted', 'stabbing', 'internal', 'fatal']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['bullet', 'stab', 'gunshot', 'knife', 'multiple', 'stabbing', 'severe', 'blast', 'several', 'splinter', 'minor', 'serious', 'two', 'open', 'internal', 'three', 'battle', 'shell', 'penetrating', 'shotgun', 'shot', 'burn', 'flesh', 'entry', 'fatal', 'arrow', 'inflicted', 'exit', 'the', 'bomb']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: A local witness said a separate group of attackers disguised in burqas — the head-to-toe robes worn by conservative Afghan women — then tried to storm the compound.\n",
      "Complex word: disguised\n",
      "SG step: generated substitutes: ['disguised', 'dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad', 'guise', 'hiding', 'draped', 'posing', 'appearing', ',', 'hidden', 'acting', 'dress', 'painted', 'seated', 'fitted', 'identified', 'covered', 'armed', 'appeared', 'cloak', 'armored', 'undercover', 'portrayed', 'depicted']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['disguised', 'dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad', 'guise', 'hiding', 'draped', 'posing', 'appearing', ',', 'hidden', 'acting', 'dress', 'painted', 'seated', 'fitted', 'identified', 'covered', 'armed', 'appeared', 'cloak', 'armored', 'undercover', 'portrayed', 'depicted']\n",
      "\n",
      "complex_word_lemma for complex word 'disguised': disguised\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad', 'guise', 'hiding', 'draped', 'posing', 'appearing', ',', 'hidden', 'acting', 'dress', 'painted', 'seated', 'fitted', 'identified', 'covered', 'armed', 'appeared', 'cloak', 'armored', 'undercover', 'portrayed', 'depicted']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['dressed', 'masked', 'disguise', 'dressing', 'armoured', 'clothed', 'concealed', 'clad', 'guise', 'hiding', 'draped', 'posing', 'appearing', ',', 'hidden', 'acting', 'dress', 'painted', 'seated', 'fitted', 'identified', 'covered', 'armed', 'appeared', 'cloak', 'armored', 'undercover', 'portrayed', 'depicted']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['masked', 'concealed', 'clothed', 'posing', 'dressed', 'clad', 'hidden', 'covered', 'dressing', 'hiding', 'draped', 'armed', 'appearing', 'acting', 'painted', 'seated', 'identified', 'dress', 'armored', 'appeared', 'depicted', 'portrayed', 'fitted', 'disguise', 'undercover', 'cloak', ',', 'armoured', 'guise']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Syria's Sunni majority is at the forefront of the uprising against Assad, whose minority Alawite sect is an offshoot of Shi'ite Islam.\n",
      "Complex word: offshoot\n",
      "SG step: generated substitutes: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy', 'aspect', 'enclave', 'heir', 'isolate', 'offspring', 'expression', 'orthodox', 'evolution', 'exception', 'example', 'sect', 'embrace', 'echo', 'approximation', 'adherence', 'adhere', 'adaptation', 'associate', 'issue', 'inhibitor', 'imitation', 'extreme']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy', 'aspect', 'enclave', 'heir', 'isolate', 'offspring', 'expression', 'orthodox', 'evolution', 'exception', 'example', 'sect', 'embrace', 'echo', 'approximation', 'adherence', 'adhere', 'adaptation', 'associate', 'issue', 'inhibitor', 'imitation', 'extreme']\n",
      "\n",
      "complex_word_lemma for complex word 'offshoot': offshoot\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy', 'aspect', 'enclave', 'heir', 'isolate', 'offspring', 'expression', 'orthodox', 'evolution', 'exception', 'example', 'sect', 'embrace', 'echo', 'approximation', 'adherence', 'adhere', 'adaptation', 'associate', 'issue', 'inhibitor', 'imitation', 'extreme']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['extension', 'affiliate', 'ally', 'arm', 'outpost', 'element', 'opponent', 'enemy', 'aspect', 'enclave', 'heir', 'isolate', 'offspring', 'expression', 'orthodox', 'evolution', 'exception', 'example', 'sect', 'embrace', 'echo', 'approximation', 'adherence', 'adhere', 'adaptation', 'associate', 'issue', 'inhibitor', 'imitation', 'extreme']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['extension', 'affiliate', 'arm', 'offspring', 'outpost', 'adaptation', 'echo', 'expression', 'evolution', 'ally', 'aspect', 'heir', 'approximation', 'extreme', 'imitation', 'exception', 'opponent', 'element', 'associate', 'enemy', 'enclave', 'embrace', 'example', 'sect', 'adherence', 'inhibitor', 'orthodox', 'isolate', 'adhere', 'issue']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: Although not as rare in the symphonic literature as sharper keys , examples of symphonies in A major are not as numerous as for D major or G major .\n",
      "Complex word: symphonic\n",
      "SG step: generated substitutes: ['symphonic', 'orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata', 'operatic', 'piano', 'concert', 'chamber', 'music', 'orchestra', 'modern', 'lyrical', 'thematic', 'instrumental', 'continental', 'orchestrated', 'scholarly', 'dramatic', 'goldberg', 'romantic', 'standard', 'choral', 'poetic', 'comparative', 'written']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['symphonic', 'orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata', 'operatic', 'piano', 'concert', 'chamber', 'music', 'orchestra', 'modern', 'lyrical', 'thematic', 'instrumental', 'continental', 'orchestrated', 'scholarly', 'dramatic', 'goldberg', 'romantic', 'standard', 'choral', 'poetic', 'comparative', 'written']\n",
      "\n",
      "complex_word_lemma for complex word 'symphonic': symphonic\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata', 'operatic', 'piano', 'concert', 'chamber', 'music', 'orchestra', 'modern', 'lyrical', 'thematic', 'instrumental', 'continental', 'orchestrated', 'scholarly', 'dramatic', 'goldberg', 'romantic', 'standard', 'choral', 'poetic', 'comparative', 'written']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['orchestral', 'classical', 'symphony', 'philharmonic', 'symphonies', 'musical', 'concerto', 'sonata', 'operatic', 'piano', 'concert', 'chamber', 'music', 'orchestra', 'modern', 'lyrical', 'thematic', 'instrumental', 'continental', 'orchestrated', 'scholarly', 'dramatic', 'goldberg', 'romantic', 'standard', 'choral', 'poetic', 'comparative', 'written']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['philharmonic', 'symphony', 'orchestral', 'operatic', 'concerto', 'thematic', 'symphonies', 'sonata', 'classical', 'musical', 'dramatic', 'choral', 'written', 'lyrical', 'concert', 'instrumental', 'music', 'modern', 'poetic', 'chamber', 'continental', 'romantic', 'orchestra', 'standard', 'comparative', 'scholarly', 'goldberg', 'piano', 'orchestrated']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: That prompted the military to deploy its largest warship, the BRP Gregorio del Pilar, which was recently acquired from the United States.\n",
      "Complex word: deploy\n",
      "SG step: generated substitutes: ['deploy', 'deployed', 'activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw', 'utilize', 'operate', 'employ', 'acquire', 'maintain', 'reinforce', 'exercise', 'install', 'build', 'move', 'drill', 'fire', 'construct', 'alert', 'dock', 'establish', 'release', 'outfit', 'station', 'ready']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['deploy', 'deployed', 'activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw', 'utilize', 'operate', 'employ', 'acquire', 'maintain', 'reinforce', 'exercise', 'install', 'build', 'move', 'drill', 'fire', 'construct', 'alert', 'dock', 'establish', 'release', 'outfit', 'station', 'ready']\n",
      "\n",
      "complex_word_lemma for complex word 'deploy': deploy\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw', 'utilize', 'operate', 'employ', 'acquire', 'maintain', 'reinforce', 'exercise', 'install', 'build', 'move', 'drill', 'fire', 'construct', 'alert', 'dock', 'establish', 'release', 'outfit', 'station', 'ready']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['activate', 'deployment', 'dispatch', 'assemble', 'launch', 'send', 'use', 'withdraw', 'utilize', 'operate', 'employ', 'acquire', 'maintain', 'reinforce', 'exercise', 'install', 'build', 'move', 'drill', 'fire', 'construct', 'alert', 'dock', 'establish', 'release', 'outfit', 'station', 'ready']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['dispatch', 'activate', 'utilize', 'station', 'employ', 'use', 'install', 'release', 'launch', 'operate', 'send', 'outfit', 'exercise', 'assemble', 'reinforce', 'dock', 'establish', 'drill', 'construct', 'maintain', 'acquire', 'fire', 'ready', 'build', 'move', 'withdraw', 'deployment', 'alert']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Sentence: #35-14 UK police were expressly forbidden, at a ministerial level, to provide any assistance to Thai authorities as the case involves the death penalty.\n",
      "Complex word: authorities\n",
      "SG step: generated substitutes: ['authorities', 'police', 'officials', '##s', 'magistrates', 'officers', 'forces', 'courts', 'authority', 'people', 'government', 'investigators', 'governments', 'victims', 'ministers', 'operators', 'bodies', 'judges', 'agencies', 'policemen', 'rulers', 'organisations', 'prosecutors', 'elements', 'offences', 'journalists', 'persons', 'subjects', 'residents', 'prisoners']\n",
      "\n",
      "SS step: a) substitute list without duplicates: ['authorities', 'police', 'officials', '##s', 'magistrates', 'officers', 'forces', 'courts', 'authority', 'people', 'government', 'investigators', 'governments', 'victims', 'ministers', 'operators', 'bodies', 'judges', 'agencies', 'policemen', 'rulers', 'organisations', 'prosecutors', 'elements', 'offences', 'journalists', 'persons', 'subjects', 'residents', 'prisoners']\n",
      "\n",
      "complex_word_lemma for complex word 'authorities': authority\n",
      "\n",
      "SS step: b) substitute list without duplicates and inflected forms of the complex word: ['police', 'officials', '##s', 'magistrates', 'officers', 'forces', 'courts', 'people', 'government', 'investigators', 'governments', 'victims', 'ministers', 'operators', 'bodies', 'judges', 'agencies', 'policemen', 'rulers', 'organisations', 'prosecutors', 'elements', 'offences', 'journalists', 'persons', 'subjects', 'residents', 'prisoners']\n",
      "\n",
      "SS step: c): substitute list without antonyms of the complex word: ['police', 'officials', '##s', 'magistrates', 'officers', 'forces', 'courts', 'people', 'government', 'investigators', 'governments', 'victims', 'ministers', 'operators', 'bodies', 'judges', 'agencies', 'policemen', 'rulers', 'organisations', 'prosecutors', 'elements', 'offences', 'journalists', 'persons', 'subjects', 'residents', 'prisoners']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS step: d) substitute list sorted by descending BERTScore: ['police', 'officials', 'government', 'magistrates', 'investigators', 'prosecutors', 'policemen', 'courts', 'judges', 'residents', 'prisoners', 'forces', 'governments', 'officers', 'operators', 'ministers', 'agencies', 'journalists', 'rulers', 'people', 'organisations', 'subjects', 'bodies', 'persons', 'elements', 'victims', 'offences', '##s']\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# in each row, for each complex word: \n",
    "for index, row in data.iterrows():\n",
    "       \n",
    "    # 1. Substitute Generation (SG): perform masking and generate substitutes:\n",
    "    \n",
    "    ## print the sentence and the complex word\n",
    "    sentence, complex_word = row[\"sentence\"], row[\"complex_word\"]\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Complex word: {complex_word}\")\n",
    "\n",
    "    ## in the sentence, replace the complex word with a masked word\n",
    "    sentence_masked_word = sentence.replace(complex_word, \"[MASK]\")\n",
    "\n",
    "    ## concatenate the original sentence and the masked sentence\n",
    "    tokenizer = fill_mask.tokenizer\n",
    "    sentences_concat = f\"{sentence} {tokenizer.sep_token} {sentence_masked_word}\"\n",
    "\n",
    "    ## generate and rank candidate substitutes for the masked word using the fill_mask pipeline\n",
    "    top_k = 30\n",
    "    result = fill_mask(sentences_concat, top_k=top_k)\n",
    "   \n",
    "    ## lowercase and print the top-k substitutes\n",
    "    substitutes = [substitute[\"token_str\"].lower() for substitute in result]\n",
    "    print(f\"SG step: generated substitutes: {substitutes}\\n\")\n",
    "    \n",
    "    # 2. Substitute Selection (SS):   \n",
    "    \n",
    "     # create a punctuation set without hyphen, in order to retain hyphens in compound substitutes\n",
    "    punctuation_without_hyphen = set(string.punctuation) - set('-')\n",
    "    \n",
    "    # a) remove duplicates and unwanted punctuation within the substitute list from the substitute list\n",
    "    substitutes_no_dupl = []\n",
    "    for sub in substitutes:\n",
    "        if sub not in substitutes_no_dupl and not any(char in punctuation_without_hyphen for char in sub):\n",
    "            substitutes_no_dupl.append(sub)\n",
    "    print(f\"SS step: a) substitute list without duplicates and undesired punctuation: {substitutes_no_dupl}\\n\")\n",
    "    \n",
    "\n",
    "   \n",
    "    # b) remove duplicates and inflected forms of the complex word from the substitute list\n",
    "    ## Lemmatize the complex word with spaCy, in order to compare it with the lemmatized substitute later to see if their mutual lemmas are the same\n",
    "    doc_complex_word = nlp(complex_word)\n",
    "    complex_word_lemma = doc_complex_word[0].lemma_\n",
    "    print(f\"complex_word_lemma for complex word '{complex_word}': {complex_word_lemma}\\n\")\n",
    "\n",
    "\n",
    "    ## remove duplicates and inflected forms of the complex word from the list with substitutes\n",
    "    substitutes_no_dupl_complex_word = []\n",
    "    for substitute in substitutes_no_dupl:\n",
    "        doc_substitute = nlp(substitute)\n",
    "        substitute_lemma = doc_substitute[0].lemma_\n",
    "        if substitute_lemma != complex_word_lemma:\n",
    "            substitutes_no_dupl_complex_word.append(substitute)\n",
    "    print(f\"SS step: b) substitute list without duplicates and inflected forms of the complex word: {substitutes_no_dupl_complex_word}\\n\")\n",
    "\n",
    "    # c) remove antonyms of the complex word from the substitute list\n",
    "    substitutes_no_dupl_complex_word_no_antonym = []\n",
    "    for substitute in substitutes_no_dupl_complex_word:\n",
    "        syn = wn.synsets(complex_word_lemma)\n",
    "        if syn:\n",
    "            syn = syn[0]\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.antonyms() and lemma.name() == substitute_lemma:\n",
    "                    print(f\"Antonym removed (lemma): {lemma.antonyms()[0].name()}\")\n",
    "                    break\n",
    "            else:\n",
    "                substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "        else:\n",
    "            substitutes_no_dupl_complex_word_no_antonym.append(substitute)\n",
    "    print(f\"SS step: c): substitute list without antonyms of the complex word: {substitutes_no_dupl_complex_word_no_antonym}\\n\")\n",
    "    \n",
    "    \n",
    "    # create sentences with the complex word replaced by the substitutes\n",
    "    sentences_with_substitutes = [sentence.replace(complex_word, sub) for sub in substitutes_no_dupl_complex_word_no_antonym]\n",
    "    #print(f\"SG step: sentences with substitutes: {sentences_with_substitutes}\\n\")\n",
    "    \n",
    "          \n",
    "    # d) use BERTScore for sorting\n",
    "    scores = bert_score.score([sentence]*len(sentences_with_substitutes), sentences_with_substitutes, lang=\"en\", model_type='bert-large-uncased', verbose=False)\n",
    "    ranked_substitutes = [substitute for _, substitute in sorted(zip(scores[0].tolist(), substitutes_no_dupl_complex_word_no_antonym), reverse=True)]\n",
    "    print(f\"SS step: d) substitute list sorted by descending BERTScore: {ranked_substitutes}\\n\")\n",
    "\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------------------')\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    # limit the substitutes to the 10 first ones for evaluation\n",
    "    top_10_substitutes = ranked_substitutes[:10]\n",
    "    \n",
    "    # add the sentence, complex_word, and substitutes to the dataframe \n",
    "    substitutes_df.loc[index] = [sentence, complex_word] + top_10_substitutes\n",
    "    \n",
    "    # remove the #34-3 and #35-14 character combinations from the sentences in the dataframe\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#34-3 \\\"\", \"\")\n",
    "    substitutes_df.iloc[:, 0] = substitutes_df.iloc[:, 0].str.replace(\"#35-14 \", \"\")\n",
    "    \n",
    "    \n",
    "\n",
    "# export the dataframe to a tsv file\n",
    "substitutes_df.to_csv(\"./predictions/trial/BertLarge_SG_SS_abc_bs.tsv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e950978c-5e41-4376-9192-73fc338ac2b3",
   "metadata": {},
   "source": [
    "python tsar_eval.py --gold_file .\\gold_trial.tsv --predictions_file ./predictions/trial/BertLarge_SG_SS_abc_bs.tsv --output_file .\\output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8490190-da1c-455c-94ff-1112ce785b1e",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/BertLarge_SG_SS_abc_bs.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "MAP@1/Potential@1/Precision@1 = 0.6\n",
    "\n",
    "MAP@3 = 0.3777\n",
    "MAP@5 = 0.2836\n",
    "MAP@10 = 0.1713\n",
    "\n",
    "Potential@3 = 0.7\n",
    "Potential@5 = 0.9\n",
    "Potential@10 = 0.9\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.3\n",
    "Accuracy@2@top_gold_1 = 0.5\n",
    "Accuracy@3@top_gold_1 = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ff82ea-47ca-483b-a0b0-ab391a8e2abe",
   "metadata": {},
   "source": [
    "Results: best result so far for BERTLarge. MAP@3,5,10 and Pot@5 also slightly better compared to Bert-base (rest is the same) These good results are surprising due to the fact that the plain results for BERTLarge were worse than the plain results for BERTBase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e52d29-5cea-4ebe-8d3c-7dab0ba5e1a0",
   "metadata": {},
   "source": [
    "### Conclusion so far"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2b9ff5-e789-413a-9302-e998410a775f",
   "metadata": {},
   "source": [
    "SS Step a, b, c for both BERT models: keep them in Subs.Selection method as they do help a bit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fb8c6d-bf06-4b28-b4ac-2e7879a6a356",
   "metadata": {},
   "source": [
    "SS Step FitBERT: remove, due to low scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a84ccf-663a-4014-903d-abd5b02c4307",
   "metadata": {},
   "outputs": [],
   "source": [
    "SS Step context. emb and Bertscore: keep in Subs selection, but differences are subtile and not always better "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d7a0e-b903-4a45-9815-3c567fb5591c",
   "metadata": {},
   "source": [
    "Best performing on MAP@1:  BertBase_SG_SS_abc_ce and  BertBase_SG_SS_abc_bs and BertLarge_SG_SS_abc_bs; when taking the other metrics into account:  BertLarge_SG_SS_abc_bs (see below). "
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e8077b1-df0c-4dc2-9beb-308987cb60e2",
   "metadata": {},
   "source": [
    "=========   EVALUATION config.=========\n",
    "GOLD file = .\\gold_trial.tsv\n",
    "PREDICTION LABELS file = ./predictions/trial/BertLarge_SG_SS_abc_bs.tsv\n",
    "OUTPUT file = .\\output\n",
    "===============   RESULTS  =============\n",
    "\n",
    "MAP@1/Potential@1/Precision@1 = 0.6\n",
    "\n",
    "MAP@3 = 0.3777\n",
    "MAP@5 = 0.2836\n",
    "MAP@10 = 0.1713\n",
    "\n",
    "Potential@3 = 0.7\n",
    "Potential@5 = 0.9\n",
    "Potential@10 = 0.9\n",
    "\n",
    "Accuracy@1@top_gold_1 = 0.3\n",
    "Accuracy@2@top_gold_1 = 0.5\n",
    "Accuracy@3@top_gold_1 = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb32f16-e4d1-45c6-9a5c-90b518b65bbc",
   "metadata": {},
   "source": [
    "### please note i updated the code after running the eval's. As I removed the punct chars after the SG step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
